Vom Forschungsprojekt zur Ausstellung
1

Herausgegeben von
Ellen Fricke, Jana Bressem

Vom Forschungsprojekt zur Ausstellung

Universitätsverlag Chemnitz 2019

2

3

Inhalt

I Gesten – gestern, heute, übermorgen

Grußworte

10

Fotografische Impressionen. Ausstellungsrundgang im

18

Museum für Kommunikation Berlin

» Ellen Fricke

Gesten – gestern, heute, übermorgen. Vom Forschungsprojekt

32

zur Ausstellung

II Hände und Objekte in Sprache, Kultur und Technik

» Ellen Fricke, Jana Bressem, Daniel Schöller und Johannes Müller-Viezens

Von der Handbewegung zum Gestenlexikon: Warum können wir

46

nicht nur mit dem Mund, sondern auch mit den Händen sprechen?

» Jana Bressem

Gesten der zwischenmenschlichen Kommunikation:

52

Ihre Vielfalt, Eigenschaften und Erforschung

» Jana Bressem

Freude und Sieg: Die Victory-Geste

64

» Martin Siefkes

Aufzeichnungstechniken der Gestenforschung

70

» Ellen Fricke

Von der Kugel zu Google Earth:

78

Wie handhabe ich einen virtuellen Globus?

» Manuel Schramm

Die Entwicklung der Globen

86

III Wie Gesten und Hände sich wandeln: Evolution, Anthropologie, Technologie

» Ellen Fricke

Die Vergangenheit in der Gegenwart sehen:

94

Zeichensprachen der Aborigines in Australien

» Susanne Grassmann

Menschen, Affen, Hunde und die Evolution von Gesten

102

» Ulrike Thomas

Menschliche Hände als Vorbild für robotische Hände?

108

» Daniel Schöller, Martin Siefkes und Ellen Fricke

Wie man früher den Telefonhörer hielt: Gesten als Wissensspeicher 114

4

IV Hände, Dinge und Gesten ästhetisch reflektiert: Interviews und Texte

» Marianne Eisl, Ellen Fricke und Christopher Lindinger

Ausgewählte künstlerische Exponate im Überblick:

126

Kurzbeschreibungen

» Interviews

“People are augmenting their bodies all the time”: An interview

132

with Golan Levin on digital bodies, technology and art

“Anything that is mechanical is almost retro”: An interview

138

with Daniel Rozin on art in the digital age

» Werner Jauk

Sound-gesture und post-digital culture: Von der symbolisch

144

zeichenhaften „forward back“ zur stimulativ signalhaften

körperlichen Interaktion von every body

» Ines Lindner

Anette Rose: Captured Motion. Bewegungsnotationen im Raum

150

» Hannah Groninger und Irene Mittelberg

Von Erinnerungen zu Objekten: Motion-Capture-Skulpturen

158

gestischer Raumbeschreibungen

» Mathias Roloff

Gesten, Zeichnungen, Dinge

166

V Industriekultur im Wandel: Vom Handgriff zur Gestensteuerung

» Angelika Bullinger-Hoffmann und Thomas Seeling

Mehr als „winke, winke“ – Gestenbedienung von Maschinen

172

in modernen Arbeits- und Lebenswelten

» Ellen Fricke

Hand, Mensch, Maschine: Die erweiterte und reduzierte Hand

178

» Manuel Schramm

Das Hämmern und Schmieden

184

» Manuel Schramm

Das Spinnen

190

» Manuel Schramm

Das Töpfern

196

» Ellen Fricke

Von der Handlung zur Geste und zurück: Analoges und

200

virtuelles Modellieren am Beispiel des Töpferns

5

» Manuel Schramm

Industrieller Fortschritt: Hoffnungen und Ängste

212

» Georg Jahn

„Nach Ihnen“ – Verkörperte digitale Technologien in

218

Hybridgesellschaften der Zukunft

VI Dokumentation

Fotografische Dokumentation der Ausstellung

226

„Gesten – gestern, heute, übermorgen“ im

Sächsischen Industriemuseum Chemnitz

Beteiligungen und Dank

251

Autorenverzeichnis

254

Impressum

256

6

7

I GESTEN – GESTERN, HEUTE, ÜBERMORGEN
» Grußworte
» Fotografische Impressionen. Ausstellungsrundgang im Museum für Kommunikation Berlin
» Ellen Fricke Gesten – gestern, heute, übermorgen. Vom Forschungsprojekt zur Ausstellung

8

9

Grußwort
Gesten bilden einen wichtigen Teil der menschlichen Kommunikation, werden aber erst seit dem späten 20. Jahrhundert von Sprachwissenschaftlern und Psychologen intensiv erforscht. In den letzten Jahren ist die Gestensteuerung von Computern, Haushaltsgeräten und Automobilen zu einem bedeutenden Zukunftsthema geworden. Dabei wird jedoch die zentrale Rolle der natürlichen Gestik des Menschen oft zu wenig beachtet. Neue Gesten für die Kommunikation mit Maschinen werden sich nur dann durchsetzen, wenn sie zur natürlichen Gestik des Menschen passen und trotzdem eindeutig und leicht erlernbar sind.
Die Ausstellung „Gesten – gestern, heute, übermorgen“ untersucht diese komplexen Herausforderungen und stellt sie in den Zusammenhang der jahrhundertealten Tradition des menschlichen Handwerks. Sie zeigt, wie unsere Gesten schon immer durch den Umgang mit Werkzeugen geprägt wurden, und wie sich heute die neuen Interaktionsweisen mit der Technik am traditionellen Repertoire unserer Gestik orientieren. Technik und menschliche Kultur treffen einander in neuen Formen der berührungslosen Interaktion. Es ist keine Frage, dass diese Kommunikationsformen zwischen Mensch und Maschine in Zukunft eine große Rolle spielen werden – am Arbeitsplatz ebenso wie im privaten Bereich.
Damit diese Kommunikation gelingt, müssen Ingenieure die sprachwissenschaftlichen und kulturellen Probleme ernst nehmen. Zugleich müssen sich Wissenschaftler in komplexe technische Zusammenhänge einarbeiten, um die richtigen Fragen zu stellen – über die Grenzen der etablierten Disziplinen hinweg. Im Rahmen ihrer Kernkompetenz „Mensch und Technik“ werden an der TU Chemnitz diese und weitere entscheidende Fragestellungen der Zukunft bearbeitet. Eine Vernetzung, auch über Fachgrenzen hinweg, wird dabei groß geschrieben. Wissenschaftler forschen aus unterschiedlichen Perspektiven in diversen interdisziplinären Projekten und kommen zu fruchtbaren, gesellschaftsrelevanten Ergebnissen.
Die vorliegende Ausstellung ist ein hervorragendes Beispiel für eine gelungene Zusammenarbeit von Geistes- und Technikwissenschaften und kann daher als Musterbeispiel gelten, das weit über Chemnitz und auch über Sachsen hinaus ausstrahlen wird. Entstanden ist die Idee für die aktuelle Ausstellung im Rahmen des Forschungsprojekts „Hands and Objects in Language, Culture, and Technology: Manual Actions at Workplaces between Robotics, Gesture, and Product Design (MANUACT)“. Seit 2015 kooperieren hier die Professur Germanistische Sprachwissenschaft, Semiotik und Multimodale Kommunikation (Prof. Dr. Ellen Fricke) der Philosophischen Fakultät sowie die Professur Arbeitswissenschaft und Innovationsmanagement
10

(Prof. Dr. Angelika Bullinger-Hoffmann) der Fakultät für Maschinenbau der TU Chemnitz mit dem Sächsischen Industriemuseum, um Ideen zu entwickeln, wie die Zusammenarbeit an der Schnittstelle zwischen Mensch und Maschine in Zukunft aussehen könnte. Die Ausstellung ordnet sich in die bereits seit vielen Jahren bestehende und bewährte Kooperation verschiedener Professuren der TU Chemnitz mit dem Sächsischen Industriemuseum ein. Durch MANUACT wird diese enge Verbindung ein weiteres Mal mit Leben gefüllt. Als internationaler Partner des Projekts konnte das weltweit renommierte Ars Electronica Futurelab aus Linz in Österreich gewonnen werden.
Ich möchte die Gelegenheit nutzen, den Organisatoren der Ausstellung und allen beteiligten Wissenschaftlerinnen und Wissenschaftlern meinen herzlichen Dank für die geleistete Arbeit auszusprechen. Ein weiterer Dank gilt dem Bundesministerium für Bildung und Forschung, der Ostdeutschen Sparkassenstiftung, der Sparkasse Chemnitz sowie der Kulturstiftung des Freistaates Sachsen, die die Durchführung der Ausstellung finanziell unterstützen.
Ich wünsche der Ausstellung „Gesten – gestern, heute, übermorgen“ nach dem erfolgreichen Auftakt im Industriemuseum Chemnitz auch in den Museen für Kommunikation in Berlin und Frankfurt a. M. alles Gute und allen Besucherinnen und Besuchern in den kommenden Monaten viele neue Erkenntnisse beim Blick in die Vergangenheit sowie fruchtbare Inspirationen vor dem Hintergrund der gezeigten Zukunftsvisionen.
Prof. Dr. Gerd Strohmeier Rektor der Technischen Universität Chemnitz
11

Grußwort
Das Chemnitzer Industriemuseum geht mit der neuen Sonderausstellung „Gesten – gestern, heute, übermorgen“ einmal mehr innovative Wege. Die bundesweit einzigartige Ausstellung widmet sich – wie der Name schon sagt – der faszinierenden Welt der menschlichen Gesten. Sie ist das Ergebnis einer wissenschaftlich-künstlerischen Kooperation der Technischen Universität Chemnitz und des Ars Electronica Futurelabs aus Linz im Rahmen des Projekts MANUACT mit dem Zweckverband Sächsisches Industriemuseum.
In der Ausstellung erleben die Besucherinnen und Besucher nicht nur die faszinierende „Sprache der Gesten“, sondern auch die Arbeitswelt der Zukunft. Für alle Interessierten – egal ob Jung oder Alt – werden Gesten und ihre vielfältigen Bezugspunkte zu aktuellen kulturellen und technischen Entwicklungen und Wandlungsprozessen erfahr- und erlebbar.
Ich freue mich besonders, dass auch international erfolgreiche Künstler für die Ausstellung gewonnen werden konnten.
Damit wird eine Ausstellung präsentiert, die Zukunftsvisionen zeigt und gleichzeitig anregt, die Welt der Gesten und Mensch-Maschine-Interaktionen mit allen Sinnen zu erleben und zu begreifen. Die neue Sonderausstellung reiht sich ein in die große Vielzahl – mehr als 100 sind es seit Gründung des Industriemuseums Chemnitz – besonderer Ausstellungen, die den Ruf des Hauses als Forschungsinstitution und Kompetenzzentrum für Industriekultur stärken.
12

Ich danke allen Organisatoren der Ausstellung – den Mitarbeitern des Industriemuseums Chemnitz, den Wissenschaftlern der Technischen Universität sowie den Vertretern des Ars Electronica Futurelab – für ihr Engagement. Mein besonderer Dank gilt dem Bundesministerium für Bildung und Forschung, der Ostdeutschen Sparkassenstiftung und der Sparkasse Chemnitz, der Kulturstiftung des Freistaats Sachsen sowie dem Freistaat Sachsen selbst für die finanzielle Unterstützung der Ausstellung.
Ich wünsche den Besuchern inspirierende Momente in einer Wissenschaft, Technik und Kunst verbindenden Ausstellung.
Ihre Barbara Ludwig Oberbürgermeisterin der Stadt Chemnitz Verbandsvorsitzende des Zweckverbandes Sächsisches Industriemuseum
13

Grußwort
Das Industriemuseum Chemnitz blickt auf eine lange Zeit des Austauschs mit der TU Chemnitz zurück, der im Kooperationsvertrag mit dem Projekt „Hands and Objects in Language, Culture and Technology: Manual Actions at Workplaces between Robotics, Gesture and Product Design“ (MANUACT) eine für unser Haus ausgesprochen interessante Fortsetzung fand. Sie hat die bundesweit einzigartige Ausstellung „Gesten – gestern, heute, übermorgen“ zu ihrem Ergebnis. Das vorliegende Buch dokumentiert dieses Ergebnis einer wissenschaftlich-künstlerischen Kooperation zwischen der TU Chemnitz und dem Ars Electronica Futurelab (Linz/ Österreich) zusammen mit dem Zweckverband Sächsisches Industriemuseum.
Dass das Industriemuseum Chemnitz als institutioneller Projektpartner ausgewählt wurde, haben wir als besondere Auszeichnung empfunden. Nach über 100 Sonderausstellungen hat uns diese Ausstellung vor völlig neue Herausforderungen gestellt. Es galt eine museale Klammer zu finden zwischen Forschung, künstlerischen Objekten und interaktiven Stationen.
Das Forschungs- und Ausstellungsvorhaben arbeitet die Bedeutung von Objekten heraus bzw. hinterfragt diese in einem interdisziplinären Diskurs geistes-, kultur-, sozial- oder technikwissenschaftlicher Ansätze. Dem Industriemuseum kam in der musealen Aufbereitung und Kontextualisierung historischer Objekte und ihrer Handhabung dabei eine besondere Vermittlerrolle zu.
Das Industriemuseum Chemnitz versteht es als seine Aufgabe, Industriekultur in den Fokus der Öffentlichkeit zu rücken. Industriekultur verbindet Technik-, Kultur- und Sozialgeschichte und umfasst das Leben der Menschen in der Industriegesellschaft. Wie die Ausstellung auf vielfältige Weise zeigt, bieten Gesten auf diese Zusammenhänge überraschend vielseitige Perspektiven.
Das historische Handhabungswissen von Werkzeugen und Maschinen droht im aktuellen technologischen Wandel als kulturelles Erbe verloren zu gehen. Eine unserer Expertisen besteht nun gerade darin, das Wissen über die Instandsetzung historischer Werkzeuge und Maschinen mit dem Wissen über ihre Funktionsweise und Handhabung zusammenführen zu können.
Das Thema schließt also in unterschiedlicher Weise an das unmittelbare Lebensumfeld der Menschen an. Daher geht es in der Ausstellung nicht nur um die Kommunikation mittels Gesten, sondern im Wesentlichen auch um die Arbeitswelt der Vergangenheit und Zukunft. Beides wird an Mensch-Maschine-Schnittstellen und ihren vielfältigen Bezugspunkten zu aktuellen kulturellen und technischen Entwicklungen und Wandelprozessen erfahr- und erleb-
14

bar gemacht. Dass solche Wandelprozesse nicht anders verstanden werden können als in der Verschweißung der drei elementaren Zeitkategorien Vergangenheit, Gegenwart und Zukunft, betont bereits der Untertitel der Ausstellung.
Das Konzept der Ausstellung hat auch überregional für große Beachtung gesorgt. Besonders erfreulich ist, dass die Museumsstiftung Post und Telekommunikation die Ausstellung in ihren Häusern in Berlin und Frankfurt a. M. zeigt. Das Gemeinschaftsprojekt wirkt so nicht nur nachhaltig für das Haus selbst, sondern entwickelt und gestaltet Perspektiven für die Stadt Chemnitz und die Region. Im Jahr des 875-jährigen Stadtjubiläums haben Universität und Museum gezeigt, welche Synergien sich in der Stadt entwickeln können, wenn man ihnen Raum gibt.
Mein herzlicher Dank gilt Anett Polig, die die Ausstellung aufseiten des Industriemuseums Chemnitz verantwortlich betreut hat. Darüber hinaus danke ich den Projektpartnern: der TU Chemnitz, und hier im besonderen Prof. Dr. Ellen Fricke, sowie dem Ars Electronica Futurelab und Christopher Lindinger für die inspirierende Zusammenarbeit. Beide Projektpartner waren gemeinsam für die wissenschaftliche und künstlerische Ausstellungskonzeption und -kuratierung maßgeblich verantwortlich.
Mein besonderer Dank gilt dem Bundesministerium für Bildung und Forschung, der Ostdeutschen Sparkassenstiftung, der Sparkasse Chemnitz, der Kulturstiftung des Freistaats Sachsen sowie dem Freistaat Sachsen selbst, die durch ihre Förderung die Ausstellung ermöglichten.
Dr. Oliver Brehm Leiter des Industriemuseums Chemnitz und Geschäftsführer des Zweckverbandes Sächsisches Industriemuseum
15

Grußwort
Die junge Frau auf dem Monitor legt ihre Hände flach gegeneinander und verbeugt sich leicht. Die Museumsbesucherin ihr gegenüber versucht, die Geste mit ebenso viel Anmut nachzuahmen und so den Gruß zu erwidern. Die kleine Szene ist so oder ähnlich unzählige Male im Museum für Kommunikation Berlin zu beobachten. Sie spielt sich ab in der Kommunikationsgalerie, in der unsere Besucher/innen eingeladen sind, unterschiedliche Wege der Kommunikation zu entdecken und selbst auszuprobieren. Gesten sind ein solches Mittel der Kommunikation, deren Ziel als soziale Handlung die Verständigung ist.
Als Museum für Kommunikation Berlin sind Vergangenheit, Gegenwart und Zukunft der Kommunikation unsere Themen. Ausgehend von einer eher technischen Betrachtung der Nachrichtenübermittelung zur Zeit der Gründung unseres Hauses als Reichspostmuseum 1872, steht rund 150 Jahre später die Kommunikation in all ihren Facetten im Mittelpunkt. Das Thema „Gesten“ ist dabei integraler Bestandteil und es lassen sich sowohl in der Dauerausstellung des Museums als auch in vergangenen Wechselausstellungen Anknüpfungspunkte und Schnittmengen finden: die Schriftkultur, die eine Vielzahl an Handhabungen und Gesten hervorbrachte; die Telefonie, die sowohl in analoger wie auch digitaler Form menschliche Gestik stark geprägt hat bzw. prägt; und nicht zuletzt die interkulturelle Kommunikation, in welcher – je nach Kulturraum – Gesten und Zeichen unterschiedlich bewertet und interpretiert werden (unter anderem gezeigt in den Wechselausstellungen „Missverständnisse. Stolpersteine der Kommunikation“ 2008 und „Glücksfälle Störfälle. Facetten interkultureller Kommunikation“ 2012).
So war es uns eine große Freude, als uns Prof. Dr. Ellen Fricke von der TU Chemnitz Anfang 2018 für eine Zusammenarbeit hinsichtlich der Ausstellung „Gesten – gestern, heute, übermorgen“ kontaktierte. Die Ausstellung, die vom 17. November 2017 bis zum 4. März 2018 mit großem Erfolg im Sächsischen Industriemuseum Chemnitz gezeigt wurde, behandelt einen speziellen Aspekt der Kommunikation auf einerseits außerordentlich fachkundige, andererseits anschauliche und vor allem erlebbare Art und Weise: den Zusammenhang zwischen menschlicher Gestik, dem Wandel der industriellen Produktion und unserer Interaktion mit Maschinen in Vergangenheit und Zukunft. Dieser auch in dem vorliegenden Buch dokumentierte Blick auf den Kommunikationswert von Gesten auf der einen und die Frage nach der Zukunft des Zusammenspiels von Mensch und Maschine auf der anderen Seite machen die Ausstellung „Gesten – gestern, heute, übermorgen“ zu einer sehr gut in unseren Themenkanon passenden
16

Ausstellung. Zudem entspricht sie unserem Anspruch, in Wechselausstellungen Aspekte der Kommunikation zu vertiefen, wie wir dies in unseren Dauerausstellungen bereits anreißen.
Ein großes Augenmerk des Museums für Kommunikation Berlin liegt auf der Vermittlung der Ausstellungsinhalte an ein möglichst breites Publikum. Die kreative Gestaltung, die interaktiven Angebote wie die künstlerischen Arbeiten der Ausstellung garantieren vielfältige Zugänge und berücksichtigen unterschiedliche Besucher/inneninteressen. Mit einem ausstellungsbegleitenden Rahmenprogramm und den dazugehörigen Vermittlungsangeboten vertiefen, erweitern und veranschaulichen wir die Aspekte dieses komplexen Themas. Im Anschluss an die Präsentation in Berlin wird die Ausstellung im Museum für Kommunikation Frankfurt zu sehen sein, das ebenfalls Teil der Museumsstiftung Post und Telekommunikation ist.
Für die wunderbare Zusammenarbeit danke ich dem gesamten Projektteam. Ein besonderer Dank geht dabei an Prof. Dr. Ellen Fricke und Dr. Jana Bressem (Gesamtleitung und Koordination des MANUACT-Projekts der TU Chemnitz). Wir freuen uns sehr, nicht nur auf den spannenden Bereich der Gestenforschung aufmerksam zu machen, sondern auch die Forschungsergebnisse des MANUACT-Projektes weiter vermitteln zu können. Dr. Oliver Brehm und Anett Polig vom Sächsischen Industriemuseum Chemnitz, wo die Ausstellung bereits erfolgreich zu sehen war, haben uns bereitwillig an ihren Kenntnissen und Erfahrungen mit der Ausstellung teilhaben lassen. Ein besonderer Dank auch an Christopher Lindinger und Marianne Eisl vom Ars Electronica Futurelab Linz, die mit ihren interaktiven Experimentierfeldern sowie der künstlerischen Ausstellungskonzeption anregende Zukunftsperspektiven zu der Ausstellung beigetragen haben.
Mit einer Geste beginnt der Besuch in unserem Museum, mit einer Geste kann er enden: Die interaktive Installation „Shadow Gestures“ am Ausgang der Ausstellung lädt ein, diese mit einer Lieblingsgeste zu verlassen und sie zumindest für einen gewissen Zeitraum für andere sichtbar zu halten. Denn die Geste war und ist vergänglich – es sei denn, es ist eine „große“.
Anja Schaluschke Direktorin des Museums für Kommunikation Berlin und Ständige Vertreterin des Kurators der Museumsstiftung Post und Telekommunikation
17

1

2

3

18

19

4

5

6

20

7

8

9

21

10
22

11
23

12

13

14

15

24

16

17

18

19

25

20
21
26

22
27

23

24

25

26

28

27

28

29

30

29

31

33

Abbildungsnachweis Alle Fotos: Tobias Naumann.

32

30

31

Gesten – gestern, heute, übermorgen.
Vom Forschungsprojekt zur Ausstellung

Ellen Fricke

Warum eine Ausstellung zu Gesten in einem Industriemuseum?

Die zentrale Rolle der Hand in Sprache, Kultur und Technologie

Eine Ausstellung zu Gesten in einem Industrie- oder Technologiemuseum? Dies scheint auf den ersten Blick – Museen sind ja meist mit dem Gestern befasst – eine ungewöhnliche Kombination. Was haben denn diejenigen Handbewegungen, die Menschen gebrauchen, wenn sie miteinander sprechen, mit Maschinen, Werkzeugen und den Erzeugnissen der sächsischen Industriekultur zu tun? Auf den zweiten Blick, der sich vom Heute in die Zukunft richtet, ergibt sich ein anderes, differenzierteres Bild. Wir befinden uns derzeit an einer Epochenschwelle, die nicht nur die Welt der Arbeit, wie wir sie bisher kennen, fundamental verändern wird, sondern die zugleich einen Umschlagpunkt der technologischen und gesellschaftlichen Entwicklung markiert, an dem sich unsere konkreten Beziehungen zu Objekten grundsätzlich wandeln. Die Rolle der Hand ist dabei von besonderer Bedeutung, denn sie stellt einen zentralen Kristallisationspunkt der vergangenen, gegenwärtigen und zukünftigen materiellen Kultur dar. Dies ist ein wichtiger Grund, diese Ausstellung nicht nur im Industriemuseum Chemnitz, sondern auch an anderen Orten und in anderen Kontexten wie den Berliner und Frankfurter Museen für Kommunikation zu zeigen.

Kulturelle Objekte werden im Gegensatz zu natürlichen nicht einfach vorgefunden, sondern unterliegen Bearbeitungsprozessen, bei denen die menschliche Hand eine entscheidende Rolle spielt. Objekte und Hände entwickeln sich aneinander, Funktionen der Hand werden durch Werkzeuge erweitert (z. B. Faustkeil oder Hammer) oder in handwerklichen und maschinellen Produktionsprozessen ersetzt (z. B. Federhämmer oder Robotergreifarme). Umgekehrt werden aber in der Produktgestaltung – man denke hier an berührungssensitive Oberflächen von Computern oder Handys – Objekte gezielt handhabbar gemacht und dabei auf grundlegende Handlungen und Gesten zurückgeführt. Ein Beispiel ist die Wischgeste. Wir wischen über das Display und bedienen so unser Smartphone oder Tablet. Im Gespräch mit einem Geschäftspartner oder Freund „wischen“ wir unliebsame Argumente wie Krümel mit dieser Geste weg.
Handbewegungen begleiten als kommunikative Gesten unser Sprechen, verkörpern innere, räumliche und bildliche Vorstellungen und sind ein wichtiger Teil der Alltagskommunikation. Mit dem Daumen nach oben geben wir unser Okay, wir imitieren mit unseren Händen Objekte

32

1  Gesten als Wissensspeicher des Objektgebrauchs
und wie wir mit ihnen umgehen. Gesten sind dabei für uns ein wichtiger visuell-kultureller Wissensspeicher des Objektgebrauchs. So sind in der Geste des Telefonierens, bei der die Hand als Ganzes mit abgespreiztem kleinen Finger und Daumen ein Handy verkörpert, noch Formaspekte des alten gebogenen Telefonhörers auffindbar. Insbesondere gewinnen Gesten für die Steuerung technischer Geräte immer größere Bedeutung und werden z. B. für die Bedienung von Fernsehern, Staubsaugern und die Kommunikation mit fahrerlosen Autos und anderen Robotern nutzbar gemacht. Mehr noch: Der menschliche Körper selbst wird zunehmend durch Technologien wie Exoskelette, Prothesen oder Virtual-Reality-Brillen, die am Körper getragen werden, erweitert und hybridisiert.

Wenn man wie beispielsweise auch das Ars Electronica Futurelab davon ausgeht, dass eine Gesellschaft selbst ihre Zukunft formt und damit jede und jeder Einzelne als Mitglied dieser Gesellschaft diese Zukunft gestaltet, dann müssen gerade vor dem Hintergrund des gegenwärtigen Wandels – auch auf der Basis geistes- und sozialwissenschaftlicher Reflexion – für die Bürgerinnen und Bürger Zugänge unterschiedlichster Art geschaffen und Möglichkeiten für Handlungsspielräume aufgezeigt werden. Das technische Problem zu lösen, wie beispielsweise ein selbstfahrendes Auto unfallfrei von A nach B kommt, ist nur ein Teilaspekt eines weitaus umfassenderen Szenarios. Eine andere Frage ist es, auf welche Akzeptanz selbstfahrende Autos bei ihren unmittelbaren Nutzern, aber insbesondere auch bei anderen Verkehrsteilnehmern wie Fußgängern oder Radfahrern stoßen. Für Verkehrs- und Mobilitätskonzepte der Zukunft ist eine solche Akzeptanz entscheidend. Sie lässt sich jedoch überhaupt nur herstellen, wenn wir innerhalb unserer Gesellschaft auch Fragen wie die folgende diskutieren: Mit welchen Zeichen können und wollen wir zukünftig im öffentlichen Raum kommunizieren?
Wenn man sich dafür entscheidet, Gesten zum Ausgangspunkt für eine weitere Forschung und Entwicklung zu nehmen, dann ist es sinnvoll, bei Gesten des menschlichen Alltagsgebrauchs anzusetzen, um zu umsetzbaren Lösungen zu kommen. Konventionalisierte Gesten, wie die Geste für ‚Stopp‘ mit der flachen Hand, deren Finger vertikal nach oben gerichtet sind, haben den Vorteil, dass wir sie schon kennen und mit kleinen Modifikationen für die Kommunikation mit fahrerlosen Autos einsetzen können.

2  Hybridgesellschaft: Mensch und selbstfahrendes Roboterauto
33

3 bis 5  Die Welt in 100 Jahren um 1910 von Jean-Marc Coté erdacht
34

Mit einem möglichen Einsatz von menschlichen Gesten zur Interaktion mit Interfaces und Robotern stellt sich jedoch auch das Problem einer Normierung bzw. Standardisierung:1 Müssen wir für jede Automarke neue Gesten lernen? Oder noch weiter gefasst: Müssen wir für jedes autonome Gerät eine neue „Sprache“ lernen? Woran erkennt der jeweilige Roboter, dass er adressiert ist und nicht das Gerät oder der Mensch neben ihm? Wie könnte ein leicht erlernbares, standardisiertes Gestenrepertoire für die Kommunikation mit fahrerlosen Autos aussehen, das möglichst ökonomisch ist und auch interkulturelle Verschiedenheiten berücksichtigt? Dieselbe Frage würde sich grundsätzlich auch für andere Zeichenarten wie z. B. Licht- oder Farbsignale stellen. Es ist sehr einfach, in einer ersten Designstudie ein einziges gestisches Signal mit einer spezifischen Reaktion des Autos zu verbinden. Aber schon bei zwanzig unterschiedlichen, willkürlich gewählten Gesten stellt sich die Frage nach der Ökonomie des Zeichenrepertoires. Hier sind Linguisten und Semiotiker als Experten für Zeichen und ihre Kombinatorik gefragt.
Dieser am Beispiel der fahrerlosen Autos kurz angerissene Wandel, auch partiell verbunden mit dem Schlagwort „Industrie 4.0“, wird von unterschiedlichen gesellschaftlichen Gruppierungen als Chance, aber auch als Gefährdung wahrgenommen.2 Parallelen einerseits zu den Maschinenstürmern des 19. Jahrhunderts und andererseits zu optimistischen Zukunftsentwürfen der Welt in 100 Jahren, die – wie z. B. bei Jean-Marc Coté – um das Jahr 1910 herum entstanden sind,3 scheinen naheliegend – oder verhält es sich doch ganz anders? Was unterscheidet die aktuelle digitale Revolution von der „manuellen“ Revolution im 19. Jahrhundert? Der Wissenschaftsjournalist Tim Dunlop veranschaulicht die Parallele unter Bezugnahme auf Calum Chace am Beispiel des Einsatzes der Pferdekraft (Calum Chace, “Reverse Luddite Fallacy”).4 In früheren Phasen der Automatisierung sei es die tierische oder menschliche Muskelkraft gewesen, die ersetzt wurde. Für die Menschen wirkte sich dieses insofern positiv aus, als die Arbeitsplätze weniger gefährlich waren und vielfach auch dadurch interessanter wurden, dass nunmehr verstärkt kognitive statt muskuläre Fähigkeiten erforderlich waren. Für das Pferd allerdings, das nur seine Muskelkraft anzubieten hatte, waren die Auswirkungen andere: Gab es um 1900 noch 25 Millionen Arbeitspferde in Amerika, sind sie heute vollständig verschwunden. Welches sind die Auswirkungen auf den Menschen, dessen kognitive Fähigkeiten am Arbeitsplatz durch die digitale Revolution ersetzt werden? Viele Ökonomen sind davon überzeugt,

dass – wie in der Vergangenheit auch – Automatisierungen am Arbeitsplatz auf lange Sicht nicht zur Arbeitslosigkeit führen, sondern Produkte und Dienstleistungen verbilligen, Lohnzuwächse ermöglichen und neue Arbeitsplätze schaffen werden. Andere Vorstellungen betonen die Möglichkeit der Befreiung von der klassischen Vorstellung eines Arbeitsplatzes und die Chance für Betätigungen in der so frei gewordenen Lebenszeit, die der individuellen und gesellschaftlichen Weiterentwicklung des Menschen dienen. Zukunftsvisionen einer Mensch-Roboter-Verschmelzung hält Dunlop entgegen: “Planning to live on Mars, or becoming a cyborg, might actually be a hightech version of burying your head in the sand. This is not to say we should shun technology, but it is to say that maybe we are thinking about this the wrong way […].” 5 Welche Formen menschlich-technologische Hybridgesellschaften zukünftig annehmen werden, hängt nicht zuletzt auch davon ab, auf welche Akzeptanz die jeweiligen Alternativen bei den einzelnen Bürgern stoßen werden.6

Wie wirkt Wissen in kulturell geschaffenen und verwendeten Objekten?
Die Idee und Gesamtkonzeption der Ausstellung „Gesten – gestern, heute, übermorgen“ ist eng verbunden mit dem interdisziplinären Forschungsprojekt „Hands and Objects in Language, Culture, and Technology: Manual Actions at Workplaces between Robotics, Gesture, and Product Design“ (MANUACT), eine Kooperation der Technischen Universität Chemnitz mit dem Industriemuseum Chemnitz und dem Ars Electronica Futurelab in Linz (www.manuact.org). An der Technischen Universität Chemnitz erforschen die Professuren Germanistische Sprachwissenschaft, Semiotik und Multimodale Kommunikation (Prof. Dr. Ellen Fricke, Gesamtprojektleitung) sowie Arbeitswissenschaft und Innovationsmanagement (Prof. Dr. Angelika Bullinger-Hoffmann) gemeinsam die Rolle der Hände und Objekte in Sprache, Kultur und Technologie.

Ziele der Ausstellung

Wir möchten in dieser Ausstellung Gesten und ihre vielfältigen Bezugspunkte zu aktuellen kulturellen und technischen Entwicklungen und Wandlungsprozessen für die Besucher erleb- und erfahrbar machen, die Neugier wecken, zur Diskussion anregen. Wir setzen bei Fragen an, die auch in unserer aktuellen Forschung zu Gesten eine Rolle spielen und denen jeder in seinem Alltag vielleicht auch schon einmal begegnet ist: Welche Rolle spielen Handbewegungen in der zwischenmenschlichen Kommunikation? Wie entstehen Gesten? Wie werden sie wissenschaftlich untersucht? Was haben Gesten mit Objektgebrauch zu tun? In welchem Zusammenhang stehen sie mit Werkzeugen, Maschinen und Robotern, die Funktionen der Hand ersetzen? Was teilen sie uns über unsere Sprache, Kultur und Technologie mit? Welche Alltagsgegenstände werden wir in welcher Weise gestisch mit unseren Händen steuern? Wie wirken solche Handbewegungen auf uns und die zwischenmenschliche Kommunikation zurück?

6  Das MANUACT-Team der Technischen Universität Chemnitz7

35

Die Frage, wie sich Wissen in kulturell geschaffenen und verwendeten Objekten manifestiert, veranlasste unseren Fördermittelgeber, das Bundesministerium für Bildung und Forschung (BMBF) im Kontext des „material turns“ der Geisteswissenschaften zu einer Ausschreibung, welche die „Sprache der Objekte“ in den Blick nimmt und die sogenannte „materielle Kultur“ im Kontext gesellschaftlicher Entwicklungen beleuchtet. Eines der erklärten Ziele des Bundesministeriums ist es, im Rahmen dieser Ausschreibung die Zusammenarbeit von Universitäten und Museen so zu stärken, dass erstens Museen wie das Industriemuseum oder die Museen für Kommunikation Berlin und Frankfurt als Orte in Erscheinung treten, an denen Objekte nicht nur gesammelt, sondern gemeinsam mit Universitäten auch erforscht werden. Zweitens ist das geförderte Format einer Abschlussausstellung zum Forschungsvorhaben auch dazu gedacht, universitäre Forschung an gesellschaftliche Diskurse und eine breite Öffentlichkeit rückzubinden. Aber nicht nur deshalb gibt es diese Ausstellung. Der Forschungsund Entwicklungsauftrag, den die TU Chemnitz an das Ars Electronica Futurelab in Linz als Forschungspartner vergeben hat, ermöglicht über die Entwicklung von künstlerischen Experimentierfeldern neue interdisziplinäre Zugänge zu unseren zentralen Forschungsfragestellungen und erschließt weiterführende Innovationspotentiale – nicht nur, aber auch – für technologische Anwendungen, die gleichzeitig reflektiert und zur Diskussion gestellt werden.
Was gute Wissenschaft und Kunst gemeinsam haben, ist Kreativität und Denken außerhalb der gewohnten Bahnen. In durch Digitalisierung und Robotik geprägten Umwelten wird der Mensch zukünftig nur durch solche Denkprozesse gesellschaftlich wirksam werden können, die neue Verbindungen zwischen bereits bekannten Bereichen des Wissens herstellen können. Der Erfolg des Desktops beispielsweise, der Schreibtischoberfläche, die als erstes bei Apple-Computern auftauchte, beruht auf genuin metaphorischem Denken, einem Bereich, der nicht unbedingt zu den klassischen Kernkompetenzen gehört, die in einem technikwissenschaftlichen Studium gefordert werden.
Was geschieht bei der Schreibtisch-Metapher? In Bezug auf das Bedienkonzept werden abstrakte, sehr komplexe Programme handhabbar gemacht und im Hinblick auf das Maß menschlichen Handelns komprimiert. Zwei Bereiche, die scheinbar nichts miteinander zu tun haben, werden miteinander verschränkt: der Bereich der abstrakten Programme und der Bildschirmoberfläche einerseits mit dem Bereich der konkreten Handlungen und Handhabungen, die

mit der Organisation eines wirklichen Schreibtisches und Büros verbunden sind, andererseits. Der Erfolg der Desktop-Metapher beruht maßgeblich auf ihrer intuitiven Zugänglichkeit und der Verankerung in der körperlichen Erfahrung.8 Automatisierbar sind zurzeit nur die bereits hinlänglich bekannten Bereiche, die Herstellung neuer Verbindungen in menschlichen metaphorischen Denk- und Imaginationsprozessen hingegen – zumindest bisher – noch nicht.
Wissenschaft, Kunst und Technologie: Exponate als Experimentierfelder der Forschung und der Alltagserkundung in einem Museum
Neue Verbindungslinien zwischen bekannten und unbekannten Arealen zu ziehen – genau das ist das erklärte Programm des Ars Electronica Futurelabs. Das Futurelab ist ein Medienkunstlabor neuer Prägung, angesiedelt im Ars Electronica Center in Linz, das sich als eine Infrastruktur und Plattform für kreatives Forschen und Entwickeln versteht. Diese Ausrichtung macht das Futurelab zu einem idealen Partner des Forschungsprojekts MANUACT und für die gemeinsame Erarbeitung einer Ausstellungskonzeption, die Kunst, Forschung und Technologie verbindet und auf eine breite Öffentlichkeit ausgerichtet ist.9
Als Kombination aus Atelier und Labor ist das Futurelab eine von vier Säulen des Ars-Electronica-Gesamtkonzepts, das außerdem aus dem Ars Electronica Center als einem Museum der Zukunft, dem jährlich stattfindenden Ars Electronica Festival und dem Prix Ars Electronica, dem „Oscar“ der Computer- und Medienkunst, besteht. Aus diesem breiten Fundus an Arbeiten, die beim jährlichen Ars Electronica Festival zu sehen sind und für den Wettbewerb eingereicht werden, wurden Exponate auch für unsere Gestenausstellung kuratiert: Daniel Rozins „Wooden Mirror“, Golan Levins „Augmented Hand Series“, Jennifer Crupis „Gesture Jewelry“ und Werner Jauks Installation „touch the sound / sound sculpting 2.0“, die im Februar 2018 in Chemnitz zu erleben war. Andere interaktive Exponate sind aus der gemeinsamen Forschung heraus entstanden und wurden speziell für die Chemnitzer Gestenausstellung entwickelt: der „Gesture Space Visualizer“, das „Gestenpuzzle“, die „Verbwolke“ als Gestenlexikonfragment von Objektgebrauchsgesten, der „Virtual Globe“, bei dem die Hand zu einem Flugzeug wird, die „Virtuelle Töpferscheibe“, mit der man sich nicht die Hände schmutzig macht, und ein Kugel-

36

7  In Holz gespiegelt: Daniel Rozins Wooden Mirror 8  Gestenzpuzzle: Wie wirken gesprochene Sprache und Gesten zusammen?

labyrinth, dessen Kugel man berührungslos versenken kann. Zur Ausstellung beigetragen haben darüber hinaus die Berliner Künstlerin Anette Rose mit ihrer dreikanaligen Videoinstallation „Modul #25 flechten, wirken, weben – motion capturing“ sowie Hannah Groninger und Irene Mittelberg mit Gestenskulpturen, die gestische Bewegungsspuren im 3D-Druck zeigen.10
Dass Innovation nicht nur ein Geschehen ist, das an Universitäten oder in Unternehmen stattfindet, sondern eine wichtige Dimension des gesamtgesellschaftlichen Zivilisationsprozesses darstellt, wird von dem langjährigen Rektor der Universität für angewandte Kunst Wien, Gerald Bast, in einem Vortrag zum Verhältnis von Kunst und Wissenschaft betont:
„Heute ist es schwer, sich vorzustellen, wie sehr sich die Arbeitswelt, unser ganzes Leben, durch die technologische, insbesondere digitale Revolution verändern wird. […] Wir wissen nicht, wie all diese Veränderungen unsere Kultur beeinflussen werden. Aber das werden sie. Wie unsere Zivilisation damit umgeht, ist nicht zuletzt eine Frage, wie wir mit dem Begriff Innovation umgehen. Es macht einen Unterschied, ob man Innovation als Domäne von Technik, Naturwissenschaften und Ökonomie begreift und betreibt, oder ob wir Innovation als zivilisatorischen Prozess sehen, in dem es um holistisches Denken und Handeln geht, wo Phantasie und Kreativität einen notwendigen Platz haben.“11
Wenn man von einem derartigen, nicht auf Technologie beschränkten Innovationsbegriff ausgeht, dann kommt insbesondere der Bildung an Schulen und in anderen öffentlichen Institutionen wie der breit gefächerten deutschen Museumslandschaft eine entscheidende Bedeutung zu. Künstler und Wissenschaftler sind auf ihrem je eigenen Gebiet Experten im Umgang mit Unsicherheit und für die Entwicklung neuer Szenarien in unserer modernen Wissensgesellschaft. Beide Kompetenzen in Kombination und in je aufgabenspezifischer Gewichtung in allen Bildungsinstitutionen zu stärken, ist eine Voraussetzung für unsere Zukunftsfähigkeit.12
Die Ausstellung „Gesten – gestern, heute, übermorgen“ war im Industriemuseum Chemnitz von Mitte November 2017 bis Anfang März 2018 zu sehen. Chemnitz feierte 2018 sein 875-jähriges Jubiläum, es ist Standort der im Jahr 2020 stattfindenden vierten Sächsischen Landesausstellung, die sich speziell der Industriekultur widmen wird, und Chemnitz wird sich für das Jahr 2025 als Europäische Kulturhauptstadt bewerben. Das Industriemuseum und Chemnitz als „Stadt der Moderne“ stehen für Identität und Verände-

37

9  Split Screen: Beschreibung des Spinnens mit eingeblendeter Gestenanalyse
10  Split Screen: Beschreibung des Töpferns mit eingeblendeter Gestenanalyse
11  Split Screen: Beschreibung des Schmiedens mit eingeblendeter Gestenanalyse
38

rung. Chemnitz ist schon immer eigene Wege gegangen, hat Neues entdeckt und Ungewöhnliches getan. Die Ausstellung präsentiert Historisches, aktuelle Forschungsergebnisse und Zukunftsvisionen und erweitert unsere Vorstellungsund Denkmöglichkeitsräume für dasjenige, was kommen wird. Auch aus diesen Gründen wanderte die Ausstellung weiter und ist vom 11. April bis 1. September 2019 im Museum für Kommunikation Berlin sowie im Anschluss vom 25. September 2019 bis 23. Februar 2020 im Museum für Kommunikation Frankfurt a. M. zu sehen, welches wahrscheinlich nicht die letzte Station sein wird.
Vom Forschungsprojekt zur Ausstellungskonzeption: Wie macht man Wissenschaft erlebbar?
Von einem Forschungsprojekt können viele Wege zu einer Ausstellungkonzeption führen. Es kann Umwege, Abwege und Sackgassen geben, bis sich ein interessanter, gangbarer Pfad mit einem funktionierenden Narrativ eröffnet. Eine Abzweigung, die wir jedoch von vornherein ausgeschlossen haben, ist eine Verdoppelung unserer Forschung durch den Wechsel in ein lediglich populäreres Darstellungsformat – die Ausstellung als Appendix. Dies hätte schon dem interdisziplinären Anspruch unseres Projekts widersprochen, in dem künstlerische Forschung als eigene und ergänzende Dimension des Erkenntnisgewinns von vornherein angelegt ist.
Eine Ausstellungskonzeption, die sich für uns ebenfalls nicht als gangbar erwies, war eine rein objektzentrierte Ausstellung nur mit Exponaten des Industriemuseums und weiteren Leihgaben, so faszinierend diese aus technikgeschichtlicher Perspektive auch jeweils sind. Denn ein wichtiger Grundgedanke unseres Forschungsprojekts, der es von allen anderen Projekten des Förderprogramms „Die Sprache der Objekte“ abhebt, ist, dass wir Objekte in den Kontext ihres händischen Gebrauchs stellen. Diese neue und erweiterte Perspektive auf Exponate ist insbesondere für Industriemuseen wie das Chemnitzer Industriemuseum interessant: Für viele Objekte der Industriekultur droht dieses Gebrauchswissen verloren zu gehen, da man ihre Nutzer in wenigen Jahren nicht mehr wird fragen können. Ohne das motorische Wissen um die händische Bedienung, die einen wesentlichen Teil früherer Arbeitsabläufe ausmachte, können wir historische Maschinen und Bedienkonzepte nicht angemessen verstehen. Es ist ein essentieller Bestandteil unseres kulturellen Erbes, den es zu bewahren gilt. In einem zusammen mit der Dokumentarfilmerin Maria Haa-

se durchgeführten Pilotprojekt wird für drei ausgewählte Exponate aus den Bereichen Spinnen, Töpfern und Schmieden dieses Handhabungswissen dokumentiert und in der Ausstellung im Kontext der jeweiligen Exponate gezeigt, und zwar mit einem speziell vom Ars Electronica Futurelab entwickelten Split Screen, der es erlaubt, die wissenschaftlichen Gestenanalysen ein- und auszublenden (Abbildungen 9 bis 11).
Damit deutet sich der Weg an, für den wir uns entschieden haben: Wir möchten die Ausstellungsbesucherinnen und -besucher einladen, neue Erfahrungen zu machen. Erfahrungen, die andere Erfahrungen ihrer Alltagswelt, wie die Kommunikation mit Gesten, in einen neuen Zusammenhang stellen; Erfahrungen, die einen unmittelbaren Zugang zu unserer Forschung und ihren Ergebnissen erschließen und Brücken schlagen zwischen Technologien der Vergangenheit, Gegenwart und Zukunft als Teil auch der sächsischen Industriekultur.
Themenbereiche und Narrativ der Ausstellung
Wie gestaltet sich das Zusammenspiel von Traditionen des Objektgebrauchs, deren Verkörperung in Gesten und der Gestaltung von händischen Bedienkonzepten an der Schnittstelle von Menschen und Maschinen? Diese wissenschaftliche Ausgangsfrage des Forschungsprojekts MANUACT ist auch für das Gesamtnarrativ der Ausstellung „Gesten – gestern, heute, übermorgen“ leitend. In drei großen Themenbereichen ermöglichen interaktive Exponate den Besucherinnen und Besuchern einen ästhetisch-experimentellen Zugang und brechen gewohnte Zugangsweisen auf: 1. Von der Geste zum Gestenlexikon: Parameter der Ge-
stenanalyse; 2. Objektgebrauch im Wandel: von der Handhabung zur
Gestensteuerung; 3. Industriekultur im Wandel: die Erweiterung und Re-
duktion der Hand. Gerahmt werden diese drei Themenstränge von einem Initial- und einem Finalexponat zu Beginn und Abschluss der Ausstellung. Den Auftakt bildet der „Wooden Mirror“ (2014) des New Yorker Medienkünstlers Daniel Rozin, der die Besucher erleben lässt, wie die eigenen Hand- und Körperbewegungen in Echtzeit sogar durch ein nichtreflektierendes Material wie Holz gespiegelt werden können. Und zum Abschluss lädt das vom Ars Electronica Futurelab konzipierte Exponat „Shadow Gestures“ die Besucherinnen und

Besucher ein, Teil der Ausstellung zu werden, indem sie sich selbst und ihre Gesten als „Schattenspuren“ hinterlassen, die mit einer Kamera aufgezeichnet und als Loop abgespielt werden.
Im ersten Bereich „Von der Geste zum Gestenlexikon: Parameter der Gestenanalyse“, der sich an den „Wooden Mirror“ anschließt, geht es um die Frage, wie Gesten dokumentiert und analysiert werden. Im Zentrum stehen sogenannte „redebegleitende Gesten“, die man beobachten kann, wenn jemand spricht, sowie konventionalisierte, sogenannte „emblematische“ Gesten, die auch ohne das Gesprochene verständlich sind, wie beispielsweise der hochgestreckte Daumen als Zeichen für ‚Okay‘: Welche interkulturellen Verschiedenheiten lassen sich beobachten (dieselbe Handform kann z. B. in einer anderen Kultur eine obszöne Bedeutung haben und zu Missverständnissen führen)? Wie haben sich menschliche Gesten und das Greifen von Objekten in der Evolution entwickelt? Wie werden Gesten in der Gestenforschung analysiert? Wie „blättert“ man in einem Gestenlexikon? Wie werden Objekte und Objektgebrauch verbal und gestisch beschrieben?
Die Aufzeichnungstechniken und Analyseverfahren der Gestenforschung reichen von verbalen Beschreibungen über Zeichnungen, Film- und Videoaufnahmen bis hin zu modernen Verfahren des Motion Capturing, bei denen die Probanden mit Markern versehen werden und die Bewegungsspuren im Raum in Echtzeit verfolgt und aufgezeichnet werden können. Beim Kubus von Anette Rose, einem der künstlerischen Leitexponate dieses Themenbereichs, werden multimodale Motion-Capturing-Aufnahmen gezeigt. Der
12  Gesture Space Visualizer

39

13  Virtuelle Töpferscheibe
14  Die „Verbwolke“ als interaktives Gestenlexikonfragment
40

Blick der Ausstellungsbesucher wird hier auf das eigentlich Unsichtbare gelenkt, nämlich die Spuren, die unsere flüchtigen Gesten im Raum hinterlassen und die eine eigene ab­ strakte bildliche Qualität in der Zeit entwickeln. An diesem und weiteren Exponaten wie der „Augmented Hand Series“ Golan Levins13 zeigt sich das ästhetische Potential neuer Technologien, wenn sie an der Schnittstelle von Kunst und Wissenschaft innovativ und reflektiert eingesetzt werden. Das interaktive Gestenlexikonfragment „Verbwolke“ ist aus wissenschaftlicher Perspektive, neben den Exponaten „Gesture Space Visualizer“ (Abbildung 12) und „Gestenpuzzle“ (Abbildung 8), das zentrale Exponat dieses Themenstrangs.14 Alle drei wurde im Rahmen von MANUACT, basierend auf den Daten und Analysen des linguistisch-semiotischen Teilprojekts, gemeinsam mit dem Ars Electronica Futurelab entwickelt.
Der zweite sich anschließende Themenstrang „Objektgebrauch im Wandel: von der Handhabung zur Gesten­steuerung“ macht den Umschlagpunkt von der berührenden analogen Handhabung von Objekten zur berührungslosen digitalen Gestensteuerung erfahrbar und zeigt am Beispiel der Geste für Telefonieren, wie Gesten der zwischenmenschlichen Kommunikation einen kulturellen Wissensspeicher für Objekte und ihre Handhabungen darstellen können. Für das Design von gestenbasierten

Mensch-Maschine-Schnittstellen ist insbesondere die Frage nach ihrer intuitiven Bedienbarkeit durch die Nutzer zentral und damit zugleich die Frage, inwieweit Gesten der zwischenmenschlichen Kommunikation einen sinnvollen Ausgangspunkt für die Gestaltung darstellen können. Nach dem die Besucher sich eingangs digital in einem „Wooden Mirror“ (Daniel Rozin) spiegeln konnten, erleben sie im Weiteren, wie sich Handhabungen von einem analogen Schulglobus bis hin zur gestischen Steuerung eines virtuellen Globus wandeln oder wie mit modellierenden Handbewegungen in einer virtuellen Töpferwerkstatt berührungslos Gefäße gestaltet werden können, die sich aus Handhabungen und Gesten ableiten. Über interaktive Split Screens, die Interview- und Dokumentationsvideos des Projekts MANUACT zeigen, können die Besucher beobachten, wie handwerkliche Tätigkeiten wie Töpfern, Spinnen und Hämmern gestisch und verbal beschrieben werden. Das Verschieben eines Reglers über den Bildschirm erlaubt die Einblendung wissenschaftlicher Gestenanalysen und macht die Beziehung von Objektgebrauch und Objektgebrauchsgesten für die Besucher sichtbar. Die gemeinsam mit dem Ars Electronica Futurelab umgesetzte Bedienung des Virtual Globe im Kontext einer Timeline von historischen Globen, welche durch das Industriemuseum bereitgestellt wurden, zeigt exemplarisch, in welcher Weise wissenschaftliche Ergebnisse des Forschungsprojekts MANUACT in die Gestaltung solcher Schnittstellen einfließen können.
Beim dritten Themenbereich „Industriekultur im Wandel: die erweiterte und reduzierte Hand“ geht es um zwei grundlegende Fragen: Wie wird die Hand durch Werkzeuge, Maschinen und Roboter ersetzt oder erweitert? Wie können wir das Wissen um die Bedienung historischer Werkzeuge und Maschinen erhalten? Am Beispiel von drei verschiedenen industriekulturellen Exponatbereichen, dem Hämmern, der Fadenherstellung und dem Töpfern werden zeitliche Entwicklungslinien deutlich, die einerseits eine Spezialisierung und Ausdifferenzierung der Handbewegungen beinhalten (z. B. vom Faustkeil zum Hammer oder vom einfachen Fadendrehen zur Spindel), wobei andererseits jedoch im Stadium spezialisierter Maschinen, durch welche eine Vielfalt vormals handwerklicher Tätigkeiten ersetzt werden, die händische Beteiligung des Menschen für ganz unterschiedliche Funktionen auf ein- und denselben Typ des Knopfdrucks oder dieselbe Art der Kurbelbetätigung reduziert wird. Das Besondere an der modernen Gestensteuerung von digitalen Interfaces ist, dass die Ausdifferenzierung der Handbewegungen, die auf kommunikativen

15  Handabgüsse von konventionalisierten Gesten
Gesten der zwischenmenschlichen Interaktion basieren, wieder zunimmt – allerdings unter Preisgabe einer vormals bestehenden und als solcher auch erlebten Ursache-Wirkungs-Beziehung (z. B. Verstärkung der menschlichen Krafteinwirkung durch den Hammer). Was als „real“ gilt, bestimmt sich in unserem Alltagsverständnis weitgehend noch immer aus der Erfahrung des Anfassenkönnens.
Weiterführende technologische Entwicklungen zielen daher darauf, diese haptische Lücke zwischen digitaler und analoger Welt zu schließen. In der Ausstellung können die Besucher die Ultraschalltechnik des „Ultrahaptics Interface“, das von Bosch für die Gestensteuerung in Autoinnenräumen entwickelt wurde, selbst ausprobieren und erfahren, wie sich ein virtuelles haptisches Feedback anfühlt. Roboter zum Anfassen, die auf menschliche Gesten und Berührungen reagieren, wird es zukünftig auch an Arbeitsplätzen geben, an denen Menschen und Roboter in Hybridgemeinschaften zusammenarbeiten. Einen Einblick in die Welt der Industrie 4.0 geben ein interaktiver Roboterarm der Firma Kuka und ein Demonstrator zur Gestensteuerung, der an der TU Chemnitz von der Professur für Arbeitswissenschaft und Innovationmanagement entwickelt wurde.15

41

16  Shadow Gestures als Finalexponat

Begleitprogramm: „Zur Zeit wird hier der Raum“
Die Ausstellung „Gesten – gestern, heute, übermorgen“ ist nicht nur eine Ausstellung im Raum, sondern auch in der Zeit. Sie nimmt damit ein wesentliches Merkmal der Gesten selbst auf, die nicht nur räumlich artikuliert werden, sondern genau wie die gesprochene Sprache eine zeitliche Gestalt haben und mit dieser eng verbunden sein können. Exponate wie die gegossenen Handformen, die in der Ausstellung gruppiert wurden, sind daher immer nur eine Momentaufnahme der Hand zum Zeitpunkt der größten Prägnanz der jeweiligen Handform. Man kann diesen Handabgüssen nicht entnehmen, wer die Geste mit welcher Absicht zu wem äußert, ob und wie sie eine gesprochene Äußerung begleitet, wo sie im Gestenraum positioniert ist, in welche Richtung sie bewegt wird und welche Orientierung die Handfläche hat, ob sie beispielsweise vom Körper abgewandt oder ihm zugewandt ist. Wo finden wir also die zeitliche Dimension?
Die zeitliche Dimension der Gesten und Handhabungen ist in der Ausstellung selbst mehrfach verankert: in den Timelines mit historischen Exponaten zur Industriekultur, deren Handhabungen wir per Video im Verlauf dokumen-

tiert haben, in den Exponaten zur Gestenforschung wie dem Gestenpuzzle oder der Verbwolke, die kurze Gestensequenzen in Videoschnipseln zeigen, in Motioncapturing-Aufnahmen, die Körperbewegungen als raumzeitliche Skelettstruktur verfremden, und nicht zuletzt in Kurzvorträgen, die einzelne Gesten genauer unter die Lupe nehmen, im Symposium „Hände, Dinge, Gesten“ mit Vorträgen international renommierter Gestenforscher sowie in einer Podiumsdiskussion gemeinsam mit dem Ars Electronica Futurelab zum Thema „Verkörperung von Technik und Technisierung von Körpern: Menschen, Maschinen und Gesten in hybriden Gesellschaften“. Mehr zum Begleitprogramm, Führungen und museumspädagogischen Angeboten der veranstaltenden Museen unter www.gesten-im-museum.de.
Begleitbuch: „Zum Raum wird hier die Zeit“
Ausstellungen und Forschungsprojekte gehen zu Ende, Bücher bleiben. Das vorliegende gleichnamige Buch „Gesten – gestern, heute, übermorgen“, herausgegeben von Ellen Fricke und Jana Bressem, ist eine Publikation zwischen Katalog,

42

Kunst und Wissenschaft. Aus unterschiedlichen Perspektiven wird ein Rundgang durch die Ausstellung präsentiert. Artikel, Interviews und Fotodokumentationen stellen die Exponate in den Kontext von Forschung und ästhetischer Reflexion und möchten einen gesellschaftlichen Diskurs zur Welt von morgen und übermorgen anstoßen. Allen, die mit ihrem Können und Enthusiasmus dieses noch immer andauernde Ausstellungsprojekt in all seinen Facetten ermöglicht haben, gilt unser Dank und unsere Wertschätzung.
Anmerkungen 1 Fricke, Ellen: Wie entstehen Gesten? Und was kann das in
Bezug auf die Interaktion mit fahrerlosen Autos in der Zukunft bedeuten. Mercedes-Benz Future Talk „Robotics“. Berlin, 30. Juni bis 2. Juli 2014. Online unter www.youtube.com/ watch?v=rUQmeQ0cgQs&t=134s (13.03.2019) sowie Fricke, Ellen: Von der Kugel zu Google Earth: Wie handhabe ich einen virtuellen Globus?, in diesem Band. 2 Siehe z. B. den Titel des Nachrichtenmagazins „Der Spiegel“ vom September 2016 „Sie sind entlassen! Wie uns Computer und Roboter die Arbeit wegnehmen – und welche Berufe morgen noch sicher sind“. Vgl. Abb. 3 im Beitrag „Industrieller Fortschritt: Hoffnungen und Ängste“, in diesem Band. 3 Eine Bildergalerie zu Jean-Marc Coté, wie er sich zu Beginn des 20. Jahrhunderts die Zukunft in 100 Jahren vorstellte, findet sich online unter www.derstandard.at/1381371707804/ Wie-man-sich-1910-die-Zukunft-vorstellte (31.03.2019). 4 Dunlop, Tim: The robot debate is over: the jobs are gone and they aren’t coming back. Online unter www.theguardian.com/ sustainable-business/2017/mar/31/the-robot-debate-is-overthe-jobs-are-gone-and-they-arent-coming-back (13.03.2019) sowie Chase, Chalum: The Reverse Luddite Fallacy. Economist can be surprisingly dangerous. Online unter https://calumchace.wordpress.com/2016/09/18/the-reverse-luddite-fallacy/ (13.03.2019). 5 Dunlop, Tim: Most westerners distrust robots – but if they free us for a better life? Online unter www.theguardian.com/sustainable-business/2017/mar/27/most-westerners-distrust-robots-but-what-if-they-free-us-for-a-better-life (13.03.2019). 6 Im Ars Electronica Museum in Linz kann man beispielsweise die Roboterrobbe „Paro“ streicheln, die für viele ältere und kranke Menschen eine Alternative zu einem Haustier darstellen könnte, das sie selbst nicht mehr in der Lage wären zu versorgen. Ein interessantes Modell für die Koexistenz

von Mensch und Roboter könnte in diesem Zusammenhang das der Koevolution von Mensch und Haustier sein, wie beispielsweise die Ausdifferenzierung der Interspezies-Kommunikation von Hund und Mensch. Siehe dazu auch den Beitrag von Susanne Grassmann in diesem Band. 7 Von links nach rechts: Dr. Ulrike Lynn, Prof. Dr. Angelika Bullinger-Hoffmann, Dr. Thomas Seeling, Prof. Dr. Ellen Fricke, Dr. Jana Bressem und Daniel Schöller. Nicht im Bild: Dr. Martin Siefkes, Johannes Müller-Viezens und Dr. Matthias Meiler. 8 Fauconnier, Gilles; Turner, Mark: The Way we Think. Conceptual Blending and the Mind’s Hidden Complexities, New York 2002, S. 22 ff. 9 Siehe die Internerpräsenz des Ars Electronica Futurelab. Online unter https://ars.electronica.art/futurelab/about/ (13.03.2019). 10 Siehe die entsprechenden Beiträge in diesem Band. 11 Bast, Gerald: Kunst. Wissenschaft. Forschung. Territoriale Machtkämpfe und Bedeutungshoheit für die Welterklärung. Vortrag bei der Jahrestagung des österreichischen Wissenschaftsrats 2015. Online unter www.geraldbast.at/kunstwissenschaftforschung.html (13.03.2019). 12 Vgl. die ausstellungsbegleitende Podiumsdiskussion „Verkörperung von Technik und Technisierung von Körpern: Menschen, Maschinen und Gesten in hybriden Gesellschaften“ am 9. Juli 2019 im Museum für Kommunikation (Moderation: Ellen Fricke). 13 Siehe das Interview mit Golan Levin sowie den Beitrag von Ines Lindner zu Anette Rose in diesem Band. 14 Siehe den Beitrag von Ellen Fricke, Jana Bressem, Daniel Schöller und Johannes Müller-Viezens in diesem Band. 15 Siehe die Beiträge von Ulrike Thomas sowie von Angelika Bullinger-Hoffmann und Thomas Seeling in diesem Band. ­
Abbildungsnachweis 1 Foto: TU Chemnitz/Pressefoto Schmidt. 2 Foto: Mercedes-Benz. 3–5 »Correspondance cinéma-phono-télégraphique«, 1900.
Künstler: Jean-Marc Coté, Abbildung aus der Bildserie »En L´An 2000« © bpk-Bildagentur / adoc-photos. 6 Foto: Sven Gleisberg. 7 Foto: TU Chemnitz/Pressefoto Schmidt. 8 Foto: Tobias Naumann. 9–11 Fotos: Dietmar Träupmann. 12 Foto: TU Chemnitz/Pressefoto Schmidt. 13–15 Fotos: Tobias Naumann. 16 Foto: TU Chemnitz/Pressefoto Schmidt.

43

II HÄNDE UND OBJEKTE IN SPRACHE, KULTUR UND TECHNIK
» Ellen Fricke, Jana Bressem, Daniel Schöller und Johannes Müller-Viezens Von der Handbewegung zum Gestenlexikon: Warum können wir nicht nur mit dem Mund, sondern auch mit den Händen sprechen ?
» Jana Bressem Gesten der zwischenmenschlichen Kommunikation: Ihre Vielfalt, Eigenschaften und Erforschung
» Jana Bressem Freude und Sieg: Die Victory-Geste
» Martin Siefkes Aufzeichnungstechniken der Gestenforschung
» Ellen Fricke Von der Kugel zu Google Earth: Wie handhabe ich einen virtuellen Globus?
» Manuel Schramm Die Entwicklung der Globen

44

45

Von der Handbewegung zum Gestenlexikon:
Warum können wir nicht nur mit dem Mund, sondern auch mit den Händen sprechen?

Ellen Fricke, Jana Bressem, Daniel Schöller und Johannes Müller-Viezens

Die Rolle unseres Körpers beim Sprechen
Wenn wir in Alltagssituationen über Sprache nachdenken, dann geht es oft um Fragen, wie Äußerungen einer anderen Person zu interpretieren sind, welche Absichten sie verfolgt, wie die Inhalte einer Äußerung zu verstehen sind und wie wir auf eine Äußerung angemessen reagieren. Oft geht es auch um Fragen von richtig oder falsch: Ist das Gesagte oder Geschriebene grammatisch korrekt? Oder es geht um Fragen der Wortwahl: Kann ich dasjenige, was ich meine, vielleicht noch präziser ausdrücken?
Welche Rolle unser Körper beim Sprechen spielt, gerät meist nicht in den Blick. Seine Beteiligung und sein Funktionieren werden als selbstverständlich vorausgesetzt. Oft wird uns die körperliche Dimension des Sprechens erst bewusst, wenn etwas nicht so optimal funktioniert: Wenn wir aufgrund einer Erkältung heiser sind und unsere Stimmbänder im Kehlkopf nicht richtig schließen und schwingen können, wenn wir beim Zahnarzt eine Spritze bekommen haben, die einseitig eine Mundhälfte betäubt, so dass wir mit unserer Zunge und unseren Lippen nicht mehr gewohnt präzise artikulieren können. Oder wir merken, dass etwas nicht zusammenpasst: Wenn in einem Film z. B. ein großer Mann mit einer hohen weiblichen Stimme synchronisiert

wird, fangen wir an zu lachen und finden es komisch. Der Effekt beruht darauf, dass wir aufgrund des Geschlechts und der Körpergröße eine tiefe Stimme erwarten, da die Stimmbänder in dem größeren männlichen Kehlkopf länger sind. Wir kennen dies auch von Saiteninstrumenten: Lange Saiten erzeugen tiefere Töne als kurze Saiten. Das Exponat „Gestenpuzzle“ lässt den Besucher in der Ausstellung mit solchen Erwartungshaltungen spielen.
Dass nicht nur der Mund am Sprechen beteiligt ist, sondern der ganze Körper und insbesondere auch unsere Hände, können wir beobachten, wenn wir bei Talkshows oder Spielfilmen den Ton abstellen. Das Gehörte oder Gesehene ist zwar jeweils für sich informativ, aber isoliert betrachtet in unterschiedlichem Ausmaß ergänzungsbedürftig. Es ist für viele überraschend, wie vielfältig die Körperbewegungen sein können, die das Sprechen begleiten und wie der Sprecherwechsel, also wer nach wem spricht, oft allein durch die Körperbewegungen organisiert wird.
Unser Sprechen ist also nicht nur hörbar, sondern auch sichtbar. Der Anthropologe und Gestenforscher Adam Kendon nimmt an, dass redebegleitende Gesten und die Lautsprache Bestandteile ein- und desselben Äußerungsprozesses sind. Beim Sprechen kommen also mindestens zwei Sinnesmodalitäten ins Spiel. Dieses Zusammenspiel

46

wird auch als Multimodalität bezeichnet. Wie eng Wörter und Gesten zusammenwirken, kann unterschiedlich ausgeprägt sein. Gesten können beispielsweise verbale Bedeutungen präzisieren oder ergänzen, oder wie beim Zeigen die Aufmerksamkeit des Angesprochenen auf Gegenstände in der Umwelt lenken, außerdem sind sie sehr eng mit der Sprechmelodie verbunden.
Wie eng die Verbindung sein kann, wird besonders deutlich, wenn wir darauf achten, wie wir Zeigegesten verwenden. Man stelle sich eine Situation in einem großen Kaufhaus oder in einer Einkaufspassage vor, in der man zu einem ganz bestimmten Ausgang gehen möchte. Auf die Frage, wo denn der Ausgang zum Rathausplatz sei, bekommt man von der angesprochenen Person nur die Antwort „Da!“, ohne irgendeine hinweisende Körperbewegung. Es ist anzunehmen, dass die fragende Person erstens mit dieser Information allein nichts anfangen kann und zweitens diese Antwort auch nicht als angemessene Reaktion auf ihre Frage betrachtet. Angemessen wäre eine Antwort wie „Das weiß ich nicht!“ oder „Erst links und dann nach dem dritten Geschäft rechts und dann immer gerade aus“ oder eben eine Verbindung der Äußerung des Wortes da mit einer begleitenden hinweisenden Zeigegeste, die die Aufmerksamkeit der fragenden Person in die Richtung des gewünschten Ausgangs lenkt. Wir sehen an diesen Antwortalternativen, dass man sich zwar auch ohne Gesten rein lautsprachlich verständigen kann, dass man aber bei dem Gebrauch von Wörtern wie da oder dort in bestimmten Situationen eine begleitende Zeigegeste verwenden muss. Sprachwissenschaftler sprechen bei solchen Verbindungen, die ziemlich häufig sind, auch von einer sogenannten „Zeigegestennot­wendigkeit“. Wie umfassend und differenziert das Artikulationsp­ otential der Hände für sich genommen ausgeschöpft werden kann, zeigen uns die Gebärdensprachen der Gehörlosen, die gleich den Lautsprachen voll ausgebildete Sprachen sind, oder auch – wenn auch weniger umfänglich als die Gebärdensprachen – die gestischen Zeichensprachen der Aborigines.1
Sprechen ohne Hände: Warum Hören manchmal zu wenig ist
Wenn wir miteinander sprechen, dann berücksichtigen wir in der Regel auch die Situation, in der wir uns gerade befinden. Wir berücksichtigen beispielsweise auch, was unsere Kommunikationspartner wahrnehmen können und was nicht. Wenn uns ein Blinder nach dem Weg fragt, werden wir keine Gesten verwenden, sondern versuchen, den Weg

rein verbal so präzise wie möglich zu beschreiben und die Person vielleicht berührend ausrichten und ein Stück begleiten, wenn der Weg sich sehr kompliziert gestaltet. An Orten, die so laut sind, dass jedes Sprechen übertönt wird, oder wenn die Kommunikationspartner sich nicht in Hörweite, sondern nur in Sichtweite befinden, dann sind Handbewegungen oft ein gutes Mittel, um sich über einfache Dinge zu verständigen: z. B. mit einer Telefoniergeste, dass man sich später noch anruft oder gleich eine SMS schreibt, mit einer Zeigegeste, dass man in eine bestimmte Richtung geht oder den Ort verlässt. Für Gehörlose, die visuelle Gebärdensprachen sprechen, stellen solche Orte kein Hindernis für eine komplexe Verständigung dar, solange sie sich nur wechselseitig sehen können.
Ein anderer Aspekt, der in solchen Kommunikations­ situ­at­ionen eine Rolle spielt, ist, dass wir uns und unseren Adressaten die Verständigung nicht unnötig erschweren wollen. So gibt es Dinge, die man beispielsweise besser mit Unterstützung der Hände erklären kann als ohne. Es stellt sich für die beteiligten Kommunikationspartner oft als kog­ nitiv einfacher heraus, da Gesten das Potential besitzen, unsere bildlichen und räumlichen Vorstellungen für jemand anderen raum-zeitlich zu verkörpern und dadurch zu visualisieren. Wegbeschreibungen und die Erklärung räumlicher Lageverhältnisse sind Beispiele, aber auch wie man bestimmte Handlungen ausführt und Objekte gebraucht.
Wenn man jemandem ohne Beteiligung der Hände erklären will, wie eine Schleife gebunden wird, dann kann das ziemlich kompliziert und umständlich werden. Wenn wir die Bewegung jedoch einfach nachahmen oder vormachen, dann ist dies für die meisten viel besser verständlich und einfacher nachvollziehbar. Wir können über die Beobachtung von redebegleitenden Gesten oft direkt „sehen“, was sich jemand vorstellt oder woran sich jemand erinnert. Um zu erklären, wie man beispielsweise ein Ikea-Regal zusammenbaut, haben alle Probanden, deren Beschreibungen im Forschungsprojekt MANUACT per Video aufgezeichnet wurden, nicht nur Wörter, sondern auch Gesten verwendet. Was Sprachwissenschaftler und Semiotiker an solchen Aufzeichnungen interessiert, ist, wie im Einzelnen Gesten und Lautsprache zusammenwirken und welche Strukturen und Muster man erkennen kann.

47

1  Das zeitliche Zusammenwirken von Gesten und lautlichem Sprechen

2  Das interaktive Exponat „Gestenpuzzle“ zum Erkunden des Miteinanders von Wörtern und Gesten

Gesten und Lautsprache wirken unterschiedlich eng zusammen
Diejenigen Handbewegungen, die man während des laut­ lichen Sprechens und begleitend zu diesem beobachten kann, sind auf unterschiedlichen Ebenen mit diesem verknüpft. Gesten sind in den Intonationsverlauf einer laut­ lichen Äußerung integriert und auf ihre „Sprechmelodie“ und Akzentsetzungen abgestimmt. Der Höhepunkt einer Geste fällt oft mit den starken Betonungen in einer lautlichen Äußerung zusammen. In einer Äußerung wie „DEN da meine ich!“ wird der gestische Höhepunkt der Zeigegeste mit dem stark betonten Pronomen den synchronisiert. Taktstockgesten, die so heißen, weil sie dem rhythmischen Schlagen des Pulses in der Musik ähneln, oder gestische Wiederholungen sind in der Regel zeitlich mit den Akzentsetzungen der lautlichen Äußerung koordiniert. Schon geringe zeitliche Verschiebungen werden als Irritation wahrgenommen.
Ein weiterer Aspekt der zeitlichen Koordination zwischen lautlicher Äußerung und Geste ist dadurch gegeben, dass sie sich auf gemeinsame Konzepte und Bedeutungen beziehen, diese aber unterschiedlich vermitteln. Dieses Miteinander von Gesten und Wörtern wird in der Ausstellung durch die beiden

interaktiven Exponate „Gestenpuzzle“ und „Verbwolke“ aufgegriffen, die in Zusammenarbeit mit dem Ars Electronica Futurelab (Linz) entstanden sind.
Das Gestenpuzzle vermittelt dem Besucher einen ersten Eindruck von einem multimodalen Zusammenwirken von Gesten und Lautsprache auf ganz unterschiedlichen Ebenen. Einer Videospur können dabei unterschiedliche Tonspuren zugeordnet werden, von denen allerdings nur eine richtig ist. Die passende Sequenz kann dadurch gefunden werden, dass man immer eine Tonspur auf das Video zieht, so dass beide Spuren schließlich synchron abgespielt werden. Das Gestenpuzzle setzt erste spielerische Impulse für eine Reflexion gestischer und lautlicher Muster, die den Ausgangspunkt für eine weitere Systematisierung im interaktiven Gestenlexikonfragment „Verbwolke“ bilden. Es macht erfahrbar, wie Gesten über den Rhythmus von Wörtern und Äußerungen mit diesen synchronisiert sind und dass sich der Inhalt des Gesagten auf die Koordination von Geste und Rede auswirkt, z. B. in der Weise, dass das als besonders wichtig Erachtete gestisch abgebildet und räumlich präzisiert wird.

3  Das interaktive Gestenlexikon „Verbwolke“

48

49

den Wortschatz im engeren Sinn hinaus. Bei den Gebärdensprachen der Gehörlosen werden die wortähnlichen Gebärden ebenfalls in einzelsprachlichen Lexika erfasst.
Ein weiteres wichtiges Anwendungsfeld eines Gestenlexikons – insbesondere zu Objektgebrauchsgesten – ist der Beitrag zur Gestaltung einer „intuitiven“ Gestensteuerung von digitalen Interfaces und autonomen Robotern, die für die Konzeption artifizieller Gesten in der Mensch-Maschine-Kommunikation von den natürlichen Gesten der zwischenmenschlichen Kommunikation ihren Ausgangspunkt nimmt.2

4  Stoppgeste zur Steuerung eines Roboters der Firma Kuka

Von der Geste zur Gestenanalyse: Wie blättert man in einem „Gestenlexikon“?
Wenn man in einem Wörterbuch des Deutschen blättert, dann sind die Einträge alphabetisch geordnet. Es geht um die Vermittlung sprachlichen Wissens zum Wortschatz einer Sprache. Wie kann man in gleicher Weise Gestenvokabulare sammeln und strukturieren? Eine alphabetische Liste ist ausgeschlossen, denn Gestenformen haben keine Anfangsbuchstaben. Deshalb bietet es sich an, einzelne Gesten nach bestimmten gestischen Analyseparametern wie Handform, Orientierung der Handfläche, Position im Gestenraum und Bewegung zu ordnen. Im interaktiven Exponat „Verbwolke“ wird das Zusammenwirken von Verben und Gesten anschaulich gemacht.
Wird der Bildschirm durch eine Berührung aktiviert, erscheinen 70 Verben (z. B. die Verben machen, schrauben, sägen, drehen, hineinstecken, anbringen, abhobeln), die je nach Vorkommenshäufigkeit größer oder kleiner dargestellt sind und sich auf dem Bildschirm verteilt langsam auf- und abbewegen. Die Verben sind anklickbar. Mit Klick auf ein Verb wird ein Video abgespielt, das Personen dabei zeigt, wie sie die Arbeit eines Stuhlbauers und den Zusammenbau eines Ikea-Regals in einzelnen Arbeitsschritten beschreiben.

Gesten machen dabei die inneren Vorstellungen von Vorgängen und Gegenständen sichtbar. Beispielsweise lassen sich zu Äußerungen des Verbs sägen unterschiedliche Perspektivierungen auf dasselbe Geschehen beobachten: Einige Probanden ahmen das Greifen einer Säge und das Hin- und Herbewegen nach, bei anderen wird die flache, ausgestreckte Hand selbst zum Werkzeug und repräsentiert die Säge gesamthaft. Wenn Besucherinnen und Besucher die Icons „Wortstamm“, „Handform“ und „Handform und Bewegung“ anklicken, können sie sich die Welt der Sprache interaktiv erschließen und selbst aktiv durchlaufen, was für Forschende unerlässlich ist: gruppieren und kategorisieren. Warum gibt es bei demselben lautsprachlichen Verb unterschiedliche Gestenvarianten? Verwenden verschiedene Sprecher dieselben Gesten? Welche Beziehungen bestehen zwischen verwandten Verben und verwandten Gesten? Was haben Verben wie sägen, absägen, durchsägen, zersägen gemeinsam? Unterscheiden sich die Gesten, und wenn ja, warum? Inwiefern sind nun diese Gesten verwandt? Warum sind einige „verwandter“ als andere? Eine Dokumentation existierender Repertoires von Objektgebrauchsgesten ist zum einen – wie andere Wörterbücher auch – von einem sprachwissenschaftlichen Erkenntnisinteresse geleitet und leistet einen Beitrag zur Erschließung des „Gestens­chatzes“ einer Sprache über

Anmerkungen 1 Siehe die Beiträge „Menschliche Hände als Vorbild für
robotische Hände?“ von Ulrike Thomas und „Mehr als ‚winke, winke‘: Gestenbedienung von Maschinen in modernen Lebenswelten“ von Angelika Bullinger-Hoffmann und Thomas Seeling in diesem Band. 2 Siehe den Beitrag „Die Vergangenheit in der Zukunft sehen: Zeichensprachen der Aborigines in Australien“ von Ellen Fricke in diesem Band.
Abbildungsnachweis 1 Foto: Dietmar Träupmann. 2–4 Fotos: Tobias Naumann, Technische Universität Chemnitz.

50

51

Gesten der zwischenmenschlichen
Kommunikation:
Ihre Vielfalt,
Eigenschaften und
Erforschung
Jana Bressem

Von der Geste zur Gebärde: Die Fülle kommunikativer Handbewegungen
Beobachten wir Menschen in der U-Bahn, Cafés oder im Park, dann sehen wir, dass nicht nur der Mund spricht, sondern der ganze Körper am Gespräch beteiligt ist. Denn gesprochene Sprache ist auf vielfältige Weise mit anderen Artikulatoren verflochten. Mit unserem Blick steuern wir die Aufmerksamkeit des Gegenübers. So können wir problemlos mit den Augen auf Orte und Personen im sichtbaren Umfeld verweisen und damit die Aufmerksamkeit des Gegenübers in diese Richtung lenken. Direkten Augenkontakt nutzen wir, um Interaktionen zu beginnen und in Gesprächen Rederollen festzulegen.1 Körperhaltung trägt zur Herstellung von Nähe und gemeinsamen Interaktionsräumen bei: Eine zugewandte Orientierung des Körpers ist deutlicher Ausdruck von Fokussierung aufeinander und damit Zeichen eines gemeinsamen Interaktionsraumes und Herstellung von Nähe. Die Abwendung des Körpers hingegen führt zu Abgrenzung und der Herstellung von Distanz.2 Wechselnde Körperhaltungen markieren aber nicht nur interpersonale Einstellungen und soziale Beziehungen, sondern zeigen auch auf der Ebene des Diskurses unterschiedliche Einheiten an. Veränderungen in der Körperhaltung,

nach vorn beugen beispielsweise, markiert den Wunsch zu sprechen.3
Die weitaus größte funktionale Bandbreite und Relevanz aller körperlicher Artikulatoren aber weisen Gesten, d. h. kommunikative Handbewegungen, auf. Diese lassen sich in drei große Klassen unterteilen: Gebärden der Gehörlosen, Embleme und redebegleitende Gesten.4 Mit Rückgriff auf eine Idee des Gestenforschers Adam Kendon aus dem Jahr 1988, dass Bewegungen der Hände je nach kommunikativer Situation und Anforderung unterschiedliche Eigenschaften ausprägen, ordnet der Gestenforscher David McNeill5 diese auf einer Skala an, die er mit Bezug auf den Anthropologen Adam Kendon das „Kendonsche Kontinuum“ nennt. Beim Kontinuum stellt McNeill die Tatsache ins Zentrum, dass sich kommunikative Handbewegungen darin unterscheiden, ob sie sprachliche Eigenschaften aufweisen und wie stark sie an die Anwesenheit von Sprache gebunden sind. Das 1992 in seinem Buch „Hand and Mind“ eingeführte Kontinuum erweitert McNeill in den folgenden Jahren um zwei weitere Aspekte, den Grad der Konventionalisierung und die Aspekte der Segmentierbarkeit und Kompositionalität,6 die er zur Charakterisierung und Unterscheidung von Handbewegungen heranzieht.

52

‚Gestik’

‚Leipzig’

‚Auto’

‚Technik’

1 bis 4  Gebärden der Deutsche Gebärdensprache für …

Auf der rechten Seite der Skala finden sich die Gebärden der Gehörlosen. Hierbei handelt es sich um voll ausgebildete grammatische Strukturen. Von unserer Lautsprache unterscheiden sich Gebärdensprachen lediglich darin, dass sie die visuell räumliche Modalität nutzen, sprich die Hände, das Gesicht und den Oberkörper und nicht die auditive Modalität. Von allen im Kontinuum abgebildeten Handbewegungen sind Gehörlosengebärden am stärksten sprachlich. Wie unsere Lautsprache verfügen sie über eine komplexe Lexik oder Syntax und stehen damit unseren Lautsprachen in nichts nach. Ähnlich wie bei Wörtern sind Form und Bedeutung von Gebärden konventionalisiert. Daher werden sie in Lexika aufgeführt, die neben der Form und der Ausführung auch die Bedeutung einer Gebärde festlegen. Vier Beispiele aus der Deutschen Gebärdensprache, verdeutlichen diese Eigenschaften und zeigen exemplarisch auf, dass die Zuordnung von Form und Inhalt, ähnlich wie bei Wörtern in der Lautsprache, auch in Gebärden Konventionen von Sprachgemeinschaften folgt und damit nicht zwangsläufig einen Zusammenhang zwischen der Form der Gebärde und dem damit verbundenen Inhalt erkennen lassen muss (vgl. Abbildungen 1 bis 4).
Die Abbildungen heben zudem hervor, dass Gebärdensprachen zur Herstellung von Form-Inhaltspaaren die Form der Hand, die Orientierung der Handfläche, die Bewegung der Hände und/oder die Positionierung der Hände im Gestenraum variieren. Diese Parameter, in den 1960er Jahren vom Sprachwissenschaftler William Stokoe7 eingeführt und später von Gebärdensprachlinguisten erweitert,8 erfassen Gebärden, in Analogie zur Lautsprache, als Bündel bedeutungsunterscheidender Merkmale. Mit Hilfe dieser Bündel

ist es möglich, ähnlich wie mit Morphemen in Lautsprachen, eine unendliche Anzahl neuer Gebärden zu bilden. Als vollständig eigenständige Sprachen sind Gebärdensprachen daher auch nicht auf das Vorkommen anderer Modalitäten, wie der Lautsprache, angewiesen. Gebärden werden also grundsätzlich unabhängig von Lautsprache gebraucht. Die Rede ist obligatorisch abwesend.
Weiter links auf der Skala angeordnet finden sich Em­ bleme. In seinem Buch “Gesture, Race and Culture” charakterisiert David Efron solche Handbewegungen als emblematisch, die “either a visual or a logical object by means of a pictorial or non-pictorial form” darstellen, aber keine Ähnlichkeit auf der Ebene der Form mit dem Referenzobjekt aufweisen.9 Die Efronsche Definition spitzen Ekman und Friesen in den 1970er Jahren zu. Embleme werden nun als “those non-verbal acts” verstanden, “which have a direct verbal translation, or dictionary definition, usually consisting of a word or two, or perhaps a phrase”.10 Mit der Bezeichnung “autonomous gestures”11 oder “quotable gestures”12 führt Adam Kendon in den 1980er Jahren eine weitere Bezeichnung ein, die herausstellt, dass es sich hierbei um Handbewegungen handelt, die ihren Weg in das Lexikon einer Sprache finden.13 Zusammengefasst lässt sich also festhalten, dass es sich bei Emblemen um Gesten handelt, die über stabile Form-Inhaltsbeziehungen verfügen und deren Bedeutung oft in einem Wort oder einer Phrase zusammengefasst werden kann. So können wir die Bedeutung der Schwurgeste mit dem Satz Ich schwöre versprachlichen. Im Falle der Victory-Geste handelt es sich um das Nomen Sieg oder Freude (vgl. Abbildung 6). Embleme haben zudem eine illokutionäre Kraft, die mit denen von verbalen

53

5  Schwurgeste

6  Victory-Geste im Sinne von Sieg und Freude

7  Victory-Geste im Sinne einer Beleidigung

Sprechakten, wie auffordern, schwören, beschwichtigen, verglichen werden können. Mit der Schwurgeste, im Rahmen einer öffentlichen Vereidigung zum Beispiel, wird die kommunikative Handlung des Schwörens ausgeführt und rechtskräftig (vgl. Abbildung 5). Die Ausführung emblematischer Gesten folgt dabei bestimmten Normen. Für die Schwurgeste haben deutsche Sprecher und Sprecherinnen die Wahl zwischen der Variante in Abbildung 5 oder der Variante, in der Daumen, Zeige- und Mittelfinger gestreckt werden. Für die Victory-Geste haben wir in Deutschland jedoch nur die Möglichkeit, die Geste wie in Abbildung 6 auszuführen. Die Bedeutung, die mit beiden Formen verbunden ist, ist deutschen Sprechern und Sprecherinnen bewusst. Allgemein lässt sich daher festhalten, dass die Form und Bedeutung emblematischer Gesten in einer Sprachoder Kulturgemeinschaft bekannt ist. Daher nutzen wir sie auch häufig ohne Rede. Durch ihre Konventionalisierung können Embleme zudem, wie Gebärden, in Lexika gesammelt werden. Weiterhin sind sie häufig sprach- und kulturspezifisch unterschiedlich und können so zu interkulturellen Missverständnissen führen. Die Victory-Geste im Sinne von Sieg oder Freude ist dadurch gekennzeichnet, dass der gestreckte Zeige- und Mittelfinger zu einem V geformt mit der Handfläche nach außen zeigt. Zeigt jedoch die Handfläche zum Körper hin, ändert sich die Bedeutung der Geste im englischen Sprachraum zu einer Beleidigung. Mit der Drehung der Handfläche geht also eine Bedeutungsveränderung einher (vgl. Abbildung 7 und die Abbildungen und Beispielanalyse in Fricke14). Obwohl emblematische Gesten auf den ersten Blick viele Eigenschaften mit Gebärden zu teilen scheinen (Konventionalisierung und Lexikalisierung)

und daher auf dem Kontinuum gleich links von ihnen angeordnet sind, unterscheiden sich beide Gestenklassen jedoch in einem grundlegenden Aspekt: Embleme lassen sich nicht zu komplexen Wörtern oder Sätzen kombinieren und haben daher, anders als Gebärdensprachen, keine grammatischen Strukturen auf der Ebene der Syntax.
Den linken Pol des Kontinuums bilden Handbewegungen, die am wenigsten sprachlich sind. Redebegleitende Gesten sind „kommunikative Bewegungen der Hände und Arme, die – ähnlich wie Sprache – dazu verwendet werden, die Gedanken, Gefühle und Intentionen eines Sprechers zum Ausdruck zu bringen und die soziale Ordnung des Gesprächs aktiv herzustellen.“15 Wie auch lautsprachliche Äußerungen ermöglichen sie Aussagen über Gegenstände in der Welt („Darstellung“), haben das Vermögen das Verhalten anderer zu regulieren („Appell“) und treffen Aussagen über den inneren Zustand des Sprechers („Ausdruck“) und erfüllen somit alle die vom Sprachwissenschaftler Karl Bühler aufgeführten Funktionen sprachlicher Zeichen.16 Mit Hilfe von Gesten können Sprecher Handlungen oder die Form und Größe von Gegenständen nachahmen oder das Gegenüber von der Ausführung kommunikativer Handlungen abhalten. Des Weiteren drücken Sprecher mittels Gesten affektive Zustände oder positive und negative Bewertungen aus. So markiert eine abwinkende Geste das lautsprachlich Ausgedrückte als uninteressant oder negativ besetzt. Zusammen mit der Lautsprache werden Gesten dabei als Bestandteile ein und desselben Äußerungs- und Produktionsprozesses verstanden. Rede und Geste sind so eng miteinander verbunden, dass sie “together as manifestations of the same process of utterance” erscheinen:17 “Gesture and

54

language are one system.”18 Redebegleitende Gesten sind sowohl strukturell als auch funktional eng mit der lautsprachlichen Äußerung verbunden. Die Bedeutung der Geste erschließt sich, anders als bei Emblemen, im Kontext des geäußerten Wortes. Weiterhin finden sich bei redebegleitenden Gesten keine derartigen Ausführungsstandards, wie dies für die beiden anderen Gestenklassen zu beobachten ist. Die Form einer redebegleitenden Geste, so McNeill, ist von Sprecher zu Sprecher verschieden, sprich idiosynkratrisch.
Neuere Ergebnisse aber zeigen, dass sich auch in redebegleitenden Gesten Form-Inhaltspaare identifizieren lassen, die über Sprecher und Kontexte hin stabil bleiben.19 Solche rekurrenten Gesten werden nicht im Moment des Sprechens hinsichtlich der Form spontan erzeugt, sondern bilden ein Repertoire konventionalisierter Gesten.20 Ein sehr bekanntes Beispiel ist die Geste der flachen Hand (vgl. Abbildung 8). Die Geste ist durch einen stabilen Formkern gekennzeichnet (die nach oben gerichtete Handfläche) mit Hilfe dessen Ideen, Argumente und andere Redegegenstände auf der offenen Hand präsentiert und dem Gegenüber zur Inspektion angeboten werden. Variationen im Bewegungsmuster der Geste (Bewegung nach unten, kreisende Bewegungen) führen zu Bedeutungsveränderungen.21 So dient die Bewegung nach unten der wiederholten Aufzählung, die kreisende Bewegung hingegen dazu, die Weiterführung der Argumente anzuzeigen. Weitere im Deutschen häufig dokumentierte rekurrente Gesten sind die Geste des Weghaltens mit Hilfe derer eigene oder fremde Redebeiträge oder Handlungsaufforderungen abgelehnt und abgewehrt werden können (vgl. Abbildung 8) oder auch die Ring-Geste, die u. a. dazu dient, Argumente als besonders präzise und relevant zu markieren (vgl. Abbildung 8). Form und Inhalt rekurrenter Gesten ist also ähnlich wie bei Em­ blemen für Sprach- und Kulturgemeinschaften festgelegt. Im Gegensatz zu Emblemen sind sie jedoch noch nicht lexikalisiert und können daher nicht in Wortgruppen oder Sätze übersetzt werden. Obwohl auch bei rekurrenten Gesten die Anwesenheit der Rede optional ist, sind sie dennoch, anders als Embleme, häufig durch eine enge Beziehung zur Lautsprache gekennzeichnet.22 So kann die Geste des Weghaltens nicht nur zur Abwehr von Argumenten genutzt werden, sondern auch zeitgleich mit dem Verb blocken oder stoppen gebraucht werden und damit die Bedeutung des Verbs verkörpern. Aufgrund der oben erwähnten Beispiele stellen rekurrente Gesten daher nicht die Handbewegungen dar, die am wenigsten sprachlich sind. Vielmehr wird der äußere linke Rand des Kontinuums durch eine weitere

Klasse redebegleitender Gesten aufgefüllt, nämlich die singulären Gesten.
Singuläre Gesten sind Bewegungen der Hände, die „im Moment des Sprechens erzeugt werden und eng mit kognitiven, affektiven und interaktiven Prozessen verbunden sind.“ 23 Sie sind stets auf Rede angewiesen und erhalten ihre Bedeutungszuschreibung durch ihren zeitlichen Bezug zur Lautsprache. Singuläre Gesten sind typischerweise Bestandteil lautsprachlicher Äußerungen und haben Einfluss auf den Inhalt der verbalen Äußerung, indem sie diesen semantisch und syntaktisch ergänzen und erweitern. So kann eine mit dem Zeigefinger gezeichnete Linie die Form eines konkreten oder abstrakten Weges, wie einer beruflichen Karriere, anzeigen.24 Ein mit beiden Zeigefingern gezeichneter Kreis kann die verbale Äußerung der neue Tisch und dabei insbesondere das Nomen des Satzes (Tisch) ähnlich wie lautsprachliche Adjektive um die Eigenschaft der Formqualität ergänzen (rund).25 Das Potential für diese diversen Funktionen ziehen singuläre Gesten aus der Eigenschaft mit der Lautsprache semantisch koexpressiv zu sein, indem sie das gleiche Konzept zur gleichen Zeit, jedoch in ihrer modalitätspezifischen Charakteristik übermitteln.26 So eignen sich Gesten besonders gut dazu, Formeigenschaften, räumliche Verhältnisse oder Größeninformationen zu übermitteln. Hierbei sind singuläre Gesten eng mit bestimmten Abschnitten der Rede verbunden und überschneiden sich zeitlich häufig mit einem Wort oder einer Phrase in der verbalen Äußerung, die als lexikalischer Bezugspunkt für die Geste und die in ihr übermittelte Bedeutung verstanden werden kann. Zudem sind singuläre Gesten häufig durch verbale Zeigwörter, wie hier und dort oder Adverbien wie so oder son direkt in die Rede eingebunden.27 Als zusätzliche Elemente lautsprachlicher Äußerungen und als “a partner with speech in the utterance as finally constructed”28 erlauben sie ferner die Darstellung von zusätzlichen, in der verbalen Äußerung nicht enthaltenen Aspekten. Mit diesen Eigenschaften stellen singuläre Gesten den äußeren Rand des Kontinuums dar, da sie von allen kommunikativen Handbewegungen am wenigsten sprachlich und am stärksten auf die Anwesenheit von Lautsprache angewiesen sind.
Mit der Unterteilung redebegleitender Gesten in singuläre und rekurrente Gesten ist jedoch eine Revision des von McNeill vorgeschlagenen Kontinuums notwendig,29 die der Tatsache Rechnung trägt, dass in Handbewegungen hörender Sprecher und Sprecherinnen unterschiedliche Stufen der Konventionalisierung und Lexikalisierung auszumachen sind.

55

8  Konventionalisierte Gesten des Deutschen: Embleme und rekurrente Gesten

In der Ausstellung heben Zeichnungen des Berliner Künstlers Mathias Roloff30 die Flüchtigkeit und Vielfalt und die besondere visuelle Ästhetik singulärer Gesten im drei­ dimensionalen Raum hervor. Sie sind im Rahmen langjähriger Zusammenarbeit mit der Gestenforscherin Cornelia Müller entstanden und stellen auf wissenschaftlich-künstlerische Weise die Besonderheit redebegleitender Gesten dar. In Alginat gegossene emblematische und rekurrente Gesten, die aus der Wand herausragen, stellen wiederum die Besonderheit dieser beiden Gestenklassen ästhetisch in den Vordergrund (vergleiche Abbildung 9). Für das Deutsche typische Exemplare machen dem Besucher insbesondere die standardisierte und konventionalisierte Zuordnung von Form und Inhalt bei den Gesten deutlich und schärfen den Blick für die Verdauerung und Verbindlichkeit der Gesten, die ihnen aufgrund von Formstandards und festen Bedeutungen in Sprach- und Kulturgemeinschaften zukommt.
Gestische Darstellungsweisen: Wie Hände zu Gesten werden
Macht man sich die Vielfalt gestischer Darstellung bewusst, so stellt sich unweigerlich die Frage, wie die Hände als Artikulationsorgan in der Lage sind, eine solche Formen- und

Bedeutungsvielfalt auszubilden. Mit Bezug auf die Gestenforscherin Cornelia Müller31 lassen sich vier Grundformen gestischer Darstellung unterscheiden, die grundlegende Techniken der Hände zur Herstellung ges­tischer Zeichen erfassen: Agieren, Zeichnen, Modellieren und Repräsentieren. Im Modus „Agieren“ ahmen die Hände tatsächliche Handlungen nach, wie z. B. beim Hämmern, Schneiden, Türöffnen oder Wegwischen. „Zeichnen“ die Hände, skizzieren sie die Umrisslinie von Objekten oder Bewegungsverläufen im Raum und lassen somit eine zweidimensionale flüchtige Darstellung entstehen. „Modellieren“ die Hände hingegen, kreieren sie eine dreidimensionale Darstellung wie die einer Schale oder Kugel. Im Modus „Repräsentieren“ ahmen die Hände nicht mehr Handlungen der Hand nach, sondern werden selbst zum Objekt und verkörpern dieses als Ganzes. So kann die flache Hand bspw. ein Auto darstellen oder der ausgestreckte Zeigefinger einen Stift. Die Wahl der Darstellungsweise erfolgt dabei nicht willkürlich, sondern ist gezielt auf kommunikative Zwecke und das Ziel der gestischen Nachahmung abgestimmt. Die einzelnen Darstellungsweisen implizieren somit eine bestimmte Orientierung des Sprechers auf Dinge und Handlungen in der Welt. Aber – und das macht die einzelnen Darstellungsweisen nicht nur für Fragen der gestischen Bedeutungs-

56

9  Gestische Darstellungsweisen nach Cornelia Müller in der Interviewpassage mit einem Chemnitzer Buchbinder

konstruktion, sondern auch als „Fenster zum Denken“,32 als Einblick in Denkprozesse so interessant – sie zeigen die Orientierung und den Fokus des Sprechers bezogen auf die darzustellenden Handlungen und Dinge. Daher sind die unterschiedlichen Weisen der Darstellung “subtle variable conceptualizations of a perceived reality – designed for and triggered by the purposes of communication at a given moment in the flow of interaction.”33
Diese Eigenschaften gestischer Darstellungsweisen lassen sich gut am Beispiel einer Interviewpassage mit einem Chemnitzer Buchbinder illustrieren, in der die Handhabung verschiedener Vergoldewerkzeuge bei der Tätigkeit des Vergoldens beschrieben wird. Der Buchbinder führt zu Beginn seiner Erläuterung parallel zur verbalen Äußerung man muss sich das so vorstellen wie einen Stempel mit der Darstellungsweise „Agieren“ zunächst den Gegenstand ein, indem er so tut, als würde er den Stempel mit seiner linken Hand greifen (vgl. Abbildung 9). Im Anschluss daran geht er auf bestimmte Teile des Stempels ein und führt aus, dass dieser Stempel unten keine Gummiplatte dran hatte, sondern ein graviertes Ornament aus Messing. Parallel zur verbalen Äußerung unten keine Gummiplatte dran hatte hält die linke Hand noch immer den Stempel. Die rechte Hand kommt hinzu und repräsentiert als Ganzes die unten am Stempel befes-

tigte Gummiplatte. Die flache Hand ahmt nicht, anders als die linke Hand, eine Handlung nach, sondern steht für das flache Objekt, oder vereinfacht ausgedrückt, die rechte Hand wird zur Gummiplatte. Zeitgleich mit der Äußerung sondern ein graviertes Ornament aus Messing beginnt der Zeigefinger der rechten Hand einen Kreis zu zeichnen. Im Darstellungsmodus „Zeichnen“ skizziert er die Umrisslinie des Messingornaments. Ähnlich wie ein Stift lässt er so eine flüchtige Linie im Gestenraum entstehen. Zum Ende seiner Beschreibung führt der Buchbinder aus: Und zu guter Letzt gehörten noch Werkzeuge, sogenannte Fileten, dazu … auch wieder Handstempel in einer Größe, dass unten wie ein kleiner Bogen dran war. Hier wechselt nun die Aufteilung der Hände: Die rechte Hand hält nun den Handstempel und ahmt erneut im Darstellungsmodus „Agieren“ das Festhalten des Stempels nach. Die linke Hand, die leicht gebogen ist, modelliert durch kleine gebogene Bewegungen den unten am Stempel befestigten Bogen. Durch die Handform und die Bewegung erschafft die Hand eine dreidimensionale Darstellung des Bogens (vgl. Abbildung 934).
Das Beispiel zeigt mit dieser Abfolge sehr eindrücklich, dass mit der Wahl jeder Darstellungsweise ein spezifischer Blick auf den darzustellenden Gegenstand verbunden ist. Die Wahl der Darstellungsweise erfolgt dabei nicht willkür-

57

10  Gestische Bewegungsphasen aus einem Interviewausschnitt mit einer Chemnitzer Töpferin

lich, sondern ist gezielt auf kommunikative Zwecke und das Ziel der gestischen Nachahmung abgestimmt. Die Modi der Darstellung sind also ein gestischer Blick auf die Welt. So werden im Darstellungsmodus „Agieren“ bedeutungstragende Teile eines Handlungsschemas isoliert. Im Modus „Modellieren“ hingegen werden bedeutungstragende Teile einer Oberflächengestalt herausgelöst. Der Modus „Zeichnen“ ist durch die Isolierung bedeutungstragender Formen oder Linien eines Objekts gekennzeichnet, und im Darstellungsmodus „Repräsentieren“ haben wir es mit der Konzeptualisierung der charakteristischen Gestalt eines Objekts als Ganzes zu tun.35 Ein Objekt kann dabei, das zeigt das Beispiel des Buchbinders sehr eindrücklich, mit allen vier Modi verkörpert werden und lässt so einen umfassenden Eindruck vom Gegenstand und dessen Handhabung im Gestenraum entstehen.
Gestenphasen: Gestische Bewegung und ihre Strukturierung in der Zeit
Ebenso wie Lautsprachen erstrecken sich redebegleitende Gesten in der Zeit. Anders als Lautsprache aber sind sie nicht auditiv und eindimensional, sondern hinterlassen vi-

suell wahrnehmbare Bewegungsspuren im dreidimensionalen Raum. Dabei zeigen Gesten einen zeitlichen Verlauf, auf den Forscher bereits zum Ende des 19. Jahrhunderts hingewiesen haben. So hebt Edward Amherst Ott in seinem Buch „How to gesture“36 hervor, dass jede Geste in drei wesentliche Bewegungssegmente zu unterteilen sei: Um einen bedeutungstragenden Kern, dem Bedeutungshöhepunkt, herum finden sich Aufbau- und Rückzugsphasen. Die erste systematische Beschreibung der zeitlichen Struktur gestischer Bewegungen legt Adam Kendon in seinem Aufsatz „Gesticulation and speech: Two aspects of the process of utterance“37 vor. Basierend auf der Beobachtung, dass gestische Bewegungen, die mit der Rede einhergehen, eine hierarchische Anordnung aufweisen, die auf die Anordnung verbaler Einheiten abgestimmt ist, identifiziert Kendon fünf grundlegende gestische Bewegungsphasen: Ruheposition, Vorbereitung, Kern („stroke“), Haltephase, Rückzug.
Diese gestischen Bewegungsphasen werden den Besuchern in der Ausstellung anhand eines Interviewausschnitts nahegebracht, in dem eine Chemnitzer Töpferin die Arbeitsschritte zur Herstellung eines Henkels beschreibt. Standbilder und in Alginat abgeformte Hände stellen prägnante gestische Bewegungssegmente dieser Sequenz dar und machen den Besucher einerseits auf die unterschied-

58

11  Nahaufnahme einzelner gestischer Bewegungsphasen und Handkonfigurationen aus einem Interviewausschnitt mit einer Chemnitzer Töpferin

lichen Gestenphasen und ihre Charakteristika, andererseits auf die lineare und simultane Komplexität multimodaler Äußerungen aufmerksam (vgl. Abbildungen 10 und 11).
Zu Beginn gestischer Bewegungen befinden sich die Hände in vollständiger Ruhe und bewegen sich nicht. Sie verharren in einer Ruheposition. Häufig legen sitzende Sprecher die Hände in den Schoß oder auf die Armlehne. Stehende Sprecher lassen die Arme oft seitlich am Körper herunterhängen. Der Phase der Ruhe schließt sich eine Vorbereitungsphase an, in der die Hände sich in Bewegung setzen, in eine Position vor dem Körper des Sprechers gebracht werden und somit die Durchführung der nächsten Phase, den Kern der Geste, vorbereiten. Im Laufe der Vorbereitungsphase bildet sich dabei die Handform aus, die im Kern der Geste dann klar und deutlich zu erkennen ist. Beide Phasen sind deutlich in der Töpfersequenz zu erkennen. Die Sequenz, die die einzelnen Schritte zur Henkelherstellung in ihrer Abfolge wiedergibt, beginnt mit einer kurzen Thematisierung der zu treffenden Vorbereitungen, in der, begleitend zur verbalen Äußerung nehme ich einen Klumpen, die Hände in einer Ruheposition sind. Parallel mit dem Nomen ‚Ton‘ setzen sich die Hände der Sprecherin in Bewegung, um den Kern der Geste vorzubereiten. In dieser Phase beginnen sich die Handformen auszubilden. Der

stroke, der Bewegungshöhepunkt, ist der eigentlich bedeutsame Teil einer Geste und folgt der Vorbereitung. Er geht in der Regel mit lexikalischen Bezugswörtern einher, die als das lautliche Äquivalent des Kerns verstanden werden können. Im Bewegungshöhepunkt haben die Hände die größte artikulatorische Freiheit. Die Hände werden in vielfältiger Art und Weise geformt und bewegt und greifen auf eine der oben genannten gestischen Darstellungsweisen zur Übermittlung gestischer Bedeutung zurück. In unserem Beispiel der Chemnitzer Töpferin zeigt sich dies schön begleitend zum Nomen ‚Wulst‘. In diesem stroke sind beide Hände klar und deutlich geformt und modellieren durch eine gleichförmige Bewegung der Hände eine röhrenähnliche Form, eine Wulst. Einem Kern kann sich eine weitere bedeutungstragende Gestenphase anschließen, die im Gegensatz zum stroke durch das Fehlen von Bewegung gekennzeichnet ist: die Haltephase. In dieser Phase verharren die Hände in der Position, die sie am Ende des strokes eingenommen haben und warten, wie der Gestenforscher Sotaro Kita38 es formuliert, auf die Rede. Dadurch erweitern Haltephasen die zeitliche Dauer des Kerns und erlauben es Sprechern, Rede und Geste so zu synchronisieren, dass beide Modalitäten gleichzeitig und im Zusammenspiel ein Konzept übermitteln können. Begleitend zur verbalen Äußerung und halte ihn mit der linken Hand

59

12  Darstellung des gestischen Radius

tatsächlichen Handlung zu verkörpern. Erst danach bewegen sich die Hände parallel zur Äußerung äh das nennt man vorziehen eines Henkels über eine Rückzugsphase in die Ruheposition zurück. Die rechte Hand nimmt eine entspannte Position an der Seite des Körpers ein, während die linke vor dem Körper verweilt.
Das Beispiel der Töpferin illustriert neben den unterschiedlichen Phasen noch eine weitere Eigenschaft gestischer Bewegungssegmente, nämlich die Tatsache, dass die jeweiligen Phasen in bestimmter Weise mit der lautsprachlichen Äußerung verbunden sind. Während Ruhe- als auch Haltepositionen dazu tendieren, längere verbale Einheiten zu umspannen, neigen Kerne dazu, kürzere Einheiten, wie einzelne Wörter oder Phrasen, einzuschließen.
Redebegleitende Gesten sind somit als Bewegungen im Raum und in der Zeit strukturiert und unterschiedlich komplex. Zum einen lassen sich gestische Bewegungsabläufe in einzelne Phasen segmentieren, zum anderen bilden redebegleitende Gesten Einheiten unterschiedlicher Größe und Komplexität, die von kleineren gestischen Phrasen bis hin zu größeren „gesture units“39 reichen und mit lautsprachlichen Syntagmen auf bestimmte Weise verbunden sind.40

nach oben ermöglicht diese Abstimmung zeitlich synchron die Verbalisierung und Verkörperung der Handlung des Festhaltens. Nach Ausführung eines Kerns und/oder einer Haltephase bewegen sich die Hände in Richtung Ruheposition zurück und die bisher klar und deutlich zu erkennende Handform löst sich auf.
Die Abfolge von Ruheposition zu Vorbereitung, Kern, Rückzug und wiederum Ruheposition stellt einen idealtypischen gestischen Bewegungsverlauf dar und wird von Adam Kendon als „gesture unit“ bezeichnet. Viel häufiger aber bereiten die Hände nach einem Kern die Ausführung eines oder sogar mehrerer Kerne vor, sodass sich eine Reihe unterschiedlicher Vorbereitungsphasen mit Höhepunkten abwechseln können. Diese Einheiten bezeichnet Kendon als „gesture phrases“. Eine solche komplexe Abfolge von Vorbereitungen und Kernen folgt unserem Beispiel der Haltephase. Begleitend zur verbalen Äußerung und mit Wasser äh ziehe ich den Strang immer in solchen Bewegungen rechts und links, äh dass er sich äh nach unten verjüngt und eben diese grobe Form annimmt führt die Töpferin sukzessive hintereinander jeweils drei Vorbereitungen und Kerne aus, in denen die zuvor begonnene röhrenähnliche Form, die Wulst, sprachlich als auch gestisch weiter ausdifferenziert wird. Die Abfolge erlaubt es der Sprecherin, die Iterativität der

Video, Motion Capture und Annotation: empirische Zugänge zu Gesten
Wie gelingt es nun, diese lineare Komplexität für wissenschaftliche Untersuchungen empirisch aufzubereiten und aufzubrechen? Hierfür muss es möglich sein, Rede und Geste in ihrem zeitlichen Zusammenspiel analysieren zu können. Pionieren der Gestenforschung, wie John Bulwer41 oder Andrea de Jorio42, war dies nicht vergönnt. Da technische Geräte zur Aufzeichnung fehlten, griffen sie auf Zeichnungen und verbale Beschreibungen, die auch in der Ausstellung zu sehen sind, zurück. Erst technische Neuerungen des 20. Jahrhunderts wie Fotografie und Filmaufnahmetechnik legten den Grundstein für die Verdauerung und das Festhalten gestischer Bewegungen in ihren natürlichen Interaktionszusammenhängen und eröffneten damit neue Möglichkeiten der Analyse sprachlicher Multimodalität.
Als Erster macht sich David Efron diesen technischen Fortschritt in einer Untersuchung aus den 1930er Jahren zu Nutze, in der er aus einer vergleichenden Perspektive das Gestenverhalten assimilierter und nicht-assimilierter osteuropäischer Juden und süditalienischer Einwanderer in New York untersucht. Efrons Untersuchung ist die erste empi-

60

rische Studie, die auch auf Filmaufnahmen beruht. Dies erlaubt es Efron, Gesten in ihrem Verlauf zu erfassen und gestische Bewegung empirisch zugänglich zu machen. Efron analysiert daher detailliert gestische Bewegungsverläufe. Dabei konzentriert er sich u. a. auf die Bewegungstypen und -richtungen, den Radius der Bewegung und auch das Tempo sowie die Dauer der Geste.43 Seine Ergebnisse hält er u. a. in Form von Zeichnungen fest (vgl. Abbildung 12).
Für die Detailanalyse macht sich Efron eine Technik zunutze, die heute Standard in Analysen redebegleitender Gesten ist: Um die Entwicklung der Geste nachzuverfolgen, schaut er sich in mühsamer Arbeit die Einzelbilder eines Films an. Heutige Forscher sind in einer komfortableren Position: Annotationsprogramme, Software eigens für die Analyse von Gebärden und Gesten entwickelt, erlauben es, Video- und Tonmaterial einzubeziehen, Ebenen der Analyse festzulegen und so detailliert das Zusammenspiel von Rede und Geste zu erfassen. Das wohl bekannteste Beispiel ist das Annotationsprogramm ELAN, das am Max-Planck-Institut in Nijmegen entwickelt wurde und als open source-Programm der Forschergemeinschaft zur Verfügung steht.44 Im Forschungsprojekt MANUACT,45 aus dem zahlreiche der in

der Ausstellung zu sehenden Exponate hervorgingen, wurde das Annotiationsprogramm u. a. zur Analyse des Verhältnisses von Handlungsverben und Gesten verwendet. Mit Hilfe des Programms war es u. a. möglich, gezielt Formen und Varianten redebegleitender Gesten und die strukturelle Korrelation von Rede und Geste auf unterschiedlichen Analyseebenen zu erfassen (vgl. Abbildung 13).
Zusätzlich zu diesen visuellen Beschreibungen gestischer Bewegungsverläufe profitiert die Multimodalitätsforschung in den letzten Jahren von weiteren technischen Entwicklungen, wie dem Motion-Capture. Mit Hilfe von Markern, kleinen reflektierenden Kugeln, die auf der Kleidung und am Körper von Sprechern angebracht sind und mit Infrarotlicht angestrahlt werden, ist es möglich, die Reflexionen der Marker mit Kameras aufzunehmen, 3D-Bilder zu berechnen und so die Bewegung der Gesten und die Positionierung und Entfernung der Hände voneinander technisch zu modellieren. Eine künstlerische Umsetzung dieses Analyseverfahrens findet sich in der Ausstellung im Kubus der Künstlerin Anette Rose. Der begehbare Kubus macht die Modellierung der Bewegungsspuren für den Besucher begehbar und erfahrbar.

13  Ausschnitt aus einer ELAN-Annotation des Forschungsprojekts „MANUACT – Hands and Objects in Language, Culture, and Technology: Manual Actions at Workplaces between Robotics, Gesture, and Product Design“
61

Anmerkungen 1 Vgl. Argyle, Michael u. a.: The Different Functions of Gaze.
New York 1984. 2 Vgl. Argyle, Michael: Bodily Communication. London/New
York 1975. 3 Vgl. Kendon, Adam: Some relationship between body motion
and speech. In: Seigman, Aron; Pope Benjamin (Hg.): Studies in Dyadic Communication. Elmsford, New York 1972, S. 177– 216. 4 McNeill unterscheidet zudem noch die Pantomime, die hier nicht näher besprochen werden soll. 5 McNeill, David: Hand and Mind. What Gestures Reveal About Thought. Chicago 1992. 6 Ders.: Gesture and Thought. Chicago 2005 sowie ders. (Hg.): Language and Gesture. Cambridge 2000. 7 Stokoe, William: Sign Language Structure. Buffalo 1960. 8 Vgl. Klima, Edward S.; Beluggi, Ursula: The Signs of Language. Cambridge 1979. 9 Efron, David: Gesture, Race and Culture. Paris/Den Haag [1941] 1972, S. 96. 10 Ekman, Paul; Friesen, Wallace V.: The repertoire of nonverbal behavior: Categories, origins, usage, and coding. In: Semiotica 1 (1969), S. 49–98. 11 Kendon, Adam: Gesture and speech: how they interact. In: Wiemann, John M. (Hg.): Nonverbal Interaction. Beverly Hills 1983, S. 13–46. 12 Kendon, Adam: Did gesture have the happiness to escape the curse at the confusion of Babel. In: Aaron, Wolfgang (Hg.): Nonverbal Behavior: Perspectives, Applications, Intercultural Insights. Lewiston/New York 1984, S. 75–114. 13 Ders.: Gesture: Visible Action as Utterance. Cambridge 2004. 14 Fricke, Ellen: Phonaestheme, Kinaestheme und multimodale Grammatik. Sprache und Literatur 41 (2010). S. 69 f. sowie "Freude und Sieg: Die Victory-Geste" von Jana Bressem, in diesem Band. 15 Müller, Cornelia: Redebegleitende Gesten: Kulturgeschichte, Theorie, Sprachvergleich. Berlin 1998. 16 Vgl. ebd. 17 Kendon, Adam: Gesticulation and speech: Two aspects of the process of utterance. In: Key, Mary Ritchie (Hg.): Nonverbal Communication and Language. Den Haag 1980, S. 207–227. 18 McNeill (wie Anm. 5), S. 2. 19 Vgl. Ladewig, Silva H.: Putting the cyclic gesture on a cognitive basis. In: CogniTextes 6 (2011) sowie Müller, Cornelia: Wie Gesten bedeuten. Eine kognitiv-linguistische und sequenzanalytische Perspektive. In: Sprache und Literatur 41 (2010), S. 37–68.

20 Vgl. Bressem, Jana; Müller, Cornelia: A repertoire of recurrent gestures of German. In: Müller, Cornelia u. a. (Hg.): Body – Language – Communication. An international Handbook on Multimodality in Human Interaction, Bd. 2. Berlin/Boston 2014, S. 1575–1591.
21 Vgl. Kendon (wie Anm. 13) sowie Müller, Cornelia: Forms and uses of the Palm Up Open Hand. A case of a gesture family? In: Müller, Cornelia; Posner, Roland (Hg.): Semantics and Pragmatics of Everyday Gestures. Berlin 2004, S. 233–256.
22 Vgl. Ladewig, Silva H.: Recurrent gestures. In: Müller, Cornelia u. a. (Hg.): Body – Language – Communication. An international Handbook on Multimodality in Human Interaction, Bd. 2. Berlin/Boston 2014, S. 1558–1574.
23 Vgl. Müller (wie Anm. 18). 24 Vgl. ebd. 25 Vgl. Fricke, Ellen: Grammatik multimodal: Wie Wörter und
Gesten zusammenwirken. Berlin 2012. 26 Vgl. McNeill (wie Anm. 5) sowie ders. (Anm. 6). 27 Vgl. Fricke (wie Anm. 24). 28 Kendon (wie Anm. 13). 29 Vgl. Fricke (wie Anm. 24) sowie Müller (wie Anm. 18). 30 Online unter www.mathiasroloff.de (10.02.2018). 31 Müller (wie Anm. 14). 32 McNeill, David; Duncan, Susan: Growth points in thin-
king-for speaking. In: McNeill, David (Hg.): Language and Gesture. Cambridge 2000, S. 141–161. 33 Müller, Cornelia; Bressem, Jana; Ladewig, Silva H.: Towards a grammar of gesture: A form-based view. In: Müller, Cornelia u. a. (Hg.): Body – Language – Communication: An international Handbook on Multimodality in Human Interaction. Bd. 1, Berlin/Boston 2013, S. 713. 34 Siehe die Beispielanalysen zum Chemnitzer Buchbinder in Fricke, Ellen: Hands and Objects in Language, Culture, and Technology. Manual Actions at Workplaces between Robotics, Gesture, and Product Design (MANUACT). BMBF-Statustagung. Bonn, 26.10.2015. 35 Vgl. ebd. sowie dies.: Gestural Modes of Representation as techniques of depiction. In: Müller, Cornelia u. a. (Hg.): Body – Language – Communication. An international Handbook on Multimodality in Human Interaction, Bd. 2. Berlin/Boston 2014, S. 1687–1702. 36 Ott, Edward A.: How to Gesture. New York City [1892] 1902. 37 Kendon (wie Anm. 15). 38 Kita, Sotaro: The Temporal Relationship between Gesture and Speech: A Study of Japanese-English Bilinguals. Chicago 1990. 39 Kendon (wie Anm. 12). 40 Siehe auch Fricke (wie Anm. 23) sowie Müller u. a. (wie Anm. 31).

41 Bulwer, John: Chirologia: Or the Natural Language of the Hand. And: Chironomia. Or the Art of Manual Rhetoric (London 1644). Edited with an Introduction by James W. Cleary. Carbondale/ Edwardsville 1974.
42 De Jorio, Andrea: Gesture in Naples and Gesture in Classical Antiquity. A translation of La mimica degli antichi investigata nel gestire napoletano (Fibreno, Naples 1832) and with an introduction and notes by Adam Kendon. Bloomington/Indianapolis 2000.
43 Vgl. Efron, David: Gesture, Race and Culture. Paris/ Den Haag [1941] 1972.
44 Wittenburg, Peter u. a.: ELAN: A Professional Framework for Multimodality Research. Proceedings of LREC 2006, Fifth International Conference on Language Resources and Evaluation.
45 Online unter www.manuact.org (10.02.2018).
Abbildungsnachweis 1–4 Vokabelheft des allgemeinen Gebärdenwörterbuchs der Uni-
versität Hamburg, online unter www.sign-lang.uni-hamburg.de/alex/ (16.06.2018). 5–7 Zeichnungen: Uliana Schöller. 8–9 Fotos: Dietmar Träupmann. 10–11 Fotos: Tobias Naumann. 12 Efron, David: Gesture, Race and Culture. Paris/Den Haag [1941] 1972, S. 147. 13 MANUACT-Projekt, TU Chemnitz.

62

63

Freude und Sieg:
Die Victory-Geste

Jana Bressem

Die Neue Osnabrücker Zeitung1 hat sie für veraltet erklärt: Die Victory-Geste, bei der die gestreckten Zeige- und Mittelfinger zu einem V geformt mit der Handfläche nach außen Freude oder Sieg ausdrücken. Diese Geste, so die Zeitung, wäre aus der Mode gekommen und die Menschen ihrer überdrüssig: Viel zu häufig hätte man sie benutzt, auf fast jedem Selfie sei sie zu sehen und zu oft sei sie falsch gebraucht. So wie von Josef Ackermann, dem ehemaligen Chef der Deutschen Bank und wegen Vorwurfs der Untreue 2004 vor Gericht (vgl. Abbildung 1). Zu Beginn des Prozesses lichtet ihn ein Fotograf mit der Geste ab und Presse und Politik sind sich einig: Die Geste und der fröhliche Gesichtsausdruck sind Ausdruck der Arroganz Ackermanns und verhöhnen den Prozess und das Gericht. Später wird jedoch deutlich, dass die Geste aus ihrem Kontext herausgenommen wurde, sich nicht auf den Prozess bezog und somit ein solcher Eindruck nicht von ihm intendiert war.
Die Victory-Geste ist eines von zahlreichen Beispielen für Embleme: Gesten, die über stabile Form-Inhaltsbeziehungen verfügen, deren Bedeutung oft in einem Wort oder einer Phrase zusammengefasst werden kann und die zudem häufig sprach- und kulturspezifisch unterschiedlich sind und so zu interkulturellen Missverständnissen führen können (vgl. den Beitrag „Gesten der zwischenmenschlichen

1  Josef Ackermann führt die Victory-Geste aus
Kommunikation: Ihre Vielfalt, Eigenschaften und Erforschung“, in diesem Band). Diese Eigenschaften erwecken schnell den Eindruck, als wisse man um die Bedeutung und den richtigen Gebrauch der Geste. Doch zeigt gerade die Victory-Geste, wie komplex der Zusammenhang von Form, Bedeutung und Gebrauch sein kann. Ein Grund, warum die Gestenklasse der Embleme besonders für Fragen nach der Herkunft und Entstehung von Gesten, Konventionalisierungs- und Lexikalisierungsprozessen sowie Fragen des Bedeutungswandels in Gesten interessant ist.

64

2  Verteilung der Victory-Geste mit der Bedeutung ‚Sieg‘ im europäischen Raum

Aus der Reihe der Embleme gehört die Victory-Geste sicherlich zu den bekanntesten weltweit. Im Sinne von Sieg ist sie dabei nicht nur in Europa verbreitet (vgl. Abbildung 2), sondern in weiten Teilen der Welt bekannt. Daher wird die Geste in allen existierenden Lexika emblematischer Gesten aufgeführt. Am ausführlichsten stellen sie Morris und Kollegen2 in ihrer Dokumentation „Gestures, Their Origins and Distribution“ vor. Auf Grundlage einer dreijährigen Feldstudie, in der 20 emblematische Gesten mit 1200 Informanten aus 40 Orten, 25 Ländern und 15 Sprachen Europas untersucht wurden, charakterisieren Morris und Kollegen die Victory-Geste hinsichtlich ihrer Form, Bedeutung, Herkunft und Verbreitung und zeigen auf, wie stark die Geste mit kulturellen, gesellschaftlichen und historischen Wandlungsprozessen verbunden ist.
Ihren Siegeszug und auch ihre bekannteste Bezeichnung hat die Geste in den Jahren ab 1945 durch Premierminister Winston Churchill erfahren: als Zeichen für den Sieg über

Nazideutschland. Seither ist sie eng mit der Bedeutung im Sinne von Sieg verbunden. Ihren Kern, so eine Erklärung, bezieht die Geste dabei aus einer ikonischen Beziehung zwischen der Form der Geste (gestreckter Zeige- und Mittelfinger) und dem Buchstaben V, wie im englischen Wort für Sieg (victory): Die Finger repräsentieren, verkörpern also den Anfangsbuchstaben (siehe Frickes Beitrag zum analogen und virtuellen Modellieren, in diesem Band).
Dieser Sinn geht auf die Idee eines belgischen Politikers aus dem Jahr 1941 zurück. Unzufrieden mit bestehenden Zeichen des Widerstandes erfand Victor de Laveleye die Geste als ein leicht verständliches und sprachübergreifendes Symbol für den Kampf gegen die deutsche Besatzung: Das mit den Fingern gebildete V als Anfangsbuchstabe für das englische victory, das niederländische vrijheid oder das französiche victoire. Winston Churchill greift das Handzeichen auf und macht die Geste damit weltweit bekannt.

65

Simultane Komplexität in Gesten

Weniger bekannt, aber für sprachwissenschaftliche Fragen besonders interessant ist, dass Winston Churchill die Geste zu Beginn nicht nur in der standardisierten Form ausgeführt hat, sondern auch mit einer Formveränderung, nämlich der Handfläche nach innen (vgl. Abbildung 3).
Eine folgenschwere Entscheidung, denn mit dieser Formvariante ist ein anderer Inhalt verbunden: In England gilt der nach außen gerichtete Handrücken als obszöne Beleidigung. Mit der Änderung der Handfläche geht also eine Bedeutungsveränderung einher. Hier sehen wir eine Eigenschaft in Gesten, die wir aus der Lautsprache unter dem Konzept der Minimalpaarbildung kennen: In Wörtern wie Laus, Maus oder Haus resultiert aus der Änderung des Anlauts eine Bedeutungsunterscheidung. Ähnlich verhält es sich mit der Victory-Geste. Durch die Änderung der Orientierung der Handfläche ist die V-Form der Finger nun nicht mehr als ikonische Verkörperung des Buchstabens zu verstehen und mit dem Inhalt im Sinne von Sieg verbunden, sondern wird mit einer anderen Bedeutung aufgeladen.
Nicht nur Embleme wie die Victory-Geste, sondern alle kommunikativen Bewegungen der Hände greifen zur Herstellung derartiger Bedeutungsunterschiede auf den großen artikulatorischen Spielraum der Hände zurück. Zur Systematisierung und Beschreibung dieser Bandbreite machen sich Gestenforscher vier Parameter zu Nutze, die der Sprachwissenschaftler William Stokoe in den 1960er Jahren zur Analyse von Gebärden eingeführt hat:3 Form, Ausrichtung und Bewegung der Hand sowie Position im Gestenraum. Im Falle der Victory-Geste strecken wir den Zeige- und Mittelfinger aus und richten die Handfläche vom Körper weg. Die Hände sind vor unserem Körper in unterschiedlicher Höhe positioniert und verbleiben dort. Zeigt jedoch die Handfläche zum Körper hin, ändert sich die Bedeutung der Geste von Sieg und Zuversicht zu einer Beleidigung, wie in England. Variieren wir nicht die Orientierung der Handfläche, sondern die Form der Hände und führen Zeige- und Mittelfinger zusammen, erhalten wir die Schwurgeste (vgl. Abbildung 4). Behalten wir die Handform der Victory-Geste bei, ändern jedoch die Position und führen die Hand an den Hinterkopf, repräsentieren die beiden gestreckten Finger am Kopf Hasenohren (vgl. Abbildung 4).
Abgesehen von unseren Stimmwerkzeugen ermöglicht uns kein anderer Körperteil eine solch differenzierte Bandbreite und hohe Flexibilität.5 Im Falle der Abwesenheit von Lautsprache erlaubt es diese Artikulationsvielfalt, dass Be-

3  Winston Churchill führt die Geste mit der Handfläche nach innen aus
wegungen der Hände sich zu voll ausgebildeten Sprachen entwickeln, wie dies bei den Gebärdensprachen der Fall ist. Die Beschreibung von Gesten mithilfe der von Stokoe eingeführten Formparameter gestattet es Gestenforschern, dieses sprachliche Potential kommunikativer Handbewegungen aufzudecken. Durch sie kann die gleichzeitige Komplexität gestischer Zeichen aufgebrochen und einzelne Formaspekte können systematisch zueinander in Relation gesetzt werden. So ermöglichen die Parameter die Identifikation gestischer Minimalpaare, d. h. Gesten, die sich nur in einem Formmerkmal unterscheiden, wie im Fall der Victory-Geste. Ebenso lassen sich größere Gruppen von Gesten erfassen, sogenannte Gestenfamilien6, die sich systematisch in einzelnen Form- und Bedeutungsaspekten unterscheiden (vgl. den Beitrag „Gesten der zwischenmenschlichen Kommunikation: Ihre Vielfalt, Eigenschaften und Erforschung“, in diesem Band). Ähnlich wie Wortfelder in der Lautsprache bilden Gesten in diesen Fällen zusammenhängende Bedeutungsnetzwerke. Solche Strukturierungsprinzipien, anhand

66

4  Parameterveränderungen und die damit verbundenen Bedeutungsveränderungen: Victory-Geste, Beleidigungsgeste (Änderung der Orientierung der Handfläche), Schwurgeste (Änderung der Handform) und die Finger als Verkörperung von Hasenohren (Änderung der Position im Gestenraum)4

derer das sprachliche Potential von kommunikativen Handbewegungen zum Tragen kommt, finden sich vor allem in konventionalisierten Gesten, wie den Emblemen. Wie aber entstehen solche Form-Inhaltsoppositionen und im Falle der Victory-Geste zwei so grundlegend verschiedene Bedeutungen (‚Sieg‘ vs. ‚Beleidigung‘)?
Form- und Bedeutungsvarianten: Ursprung und Herkunft der Victory-Geste
Will man den Ursprung solcher Varianten ermitteln, ist man vor besondere Probleme gestellt. Anders als bei Sprachen, in denen sich in Texten über Jahrhunderte Wörter belegen und in ihren Kontext stellen lassen, ist dies bei Gesten nicht so leicht möglich. Zwar finden sich u. a. auf antiken Vasen Abbildungen emblematischer Gesten, gesicherten Aufschluss über ihre Bedeutung geben diese Überlieferungen aber nicht. Daher bleibt nur, ausgehend von historischen

Belegen, die Bedeutungsentwicklung von Emblemen nachzuzeichnen und mit daraus entstehenden Unsicherheiten zu leben. Nur wenige emblematische Gesten weisen dabei eine solch hohe Anzahl unterschiedlicher Etymologien auf wie die Victory-Geste. Morris und Kollegen nennen in ihrer Dokumentation allein zehn mögliche Ableitungen. Der tatsächliche Ursprung ist jedoch bis heute nicht abschließend geklärt. Eine mögliche Erklärung stellt die Erfindung durch den belgischen Politiker dar. Ein weiterer Entstehungskontext geht auf das mittelalterliche Bogenschießen zurück, bei dem die Schützen den Langbogen mit Zeige- und Mittelfinger spannten. Da den Schützen in den Gefechten eine zentrale Rolle zukam, trennte man Gefangenen daher diese Finger und den Daumen ab, um ihnen den Gebrauch des Bogens in Zukunft unmöglich zu machen. Rothero7 weist darauf hin, dass englische Bogenschützen im Hundertjährigen Krieg vor und nach dem Krieg die gestreckten Zeige- und Mittelfinger in die Luft strecken, um ihren Siegeswillen auszudrücken. Frühe schriftliche Belege für den

67

Gebrauch der Geste im Sinne der Beleidigung finden sich im 16. Jahrhundert. Der erste fotografische Beweis stammt von einem englischen Fußballspiel aus dem Jahr 1913.8 Als phallisches Symbol können die gestreckten Finger bei der Beleidigungsgeste u. a. die gespreizten Beine der Frau beim Geschlechtsakt darstellen. Die Orientierung der Handfläche ist in diesen überlieferten Ursprüngen der Beleidigung in der Regel nicht bedeutsam. Die Vermutung liegt also nahe, dass dieses Formmerkmal willkürlich begründet ist und lediglich dazu dient, beide Inhalte voneinander abzugrenzen. In Sprach- und Kulturgemeinschaften, in denen sich andere Beleidigungsgesten herausgebildet haben, wie der Stinkefinger in Deutschland oder den USA (vgl. Abbildung 6), ist der Bedeutungsunterschied, der mit der Änderung der Handflächenorientierung verbunden ist, häufig gar nicht bekannt. Denn für beide Inhalte existieren in diesen Sprach- und Kulturgemeinschaften unterschiedliche Embleme. Da das Formmerkmal (Orientierung der Hand-

fläche) also nicht als Unterscheidungsmerkmal gebraucht wird, sind Sprecher in ihrer Ausführung oft nicht konsequent und gebrauchen beide Varianten austauschbar. Da die Geste im Sinne einer Beleidigung zudem fast ausschließlich auf den britischen Raum beschränkt ist, ist weiterhin auch eine Quelle für interkulturelle Missverständnisse gegeben, wie sich in Abbildung 5 zeigt. Bei einem Besuch Winston Churchills 1949 in Griechenland stellt die Geste die Soldaten vor besondere Herausforderungen: Da die Victory-Geste mit der Handfläche nach außen in Griechenland als Beleidigung gilt, müssten sie diese eigentlich umkehren. Da jedoch diese Variante in England als Beleidigung gilt, sind die Soldaten unschlüssig und wählen eine unverfängliche Ausführung mit der Handfläche zur Körpermitte.9
An der Victory-Geste zeigt sich daher exemplarisch, was Morris und Kollegen in ihrer Arbeit an einem Lexikon für eine Vielzahl von Emblemen gefunden haben: Sie können über mehrere Bedeutungen verfügen, die von der häu-

^ 5  Winston Churchill 1949 mit griechischen Soldaten <6  Peer Steinbrück gebraucht den Stinkefinger in einem Artikel der Süddeutschen Zeitung
68

figen und lokalen Auswahl unterschiedlicher symbolischer Routen herrühren. Viele sind in ihrer Verbreitung dabei an kulturelle und historische Grenzen und Regionen gebunden und weniger als gemeinhin angenommen an nationale und sprachliche Grenzen. Damit sind Embleme nicht nur als gestische Zeichen für eine semiotische und sprachwissenschaftliche Perspektive besonders interessant, sondern auch weil sie Wissensspeicher kultureller, gesellschaftlicher und historischer Wandlungsprozesse sind.
Die Zukunft der Victory-Geste
Wendet man nun den Blick nicht ausschließlich in die Vergangenheit, sondern in die Zukunft, zeigt sich, dass die Victory-Geste auch hier exemplarisch eine besondere Rolle einnimmt. Sicherheitsforscher des japanischen National Institute of Informatics (NII) haben kürzlich davor gewarnt,10 dass immer hochauflösendere Fotos die Extraktion der Fingerabdrücke erlauben würden. Diese Daten könnten dann dazu genutzt werden, um biometrische Sicherheitsmaßnahmen, wie beispielsweise am Laptop oder Smartphone, zu umgehen. Insbesondere Jugendliche benutzen in den sozialen Medien, wie Facebook oder Instagram, die Victory-Geste häufig, um ihre Begeisterung für eine bestimmte Situation zum Ausdruck zu bringen. Da die Finger dabei immer zum Betrachter der Bilder zeigen, erlaubt dies neue Technologie, die Fingerabdrücke aus Bildern wie Selfies zu extrahieren und zu reproduzieren. Einen anderen Weg haben Forscher aus Jordanien beschritten.11 Anhand von Fotoaufnahmen von Victory-Gesten haben sie einen Algorithmus entwickelt, der es ihnen erlaubt, die Hand ihren Benutzern zuzuordnen, auch wenn die Gesichter verborgen waren.
Wagt man nun einen positiven Ausblick in die Zukunft, dann ist die Victory-Geste aufgrund ihrer weltweiten Verbreitung eventuell ein guter Ausgangspunkt für die Gestaltung von Mensch-Maschine-Schnittstellen. Da die Geste in ihrer positiven Bedeutung nicht auf bestimmte Regionen der Welt beschränkt und in ihrer Form und Ausführung in unterschiedlichen Kultur- und Sprachgemeinschaften bekannt ist, eignet sie sich vielleicht besonders gut, bestimmte positive oder bestätigende Befehle in der Kommunikation mit neuen technischen Interfaces umzusetzen. Die Geschichte emblematischer Gesten, das zeigt die Victory-Geste deutlich, ist immer durch Bedeutungswandel gekennzeichnet. Welchen Einfluss technische Erneuerungen auf diese ausüben können, bleibt dabei gespannt abzuwarten.

Anmerkungen 1 Lüddemann, Stefan: Kleine Gesten der Gegenwart. Das
Victory-Zeichen ist aus der Mode gekommen (Beitrag vom 23.08.2016). Online unter www.noz.de/deutschland-welt/kultur/artikel/762955/das-victory-zeichen-ist-aus-der-mode-gekommen (07.08.2017). 2 Morris, Desmond u. a.: Gestures, Their Origins and Distribution. Ohne Ort 1979. 3 Stokoe, William C.: Sign Language Structure. Buffalo 1960. 4 Fricke, Ellen: Phonaestheme, Kinaestheme und multimodale Grammatik: Wie Artikulationen zu Typen werden, die bedeuten können. Sprache und Literatur, 41(1), 70–88. 5 Vgl. Müller, Cornelia: Redebegleitende Gesten: Kulturgeschichte, Theorie, Sprachvergleich. Berlin 1998. 6 Vgl. Kendon, Adam: Gesture: Visible Action as Utterance. Cambridge 2004. 7 Rothero, Christopher: The Armies of Crécy and Poitiers. London 1981. 8 Vgl. Morris (wie Anm. 2). 9 Vgl. o. A.: Researchers warn of fingerprint theft from ‘peace’ sign. Online unter www.japantimes.co.jp/news/2017/01/11/ national/crime-legal/researchers-warn-fingerprint-theft-peace-sign/#.WXdoqsb5yV4 (07.08.2017). 10 Collett, Peter: Der Europäer als solcher ... ist unterschiedlich. Verhalten, Körpersprache, Etikette. Hamburg 1994. 11 Vgl. Knoke, Felix: Neue Biometrie-Methode: V for überführt. Online unter http://de.engadget.com/2016/03/14/v/ (07.08.2017).
Abbildungsnachweis 1 Picture Alliance dpa. 2 Grafik: Jana Bressem (basierend auf Morris, Desmond: Gestu-
res, Their Origins and Distribution. Ohne Ort 1979). 3 © Getty Images. 4 Zeichnungen: Uliana Schöller. 5 Foto: Süddeutsche Magazin, © Alfred Steffen. 6 Churchill Meets Evzones, Bride Lane Library, © Popperfoto.

69

Aufzeichnungstechniken der
Gestenforschung

Martin Siefkes

Die Gestenforschung als ein interdisziplinäres Forschungsfeld, das theoretisch sowie methodisch unterschiedliche Ansätze vereint, arbeitet mit einer Reihe von Aufzeichnungstechniken, um Gestik dokumentieren und erforschen zu können. Dabei wurde schon früh erkannt, dass die Mittel der Sprache für diese Zwecke nicht ausreichen: Die Möglichkeiten des menschlichen Bewegungsapparats sind zu komplex, um Gesten präzise und dennoch verständlich verbal beschreiben zu können. Die frühen Gestenforscher wie etwa John Bulwer (1644)1 oder Andrea de Jorio (1832)2 griffen daher bereits auf Zeichnungen zurück, um Gesten mit bestimmten Bedeutungen darzustellen.
Dabei können jedoch der Bewegungsablauf und die Räumlichkeit, die für Gesten entscheidend sind, nur auf Umwegen abgebildet werden. Dazu kommt das Problem, dass eine Geste mit einer bestimmten Bedeutung ebenso wie sprachliche Laute und andere Zeichen unterschiedlich ausgeführt werden kann, so dass eine konkrete bildliche Darstellung immer nur einen Einzelfall herauszugreifen vermag. Während es sich bei einer Geste um einen „Typ“ handelt, kann eine Abbildung stets nur ein konkretes „Exemplar“ darstellen.
An der Wende zum 20. Jahrhundert begannen Anthropologen wie Alfred C. Haddon und W. Baldwin Spencer

damit, die Tänze verschiedener Volksstämme fotografisch aufzuzeichnen.3 In den 1930er und 1940er Jahren machten Franz Boas, Margaret Mead und David Efron erstmals Fotound Filmaufnahmen, die gezielt auf die Erfassung von Gesten abzielten.4
Bis heute sind Videoaufzeichnungen die wohl gebräuchlichste Aufzeichnungstechnik der Gestenforschung.5 Dabei wurden auch Verfahren entwickelt, um mit der Unterscheidung zwischen Gestentyp und Exemplar, also der konkreten Aufzeichnung, umzugehen: In Korpusanalysen werden die verschiedenen Ausführungsweisen mit Hilfe von Annotationen erfasst, bei denen mehrere Kodierer einschätzen, ob es sich bei einer Geste um ein Exemplar eines bestimmten Gestentyps handelt. In experimentellen Studien kann zudem die Situation der Gestenausführung, etwa über Themenvorgaben für ein Gespräch oder spezifische kommunikative Settings, kontrolliert werden, so dass die auftretende Gestik besser verglichen werden kann.
Dennoch bleibt bei der Einschätzung von Gesten immer ein Element der Subjektivität, das damit erklärbar ist, dass es sich eben nicht um bloße Handbewegungen, sondern um Zeichen handelt. Da die Bedeutung eines Zeichens nicht sichtbar ist, bleibt es immer ein Stück weit eine Frage der subjektiven Einschätzung, um welche Geste es sich handelt.

70

Die dritte Dimension wird erobert

Datenhandschuhe

Im künstlerischen Bereich war es traditionell die Plastik, die sich mit der räumlichen Darstellung von Gesten beschäftigte. Innerhalb vieler Traditionen finden sich Skulpturen, die Gesten ausführen, etwa die symbolischen Handhaltungen (Mudra) von Buddha-Statuen oder die ausdrucksstarken Körperhaltungen und Gesten antiker Skulpturen. Allerdings ist die Gestik in solchen Darstellungen künstlerisch nachempfunden und häufig auch stilisiert. Es gab – anders als etwa bei Gipsabdrücken, die Körperformen präzise dokumentieren können – lange Zeit keine Möglichkeit, zu überprüfen, ob die Haltung einer Skulptur tatsächlich einem bestimmten Moment bei der Ausführung einer Geste entspricht. Erst seit wenigen Jahren stehen Verfahren zur Verfügung, die es ermöglichen, Gesten im dreidimensionalen Raum präzise aufzuzeichnen. In der Ausstellung werden sechs verschiedene Aufzeichnungsverfahren vorgestellt, die diese Bedingung erfüllen, dabei aber verschiedene Vor- und Nachteile haben.

Datenhandschuhe basieren auf dem Verfahren des mechanischen Trackings, bei dem die Bewegungen von Körperteilen mittels Sensoren erfasst werden, die sich in Kleidungsstücken befinden oder direkt am Körper befestigt werden und die gemessenen Bewegungen in den virtuellen Raum übertragen. Dabei kommen verschiedene Typen von Sensoren zum Einsatz: Lagesensoren erfassen die Ausrichtung der Hand im Raum; Bewegungssensoren (Gyroskope) erfassen Beschleunigung und Abbremsung und berechnen daraus die Bewegungen des Handschuhs; Biegesensoren messen, ob Finger gebeugt, gestreckt oder abgespreizt werden.
Mechanisches Tracking kann aber auch für die Erfassung von Körperbewegungen mittels spezieller Kleidungsstücke eingesetzt werden, etwa in Ganzkörper-Anzügen der Firma XSens. Die Daten werden dabei drahtlos zu Em­ pfangsstationen übertragen, wo ein Modell der Körperbewegungen berechnet wird.

1 1 und 2  Aufzeichnung von Gesten mit dem Datenhandschuh VMG 35 PlusTM
71

2

Datenhandschuhe werden heute in verschiedenen Kontexten verwendet; in der Regel sind sie primär für den Einsatz in Virtual-Reality-Simulationen und Computerspielen konzipiert. Der wissenschaftliche Einsatz für die Forschung ist ein noch vergleichsweise kleines Gebiet, das jedoch zunehmend wichtiger wird.6 Die Stärken von Datenhandschuhen für die Gestenforschung liegen in der Möglichkeit, Handform und Bewegungen der Finger auch in komplexen Bewegungsfolgen millimetergenau zu erfassen, wobei anders als bei kamerabasierten Verfahren keine Okklusionen (Verdeckungen) auftreten, die meist eine Nachbearbeitung der Daten erforderlich machen.
Der größte Anbieter von Datenhandschuhen ist derzeit die Firma CyberGlove. In der Ausstellung wird der Datenhandschuh VMG 35 PlusTM der Firma Virtual Realities7 vorgeführt. Dieser Handschuh stammt aus dem Virtual Environments Learning Lab der TU Chemnitz. Er kann über WLAN oder Bluetooth drahtlos betrieben werden und besitzt 30 Sensoren: Zwei Sensoren je Finger, die die Beugung der Fingerglieder messen, vier Abduktionssensoren zur Messung der Spreizung der Finger, ein Sensor für die Wölbung der Handfläche, einer für die Überkreuzung des Daumens, fünf Drucksensoren zur Messung von Berührungen mit den Fingern und neun Sensoren für die Messung der Lage und der Bewegung im Raum.

Die „Plus“-Variante des Handschuhs gibt zudem haptisches Feedback durch vibrierende Aktuatoren in den Fingerspitzen, die dem Benutzer anzeigen, wenn er etwas in der virtuellen Welt berührt.
Die Handschuhe arbeiten mit einer Frequenz von 100 Hz und liefern eine flüssige Darstellung. Auch die Bewegungen der Hand im Raum werden präzise erfasst. Allerdings funktioniert die Erkennung der Fingerkrümmung bisher noch nicht genau genug, um für die Aufzeichnung aller Handgesten geeignet zu sein. Probleme gibt es bei Berührungen von Fingerspitzen, wie sie etwa für die sogenannte Ringgeste (Daumen und Zeigefinger bilden einen Ring für „Okay“) erfasst werden müssen.
Datenhandschuhe wie der VMG 35 PlusTM kommen für die genaue Aufzeichnung von absichtsvoll ausgeführten konventionalisierten Gesten ebenso infrage wie für die Erfassung von Bewegungsmustern, die bei der Ausführung von Handhabungen (manuellen Tätigkeiten) auftreten. Für die Untersuchung redebegleitender Gestik sind sie dagegen weniger geeignet, da sie einen spürbaren Widerstand bieten und die spontan auftretenden Bewegungsmuster, die für diese Form der Gestik typisch sind, beeinflussen würden.

72

Markerbasiertes Tracking

Bei dieser gebräuchlichen Form des Motion Capture tragen die Personen Marker auf der Kleidung, kleine reflektierende Kugeln, die mit Infrarotlicht angestrahlt werden. Die Reflexionen werden von Kameras aus verschiedenen Richtungen aufgenommen. Später wird daraus ein 3D-Bild berechnet. Markerbasiertes Tracking ist bereits seit Jahren Standard in verschiedenen Anwendungsbereichen, da sich hiermit Konturen und Bewegungen des ganzen Körpers präzise in ein virtuelles Modell übertragen lassen. Es spielt auch innerhalb der Gestenforschung eine wichtige Rolle.8
Markerbasiertes Tracking wird heute häufig für Spezial­ effekte bei der Filmproduktion eingesetzt. So spielte im Film „The Desolation of Smaug“ der Schauspieler Benedict Cumberbatch den Drachen Smaug, während sein Körper und Gesicht mit Markern getrackt wurden. In der Filmindustrie spricht man von „Performance Capture“, wenn nicht nur Körperbewegungen, sondern auch Gesichtsausdrücke detailliert erfasst werden. Die Bewegungen wurden auf den per Computer animierten Drachen im Film übertragen.
Das präzise Tracking von Hand- und Fingerbewegungen ist ebenfalls möglich. Dafür werden die Marker meist auf einem Handschuh angebracht – andere Lösungen, etwa das Aufkleben direkt auf die Haut oder die Anbringung mit Bändern und Ringen, sind aufwendiger. Ein Vorteil gegenüber Gestenhandschuhen besteht darin, dass die Handschuhe leichter sind und nach einer kurzen Eingewöhnungszeit von den Probanden kaum mehr wahrgenommen werden. Damit sind markerbasierte Verfahren gut geeignet, um Gestik in natürlichen Settings, etwa der Face-to-Face-Kommunikation, aufzuzeichnen. Dies geschieht etwa im seit 2010 bestehenden Natural Media Lab der RWTH Aachen.9
Bei der markerbasierten Aufzeichnung von Gesten ist in der Regel eine Nachbearbeitung der Daten erforderlich, dafür liefert es jedoch Daten von hoher Qualität und kann mit dem Tracking von Körperbewegungen und von Gesichtsausdrücken als anderen Aspekten des kinesischen Körperverhaltens verbunden werden. Es ist daher geeignet, um Gesten als Teil des kinesischen Verhaltens des Menschen in natürlichen Interaktionssituationen aufzuzeichnen. Schwierig wird es allerdings im Bereich der sogenannten eigen- und fremdberührenden Gesten. Die Marker stören, sobald man die Hände in die Nähe von anderen Körperteilen oder von Gegenständen bringt. Man kann sich damit nicht unbefangen am Kopf kratzen, einen Vogel zeigen oder jemandem die Hand schütteln. Auch auf die Körperhal-

3  Markerbasiertes Tracking des ganzen Körpers
tung insgesamt haben die Marker Auswirkungen. Man wird beispielsweise vorsichtig sein, wenn man den Kopf in die Hände stützt10 oder auf die Knie legt. Auf diese Einschränkungen sollte bei wissenschaftlichen Studien geachtet werden. In jedem Fall ist eine ausreichende Eingewöhnung der Probanden wichtig.
Markerloses Tracking
Die Entwicklung von Gestensteuerung für Spielkonsolen hat zu einer Revolution im Bereich des Motion Capture geführt. Die entsprechenden Sensoren, die innerhalb der letzten Jahre entwickelt wurden, verwenden Tracking-Verfahren, die ohne aufwendige Marker und zahlreiche im Raum platzierte Kameras auskommen. Seitdem ist die Technologie der Gestenerkennung in privaten Haushalten angekommen. Auch für die Gestenforschung bieten markerlose Aufzeichnungsmethoden neue Perspektiven.
2010 führte Microsoft mit der Kinect einen Gestensensor für die Xbox ein, der seit 2012 auch für Windows verfügbar ist. Die Kinect kombiniert eine Tiefenkamera mit einer Infrarotkamera, einer normalen Farbkamera und einem 3D-Mikro­fon. In der aktuellen Version lässt sich damit der gesamte Körper mehrerer Personen erfassen. Die

73

Tiefenkamera der Kinect arbeitet mit dem Time-of-FlightPrinzip. Es wird ein Infrarotpuls ausgestrahlt und für jedes Pixel einzeln gemessen, wie lange das Licht unterwegs ist, das von der Umgebung zum Sensor zurück reflektiert wird. Aus diesen Daten wird eine 3D-Simulation der Umgebung errechnet. Es existieren auch andere Typen von Tiefenkameras, die ohne Verwendung von Markern in der Lage sind, ein dreidimensionales Bild der Umgebung zu liefern, etwa die RealSense-Kameras des Unternehmens Intel.
Für die Gestenforschung sind markerlose Verfahren vielversprechend. Während das markerbasierte Tracking eine Veränderung am Körper der aufgezeichneten Personen erfordert und damit die aufgezeichnete Situation beeinflusst – man spricht auch von einem „invasiven“ Verfahren –, ist das beim markerlosen Tracking nicht der Fall. Für die Forschung ist dieser Unterschied wichtiger als für die Filmproduktion: Während Schauspieler ihr kinesisches Verhalten sowieso bis zu einem gewissen Grad kontrollieren, kommt es in der Gestenforschung meist darauf an, spontanes kinesisches Verhalten möglichst unverfälscht zu erfassen. Zudem lassen sich Probanden leichter irritieren als professionelle Schauspieler.
Da sie auch an einem Windows-PC betrieben werden kann, wird die Kinect häufig in wissenschaftlichen Studien eingesetzt. Einfache Gesten, etwa die geballte Faust oder die geöffnete Hand mit gestreckten Fingern, werden von der gelieferten Software bereits erkannt. Durch die Verwendung mehrerer Kinects können Personen von allen Seiten erfasst werden. Bei komplexeren Gesten stößt die Gesten­ erkennung der Kinect allerdings rasch an ihre Grenzen. Die Erfassung ist nicht genau genug, um die Position jedes Fingers genau erfassen zu können. Bestimmte Gesten können daher nicht voneinander unterschieden werden. Es bleibt abzuwarten, ob dies in Zukunft durch eine höhere Auflösung des Sensors und bessere Handmodelle, auf die die Daten abgebildet werden, behoben werden kann.
Tracking durch Muskelaktivität
Eine grundlegend andere Technik nutzt das Myo-Armband der Firma Thalmic Labs, das am Unterarm getragen wird. Es misst mit Hilfe von Elektromyographie (EMG) die Muskelbewegung im Unterarm, indem mit Elektroden, die auf der Haut aufliegen, die Kontraktion der Muskeln erfasst wird. Das Myo-Armband kann fünf verschiedene Handhaltungen unterscheiden: Die geballte Faust, Winken nach

4  Das Myo-Armband misst die Muskelaktivität und berechnet daraus Hand- und Fingerbewegungen
rechts und nach links, Spreizen der Finger und doppeltes Fingertippen. Zusätzlich besitzt das Armband Lage- und Inertialsensoren, mit denen die Ausrichtung des Arms im Raum und Bewegungen in verschiedene Richtungen gemessen werden.
Das Myo-Armband wurde ebenso wie die Kinect primär für die Steuerung von Spielen entwickelt, es stehen aber auch eine Reihe weiterer Anwendungen zur Verfügung. So können beispielsweise Drohnen damit geflogen, durch Präsentationen navigiert oder Anwendungen im „Smart­home“ realisiert werden, etwa die Bedienung eines Fernsehers. Allerdings ist die praktische Einsetzbarkeit in diesen Bereichen noch eingeschränkt, da bislang nur wenige Gesten voneinander unterschieden werden können.
Für die Aufzeichnung von Gestik ist das Myo-Armband nur beschränkt geeignet. Anders als die bislang genannten Verfahren zeichnet es die Position der Hand und der Finger nicht direkt auf, sondern kann nur bestimmte Aspekte aus der Muskelaktivität erschließen, etwa die Beugung der Finger. Die Zukunft dieser Technologie liegt wohl eher im Bereich der Gestensteuerung. Damit sie sich dort durchsetzt, wird es jedoch nötig sein, das Armband noch leichter zu machen, so dass es am Arbeitsplatz oder zu Hause über längere Zeiträume getragen werden kann. Vorläufig bleibt das Myo-Armband ein Experiment, das primär für Virtual-Reality-Simulationen und Computerspiele eingesetzt wird.

74

Projekt Soli

Noch futuristischer ist das von einem Google-Team entwickelte Projekt Soli. Es nutzt Radartechnologie, um Fingerbewegungen aufzeichnen zu können.11 Auf einem kleinen Chip befinden sich eine Antenne, die ein Radarsignal ausstrahlt, und ein Sensor, der die reflektierten Radarwellen wieder einfängt. Zwar können aus diesen Daten, anders als bei kamerabasierten Verfahren, nicht direkt räumliche Konturen berechnet werden. Mit entsprechend trainierter Software ist es jedoch möglich, die charakteristischen Signaturen der reflektierten Wellen verschiedenen Bewegungsmustern zuzuordnen.
Es wird angestrebt, mit Hilfe dieser Technologie kleinste Fingerbewegungen zu unterscheiden. Auf diese Weise will das Projekt virtuelle Interfaces simulieren, wie die Projektwebseite erläutert:
“Virtual Tool Gestures. Imagine an invisible button between your thumb and index fingers – you can press it by tapping your fingers together. Or a Virtual Dial that you turn by rubbing thumb against index finger. Imagine grabbing and pulling a Virtual Slider in thin air. These are the kinds of interactions we are developing and imagining.”12
Sofern dies gelingt, werden virtuelle Interfaces möglich, die durch Knöpfe, Regler und Anzeigeinstrumente vielfältige Interaktionsmöglichkeiten ermöglichen. Das dabei gewählte Verfahren ist aus Sicht der Gestenforschung sehr interessant, denn es nutzt Abstraktionsvorgänge, die Handhabungen in Gesten überführen. Die gestischen Interaktionen werden von tatsächlichen Bedienvorgängen moderner technischer Geräte abstrahiert, die Druckknöpfe, Drehknöpfe und Schieber aufweisen – man denke etwa an eine traditionelle Hifi-Anlage. Die Gesten entstehen dabei nicht einfach, indem das eigentliche Bedienelement weggelassen und seine Bedienung „in der Luft“ ausgeführt wird. Vielmehr werden die Bewegungen abstrahiert und an die formseitigen Konventionen und inhaltsseitigen Repertoires der menschlichen Gestik, die ein konventionalisiertes Zeichensystem bildet, angepasst. Wenn beispielsweise das Drücken eines Knopfs simuliert wird, indem zwei Finger mit den Fingerspitzen gegeneinander tippen, repräsentiert der eine Finger den Knopf, während der andere agiert, indem er den Finger nachahmt, der den Knopf drückt. Dabei handelt es sich um verschiedene gestische Repräsentationsformen13, die hier in einer Geste kombiniert werden.
Bisher steckt die radarbasierte Gestenerkennung noch in ihren Kinderschuhen. Ebenso wie bei den meisten an-

5  Project Soli entwickelt ein System zur radarbasierten Gestenerkennung
deren Verfahren lassen sich damit nur einige Gesten zuverlässig unterscheiden. Diese Aufzeichnungstechnik ist dabei komplementär zu anderen Verfahren, da sie darauf abzielt, detaillierte Fingergesten zu erkennen. Sie könnte langfristig ergänzend zu anderen Aufzeichnungstechniken, etwa dem markerlosen Tracking mit der Kinect oder vergleichbaren Sensoren, eingesetzt werden, um feine Hand- und Fingerbewegungen hinzuzufügen, an denen diese Verfahren bislang scheitern. Realistisch ist dies allerdings derzeit nur in kontrollierten Settings, etwa in einem Fahrsimulator. Für freie Gesprächssituationen ist die radarbasierte Aufzeichnung auf absehbare Zeit nicht geeignet, weil sie nur funktioniert, wenn die Abstände relativ klein und die Hände im Raum entsprechend ausgerichtet sind.
Im Hinblick auf Gestenerkennung geht das Project Soli einen interessanten Weg, um feinmechanische Steuerungsvorgänge in den virtuellen Raum zu übertragen. Anstatt konkrete Handlungsergebnisse in abstrahierter Form nachzuahmen – man könnte etwa das Lauterstellen der Musik durch ein „Aufschwellen“ ikonisch darstellen, indem beide Hände auseinandergezogen werden –, wird die Bedienung von gebräuchlichen Interfaces gestisch repräsentiert. Dabei werden Bedienvorgänge simuliert, die heutigen Nutzern gut bekannt sind. Falls sich diese Form der Bedienung durchsetzt, könnte es zu einer Konventionalisierung der entsprechenden Steuerungsgesten kommen. Diese würden unter Umständen auch dann weiterexistieren, wenn die nachgeahmten Interfaces nicht mehr allgemein bekannt sind.

75

6  Gestenerkennung mit dem Leap Motion Controller
Leap Motion
Eine weitere Form des Sensors, die für die Aufzeichnung von Handbewegungen verwendet werden kann, ist der Leap Motion Controller. Ähnlich wie die Kinect verwendet auch die Leap Motion Infrarotlicht, das von drei LEDs abgestrahlt und dessen Reflexionen mit zwei Kameras wieder aufgefangen werden.
Die Reichweite der Leap Motion ist relativ klein, sie beträgt maximal einen Meter. Innerhalb dieses Bereichs ist präzises Tracking von Bewegungen der offenen Hand oder eines einzelnen Fingers möglich. Somit kann beispielsweise auf einem Monitor mit einem Finger eine Kontur gezeichnet werden, oder es wird in einem Spiel ein Flugobjekt gesteuert. Es handelt sich um ein Eingabegerät, das für spezielle Szenarien geeignet ist, etwa für die Steuerung von Spielen, die Interaktion mit Objekten im virtuellen Raum oder für die Bedienung spezieller Software. Die Erfassung komplexer Handformen wie etwa der Ringgeste ist jedoch nicht möglich.
In der Ausstellung befindet sich ein Kugellabyrinth, das mit einem Leap Motion Controller berührungslos bedient wird. Die Besucher können dabei selbst ausprobieren, wie sich diese Methode der Steuerung anfühlt.
Wie sieht das ideale Aufzeichnungsverfahren aus?
Wie bereits deutlich wurde, haben alle Aufzeichnungstechniken von Gesten ihre Vor- und Nachteile. Welches Verfahren sich am besten eignet, hängt daher von der Fragestellung und dem Studiendesign ab. Man sollte sich allerdings bewusst machen, dass die Aufzeichnung von Gesten noch

lange nicht ausgereift ist. Es lohnt sich daher zu überlegen, was eigentlich wünschenswert wäre, um Gesten für die Forschung zuverlässig erfassen und aufzeichnen zu können.
Dabei unterscheiden sich die Anforderungen für die Forschung teilweise von denen im Bereich der Gestensteuerung. Ideal wäre für die Gestenforschung ein Aufzeichnungsverfahren, das die folgenden Bedingungen erfüllt: 1. Handbewegungen werden möglichst genau und mit ho-
her Auflösung erfasst. Dabei wird insbesondere auch mit Bewegungen und Überkreuzungen der Finger überzeugend umgegangen. Als Goldstandard für die Gestenforschung kann gelten, dass die Bewegungen hinreichend genau erfasst werden, um Berührungen von Fingern, etwa das Zusammenbringen des Daumens und einer anderen Fingerkuppe, zuverlässig zu erkennen. Dieser Standard wird bisher bei keiner Tracking-Methode durchgehend erreicht. 2. Es ist eine möglichst geringe Nachbearbeitung der Daten erforderlich. Insbesondere werden die Finger auch bei Drehungen der Hand nicht ‚durcheinandergebracht‘ und nach Verdeckungen – etwa wenn die Hände zwischen die Knie geklemmt wurden – wieder sicher zugeordnet. Dies gelingt bei markerbasierten Verfahren bisher nur unzureichend. 3. Die Daten werden mit möglichst geringer Latenz auf ein virtuelles Handmodell übertragen, wobei auch die Arme einbezogen werden können. 4. Auch die absolute Position der Hände und Arme im Raum und ihre Ausrichtung relativ zum Körper wird erfasst, und die Daten können mit anderen Formen des kinesischen Trackings, insbesondere dem Motion Capture des ganzen Körpers und der Erfassung von Gesichtsausdrücken, kombiniert werden. Zudem gibt es Möglichkeiten, um Eigenberührungen wie das Ablegen der Hände auf den Knien, Fremdberührungen wie das Händeschütteln oder Schulterklopfen, sowie Artefaktberührungen wie das Greifen eines Gegenstands oder Anlehnen an die Wand, zu erfassen. 5. Bei Bedarf gibt es die Möglichkeit, individuelle Variation von Körpermerkmalen – etwa von Handformen und Fingerlängen – ebenfalls aufzuzeichnen. Obwohl die genauen Körpermaße normalerweise nicht wichtig sind, kann dies für bestimmte Problemstellungen relevant sein, etwa wenn bestimmte Bedienvorgänge abhängig von den Körpermerkmalen leichter oder schwerer auszuführen sind. Diese Erfassung ist bislang bei vielen Verfahren problematisch, weil die Daten auf vorpro-

76

grammierte Avatare (Körper- oder Handmodelle) abgebildet werden. Da keines der existierenden Verfahren alle Bedingungen erfüllt, werden verschiedene Aufzeichnungsverfahren bislang abhängig von Studiendesign und Forschungsfragen verwendet oder bei Bedarf miteinander kombiniert. Nach wie vor ist die Videoaufzeichung mit einer oder mehreren Kameras ein wichtiges Verfahren, wenn Gestenkorpora zusammengestellt oder konkrete Studien durchgeführt werden. Videobasierte Studien bieten sich insbesondere an, wenn sowieso eine Kodierung der Gesten erfolgt, wobei Gesten-Vorkommen von Personen, die mit dem jeweiligen Klassifikationssystem vertraut sind, verschiedenen Gestentypen zugeordnet werden. Videobasierte Studiendesigns sind die beste Wahl, wenn es primär um das Vorkommen von Gesten und ihre Zuordnung zu Typen geht. Die Verwendung von Motion Capture bringt in solchen Fällen meist keinen zusätzlichen Nutzen. Anders sieht es aus, wenn konkrete Ausführungsweisen von Gestik untersucht werden sollen, etwa die Größe des verwendeten Gestenraums oder die Geschwindigkeit der Ausführung von Gesten. In diesem Fall liefern Motion Capture oder Datenhandschuhe unmittelbar jene Daten, aus denen sich die relevanten Parameter berechnen lassen. Zu beachten ist bei der Wahl eines Verfahrens außerdem, dass alle beschriebenen Verfahren mit Ausnahme des markerlosen Trackings invasiver sind als die reine Videoaufzeichnung, da sie stärker in die aufgezeichnete Situation eingreifen. Es ist gut vorstellbar, dass in der Zukunft das markerlose Tracking mit strukturiertem Licht, eventuell ergänzt durch radarbasierte Messverfahren, zum universellen Aufzeichnungsverfahren für die Gestenforschung wird. Solange es noch nicht so weit ist, sollte bei jeder Studie überlegt werden, welche Verfahren am besten geeignet sind. Für umfangreiche Korpora ist es sicherlich von Vorteil, wenn für die Aufzeichnung neben mehreren Videokameras auch Motion Capture genutzt wird, um zukunftssichere Daten zu gewinnen, die langfristig in verschiedenen Kontexten nutzbar sind.

3 Vgl. Mondada, Lorenza: Video as a tool in the social sciences. In: Müller (wie in Anm. 13), Bd. 1, Berlin/Boston 2013, S. 983.
4 Vgl. ebd., S. 984–985. 5 Vgl. den Überblick ebd. 6 Vgl. Pfeiffer, Thies: Documentation of gestures with motion
capture. In: Müller (wie in Anm. 13), Bd. 1, S. 868–879. 7 Weitere Informationen zum Handschuh online unter www.
vrealities.com/products/data-gloves/vmg30 (28.05.2017). 8 Vgl. Pfeiffer (wie Anm. 6), S. 868–879. 9 Vgl. Mittelberg, Irene: Aufzeichnungstechniken der Gesten-
forschung und ihre künstlerische Umsetzung mittels Gestenskulpturen, in diesem Band. 10 Vgl. Schöps, Doris: Körperhaltungen und Rollenstereotype im DEFA-Film. Eine korpusanalytische Untersuchung. Würzburg 2016, S. 177–179. 11 Vgl. Donath, Andreas: Project Soli: Google nutzt Radargerät für die Fingererkennung (Beitrag vom 31.05.2015). Online unter www.golem.de/news/project-soli-google-nutzt-radargeraet-fuer-die-fingererkennung-1505-114359.html (28.05.2017) sowie Floemer, Andreas: Project Soli: Google zeigt berührungslose Gestensteuerung per Radar in Smartwatch (Beitrag vom 23.05.2016). Online unter http://t3n.de/news/project-soli-smartwatch-708866 (28.05.2017). 12 Project Soli Webseite: https://atap.google.com/soli (28.05. 2017). 13 Vgl. Müller, Cornelia: Gestural modes of representation as techniques of depiction. In: Müller, Cornelia u. a. (Hg.): Body – Language – Communication: An International Handbook on Multimodality in Human Interaction. Bd. 2, Berlin/Boston 2014, S. 1691.
Abbildungsnachweis 1 MANUACT-Projekt, TU Chemnitz. 2 MANUACT-Projekt, TU Chemnitz. 3 Foto: Dietmar Träupmann. 4–6 Fotos: Ars Electronica Futurelab.

Anmerkungen 1 Bulwer, John: Chirologia: or the Naturall Language of the Hand.
London 1644. 2 Jorio, Andrea de: La Mimica degli antichi investigata nel gestire
napoletano. Napoli 1832.
77

Von der Kugel zu Google Earth:
Wie handhabe ich einen virtuellen Globus?

Ellen Fricke

Objektgebrauch an einem Umschlagpunkt des technologischen Wandels
Wir befinden uns gerade an einem Umschlagpunkt der technologischen und gesellschaftlichen Entwicklung, an dem sich unsere konkreten Beziehungen zu Objekten grundsätzlich wandeln: Einen Schulglobus versetzen wir manuell in Rotation, indem wir ihn mit der Hand berühren, virtuelle Globen wie Google Earth in Verbindung mit einem Con­troller der Firma Leap Motion werden zukünftig jedoch mit berührungslosen Handbewegungen gesteuert, die mit der ursprünglichen Ausgangshandlung des In-Drehung-Versetzens scheinbar nichts mehr zu tun haben.
Gestensteuerungen werden derzeit auch für andere Objekte unseres Alltags entwickelt und eingesetzt, wie z. B. Fernseher, Staubsauger und nicht zuletzt fahrerlose Autos, die nichts anderes als autonome, selbständig agierende Roboter sind. Mit anderen Worten: Bisherige händische Alltagserfahrungen des Menschen unterliegen einem fundamentalen Wandel.
Für die Entwicklung „intuitiver“ Mensch-Maschine-Schnittstellen zur Gestensteuerung werden zwischenmenschliche Gesten des Alltagsgebrauchs insofern als ein vielversprechender Ansatzpunkt betrachtet, als sie bereits

im Gedächtnis verankert sind und nicht neu gelernt werden müssen. Mit dem Versuch, ein menschliches Gestenrepertoire speziell für die Interaktion mit Robotern und für die Bedienung von Geräten allgemein aufzustellen, stellt sich zugleich das Problem einer Standardisierung:1 Müssen wir für jede Automarke neue Gesten lernen? Oder noch weiter gefasst: Müssen wir für jedes autonome Gerät eine neue „Sprache“ lernen? Woran erkennt der jeweilige Roboter, dass er es ist, der durch einen Menschen angesprochen wird und nicht das Gerät oder der Mensch neben ihm? Wie erkennt beispielsweise ein fahrerloses Auto, dass es durch einen Menschen adressiert wird? Was sollen Menschen dem fahrerlosen Auto kommunizieren? Und wie? Wie könnte ein leicht erlernbares, standardisiertes Gestenrepertoire für die Kommunikation mit fahrerlosen Autos und anderen Robotern aussehen, das möglichst ökonomisch ist und auch interkulturelle Verschiedenheiten berücksichtigt? Um solche Fragen beantworten zu können, müssen Ingenieure und Technikwissenschaftler noch mehr über Gesten und menschliche Handbewegungen wissen.
Eine andere Frage, die für unser Alltagsleben immer wichtiger werden wird:2 Wie formen die Interfaces und autonomen Roboter uns? Wie wirken die Gesten, die wir für die Interaktion mit autonomen Robotern benutzen, auf

78

1 und 2  Von der Kugel zu Google Earth: analoge und digitale Handhabungen von Globen

die zwischenmenschliche Kommunikation zurück? Wie verändern sich dadurch unsere Konzepte von Objekt, Objektgebrauchshandlung und Objektgebrauchsgeste? Wie verändert sich möglicherweise unser Begriff von Kausalität? Dass auch neuere Technologien wie der Gebrauch von Touchscreens relativ schnell auf den Gebrauch von Gesten in der zwischenmenschlichen Kommunikation zurückwirken können, zeigt sich an dem zunehmenden Gebrauch des Wischens mit der flachen Hand oder der Nachahmung des Zoomens, bei der Daumen und Zeigefinger voneinander abgespreizt werden, um im Gespräch redebegleitend auf Tablets Bezug zu nehmen.
Die Auflösung der Kausalität I: Wie Gesten sich von Hand­lungen unterscheiden
Konkrete Handlungen, Gesten in der zwischenmenschlichen Kommunikation und Gesten zur Steuerung von Interfaces, Robotern und virtuellen Objekten sind nicht dasselbe, auch wenn sie sich im Hinblick auf ihre Form ähneln können. Am besten vergegenwärtigt man sich die Gemeinsamkeiten und Unterschiede an einem Beispiel. Wir alle kennen die konventionalisierte Geste mit der Bedeutung ‚Stopp!‘, die mit einer flachen, vom Körper abwandten Hand ausgeführt wird. Diese Geste lässt sich auf eine grundlegende Basishandlung zurückführen.3 Diese Handlung ist dadurch gekennzeichnet, dass ein größeres Objekt wie beispielsweise ein Karton mit Kraft weggehalten oder am Herunterfallen gehindert wird. Wir haben es also mit einer Kausalbeziehung zu tun: Die Krafteinwirkung der Hände verursacht das Fernbleiben bzw. Nichtherunterfallen des Objekts.

Wenn man nun keinen Karton oder ein anderes unbelebtes Objekt weghalten oder entfernen möchte, sondern einen Menschen, dann hat man mindestens zwei Möglichkeiten: Die erste Möglichkeit besteht darin, ihn ebenfalls über die Krafteinwirkung der Hände fernzuhalten etwa durch ein Wegschieben mit beiden Händen. Die zweite Möglichkeit nutzt die zwischenmenschliche Kommunikation und setzt voraus, dass zwei Menschen sich sprachlich und über andere Zeichen wie beispielsweise zwischenmenschliche Gesten verständigen können. Die Form der Geste ähnelt einem beidhändigen Weghalten als Handlung, jedoch wird der Adressat nicht berührt. Wie kann es nun dazu kommen, dass, obwohl keine Kraft einwirkt, die andere Person dennoch nicht näherkommt? Das Weghalten als Geste zielt nicht auf das Erreichen eines physikalischen Zwecks, sondern darauf, dass der Adressat die Absicht des Gestikulierenden versteht, und aufgrund der Tatsache, dass er die Bedeutung des Zeichens kennt, nämlich ‚Stopp!‘ oder ‚Keinen Schritt weiter!‘, sich nicht weiter nähert. In diesem Fall wirkt also keine Kausalbeziehung, sondern eine Zeichenbeziehung. Durch die Geste und ihre Bedeutung wird dem Adressaten mitgeteilt, er solle sich fernhalten. Der Adressat versteht die Absicht des Senders und handelt gegebenenfalls gemäß dieser Absicht.
Für die Gestaltung der Interaktion zwischen Menschen und autonomen Robotern wie beispielsweise fahrerlosen Autos ist es von besonderer Bedeutung, dass wir auf die geschilderte Weise mit Zeichen handeln, sie also für die zwischenmenschliche Kommunikation einsetzen. Was geschieht, wenn ein Fußgänger die Straße überqueren möchte? Wenn er davon ausgehen kann, dass in einem sich nähernden Auto ein Mensch sitzt, der seine Gesten versteht, könnte er eine

79

3  Stopp-Geste: Mercedes-Benz-Studie zur Fußgänger-Auto-Kommunikation
Geste für ‚Stopp!‘ ausführen. Der Autofahrer versteht die Absicht des Fußgängers, reagiert eventuell seinerseits mit einer Geste, die signalisiert, dass er erstens den Fußgänger gesehen hat, zweitens seine Absicht verstanden hat und drittens gemäß dieser Absicht handeln wird, also nicht einfach weiterfährt, sondern anhält.
Was aber geschieht, wenn sich ein autonomes, selbstfahrendes Fahrzeug nähert, in dem kein Mensch sitzt? Auf die Krafteinwirkung der Hände zu setzen, wäre keine gute Option. Eine Stoppgeste auszuführen, wäre jedoch nur dann ein vielversprechender Kommunikationsversuch, wenn der Auto-Roboter ebenfalls in der Lage ist, zu signalisieren, dass er erstens den Fußgänger gesehen, zweitens seine Absicht verstanden hat und drittens gemäß dieser Absicht handeln wird, also ebenso wie ein menschlicher Autofahrer anhält und nicht einfach weiterfährt. Anders als ein menschlicher Autofahrer kann das autonome Fahrzeug jedoch keinen Blickkontakt herstellen oder eine Geste ausführen. Um dieselben Funktionen in der Interaktion zu erfüllen, muss das fahrerlose Fahrzeug auf andere Zeichen wie z. B. Lichtsignale zurückgreifen. In der abgebildeten Mercedes-Benz-Studie zur Fußgänger-Auto-Kommunikation wird beispielsweise ein Zebrastreifen als Lichtsignal auf die Fahrbahn projiziert, der dem Fußgänger anzeigen soll, dass er wahrgenommen und dass seine Absicht, die Straße zu überqueren, verstanden wurde (vgl. Abbildung 3).
Es ist dabei für Designer eine zentrale Frage, auf welche Weise wir zukünftig Roboter und andere digitale Interfaces adressieren. Beispielsweise ist das Konzept eines maximal anthropomorphen Adressaten eine zwar naheliegende, aber nicht unbedingt die beste Lösung. In einem solchen Fall

wird der menschliche Fahrer simuliert und durch ein fahrerloses autonomes Fahrzeug die Illusion erzeugt, es sei gar nicht autonom. Der Vorteil wäre, dass ein bereits bestehendes Adressatenkonstrukt, nämlich dass ein Auto immer von einem Menschen gesteuert wird, für die anderen Verkehrsteilnehmer aufrechterhalten werden kann. Diese Variante scheint naheliegend, kommt unserer Bequemlichkeit entgegen und entspricht der Tendenz, einen bestehenden Status quo zu erhalten. Das Problem dabei ist, dass diese vermenschlichende Illusion gefährlich sein kann. Im Rahmen eines anthropomorphen Modells eines autonomen Fahrzeugs stellen Fußgänger ihr Zeichenrepertoire auf die Verhaltenskomplexität menschlicher Adressaten ein, welche solche Fahrzeuge nicht haben. Sie würden vielleicht nach der ersten Reaktion des vermeintlichen Fahrers noch auf ein Kind zeigen, das sich auf der Straße befindet, und würden davon ausgehen, dass diese Zeigegeste als Warnhinweis verstanden wird.2 Es ist also zentral, dass ein Roboter immer klar signalisiert, dass er ein Roboter ist, damit er als ein solcher auch adressiert wird.3 Wie wir zukünftig unser Zusammenleben in solchen Mensch-Technik-Hybridgemeinschaften in einer demokratischen Gesellschaft gestalten können und wollen, ist ein zentrales Zukunftsthema der kommenden Jahre.
Solche körperlichen Basishandlungen, wie sie der konventionalisierten Geste für ‚Stopp!‘ zugrunde liegen, sind mit der gestischen Form über einen Abstraktionsprozess verbunden. Es finden sich nur bestimmte Merkmale der zugrundeliegenden Ausgangshandlung in der Geste selbst wieder. Die Form der flachen Hand mit einer Orientierung der Handfläche vom Körper weg und den Fingerspitzen nach oben findet sich sowohl in der Basishandlung als auch in der Geste. Auch die Bewegungsform und -richtung geht in beiden Fällen vom Körper weg. Während jedoch die Basishandlung des Wegschiebens eines größeren Objekts mit einem entsprechenden Kraftaufwand verbunden ist, der die tatsächliche Entfernung eines schwereren Objekts verursacht, ist das gestische Wegschieben eines flüchtigen, vorgestellten Objekts nur stilisiert. Wenn man die Position im Gestenraum betrachtet, an der die Stopp-Geste ausgeführt wird, dann ist der Ausführungsort meist in Brusthöhe und oft werden nicht beide Hände, sondern nur eine Hand gebraucht. Da es sich um ein Wegschieben oder Weghalten als Zeichen für ‚Stopp!‘ handelt, ist die Kraft beider Hände nicht erforderlich. Der Gebrauch der linken oder rechten Hand ist in diesem Fall für die Realisierung der gestischen Zeichenfunktion völlig hinreichend. Beidhändigkeit auf

80

4  Welthandels- und Verkehrsglobus (ca. 1920) (Standglobus in der Mitte des Bildes)

5  Smart Globe

6  Schwebeglobus, Fa. Stellanova

Zeichenebene hat die Funktion der Intensivierung: Je mehr Hände dieselbe gestische Form ausführen, desto intensiver also gleichsam „lauter“ wird diese Bedeutung kommuniziert. Anders als bei der Handlung des Wegschiebens eines Objekts, kann die Position der Hände bei einer Geste viel weniger variabel sein, da die Geste der konkreten Handhabungssituation viel stärker entbunden ist. Bei der Handlung des Wegschiebens oder Weghaltens eines Objekts richtet sich die Position der Hände nach den Eigenschaften des zu entfernenden Objekts. Muss ein schwerer Karton mit zwei nach oben ausgestreckten Händen daran gehindert wer-

den, von einem Schrank herunterzufallen, dann werden die Handflächen nicht wie bei der Stopp-Geste vor der Brust parallel zum vertikalen Körper positioniert, denn dann würden die Hände ihre Aufgabe nicht erfüllen können und der Karton auf den Boden fallen. Bei der Geste des Weghaltens mit der Bedeutung ‚Stopp!‘ hingegen hängt die Position der Hände nur von der konventionalisierten Form des Zeichens ab. Da es sich um ein Zeichen handelt, sind die Handflächen nicht in Bezug auf ein zu entfernendes Objekt, sondern auf einen potentiellen Adressaten hin orientiert. Wenn wir also gestische Formaspekte von zugrundeliegenden Ba-

81

sishandlungen ableiten wollen, dann haben wir es mit vielfältigen Prozessen der Stilisierung und Abstraktion zu tun. Oft werden in diesen Prozessen einzelne Teilaspekte von Formen herausgegriffen, die dann pars pro toto bzw. metonymisch für ein Ganzes stehen.4
Interessant ist nun, dass man bei der Bedienung von Geräten und den entsprechenden Objekthandhabungen selbst ebenfalls zunehmende Abstraktionsprozesse beobachten kann, die mit den gestischen Abstraktionsprozessen partiell übereinstimmen. Wenn man die Globenreihe in der Ausstellung betrachtet, dann zeigen die einzelnen Globen unterschiedliche Abstraktionsstufen einer Handhabung an, die mit einem Wandel im Kausalitätserleben einhergehen: Der Welthandels- und Verkehrsglobus (ca. 1920) wird unmittelbar mit der Hand in Rotation versetzt, der Smart Globe wird nicht mehr unmittelbar mit der Hand, sondern nur mittelbar mit einem Stift bedient und der Schwebeglobus ist dank eines Magnetfeldes in der Lage, sich freischwebend zu drehen (siehe Abbildungen 4 bis 6). Wir können hier einen Wandel im Objektgebrauch beobachten, der sich zumindest beim Smart Globe nicht mehr intuitiv erschließt und auf Handhabungsbeschreibungen angewiesen ist.5 Ein anderer zentraler technikgeschichtlicher Aspekt ist, dass stark ausdifferenzierte Handhabungen, die zunächst mit spezifischen Objekten und handwerklichen Tätigkeiten verbunden sind, mit fortschreitender Technologisierung von diesen Objekten abgelöst und reduziert werden, beispielsweise auf einen Knopfdruck oder im Fall des Smart Globes auf das Antippen mit einem Stift. Mit demselben Bedienungstyp eines manuellen Knopfdrucks oder der Betätigung eines Hebels oder einer Kurbel können über Maschinen und Interfaces ganz unterschiedliche Vorgänge ausgelöst werden, die untereinander keine Ähnlichkeit aufweisen, z. B. drückt man jeweils auf einen Knopf, um Computer, Waschmaschinen, Staubsauger, Lampen an- oder auszuschalten oder kann mit einigen Klicks am Computer komplexe Produktionsabläufe steuern, die früher eine festgelegte Abfolge von Handgriffen erfordert hätten.
Setzt man die Globenreihe in die Zukunft fort, beispielsweise durch einen virtuellen Globus von Google Earth, der mittels Gestensteuerung bedient werden kann, dann kommen für eine Bedienung beliebig viele verschiedene Handkonfigurationen in Frage. Die Beziehung zwischen der Handbewegung und demjenigen, was mit ihr ausgelöst werden soll, etwa ein Heranzoomen an die Erdoberfläche, ist grundsätzlich willkürlich und beruht lediglich auf einer Festlegung, die von einem Designer getroffen wird und die

man sich über eine Bedienungsanweisung erschließen muss. Oft sind solche kommerziellen Anwendungen für die Nutzer noch sehr unbefriedigend. Das potentielle Spektrum möglicher Handbewegung lässt sich jedoch dadurch eingrenzen, dass man sich die folgenden Fragen stellt: Sind für bestimmte Funktionen an technischen Geräten bestimmte Handbewegungen bereits bei Nutzern etabliert? Wenn ja, wäre für ein neues Gerät mit Gestensteuerung zu prüfen, ob man daran anknüpfen möchte. Einen weiteren Anschluss an bereits Bekanntes eröffnet die Berücksichtigung von konventionalisierten Gesten in der zwischenmenschlichen Kommunikation, die mit ihrer Bedeutung bei den Nutzern im Gedächtnis niedergelegt sind.
Zwischenmenschliche Gesten des Alltagsgebrauchs beruhen jedoch nicht nur auf der Ableitung und partiellen Imitation von zugrundeliegenden Basishandlungen, wie wir sie anhand der Stopp-Geste aufgezeigt haben, sondern können auch metaphorische Konzepte im Sinne von Lakoff und Johnson (1980)6 verkörpern. So hat eine gemeinsame Pilotstudie von Linguisten, Semiotikern und Arbeitswissenschaftlern im MANUACT-Projekt der Technischen Universität Chemnitz für die Nutzung von Google Earth ergeben, dass die metaphorische Geste der flachen Hand als Flugzeug von Probanden produktiv gebraucht wird, um auf einem virtuellen Globus zu navigieren. Die Geste der flachen Hand als Flugzeug ist in verschiedenen Varianten konventionalisiert und stellt dadurch einen vielversprechenden Ausgangspunkt für die intuitive Handhabung dieser Mensch-Maschine-Schnittstelle dar.
Die Auflösung der Kausalität II: Wie Gesten metaphorische Konzepte verkörpern
Um den Grundgedanken einer gestischen Verkörperung von metaphorischen Konzepten in Abgrenzung zur gestischen Imitation grundlegender Basishandlungen klar herauszuarbeiten, greifen wir die Geste des Weghaltens wieder auf. Wie wir am Beispiel des Weghaltens als konventionalisierte, emblematische Geste für ‚Stopp!‘ gesehen haben, geht es bei Gesten im Gegensatz zur Handlungen nicht um das direkte Erreichen eines physikalischen Zwecks, sondern der Zweck wird durch die Geste als Zeichen lediglich angezeigt. Die Geste ist nicht die kausale Ursache dafür, dass der Adressat sich nicht nähert, sondern der Adressat versteht die Bedeutung des Zeichens und die Absicht des Gestikulierenden und kommt deshalb nicht näher. Die Geste stellt dabei oft,

7
8 7 und 8  Experimentierfeld „virtueller Globus“

82

83

wie schon erwähnt, eine verkürzte abgeschwächte Form der Ausgangshandlung dar.
Die Geste des Weghaltens kann im Zusammenwirken mit der gesprochenen Sprache auch metaphorisch, das heißt nicht „wörtlich“ im Sinne einer zugrundeliegenden Basishandlung, sondern übertragen gebraucht werden. Sie wird oft im Zusammenhang von lautsprachlicher Verneinung verwendet und illustriert, wie man sich etwas Abstraktes wie die grammatische Negation als leiblich verankert vorstellen kann.
Dies wird sehr deutlich an einem Ausschnitt aus der Fernsehsendung „Genial daneben“, in der sich ein Teilnehmer mit der Äußerung damit ich jetzt keinen Fehler mache an die anderen Teilnehmer wendet. Das Wort keinen ist im Deutschen ein Negationswort. Begleitend zur verbalen Negation von Fehler (keinen Fehler) wird durch eine beidhändige Geste des Weghaltens ein imaginäres Objekt aus dem Gestenraum ferngehalten. Wir haben es wieder mit einer Zeichenbeziehung zu tun, die in diesem Fall jedoch metaphorisch ist: Abstrakte Begriffe wie „Fehler“, die man nicht anfassen kann, können gestisch wie konkrete Objekte weggehalten und abgewehrt werden. Eigenschaften aus dem Bereich konkreter, abgegrenzter und berührbarer Objekte werden auf den völlig anderen Bereich der abs­trakten Begriffe übertragen. An diesem Beispiel wird auch deutlich, wie Gesten innere Vorstellungen und Konzepte eines Menschen verkörpern und für andere intersubjektiv wahrnehmbar machen können.7
Im MANUACT-Projekt wurde in einer Pilotstudie die Steuerung eines virtuellen Globus mit Leap Motion getestet.8 Bei Leap Motion handelt es sich um einen Controller, eine Kombination von Hardware und Software, die jeden PC oder Mac mit Gestensteuerung versieht. Es werden die Hände des Nutzers mit den einzelnen Fingern erkannt.9 Die Aufgabe für die Probanden bestand nun darin, ohne Kenntnis einer Bedienungsanleitung selbständig herauszufinden, wie man auf Google Earth als einem virtuellen Globus mithilfe von Gestensteuerung navigiert. Das Ziel war, den Berliner Fernsehturm zu finden und die erfolgreiche Suche mit einem Screenshot zu dokumentieren. Auf den ersten Blick scheint die Bedienung von Google Earth eine einfache Sache zu sein. Beim ersten Ausprobieren und Testen der Instruktion durch die MANUACT-Mitarbeiter wurde dieses Ziel jedoch erst nach mehreren Anläufen oder gar nicht erreicht: Einige verschwanden unter der Erde oder in der Weite des Alls, andere gingen in den Tiefen des Ozeans verloren. Ein besonders erfolgreicher Proband zeichnete sich später bei der eigentlichen Durchführung dadurch aus,

dass er eine Geste verwendete, die für die Bedienung gar nicht vorgesehen war. Was machte ihn so erfolgreich? Er benutzte das Konzept eines Flugzeugs, das um die Erde fliegt, um mit dem virtuellen Globus zu interagieren. Dieses Konzept wurde durch die flache Hand verkörpert, deren Handfläche nach unten orientiert war. Zugleich ist diese Geste eine konventionalisierte Geste des Alltagsgebrauchs, wie Vorkommnisse in unterschiedlichen Kontexten zeigen: Die Hand als Ganzes repräsentiert ein Flugzeug mit der Handfläche als Flugzeugunterseite und wird entsprechend bewegt.
Die Flugzeugmetapher zum Ausprobieren: das Experimentierfeld des Ars Electronica Futurelabs
Die ersten Ergebnisse solcher Beobachtungen weisen darauf hin, dass durch Rückgriff auf metaphorische Konzepte digitale Mensch-Maschine-Schnittstellen sehr viel intuitiver gestaltet werden können. Zwischenmenschliche Gesten des Alltagsgebrauchs wie die Geste für Flugzeug zeigen solche Konzepte an. Es ist daher sinnvoll, das Methodenspektrum von Usability-Studien auf Grundlage der oben ausgeführten Erkenntnisse der linguistisch-semiotisch fundierten Gestenforschung zu erweitern.10 Zugleich stellen zwischenmenschliche Gesten des Alltagsgebrauchs einen vielversprechenden Ausgangspunkt dar, um künstliche Gesten für die Gestensteuerung von Robotern und digitalen Interfaces zu entwerfen.11 Das vom Ars Electronica Futurelab für die Ausstellung in Zusammenarbeit mit der Professur Germanistische Sprachwissenschaft, Semiotik und Multimodale Kommunikation der TU Chemnitz entwickelte Experimentierfeld greift die Idee der Flugzeugmetapher aus dem Forschungsprojekt MANUACT auf und arbeitet sie weiter aus. Anders als das Google Earth der ersten Pilotstudie enthält die virtuelle Umgebung des Futurelabs nicht nur einen Globus, sondern zusätzlich auch ein Flugzeug. Dieses Flugzeug kann vom Ausstellungsbesucher mit der flachen Hand gesteuert werden (siehe Abbildungen 7 und 8). Von welchen Erfahrungen die Besucher berichten können, wie sie auf diese besondere gestische Metapher reagieren und wie sie den virtuellen Globus erkunden, kann interessante Impulse für weitere Forschung in diesem Bereich liefern.

84

Anmerkungen 1 Fricke, Ellen: Wie entstehen Gesten? Und was kann das in
Bezug auf die Interaktion mit fahrerlosen Autos in der Zukunft bedeuten? Mercedes-Benz Future Talk „Robotics“. Berlin, 30. Juni bis 2. Juli 2014. Online unter www.youtube.com/ watch?v=rUQmeQ0cgQs&t=134s (13.03.2019). 2 Fricke, Ellen: Origo, Geste und Raum. Lokaldeixis im Deutschen. Berlin und New York 2007. 3 Mara, Martina: Robots From Humanoids to Robo Cars, from Science Fiction to Social Fact. Mercedes-Benz Future Talk „Robotics“. Berlin 30. Juni bis 02. Juli 2014. Online unter www. youtube.com/watch?v=rUQmeQ0cgQs&t=134s (13.03.2019). 4 Mittelberg, Irene; Waugh, Linda R.: Gestures and metonymy. In: Müller, Cornelia u. a. (Hg.), Body – Language – Communication. An International Handbook on Multimodality in Human Interaction (Handbooks of Linguistics and Communication Science 38.2). Berlin und Boston 2014, S. 1747–1766. 5 Das Bedienungswissen zu historischen Artefakten und Zeugnissen der Industriekultur droht zunehmend verloren zu gehen. Die Aufzeichung und wissenschaftliche Erschließung des entsprechenden Handhabungswissens, insbesondere mit Unterstützung denjenigen Personen, die noch über dieses Wissen verfügen, ist eine wichtige Aufgabe für Museen in Kooperation mit anderen Forschungseinrichtungen. 6 Lakoff, George; Johnson, Mark: Metaphors We Live By. Chicago und London 1980. 7 Vgl. Bressem und Müller (wie Anm. 3) sowie Fricke, Ellen: Between reference and meaning: Object-related and interpretant-related gestures in face-to-face interaction. In: Müller, Cornelia u. a. (Hg.), Body – Language – Communication. An International Handbook on Multimodality in Human Interaction (Handbooks of Linguistics and Communication Science 38.2). Berlin und Boston 2014, S. 1788–1802 und Fricke, Ellen; Bressem, Jana; Müller, Cornelia: Gesture families and gestural fields. In: Müller, Cornelia u. a. (Hg.), Body – Language – Communication. An International Handbook on Multimodality in Human Interaction (Handbooks of Linguistics and Communication Science 38.2). Berlin und Boston 2014, S. 1630–1640. 8 Seeling, Thomas; Dittrich, Frank; Fricke, Ellen; Bullinger-Hoffmann, Angelika: Gestenbasierte Google-Earth-Bedienung. Implikationen für ein natürliches Gesten-Set am Beispiel einer 3D-Topographieanwendung. In: Gesellschaft für Arbeitswissenschaft e. V. (Hg.), Arbeit in komplexen Systemen – Digital, vernetzt, human?!, 62. Kongress der Gesellschaft für Arbeitswissenschaft. Dortmund 2016, S. 88–92.

9 Siefkes, Martin: Aufzeichnungstechniken der Gestenforschung, in diesem Band.
10 Vgl. Fricke (wie Anm. 2). 11 Vgl. Fricke (wie Anm. 1 und 2).
Abbildungsnachweis: 1–2 Fotos: Tobias Naumann. 3 Foto: © Mercedes-Benz, Mercedes-Benz Advanced UX
Design. 4 Foto: Tobias Naumann. 5 Foto: Dietmar Träupmann. 6 Foto: privat. 7–8 Fotos: Tobias Naumann.

85

Die Entwicklung der Globen

Manuel Schramm

Einer verbreiteten Legende zufolge glaubten die Menschen im Mittelalter, die Erde sei eine Scheibe. Daher sei Kolumbus mit seinem Plan, den Seeweg nach Indien auf westlichem Weg zu finden, auf große Skepsis gestoßen.1 Tatsächlich war jedoch die Kugelgestalt der Erde schon seit der Antike bekannt. Der griechische Gelehrte Eratosthenes von Kyrene gelangte im 3. Jh. v. Chr. sogar zu einer recht genauen Bestimmung des Erdumfangs mit Hilfe von astronomischen Beobachtungen. Auch im Mittelalter war zumindest unter den Gelehrten die Kugelgestalt der Erde unumstritten. Daher wäre es vorstellbar, dass es in der Antike und im Mittelalter bereits Globen gab, die die Kugelgestalt der Erde anschaulich demonstrierten. Sicher ist das aber nicht. Immerhin gibt es Abbildungen, die die Erdkugel zeigten. Sie dienten weltlichen Herrschern zur Symbolisierung ihrer Macht. Im Römischen Reich wurde bereits 75 v. Chr. das Bild einer Erdkugel benutzt, um den weltumspannenden Machtanspruch seiner Herrscher zu betonen. Im Mittelalter wurde der Kugel ein christliches Kreuz hinzugefügt, und als „Reichsapfel“ gehörte sie zu den Herrschaftszeichen der römisch-deutschen Könige und Kaiser.2
Allerdings kannte die Antike Himmelsgloben. Da man sich lange Zeit den Himmel als Kugel vorstellte, lag es nahe, Globen mit den bekannten Sternbildern zu bauen. Erhal-

1  Martin Behaims „Erdapfel“, 1492

86

2  Jan Vermeer, Der Astronom, 1668

ten ist beispielsweise der so genannte „Atlas von Farnese“, eine Statue mit einem Himmelsglobus (um 300 v. Chr.).3 Der erste erhaltene Erdglobus ist der „Erdapfel“ des Nürnberger Gelehrten und Tuchhändlers Martin Behaim von 1492 (vgl. Abbildung 1). Obwohl er im Jahr der Entdeckung Amerikas vollendet wurde, repräsentiert er doch das vorkolumbianische Weltbild ohne Amerika. Vor Behaim mag es auch andere Erdgloben im 15. Jahrhundert gegeben haben. Ausgelöst wurde das Interesse an Geographie durch die Wiederentdeckung der Schriften von Ptolemäus um 1400.4 Auch dieser antike Gelehrte war bereits von der Kugelgestalt der Erde ausgegangen, unterschätzte jedoch deren Umfang und die Ausdehnung des Atlantik erheblich.

Über den Gebrauch von Behaims Globus wissen wir recht wenig. Wahrscheinlich wurde er angefertigt, um die Nürnberger Kaufleute zum Einstieg in den Überseehandel zu bewegen. Im 16. Jahrhundert wurden die nun in großer Zahl angefertigten Globen aber rasch zu wichtigen Lehrund Forschungsmitteln, zum Beispiel für den Unterricht in mathematischer Geographie an der Universität Wien.5 Den Charakter des Globus als wissenschaftliches Instrument unterstreicht auch der Globus von Gerhard Mercator von 1541, der als erster Loxodrome enthält, also Linien, die die Meridiane immer in demselben Winkel schneiden.6
Diesen wissenschaftlichen Gebrauch zeigt ein Gemälde Vermeers aus dem Jahr 1668 (vgl. Abbildung 2). Der Gelehrte, es handelt sich hier um einen Astronomen, sitzt an sei-

87

3  Geographieunterricht am Hampton Institute, Virginia, USA, 1899

nem Schreibtisch und scheint mit seiner rechten Hand den Himmelsglobus zu drehen, während vor ihm ein aufgeschlagenes Buch liegt. Sein Blick ist auf den Globus gerichtet, die linke Hand stützt sich auf einen über ein Möbelstück geworfenen Teppich. Möglicherweise versucht er, Angaben aus dem Buch anhand des Globus zu überprüfen.
Im 17. und noch mehr im 18. Jahrhundert stellte der Globus in der Tat ein wissenschaftliches Instrument dar. Dazu war er mit vielen Hilfseinrichtungen ausgestattet, wie Höhenquadrant, Kompass, Meridianring, Stundenscheibe und Horizontring. Im Laufe des 19. Jahrhunderts verschwanden diese Hilfsmittel weitgehend und der Globus wurde tendenziell ein reines Schaustück für die Lehre, aber kaum noch für die Forschung genutzt.7 Wie die Benutzung des Globus im Klassenraum aussah, verdeutlicht Abbildung 3. Sie zeigt eine Geographiestunde in den USA um 1900, bei der alle Schüler einen kleinen Globus in der Hand halten, mit dessen Hilfe die Umdrehung der Erde um die Sonne verdeutlicht werden soll.
Im 19. Jahrhundert wurden sogar Gebrauchsanleitungen für Globen verfasst, so etwa 1822 von Joseph Jüttner, der selbst einen Globus gebaut hatte. Er beschreibt die Bestimmung von geographischer Breite und Länge eines Ortes mit Hilfe des Globus folgendermaßen:

„Man orientire […] den Globus, und drehe denselben so lange, bis der gegebene Ort, dessen Länge und Breite man bestimmen will, unter dem messingenen Meridian, und zwar unter die eingetheilte Fläche zu stehen kommt, so zeigen die Grade auf dem messingenen Meridian die Breite, und jene auf dem Aequator die Länge des gegebenen Ortes an.“8 Der Globus stand hier noch in der Tradition des 18. Jahrhunderts und war mit Hilfseinrichtungen versehen (Meridian aus Messing). Diese waren nötig, um nicht nur topographische Probleme, sondern auch solche der mathematischen Geographie mit Hilfe des Globus bearbeiten zu können.
Aber nicht alle historischen Globen wurden auf die beschriebene Weise mit der Hand gedreht. Zwar kamen Globen, die mit Hilfe von Motoren in Bewegung gesetzt werden konnten, erst nach dem Zweiten Weltkrieg auf,9 aber in der Zeit des Barock wurden Riesengloben gebaut, die mit einer Öffnung versehen und somit begehbar waren. Den wohl bekanntesten dieser Riesengloben baute der italienische Gelehrte Vincenzo Coronelli 1683 für König Ludwig XIV. (vgl. Abbildung 4). Er maß 385 cm im Durchmesser und bildete zusammen mit einem Himmelsglobus ein Globenpaar.10 Er enthielt eine unglaubliche Fülle an Informationen, aber sowohl die Aufstellung als auch die Benutzung erwiesen sich als schwierig. Ludwig XIV. musste sich spezielle Opernglä-

88

ser anfertigen lassen, um die Beschriftung lesen zu können, und in der Orangerie von Versailles fand sich kein geeigneter Platz, so dass er erst 1704 im Schloss von Marly aufgestellt werden konnte.11 Heute steht er in der Französischen Nationalbibliothek.
Das 20. Jahrhundert brachte wichtige Veränderungen im Bereich der Globen. Insbesondere wurden viele neue Typen von Globen konstruiert, um zum einen die Benutzbarkeit, zum anderen die Darstellung auf den Globen zu verbessern. So kamen seit den 1920er Jahren Leuchtgloben auf, später auch Reliefgloben und Rollgloben.12 Gemeinsam war allen diesen Typen jedoch, dass sie von Hand gedreht werden mussten. Nur bei manchen größeren Globen wurde ein Motor eingebaut.
Die Nutzungsmöglichkeiten werden durch neuere Globen deutlich erweitert. So gibt es seit 2006 interaktive Globen, bei denen sich mit Hilfe eines Stiftes zusätzliche, digital gespeicherte Informationen abrufen lassen, die über inte­ grierte Lautsprecher in gesprochener Form ausgegeben werden (vgl. Abbildung 5).13 Gleichzeitig lassen sich damit verschiedene Lernspiele durchführen. Die interaktiven Globen sind allerdings eher als Lernspielzeug gestaltet und weniger als wissenschaftliches Instrument wie in früheren Zeiten.
Eine andere neue Entwicklung sind die seit ungefähr zehn Jahren existierenden Magnetschwebegloben (vgl. Abbildung 6).14 Dabei wird die Erdkugel durch einen Elek­ tromagneten in der Schwebe gehalten und dreht sich meist von selbst, kann aber auch von Hand gedreht werden. Eine weitere Nutzung ist nicht vorgesehen. Es handelt sich dabei wohl eher um ein Dekorationsobjekt als um ein Lernmittel.
Erst in den letzten Jahren gibt es Versuche, die direkte Berührung durch Techniken der Gestensteuerung zu ersetzen. Der Globus wird dabei nur noch virtuell repräsentiert, ist also streng genommen kein Globus im eigentlichen Sinne mehr. Mit gezielten Handbewegungen lässt sich der virtuelle Globus nicht nur drehen, sondern es kann auch der Maßstab verkleinert oder vergrößert werden. Somit bietet die neue Technik auch neue Möglichkeiten der Darstellung (vgl. Beitrag „Von der Kugel zu Google Earth“).15

4  Coronelli-Globus für Ludwig XIV., 1683 5  Interaktiver Globus Oregon Scientific SmartGlobe

Anmerkungen 1 Vgl. Krüger, Reinhard: Moles globosa, globus terrae und arenosus
globus in Spätantike und Mittelalter. Eine Kritik des Mythos von der Erdscheibe. Berlin 2012.

6  Magnetschwebeglobus, Hersteller: ZJchao

89

2 Vgl. Cosgrove, Denis: Apollo’s Eye. A Cartographic Genealogy of the Earth in the Western Imagination. Baltimore 2001, S. 10 f.
3 Vgl. Muris, Oswald; Saamann, Gert: Der Globus im Wandel der Zeiten. Eine Geschichte der Globen. Berlin 1961, S. 21.
4 Vgl. Cosgrove (wie Anm. 2), S. 102. 5 Vgl. Muris und Saamann (wie Anm. 3), S. 67. 6 Vgl. ebd., S. 103. 7 Vgl. ebd., S. 244. 8 Jüttner, Joseph: Anweisung für den Gebrauch eines neu verfer-
tigten Globus. Prag 1822, S. 27. 9 Vgl. Muris und Saamann (wie Anm. 3), S. 266. 10 Vgl. Seggewiß, Wilhelm: Die Coronelli-Globen. Barocke Pracht
und Wissenschaft. Trier 2015, S. 16. 11 Vgl. Cosgrove (wie Anm. 2), S. 166 f. sowie Muris und Saa-
mann (wie Anm. 3), S. 170. 12 Vgl. Muris und Saamann (wie Anm. 3), S. 253, 260, 263. 13 Vgl. OregonSmartGlobe: Oregon Scientific Smart Globe.
Online unter www.youtube.com/watch?v=WXvaoWXtHVI (10.07.2017). 14 Vgl. Vat19: Stellanova Magnetic Levitating Globe. Online unter www.youtube.com/watch?v=TmtjS2c912g (10.07.2017). 15 Vgl. SMART Technologies DE: Diercke Globus Online am SMART Board. Online unter www.youtube.com/ watch?v=BBf4VUK7QLA (10.07.2017). In der Ausstellung ist eine Kombination aus Google Earth mit Gestensteuerung durch Leap Motion zu sehen. Ausschnitte online unter http://manuact.org/auftakt2015/MANUACT_Werkstattimpressionen_2015.m4v (10.07.2017).

Abbildungsnachweis 1 Wikimedia Commons: https://commons.wikimedia.org/wiki/
File:Behaim_Globus.jpg (10.07.2013). 2 Bildarchiv Preußischer Kulturbesitz Nr. 00051343; Copyright:
bpk/RNM-Grand Palais/René-Gabriel Ojèda. 3 Wikimedia Commons: https://commons.wikimedia.org/wiki/
File:Hampton_Institute_-_geography.jpg (10.07.2017); Autor: France Benjamin Johnston. 4 Wikimedia Commons, https://commons.wikimedia.org/wiki/File:Coronelli_globe_terrestre.jpg (06.10.2017); Autor: Myrabella. 5 Foto: Dietmar Träupmann. 6 Foto: privat. 7 Foto: Dietmar Träupmann.

7  Von klassisch bis virtuell: Globenreihe in der Sonderausstellung

90

91

III WIE GESTEN UND HÄNDE SICH WANDELN: EVOLUTION, ANTHROPOLOGIE, TECHNOLOGIE
» Ellen Fricke Die Vergangenheit in der Gegenwart sehen: Zeichensprachen der Aborigines in Australien
» Susanne Grassmann Menschen, Affen, Hunde und die Evolution von Gesten
» Ulrike Thomas Menschliche Hände als Vorbild für robotische Hände?
» Daniel Schöller, Martin Siefkes und Ellen Fricke Wie man früher den Telefonhörer hielt: Gesten als Wissensspeicher

92

93

Die Vergangenheit in der Gegenwart sehen:
Zeichensprachen der Aborigines in Australien
Ellen Fricke

Aborigines leben auf dem australischen Kontinent seit mehr als 50.000 Jahren und haben vielfältige Spuren hinterlassen, die in der Gegenwart zunehmend gewürdigt und als Bestandteil des australischen kulturellen Erbes aufgefasst und vermittelt werden.1 Wenn man als Linguistin eine Stadt wie Sydney zum ersten Mal besucht und sich anhand eines Stadtplans orientieren möchte, dann fallen einem als erstes die Namen von Stadtteilen wie Cabramatta, Cammeray, Kurnell, Dee Why, Bondi oder Maroubra ins Auge, die auf Ortsbezeichnungen zurückzuführen sind, die ursprünglich von australischen Aborigines verwendet wurden, um bestimmte Landareale zu benennen.2 Auch in Namen von Parks und anderen Landmarken finden sich vergleichbare Spuren. Von einigen Hauptstraßen wie King Street, Oxford Street, George Street und Warringah Road wird angenommen, dass sie entlang von Pfaden verlaufen, die von Aborigenes begangen wurden.3 Sydney wurde also auf Landarealen und Wasserwegen errichtet, die vormals von Aborigines stark genutzt wurden (siehe Abbildung 1).
Bei der Britischen Landnahme im Jahr 1788 zur Errichtung einer Kolonie vermutete Gouverneur Arthur Philipp, dass mindestens 1500 Aborigines zwischen Botany Bay und Broken Bay, also im Küstenareal des heutigen Sydney lebten: “At that time, the British encountered Aboriginal peo-

ple fishing in canoes and saw them cooking and camping in sandstone shelters around the harbour. They witnessed great numbers of people gathering for ritual ceremonies. They discovered their rock engravings and found enormous piles of shells, the refuse of many thousands of shellfish meals consumed over the centuries.”4
Die Geschichte der Aborigines in Sydney ist seitdem eine Geschichte des Überlebens unter äußerst widrigen Umständen. Nach Ausbruch der Pocken 1789 unter den Briten in Sydney reduzierte sich die Anzahl der Ureinwohner in diesem Areal um mindestens 50 Prozent, es folgten Landenteignungen, die Zerstörung von Tradition, Sprache und materieller Kultur. Es gibt aber auch eine andere Seite, die sich in Berichten von Widerstand, kultureller Kontinuität, Überleben und Stolz widerspiegelt.5
Sprachen und soziale Struktur
Zur Zeit des ersten europäischen Kontakts wurden in Australien mehr als 250 Sprachen gesprochen und die meisten von ihnen untergliederten sich in weitere Dialekte. Es ist wichtig, sich zu vergegenwärtigen, dass die Aborigines sich nicht in erster Linie einer Sprachgemeinschaft zuge-

94

1  Alltagsszenen der Aborigines am Strand beim Fischen. Joseph Lycett, Aquarell, ca. 1820

hörig fühlen, wie dies bei Europäern der Fall ist, sondern die Zugehörigkeit zu einer sozialen Gruppe sich vielmehr über die Zugehörigkeit zu einem Clan konstituiert oder zu einer Gruppierung, die sich von einem gemeinsamen Ahnen herleitet, dem wiederum ein bestimmtes Territorium zu eigen ist.6 Das heißt, vor dem Kontakt mit Europäern waren australische Gesellschaften über die Anerkennung des Eigentums und der Eigentumsgrenzen organisiert. Das Eigentumsrecht auf ein Territorium wurde mit der Geburt erworben und hatte eine starke spirituelle Komponente: “[…] collectively, members of a community shared responsibility for sacred sites and hunting grounds, and for the cultural knowledge which linked people to these sites.” 7
Dass Aborigines nicht nur eine, sondern mehrere Sprachen sprechen konnten, war ein weit verbreitetes Phänomen,8 über das vielfach berichtet wurde. Jedoch geht es bei dieser Form der Vielsprachigkeit nicht primär darum, sich an unterschiedlichen Orten verständlich machen zu können, sondern die Verwendung einer Sprache ist primär Ausdruck einer bestimmten sozialen Identität: “Sutton9 states that people are multilingual not because they are frequently having to change their language to make themselves understood. Rather, the code one speaks is a matter of choice and by means of this choice one can give expression of one’s view of the kind of social relationship one is engaging in.” 10 Das heißt, welche Sprache oder welchen Dialekt man in einer Kommunikationssituation wählt, wird wesentlich durch die

Absicht des Sprechers bestimmt, den sozialen Kontext der Interaktion aktiv zu gestalten. Die Verwendung von gestischen Zeichensprachen ist eine besondere kommunikative Option, deren Funktion eng mit ihren spezifischen medialen Eigenschaften und mit ihrer Einbettung in ritualisierte Alltagskontexte zusammenhängt.
Zeichensprachen der Aborigines und ihre wissenschaftliche Untersuchung
Die erste detaillierte und umfassende Untersuchung von Zeichensprachen der Aborigines hat Adam Kendon 1989 mit seiner mehr als 400 Seiten umfassenden Monographie “Sign Languages of Aboriginal Australia. Cultural, Semiotic and Communicative Perspectives” vorgelegt. Es ist die erste Untersuchung, die Zeichensprachen der Aborigines zu den jeweiligen Lautsprachen in Beziehung setzt und die insbesondere Kategorien zur Beschreibung von Handbewegungen in Zeichensprachen entwickelt, die an die damalige Erforschung der Gebärdensprachen der Gehörlosen anschließen und zudem weiterführende Perspektiven für die Untersuchung emblematischer und redebegleitender Gesten eröffnen. Es handelt sich um einen Meilenstein der Gestenforschung überhaupt, der aufgrund des derzeitigen Schwerpunkts auf redebegleitenden Gesten in den letzten 25 Jahren viel zu wenig rezipiert wurde. Viele Überlegungen

95

und Kategorisierungen, die sich später in Kendons Hauptwerk „Gesture: Visible Action as Utterance“11 finden, sind in diesem Buch bereits angelegt. Darüber hinaus ergeben sich interessante Anknüpfungspunkte für die Entwicklung von künstlichen gestischen Zeichen,12 die sich für Konzepte zukünftiger Gestensteuerung von Interfaces und Robotern als relevant erweisen könnten.
Es gibt einige frühe Berichte, die auf den Gebrauch von gestischen Zeichensprachen durch Aborigines hinweisen, so beobachtet beispielsweise Gason 1874: “Besides the spoken language, they have a copious one of signs – all animals, native man or woman, the heavens, earth, walking, riding, jumping, flying, swimming, eating, drinking, and hundreds of other object or actions have each their particular sign, so that a conversation may be sustained without a single word.” 13 Die ersten wissenschaftlichen Untersuchungen zu Zeichensprachen aus einem anthropologischen Erkenntnisinteresse heraus unternehmen Ende des 19. und Anfang des 20. Jahrhunderts Roth14, Howitt15 sowie Spencer und Gillen16. Diese Arbeiten standen ähnlich wie die grundlegende Abhandlung des Leipziger Forschers Wilhelm Wundt zu Gesten in derselben Zeit noch unter dem Einfluss eines evolutionären Ansatzes17 und einer Debatte um einen möglichen Ursprung von Sprache. Insbesondere das Kapitel „The Expression of Ideas by Manual Signs: A Sign Language“ in Roths Buch über seine ethnologischen Studien in North-West-Central Queensland18 wird von Kendon als beispielhaft hervorgehoben.19 Es sei bis heute die wichtig­ ste Quelle für Zeichensprachen in diesem Teil Australiens und die einzige detaillierte Beschreibung, die es für diesen Teil gibt. Roths Buch enthält genaue Beschreibungen der Zeichen in Bezug auf ihren Ursprung und ihren Gebrauch sowie Angaben, welche Aborigines-Gruppen welche Zeichen verwenden. Die Beschreibungen werden durch präzise Zeichnungen illustriert, wie sie z. B. in den Tafeln mit den Gesten für australische Tiere zu sehen sind (siehe Abbildungen 2 und 3), die einen lebendigen Eindruck davon vermitteln können, wie die Gesten von den Aborigines ausgeführt wurden und welche Prinzipien bei der Entstehung der Gesten eine Rolle spielten, Prinzipien, die wir auch heute noch bei unseren eigenen Gesten beobachten können.
Was charakterisiert gestische Zeichensprachen?
Die Zeichensprachen der Aborigines sind dadurch gekennzeichnet, dass sie nicht als alleiniges Kommunikationsmit-

tel verwendet werden, sondern ihr Gebrauch in bestimmten Situationen eine zusätzliche Möglichkeit neben der Verwendung der primären Lautsprachen darstellt. Diese Eigenschaft unterscheidet sie von den Gebärdensprachen der Gehörlosen, deren Sprecher sich nur mit den Händen und anderen visuell wahrnehmbaren Zeichen verständigen können. Wir unterscheiden daher mit Kendon20 zwischen primären Zeichensprachen, die Kinder als erste Sprache erwerben, und alternierenden Zeichensprachen, die in bestimmten Situationen und für bestimmte Zwecke an die Stelle der primären Lautsprache treten können. Bekannte Beispiele für solche Zeichensprachen sind neben denjenigen der Aborigines die Zeichensprachen der Prärieindianer in Nordamerika und die Zeichensprachen gewisser Mönche, die in Klostergemeinschaften mit einem Schweigegebot verwendet werden (z. B. Zisterzienserklöster). Gemeinsam ist diesen Zeichensprachen, dass sie komplex sind: Sie verfügen nicht nur über einzelne konventionalisierte Zeichen, die auf einer gesellschaftlichen Übereinkunft beruhen, wie wir sie bei sogenannten emblematischen Gesten unseres Alltagsgebrauchs wie der Victory-Geste oder den Gesten für Stopp oder Okay kennen, sondern mit einem sehr umfangreichen Gestenvokabular können gestische Sätze gebildet und komplexe Sachverhalte ohne zusätzliche Verwendung der Lautsprache übermittelt und dargestellt werden. Allerdings sind alternierende Zeichensprachen im Unterschied zu den Gebärdensprachen der Gehörlosen stark von den Strukturen der primären Lautsprachen beeinflusst, denn die gestischen Zeichensprachen wurden von deren Sprechern als zusätzliche Alternative zur Lautsprache entwickelt.21 Etwas vereinfacht gesagt: Man trifft oft auf Gesten einer Zeichensprache mit dem Satzbau der primären Lautsprache oder es werden sogar, wie bei bestimmten gestischen Zeichen mönchischer Klostergemeinschaften, Laute und Lautverbindungen durch ein gestisches Alphabet wiedergegeben, eine Repräsentationsform, die den durchweg schreibkundigen Mönchen geläufig ist.
Kommunikative Funktionen von Zeichensprachen
Manuelle Zeichensprachen, die mit Händen und Armen artikuliert werden und auf das Auge wirken, weisen Eigenschaften auf, die sie für bestimmte kommunikative Zwecke besonders geeignet erscheinen lassen. Bei den Prärieindianern in Nordamerika dienen Zeichensprachen als eine Verkehrssprache oder Lingua franca, um sich trotz der Zu-

2 und 3  Tiergesten der Aborigines in North-West-Central Queensland

96

97

gehörigkeit zu unterschiedlichen Sprachgemeinschaften verständigen zu können. Bei Mönchen mit Schweigegelübde hingegen haben Gesten die Funktion, die Kommunikation durch Lautsprache vollständig zu ersetzen, auch wenn alle an der Kommunikationssituation Beteiligten in der Lage sind, dieselbe Lautsprache zu sprechen und zu verstehen. Bei den Aborigines in der zentralen Wüstenregion Australiens sind Zeichensprachen in ganz anderer Weise mit der sozialen Struktur und Interaktion verbunden. Eine wichtige Eigenschaft des sozialen Zusammenhangs, die Kendon für die Aborigines im Areal der North Central Desert herausstellt, ist die grundlegende wechselseitige Annahme, dass jede Einzelpersönlichkeit autonom ist. Daraus ergibt sich, dass die individuellen Beziehungen immer wieder neu ausgehandelt werden müssen: “That is, people behave toward each other in such a way as to make it clear that they are respecting each other’s rights to be a free agent. In most circumstances people do not attempt to constrain others to do their bidding in a direct, overt manner, and nobody is prepared to take orders from others as to what should be done.“ 22 In der alltäglichen Interaktion müssen also durch einen respektvollen Umgang immer wieder Kompromisse gefunden werden, auch um schnell ausbrechende gewaltsame Konflikte zu vermeiden.23
Zeichensprachen sind aufgrund ihrer spezifischen Medialität für bestimmte Aushandlungsprozesse besonders geeignet. Kendon nennt die folgenden Aspekte: 1. Die Verwendung von Gesten ermöglicht eine präzise
Adressierung von Personen und gewährleistet dadurch Diskretion. Handbewegungen lassen sich zum einen durch den eigenen Körper verdecken, zum anderen kann man beobachten, wer die eigenen Handbewegungen beobachtet, da dies nur durch eine bestimmte körperliche Orientierung und Zugewandtheit geschehen kann. Bei lautsprachlichen Äußerungen hingegen sind ungewollte Mithörer nicht so leicht auszuschließen. Dadurch ist es möglich, den potentiellen Adressatenkreis für die eigenen Mitteilungen sehr viel genauer zu kontrollieren.24 2. Gesten können im Hinblick auf den Prägnanzgrad und die Explizitheit ihrer Ausführung variieren. Oft sind Gesten auch nicht leicht von Handlungen zu unterscheiden. Bei lautsprachlichen Äußerungen ist ein vergleichbarer Spielraum nicht gegeben, es bleibt stets unzweideutig, ob man es mit einer sprachlichen Äußerung zu tun hat oder nicht. Dieser gestische Vagheitsspielraum ermöglicht es, indirekt und tentativ zu kommunizieren und falls erforderlich, gesichtswahrend von einer Aussage

zurückzutreten. Kendon gibt das Beispiel eines Sprechtabus in Bezug auf verstorbene Verwandte.25 Wenn man nach langer Abwesenheit aufeinandertrifft und sich nach bestimmten Personen erkundigt, dann stellt die Verwendung von gestischen Zeichensprachen in der Kommunikation sicher, dass man keine Sprechtabus in Bezug auf verstorbene Personen verletzt. Es ist äußerst delikat, auf verstorbene Personen Bezug zu nehmen. Insbesondere Frauen sind während der Trauer um einen verstorbenen Verwandten mit einem Sprechtabu belegt und verwenden stattdessen eine gestische Zeichensprache, die als indirekter und neutraler gilt und die am wenigsten persönlichste Art der Bezugnahme darstellt.26 3. Während das lautliche Sprechen mit der inneren Seele und Intimität verbunden wird, werden gestische Zeichen, die vom restlichen Körper entfernt ausgeführt werden können, als objektartig und dadurch als am wenigsten personalisiert aufgefasst. Der Objektcharakter und die Zuschreibung von Neutralität machen die Verwendung von gestischen Zeichensprachen bei den Aborigines besonders geeignet für die Bekundung von Respekt in der zwischenmenschlichen Kommunikation und in sakralen Ritualen. 4. Gestische Zeichen erlauben zudem eine „stille“ Kommunikation über größere Distanz und können dadurch auch in Situationen gebraucht werden, in denen eine Anhebung der Sprechlautstärke unangemessen wäre und als respektlos aufgefasst würde.27
Wie entstehen Gesten in Zeichensprachen? Was bilden sie ab? Was haben sie mit anderen Gesten gemeinsam?
Das Interesse an der Erforschung von Gesten in Zeichensprachen war im Vergleich zu anderen Gestentypen bisher auch deshalb eher gering, weil Zeichensprachen und andere von Lautsprachen unabhängige Gesten in unserem Alltagsleben keine oder nur eine vergleichsweise geringe Rolle spielen. Dies ist jedoch gerade im Begriff sich zu ändern. Wenn man über ein Repertoire künstlicher Gesten für die Gestaltung der Kommunikation von Menschen und Maschinen nachdenkt,28 dann bieten Zeichensprachen einen weiteren interessanten Ansatzpunkt sowohl für die Reflexion als auch für praktische Überlegungen zur Ausgestaltung solcher Interfaces. Auch bei der Mensch-Maschine-Interaktion können bestimmte Umweltbedingungen eine Rolle spielen, die Gesten in lauten Arbeitsplatzkontexten oder bei

98

99

4  Aborigines-Geste für Känguru im interaktiven Spiegelexponat „Fernblick“
Verkehrslärm, z. B. in der Kommunikation von Fußgängern und fahrerlosen Autos, als eine sinnvolle Option erscheinen lassen. Umgekehrt stellen Neuentwicklungen solcher gestischen Zeichensprachen im technologischen Kontext einen interessanten semiotischen und sprachwissenschaftlichen Untersuchungsgegenstand dar.
Wenn man den Blick auf die Frage lenkt, wie eigentlich eine Handbewegung zu einem Zeichen für andere werden kann, dann lassen sich unterschiedliche Verfahren identifizieren, die verschiedenen Gestentypen gemeinsam sind. Eines dieser Verfahren wird in den Zeichnungen von Roth29 (siehe Abbildungen 2 und 3), die Gesten der Aborigines in North-West-Central Queensland dokumentieren, besonders deutlich: Alle Hände stellen Tiere dar, aber sie tun dies in unterschiedlicher Weise. Wir können beobachten, dass nicht das ganze Tier dargestellt wird, sondern nur ein bestimmter Körperteil, manchmal auch verbunden mit einer Bewegung. Welcher Körperteil und welche Bewegung in der Geste erscheinen, ist auch nicht willkürlich, sondern es werden besonders markante Eigenschaften der Tiere her-

ausgegriffen, die sie untereinander unterscheidbar machen und es erlauben, das jeweilige Tier zu identifizieren. Für das Spiegelexponat „Fernblick“ wurden aus den Zeichnungen von Roth einige Tiere ausgewählt (siehe Abbildung 4).
Die Ausstellungsbesucher können ausprobieren und an sich selbst beobachten, welche gestische Darstellung sie für die unterschiedlichen Tiere wählen würden, um sie für jemand anderen möglichst eindeutig identifizierbar zu machen. Das Prinzip, dass ein Teil für Ganzes steht, wird auch metonymisches Prinzip genannt.30 Die abgeknickten Pfoten stehen bei den Aborigines für ein Känguru (siehe Abbildung 2, Zeichnung 24), die Hin-und-Her-Bewegung der Handfläche für ein trabendes oder galoppierendes Pferd (siehe Abbildung 2, Zeichnung 2), die an den Kopf angelegten Zeigefinger als Hörner für einen Stier (siehe Abbildung 2, Zeichnung 4) als ganzes Tier.
Genau wie bei Zeichnungen, wenn man beispielsweise an Karikaturen denkt, haben wir es bei den ebenfalls visuellen Gesten mit Stilisierungen, Verkürzungen und Übertreibungen zu tun. Kendon nennt diesen Aspekt die bildliche Repräsentation (image representation).31 Es handelt sich um die gestische Repräsentation einer Vorstellung, die man sich wie in unserem Beispiel von einem Tier macht. Daran schließt sich in Zeichensprachen ein weiterer Prozess der Zeichenformierung (sign formation) an. Bei der Zeichenformierung spielen die Beziehungen zu anderen gestischen Zeichen eine Rolle, die Art und Weise, wie bildliche Repräsentationen in konventionalisierte Zeichen überführt werden, und wie Prozesse der Zeichenformierung durch bereits bestehende Strukturierungsprinzipien der jeweiligen Zeichensprachen beschränkt werden. Nehmen wir ein hypothetisches Beispiel: Es sollen zwei verschiedene Känguruarten durch zwei unterschiedliche Gesten dargestellt werden. Wenn man in beiden Fällen dieselben abgeknickten Handformen wählt, dann hat man nur eine Geste für Känguru, ohne die beiden Arten voneinander unterscheiden zu können. Man könnte z. B. mehrere „Schläge“ (strokes) mit der nach unten abgeknickte Hand ausführen, und so die Geste für Känguru A mit einem Schlag von der Geste für Känguru B mit vier schnellen Schlägen unterscheiden. Wenn wir bei dem Beispiel bleiben, dann könnte die Zeichensprache, zu der die beiden Kängurugesten gehören sollen, jedoch die Beschränkung haben, dass sie maximal drei Repetitionen zulässt. Dann müsste die Zeichenformierung der Geste für Känguru B dahingehend abgeändert werden, dass sie einen Schlag weniger aufweist, damit sie mit den Regeln der gestischen Zeichensprache konform ist. Nun werden auf der

100

Tafel von Roth bei den Aborigines-Gesten ebenfalls zwei Känguruarten unterschieden, allerdings in anderer Weise: Das Pademelon ist eine Art „kleines“ Känguru mit einem vergleichsweise runden Kopf als prägnantem Merkmal. Bei der Geste für ein Pademelon umreißt der Zeigefinger des Gestikulierenden daher dessen Kopf mit einer kreisförmigen, zeichnenden Geste (siehe Abbildung 2, Zeichnung 21).
Zusammengefasst: Bei allen Gestentypen scheinen wir es mit gleichartigen Prozessen der metonymischen Ab­ straktion zu tun zu haben, die sich jedoch mit Bezug auf die bezeichneten Objekte und in Relation zu anderen Gesten je unterschiedlich ausprägen. Wenn man sich selbst und andere Ausstellungsbesucher am Spiegelexponat beim spontanen Erfinden von Tiergesten für ein vorgegebenes Tier beobachtet und mit den zeichnerisch dokumentierten Aborigines-Gesten des 19. Jahrhunderts vergleicht, dann können wir nicht nur die Gegenwart in der Vergangenheit, sondern auch die Vergangenheit in der Gegenwart sehen.
Anmerkungen 1 Vgl. Hinkinson, Melinda: Aboriginal Sydney. A Guide to Im-
portant Places of the Past and Present. Canberra 2015, S. xviii. 2 Vgl. ebd. 3 Vgl. ebd. 4 Ebd. 5 Vgl. Taylor, Russel: Foreword. In: Hinkinson, Melinda: Abori-
ginal Sydney. A Guide to Important Places of the Past and Present. Canberra 2015, S. viii. 6 Vgl. Hinkinson (wie Anm. 1), S. xxiv. 7 Ebd. 8 Vgl. Brandl, Maria; Walsh, Michael: Speakers of many tongues: toward understanding multilingualism among Aboriginal Australians. In: International Journal of the Sociology of Language 36 (1982), S. 71–82, zitiert nach Kendon (wie Anm. 10). 9 Sutton, Peter J.: Wik: Aboriginal Society, Territory and Language at Cape Keerweer, Cape York Peninsula, Australia. Brisbane 1978, zitiert nach Kendon (wie Anm. 10). 10 Kendon, Adam: Sign Languages of Aboriginal Australia. Cultural, Semiotic and Communicative Perspectives. Cambridge 1989, S. 455. 11 Kendon, Adam: Gesture: Visible Action as Utterance. Cambridge 2004. 12 Vgl. Fricke, Ellen. Wie entstehen Gesten? Und was kann das in Bezug auf die Interaktion mit fahrerlosen Autos in der

Zukunft bedeuten? Mercedes-Benz-Future Talk „Robotics“. Berlin 30.06. bis 02.07.2014. Sowie dies.: Hands and Objects in Language, Culture, and Technology. Manual Actions at Workplaces between Robotics, Gesture, and Product Design (MANUACT). BMBF-Statustagung, Bonn 26.10.2015. 13 Gason, Samuel: The Dieyerie Tribe of Australian Aborigines. Adelaide 1874, zitiert nach Kendon (wie Anm. 10), S. 17. 14 Roth, Walter E.: Ethnological Studies Among the North-WestCentral Queensland Aborigines. Brisbane/London 1897. 15 Howitt, Alfred W.: The Native Tribes of South-East Australia. London/New York 1904. 16 Spencer, Baldwin; Gillen, Frances J.: The Native Tribes of Central Australia. London 1904. 17 Darwin, Charles R.: The Descent of Man and Selection in Relation to Sex. London 1871. Sowie ders.: The Expression of the Emotions in Man and Animals. London 1872. 18 Roth (wie Anm. 14). 19 Kendon (wie Anm. 10), S. 219. 20 Kendon (wie Anm. 10). 21 Vgl. ebd., S. 2. 22 Ebd., S. 445. 23 Vgl. ebd., S. 446. 24 Vgl. ebd., S. 456. 25 Vgl. ebd., S. 458. 26 Vgl. ebd., S. 400 und 459 sowie Kendon, Adam: Exploring the utterance roles of visible bodily action: A personal account. In: Cornelia Müller u. a. (Hg.): Body – Language – Communication: An International Handbook on Multimodality in Human Interaction. Berlin/Boston 2013, S. 17. 27 Vgl. Kendon (wie Anm. 10), S. 57. 28 Vgl. Fricke (wie Anm. 12). 29 Roth (wie Anm. 14). 30 Für einen Überblick zum Thema Gesten und Metonymie siehe Mittelberg, Irene; Waugh, Linda R.: Gestures and metonymy. In: Cornelia Müller u. a. (Hg.): Body – Language – Communication. An International Handbook on Multimodality in Human Interaction. Berlin/Boston 2014, S. 1747–1766. 31 Kendon (wie Anm. 10), S. 162.
Abbildungsnachweis 1 National Library of Australia. 2–3 Roth, Walter E.: Ethnological Studies Among the North-West-
Central Queensland Aborigines. Brisbane/London, 1897, Tafeln II und III. 4 Foto: Dietmar Träupmann.

101

Menschen, Affen, Hunde
und die Evolution von Gesten

Susanne Grassmann

Frühe Menschen haben – ähnlich wie heutige Menschenaffen – mittels Gesten und Vokalisationen kommuniziert. Im Verlauf der Evolution des Menschen haben sich zwei Fähigkeiten, die der Kommunikation zugrunde liegen, immer weiter verfeinert: –– die feinmotorische Kontrolle, –– die soziale Kognition. Gute feinmotorische Kontrolle ist nötig, um Gesten präzise auszuführen, und soziale Kognition ist nötig, um Gesten im Verwendungskontext korrekt zu interpretieren. Es ist sehr wahrscheinlich, dass die Evolution dieser beiden Fähigkeiten parallel erfolgte. Auskunft über den möglichen Verlauf der Evolution versuchen Wissenschaftler auf zwei Wegen zu erlangen. Zum einen werden Vergleiche von Mensch und heute lebenden Tieren gemacht.1 Besonders interessant für solche Vergleiche sind unsere genetisch nächsten Verwandten, die Menschenaffen, und unsere sozialen nächsten Begleiter, die Haustiere. Außerdem analysieren Wissenschaftler Fossilien von Primaten, um Rückschlüsse auf motorische Fähigkeiten zu ziehen. Dabei sind fossile Handskelette besonders aufschlussreich.

Die Evolution der Feinmotorik
Für Menschen ist es ein Kinderspiel, die Finger einer Hand einzeln und unabhängig voneinander zu bewegen – einzige Ausnahme ist der Ringfinger. So können Menschen sehr viele Gesten mit ganz unterschiedlichen Bedeutungen bilden (siehe Abbildung 1).
Die besonders gute Fingerfertigkeit des Menschen wird zum einen durch anatomische Besonderheiten an Skelett und Muskulatur ermöglicht, zum anderen durch besonders große Regionen im motorischen Kortex im Gehirn, der für die Steuerung der Hände zuständig ist.2 Menschen und andere heute lebende Primaten haben im motorischen Kortex große Regionen, die auf die Steuerung der Hände spezialisiert sind.
Bei Menschenaffen (inklusive „Homo sapiens“) finden sich zudem ausgesprochen viele direkte Verbindungen von Nervenzellen des motorischen Kortex zu Rückenmarkzellen, von denen aus die Muskulatur gesteuert wird. Vergleichende Untersuchungen zeigen, dass die Menge solcher Direktverbindungen mit den Fingerfertigkeiten bei verschiedenen Arten korreliert: je mehr Direktverbindungen, desto größere Fingerfertigkeit.

102

erlaubt. Diese beiden anatomischen Besonderheiten sind relevant für den Werkzeuggebrauch bei der Jagd: Dank ihnen können Menschen kräftig mit Stöcken zuschlagen und Steine gezielt werfen.4 Aufgrund von fossilen Handskeletten vermuten Wissenschaftler5 bereits beim „Ardipithecus ramidus“, der vor mehr als 4 Millionen Jahren lebte, eine einigermaßen menschliche Fingerfertigkeit. Über die kommunikativen Fähigkeiten des „Ardipithecus ramidus“ ist jedoch nichts bekannt.

Gesten bei Menschenaffen

1  Gestenvielfalt durch Fingerfertigkeit: Der Mensch kann die meisten Finger unabhängig voneinander bewegen.
Die kommunikative Nutzung der Fingerfertigkeit ist jedoch eher eine Nebenerscheinung, nicht die treibende Kraft ihrer Evolution. Größere Fingerfertigkeit entsteht bei Primaten im Zusammenhang mit Umwelt- und Lebensbedingungen.3 Eine wichtige Rolle spielt, ob die Hände bei der Fortbewegung benutzt werden. Wenn die Hände zur Fortbewegung genutzt werden müssen (z. B. von Affen, die in Bäumen leben), dann ist die Fingerfertigkeit weniger gut ausgeprägt – aber besser an das Leben in den Bäumen angepasst. Zum Beispiel können Lemuren ihre Finger nur synchron bewegen. Das heißt, alle Finger sind immer in der gleichen Position, entweder ausgestreckt oder gebeugt. Krallenäffchen hingegen können ihre Finger unabhängig voneinander bewegen – genau wie Menschen und Menschenaffen. Sie sind deswegen geschickter in der Manipulation von Futter. Manuelle Gesten wurden bei Krallenäffchen bisher jedoch nicht beobachtet – wohl aber bei Menschenaffen (siehe unten).
Doch die Gesten und die feinmotorischen Fähigkeiten von Menschen und Menschenaffen unterscheiden sich deutlich. Dies erahnt man schon, wenn man die Unterschiede in der Anatomie von Affenhand und menschlicher Hand anschaut. Die menschliche Hand weist gegenüber der Affenhand zwei anatomische Besonderheiten auf: erstens einen langen kräftigen Daumen mit frei beweglichem ersten Glied und zweitens einen kräftigen fünften Finger, dessen Gelenk eine Drehung nach innen (zum Daumen hin)

Auch mit beschränkter Feinmotorik lässt es sich mittels Gesten kommunizieren. Die Beobachtung von gestischer Kommunikation bei Menschenaffen6 ist für Wissenschaftler die Grundlage auch für Theorien über die Evolution von kommunikativen Fähigkeiten beim Menschen. Die Logik hinter dieser Vorgehensweise liegt in der schon von Darwin formulierten Kontinuitätsannahme: Die Evolution verläuft schrittweise. Darum ist anzunehmen, dass man bei anderen Tieren Kommunikationsfähigkeiten beobachten kann, die den Fähigkeiten von frühen Menschen ähnlich sind.
Wissenschaftler von der Universität in St. Andrews (Schottland) haben ein Gestenlexikon für eine wildlebende Schimpansengruppe7 („Pan troglodytes“) und eine Bonobogruppe8 („Pan paniscus“) erstellt. In der Schimpansengruppe wurden 66 verschiedene Gesten beobachtet. Interessanterweise konnten die Wissenschaftler für die 66 Gesten nur 19 verschiedene Bedeutungen identifizieren. Das heißt, dass die Schimpansen viele synonyme Gesten haben – das heißt unterschiedliche Gesten, die das Gleiche bedeuten. Zusätzlich wurde bei den Schimpansen beobachtet, dass die gleiche Geste Unterschiedliches bedeuten kann. Zum Beispiel kann ein Schimpanse den Arm ausstrecken (siehe Abbildung 2), um einen anderen Schimpansen um ein Objekt zu bitten. Diese Geste kann aber auch benutzt werden, um zu signalisieren, dass ein Jungtier auf den Rücken der Mutter genommen werden will. Aus den Beschreibungen der Wissenschaftler geht nicht hervor, ob der Bedeutungsunterschied durch minimal verschiedene Hand-, Kopf-, oder Körperhaltungen signalisiert wird, oder ob die Affen raten müssen, was die Geste genau meint. Für die untersuchte Bonobogruppe haben die Forscher 68 Gesten beobachtet. Fast 90 Prozent dieser Bonobogesten stimmen mit den Schimpansengesten überein. Die Forscher glauben darum, dass das motorische Gestenrepertoire bei Menschenaf-

103

fen angeboren ist, während Bedeutungen gruppenspezifisch sein können und gelernt werden.
Wissenschaftler am Max-Planck-Institut für evolutionäre Anthropologie in Leipzig vertreten eine andere Theorie der Entstehung von Gesten.9 In einer Langzeitbeobachtung konnten sie Belege dafür finden, dass Affengesten durch Ritualisierung entstehen können. Ritualisierung ist ein Prozess, in dem Bewegungen, die zunächst Bestandteil von Handlungen sind, zu Gesten werden. Zum Beispiel streckt ein Affenjunges eventuell den Arm aus, wenn es auf den Rücken der Mutter klettert. Durch Wiederholungen wird diese Bewegung, die Teil des Kletterns ist, ein Signal für die Mutter: Die Geste ist geboren.

Diese Aussage widerspricht den Alltagserfahrungen der meisten Menschen: Immer wieder missverstehen sich Menschen. Immer wieder interpretieren wir falsch, was andere sagen oder tun. Aus wissenschaftlicher Sicht ist es jedoch gerade die Möglichkeit von Missverständnissen, die die Besonderheit der menschlichen Kommunikation ausmacht – und die eine gute Gedankenlesefähigkeit verlangt. Wenn ein kommunikatives Zeichen eine feste Bedeutung hat, wie in den meisten Tierkommunikationssystemen, besteht kein Raum für Missverständnisse.
Die Mechanismen, die in der Evolution zu den menschlichen sozial-kognitiven Fähigkeiten geführt haben, sind in der Forschung bisher nicht identifiziert. Eine interessante These wird von einer Zürcher Forschergruppe unter Leitung von Carel van Schaik10 vertreten. Aufgrund von Untersuchungen mit verschiedenen Primatenarten schlussfolgern diese Forscher, dass sozial-kognitive Fähigkeiten im Zusammenhang mit der gemeinsamen Aufzucht des Nachwuchses von beiden Eltern entstanden sein könnten. Welche spontane Genmutation zur Entstehung kooperativer Fähigkeiten geführt hat, ist jedoch noch nicht geklärt.

Der Zeigegestentest

2  Affengesten: Ein Bonobo kommuniziert
Evolution sozialer Kognition
Eingangs wurde schon erwähnt, dass gute sozial-kognitive Fähigkeiten eine Grundvoraussetzung für das korrekte Interpretieren von (gestischer) Kommunikation sind. Soziale Kognition ist ein Sammelbegriff für die Fähigkeit, sich in die Gedanken- und Gefühlswelt von anderen hineinversetzen zu können. Menschen können dies – im Vergleich zu Menschenaffen – besonders gut, so der Tenor der vergleichenden anthropologischen Forschung.

Ein wichtiger Test, mit dem die sozial-kognitiven Fähigkeiten von ganz verschiedenen Tierarten seit vielen Jahren untersucht werden, ist der Zeigegestentest. Für Menschen ist dies ein trivialer Test. Schon 12-monatige Babys11 bestehen ihn – darum schien der Test geeignet, um ihn im Tierversuch anzuwenden. Zudem ist die Zeigegeste ein idealer Testkandidat für sozial-kognitive und kommunikative Fähigkeiten bei Tieren, da sie für Tiere eine unbekannte Geste ist. An den Reaktionen von Tieren auf die Zeigegeste kann man daher sehr gut ablesen, ob und welche Tiere Fähigkeiten haben, die denen des Menschen ähneln.
Im Zeigegestentest (siehe Abbildung 3) sitzt oder steht der Testteilnehmer (zum Beispiel ein Hund) an einem vorgegebenen Ausgangspunkt. Dieser Ausgangspunkt ist gleich weit von einer gedachten Linie mit zwei oder mehr Zielpunkten entfernt. Auf der anderen Seite der Zielpunktlinie steht der Versuchsleiter. Ein Helfer hat zuvor die Ziele präpariert und dort Spielzeuge oder Becher mit Futter platziert. Der Versuchsleiter zeigt dann auf einen der Zielpunkte. Dann ist der Testteilnehmer an der Reihe. Bestanden ist der Test, wenn zuverlässig das angezeigte Ziel gewählt wird.

104

Der Hund – des Menschen bester Freund

3  Ein Hund im Zeigegestentest
Ausgangspunk der umfangreichen Untersuchungen mit vielen verschiedenen Tierarten war der Befund, dass einerseits Menschenaffen nicht in der Lage zu sein scheinen, die Zeigegeste des Menschen spontan zu interpretieren. Und dass andererseits der Hund, der vom Menschen genetisch viel weiter entfernt ist, die Zeigegeste ohne Probleme – und ohne Training – versteht.
In der Forschung kristallisierte sich dann heraus, dass Haustiere (Hunde, Katzen, Pferde, Frettchen12, Ziegen) im Zeigegestentest besser abschnitten als Wildtiere (Schimpansen, Orang-Utans, Wölfe, wilde Frettchen). Brian Hare entwickelte darauf aufbauend die Domestikationstheorie:13 Der Mensch hat bei der Domestikation direkt oder indirekt Tiere gezüchtet, die gute sozial-kognitive Fähigkeiten haben und darum erkennen, wenn jemand mit ihnen kommuniziert. Menschenaffen hingegen leben unabhängig vom Menschen und haben in ihrem Lebenskontext ihre arttypischen Fähigkeiten entwickelt.

Mensch und Hund leben und jagen seit mindestens 10.000 Jahren gemeinsam. Einige Schätzungen gehen sogar von bis zu 50.000 Jahren aus. Man geht davon aus, dass die Sesshaftigkeit von Menschen – und die damit verbundene Entstehung von „Müllhalden“ – eine wichtige Voraussetzung für den Domestikationsprozess lieferte: Zu Hunden entwickelten sich die Nachkommen jener Wölfe, die sich an die Müllhalden in der Nähe der Menschen wagten – und die von den Menschen dort geduldet wurden, weil sie ungefährlich waren. In einem Domestikationsexperiment mit sibirischen Silberfüchsen14 bestätigt sich diese These. Es zeigte sich, dass Zahmheit und Interesse an Menschen schon nach wenigen Generationen zu hundeähnlichem Aussehen und Verhalten dem Menschen gegenüber führt.
Der Hund wurde bald zu einem Kooperationspartner bei der Jagd15 – und übernahm je nach Terrain und Jagdmethode unterschiedliche Aufgaben: Dank ihrer Spürnase finden Hunde versteckte Tiere. Im offenen Gelände scheuchen sie Beutetiere auf oder lenken gefährliche Beutetiere vom menschlichen Jäger ab. Im Gebüsch können Hunde tote Tiere auffinden. Und bei der Jagd mit Giftpfeilen, oder wenn das Beutetier nur verwundet wurde, können Hunde das Beutetier verfolgen, bis es verendet.
Damit die gemeinsame Jagd erfolgreich ist, müssen Mensch und Hund sich gegenseitig verstehen. Der Hund muss kommunizieren, was er wo gefunden hat, und der Jäger muss kommunizieren, was der Hund tun soll. Im Laufe
4  Hunde erkennen, ob ein Mensch mit ihnen kommuniziert

105

der Domestikation sind wahrscheinlich immer wieder die Tiere weiter gezüchtet worden, die besonders aufmerksam und lernfähig waren. Dafür sprechen Untersuchungen,16 die zeigen, dass insbesondere Jagdhunderassen sehr aufmerksam dafür sind, wo ihr Besitzer gerade hinschaut.
Wie erstaunlich gut Hunde darin sind, die Kommunikation des Menschen zu erkennen und situationsgemäß zu interpretieren, zeigen Studien,17 in denen der Grundaufbau des Zeigegestentests leicht verändert wurde. Zum Beispiel zeigt sich, dass Hunde Zeigegesten jeglicher Form verstehen:18 mit ausgestrecktem Arm, angewinkeltem Arm, mit gekreuzter Körpermitte oder ohne. Der wichtigste Beleg dafür, dass Hunde wirklich die kommunikative Absicht hinter der Zeigegeste verstehen, besteht jedoch darin, dass Hunde nicht einfach in die Richtung laufen, in die ein Mensch seinen Arm oder Zeigefinger ausstreckt. In einer Studie19 wurde getestet, wie Hunde auf eine zufällige Zeigegeste reagieren. Die Versuchsleiterin schaute auf die Uhr und streckte dabei den Zeigefinger aus (siehe Abbildung 4). Hunde reagieren auf diese Geste nicht, selbst wenn die Versuchsleiterin den Hund anspricht und in die angezeigte Richtung schaut.
Ein weiterer Beleg für die erstaunlichen Fähigkeiten von Hunden ist die Tatsache, dass Hunde je nach Situation unterschiedlich auf die Zeigegeste reagieren. Das heißt, dass Hunde wahrscheinlich wirklich interpretieren, was die Geste in einer gegebenen Situation bedeutet. Im wissenschaftlichen Experiment wurde dies wie folgt belegt: Die Hunde wurden vor dem Zeigegestentest einzeln vom Versuchsleiter in einen Raum geführt. Die eine Hälfte der Hunde findet dort Futter, die andere Hälfte der Hunde findet nichts. Anschließend verlassen die Hunde den Raum wieder. Wenn sie das nächste Mal mit dem Versuchsleiter in den Raum kommen, zeigt der Versuchsleiter auf einen (leeren) Fleck im Raum. Die Hunde, die vorher Futter gefunden hatten, interpretieren die Zeigegeste als Hinweis, wo sie Futter suchen könnten und suchen in der angezeigten Richtung. Die anderen Hunde, die kein Futter gefunden hatten, reagieren anders: Sie setzen sich in der angezeigten Richtung hin.

wickelt – der Entwicklungsprozess ersetzt den Domestikationsprozess. Schon heute sind eine Vielzahl von Robotern für ganz unterschiedliche Aufgaben verfügbar: Fertigungsroboter, Transportroboter, Militärroboter, Flugroboter, Staubsaugerroboter, soziale Roboter usw.
Die Kommunikation mit Robotern funktioniert jedoch (noch?) ganz anders als die Kommunikation mit Hunden und anderen Haustieren. Roboter haben (noch?) keine sozial-kognitiven Fähigkeiten. Roboter können (noch?) keine kommunikativen Signale interpretieren, die sie nicht direkt einprogrammiert bekommen haben. Selbst den Zeigegestentest bestehen Roboter nicht ohne weiteres. Eine funktionierende Prozedur zur Erkennung einer Zeigegeste aus einem Videobild basiert auf folgenden sieben Schritten: –– Hautfarbige Formen identifizieren –– Hand identifizieren (z. B. per Ausschluss
„kein Gesicht“) –– Auge oder Schultergelenk finden –– Zentrum der Hand finden –– Ausgestreckten Finger finden –– Vektor Auge – Hand bestimmen –– Kopf in die entsprechende Richtung drehen / Körper in
die Richtung bewegen Alternativ können Gesten von Robotern auf der Basis von Templates erkannt werden. Ein kommunikationsfähiger Roboter bekommt dann ein mehr oder weniger umfangreiches Gestenlexikon in Form von Templates einprogrammiert. In diesem Gestenlexikon sind Bilder von Gesten mit Bedeutungen und jeweils angebrachten Reaktionen abgespeichert. Sobald der Roboter im Video eine Gestenform erkennt, kann er das Template nachschlagen und entsprechend reagieren.
Gestische Kommunikation mit Robotern – seien es Industrieroboter, Drohnen, Staubsauger oder selbstfahrende Autos – wird in Zukunft an Bedeutung gewinnen. Eine der großen Herausforderungen besteht in der Entwicklung von Programmen, die kommunikative Absichten wahrnehmen können – andernfalls fährt das selbstfahrende Auto möglicherweise in eine ungewollte Richtung, nur weil der Fahrer auf die Uhr geschaut hat …

Des Menschen neuer bester Freund

Der neue beste Freund des Menschen heißt Aibo, Paro oder Nao. Roboter sind die neuen Haustiere. Aber auch in der Industrie sind Roboter die neuen Kooperationspartner des Menschen. Roboter werden für spezifische Aufgaben ent-

106

Anmerkungen 1 Vgl. Grassmann, Susanne: Anthropologie: Sprachfähigkeit
als anthropologische Differenz. In: Kompa, Nikola (Hg.): Handbuch Sprachphilosophie. Stuttgart 2015, S. 423–433. 2 Vgl. Verendeev, Andrey; Sherwood, Chet C.; Hopkins, William D.: Organization and evolution of the neural control of the hand in primates: Motor systems, sensory feedback, and laterality. In: The Evolution of the Primate Hand. New York 2016, S. 131–153. 3 Vgl. Heldstab, Sandra A. u. a.: Manipulation complexity in primates coevolved with brain size and terrestriality. In: Scientif ic Reports 6 (2016). 4 Vgl. Young, Richard W.: Evolution of the human hand: The role of throwing and clubbing. Journal of Anatomy 202 (2003), S. 165–174. 5 Vgl. Kivell, Tracy L.: Evidence in hand: recent discoveries and the early evolution of human manual manipulation. In: Philosophical Transactions of the Royal Society B: Biological Sciences 370 (2015). Online unter http://rstb.royalsocietypublishing. org/content/370/1682/20150105 (07.08.2017). 6 Vgl. Liebal, Katja: Primate Communication: A Multimodal Approach. New York 2014. 7 Vgl. Hobaiter, Catherine; Byrne, Richard W.: The gestural repertoire of the wild chimpanzee. In: Animal Cognition 14 (2011), S. 745–767. 8 Vgl. Graham, Kirsty E.; Furuichi, Takeshi; Byrne, Richard W.: The gestural repertoire of the wild bonobo (Pan paniscus): A mutually understood communication system. In: Animal Cognition 20 (2017), S. 171–177. 9 Vgl. Halina, Marta; Rossano, Federico; Tomasello, Michael: The ontogenetic ritualization of bonobo gestures. In: Animal Cognition 16 (2013), S. 653–666. 10 Schaik, Carel P. van; Burkart, Judith M.: Social learning and evolution: the cultural intelligence hypothesis. In: Philosophical Transactions of the Royal Society of London B: Biological Sciences 366 (2011), S. 1008–1016. 11 Vgl. Rohlfing, Katharina J.: Frühkindliche Semantik. Tübingen 2013. 12 Vgl. Hernádi, Anna u. a.: Man’s underground best friend: domestic ferrets, unlike the wild forms, show evidence of dog-like social-cognitive skills. In: PLoS ONE, 7 (2012). Online unter https://doi.org/10.1371/journal.pone.0043267 (07.08.2017). 13 Vgl. Hare, Brian u. a.: The domestication of social cognition in dogs. In: Science 298 (2002), S. 1634–1636. 14 Vgl. Hare, Brian u. a.: Social cognitive evolution in captive foxes is a correlated by-product of experimental domestication. In: Current Biology 15 (2005), S. 226–230.

15 Lupo, Karen D.: When and where do dogs improve hunting productivity? The empirical record and some implications for early Upper Paleolithic prey acquisition. In: Journal of Anthropological Archaeology 47 (2017), S. 139–151.
16 Vgl. Heberlein, Marianne T. E.; Turner, Dennis C.; Manser, Marta B.: Dogs’ (Canis familiaris) attention to human perception: Influence of breed groups and life experiences. In: Journal of Comparative Psychology 131 (2017), S. 19–29.
17 Vgl. Grassmann, Susanne: Verstehen Hunde menschliche Kommunikation? In: a.r.t.e.s.-Jahrbuch 2013/2014. Köln 2014.
18 Vgl. Miklósi, Adam; Soproni, Krisztina: A comparative analysis of animals’ understanding of the human pointing gesture. In: Animal Cognition 9 (2006), S. 81–93.
19 Vgl. Scheider Linda u. a.: Domestic dogs use contextual information and tone of voice when following a human pointing gesture. In: PLoS ONE 6 (2011). Online unter https://doi. org/10.1371/journal.pone.0021676 (07.08.2017).
Abbildungsnachweis 1 Foto: Susanne Grassmann. 2 © Ltshears – own work, CC BY-S. 3.0, online unter https://
commons.wikimedia.org/w/index.php?curid=10845979. 3–4 Fotos: Susanne Grassmann.

107

Menschliche Hände als Vorbild für robotische Hände?

Ulrike Thomas

Von einfachen pneumatischen Greifern zu robotischen Mehrfingerhänden
Menschen verwenden ihre Hände für viele verschiedene Aufgaben. Wir greifen, manipulieren, verändern Gegenstände, gestikulieren und interagieren mit unseren Händen. Dabei können unsere Hände Aussagen mit Hilfe von Gesten unterstützen oder wir setzen unsere Hände ein, um Interaktionen zwischen Menschen auf unterschiedliche Art und Weise zum Ausdruck zu bringen. Unsere Hände besitzen sehr viele Muskeln, deren Hauptanteile in unseren Unterarmen liegen. Damit haben wir im Verhältnis zur Greifkraft sehr schmale filigrane Finger, die zudem mit unzähligen Rezeptoren – unserer Haut – ausgestattet sind und viele Signale liefern. Im Vergleich zu heutigen robotischen Händen ist unsere Geschicklichkeit immer noch wesentlich größer. Denken Sie beispielsweise an die Geschicklichkeit von Chirurgen bei Operationen oder die Fähigkeit, einen Faden in ein Nadelöhr einzufädeln. Gleichzeitig sind wir aber auch in der Lage, relative große Lasten zu heben und mit großer Kraft präzise Arbeiten zu verrichten.
Wenn Sie vielleicht im Jahr 2030 einen Roboter für ihre Heimarbeit oder Pflege ausleihen oder gar kaufen würden, welche Arbeiten würden Sie von ihm verrichten lassen? Si-

cherlich erwarten Sie, dass der Roboter viele der Tätigkeiten erledigt, die Sie heute noch selbst durchführen. Damit die Bandbreite an Tätigkeiten, die heute von Menschen ausgeführt werden, zukünftig durch Roboter erledigt werden können, sollten robotische Hände ähnliche Eigenschaften hinsichtlich Flexibilität, Kraft und Präzision wie menschliche Hände besitzen. Diesem Anspruch stellt sich die Robotik seit mehr als 30 Jahren. Daher ist ein Ziel der Roboterforschung, humanoide Roboter mit Händen auszustatten, die den menschlichen Händen möglichst ähnlich sind. Die Herausforderung liegt darin, ein ähnlich gutes Verhältnis zwischen Greifkraft, Bauraum und Flexibilität zu erreichen. Die ersten robotischen Greifsysteme waren pneumatisch angetrieben und kannten im Wesentlichen nur die zwei Zustände geöffnet oder geschlossen. Eine Regelung der Greifkraft wurde ausschließlich über die Druckluft erreicht und war quasi kaum möglich. Dennoch wurden solche Greifer für eine lange Zeit in der Industrie eingesetzt und erfüllen noch heute zuverlässig sogenannte „Pick und Place“- oder auch Montageaufgaben.
Schon bei der ersten Deutschen Raumfahrtmission 1993 war schnell klar, dass für telemanipulierte Roboter, die beispielsweise im Weltraum fliegende Objekte greifen sollen, wesentlich „intelligentere“ Greifsysteme notwendig sind. So

108

1  Entwicklung robotischer Hände: von starren über nachgiebige zu weichen Gelenken
wurde am Handgelenk des Roboters ein Kraft-/Momen- Finger untereinander variabel ist. Die Finger bewegen sich ten-Sensor installiert, der es erlaubte, die im Handgelenk auf einem Ring. Die einzelnen Fingergelenke bestehen aus auftretenden Kräfte und Momente zu messen. Außerdem drei Fingerelementen und zwei Aktoren. Damit ist es mögwurde der Greifer mit einem Sensor-Array ausgestattet, so lich, zylindrische Objekte gut zu greifen. Beim Greifen sind dass ein filigranes Greifen von Objekten möglich wurde. sowohl der Formschluss, die Oberfläche des Greifers passt Telemanipuliert konnte der Roboter mit seinem Greifer im sich ideal an die Oberfläche des Objekts an, als auch der All vom Boden aus gesteuert werden und Montageaufga- Kraftschluss wichtig. Ein Griff mit Kraftschluss bedeutet, ben sowie Greifaufgaben beim Fangen von Objekten in der dass die durch die Finger eingeleiteten Kräfte dazu führen, Schwerelosigkeit durchführen. Ähnliche Systeme kamen dass das Objekt sich nicht mehr bewegen bzw. verrutschen sodann auch bei terrestrischen Anwendungen zum Einsatz kann. In den weiteren Jahren der Entwicklung von robotiund Roboter waren in der Lage, auftretende Kontaktkräfte schen Händen wurden durch kleinere Motoren, bessere Gein ihre Bewegungen mit einzuregeln. Dennoch waren wei- triebe, aber auch durch Seilzugmechanismen immer neue tere Anstrengungen nötig, um robotische Hände ähnlich Roboterhände mit größerer Anzahl von Freiheitsgraden dem menschlichen Vorbild zu entwickeln. Aus den Zwei- entwickelt. Die Antriebsformen reichen von pneumatischen backengreifern, so wie wir sie aus der Industrierobotik ken- Antrieben, über rein elektrische Antriebe bis hin zu so genen, wurden robotische Hände, zunächst bestehend aus drei nannten Luft-Muskeln. Die Abbildung 1 zeigt auf einem Fingern und später auch aus fünf Fingern. Die „Evolution“ Zeitstrahl die Entwicklung verschiedener humanoider Rorobotischer Hände lässt sich der Abbildung 1 entnehmen. boterhände und in der Abbildung 2 ist die Entwicklung
Ein Beispiel für eine Dreifingerhand ist die Barrett-­ robotischer Hände am Deutschen Zentrum für Luft- und Hand, siehe Abbildung 1, bei der die relative Position der Raumfahrt im Institut für Robotik und Mechatronik zu
109

sehen. Zunehmend wurden auch so genannte redundante Finger entwickelt. Dabei hat ein Finger weniger Antriebe als Gelenkfreiheitsgrade. Bei relativ großer Beweglichkeit kann auf einige Aktoren verzichtet werden, so dass die Hand leichter und kleiner wird.
Einhergehend mit der Entwicklung robotischer Mehrfingerhände wurden auch Verfahren und Algorithmen notwendig, um den Einsatz der Roboterhände zu planen. Es hat sich ein Forschungsfeld der Greifplanung für Mehrfingerhände entwickelt, welches noch heute neue, topaktuelle Verfahren hervorbringt und insbesondere auch den Einsatz weiterer, neuerer Roboterhände plant und ermöglicht. Ein wesentlicher Mechanismus, um flexibel und angepasst auf die Umgebung zu reagieren, sind nachgiebige Gelenke. Die Nachgiebigkeit der Gelenke wird entweder durch eine aktive Regelung auf Basis gemessener Gelenkdrehmomente möglich oder auch durch nachgiebige Materialien oder Federn. Die aktive Regelung der Gelenkmomente ist beispielsweise in der Roboterhand DLR-HIT-Hand II realisiert (siehe Abbildungen 1 und 2). Hier werden die Drehmomente in den Gelenken gemessen und die Bewegung auf Basis der Umgebungssteifigkeiten nachgiebig geregelt. Damit ist es beispielsweise möglich, ein rohes Ei zu greifen, ohne es zu zerdrücken. Diese neue Roboterhand hat sich aus den Anforderungen der Raumfahrt entwickelt, und diese startete beginnend mit der bereits erwähnten D2-Mission 1993. So wird die DLR-HIT-Hand II bereits für weitere Missionen im Weltraum erprobt. Telemanipuliert kann sie von der Erde aus angesteuert werden, und es ist sogar möglich, Kontaktkräfte durch die integrierten Drehmomentsensoren auf den telemanipulierenden Menschen zu übertragen. Ein Meilenstein war der „Tele-Hand-Shake“

im Dezember 2015 zwischen dem Kosmonauten Sergei Volkov auf der ISS und dem DLR-Institutsdirektor Prof. Alin Albu-Schäffer auf der Erde.
Zukünftige Herausforderungen an die Entwicklung humanoider Roboterhände
Neben den bereits integrierten Sensoren wird es eine Herausforderung sein, zukünftig humanoide Roboter mit den sensorischen Fähigkeiten eines Menschen auszustatten. Unsere Hände sind mit mehreren Millionen Rezeptoren ausgestattet, die es erlauben, feinste Signale wahrzunehmen und zu verarbeiten. Zukünftig müssen robotische Hände mit ähnlich feiner Sensorik ausgestattet werden und hochauflösend verschiedene Größen, wie beispielsweise die Kontaktkraft, Scherkräfte, Temperatur und Feuchte messen. Sicherlich wird die Entwicklung künstlicher Haut für robotische Hände neue Möglichkeiten für die Anwendung von Robotern eröffnen. Des Weiteren erreichen robotische Hände noch immer nicht ein so gutes Kraft-zu-Bauraumverhältnis wie menschliche Hände. Folglich werden zum einen Seilzugkinematiken bei vielen neuen robotischen Mehrfingerhänden eingesetzt oder zum anderen auch mechanische Nachgiebigkeiten in Form von Federn eingebaut, mit dem Ziel, robotische Hände kleiner zu bauen, um eine ähnliche Größe wie die einer menschlichen Hand zu erreichen. Vollkommen neue Materialien ermöglichen aber auch vollkommen neue Roboterhände. Die Abbildung 1, rechte Seite, zeigt eine Roboterhand bestehend aus vielen Silikonkissen, die geschickt angeordnet sind, so dass sich mit Hilfe von Druckluft die Finger ideal an die zu greifenden

Objekte anschmiegen, ohne sie zu zerdrücken. Neue Materialien bestehen beispielsweise aus Silikon, Formgedächtnislegierungen oder auch Carbon-Nano-Tubes, welche sich vielversprechend zur Herstellung künstlicher Muskeln mit sehr großer Leistungsdichte verwenden lassen. Damit können neue robotische Hände gebaut werden, die wesentlich kleiner sind als die bisher entwickelten.
Eine Herausforderung für robotische Hände besteht unter anderem noch in der so genannten In-Hand-Manipulation, d. h. Objekte werden in der Hand gedreht, gekippt usw., um sie in eine andere Lage zu bringen. Wir Menschen führen diese Operation unzählige Male unbewusst am Tag durch. Für künstliche robotische Hände stellen diese Aktionen immer noch eine Herausforderung dar. Mit einigen robotischen Händen ist es gelungen, Manipulationen von Objekten in der Hand durchzuführen, wobei diese

sich meistens noch auf das Umorientieren der Objekte in der Hand beschränken. Menschen können aber auch noch schwierigere Aufgaben, wie beispielsweise das Aufdrehen eines Schraubverschlusses, mit ihren Händen durchführen, ohne extra umgreifen oder eine weitere Hand zur Hilfe nehmen zu müssen. Solche komplexen Aufgaben durch robotische Hände auszuführen, ist Gegenstand heutiger Forschung, um eines Tages ein ähnlich breites Spektrum an Aufgaben durch robotische Hände erledigen zu können. Die Abbildung 3 zeigt eine mögliche Taxonomie verschiedener Griffe, wie sie im täglichen Leben häufig auftreten. Diese mit heutigen Roboterhänden in der gesamten Breite abzudecken, ist immer noch eine Herausforderung. Neben den mit Drehmomenten nachgiebig geregelten Gelenken hat sich ein ganz neues Gebiet der Robotik entwickelt, das der sogenannten weichen Robotik (engl. Soft-Robotics).

2  Entwicklung von Roboterhänden im Robotik- und Mechatronik-Zentrum des Deutschen Zentrums für Luft- und Raumfahrt

3  Taxonomie des Greifens

110

111

Hierbei werden neue weiche Materialien kontrolliert in verschiedene Ausdehnungszustände gebracht. Noch steckt diese Form der Robotik in den Kinderschuhen, doch die ersten Ergebnisse hinsichtlich der Greifkraft und Flexibilität sind vielversprechend. Beispiele hierfür sind die in Abbildung 1 rechts dargestellten Roboterhände. Ein Handicap ist die schwierig zu vermessende Deformation des weichen Materials. Durch das Einbringen neuer auf Basis von Magnetfeldern entwickelten Sensoren lässt sich zukünftig die Deformation messen und somit der Roboter besser regeln.
Planen von Greifbewegungen – oder was haben die Bewegungen fürs Greifen mit jenen fürs Laufen gemein?
Was haben die Eigenschaften Laufen und Greifen gemein? Wie haben sich unsere Hände und Arme im Laufe der Evolution entwickelt? Die Arme dienten noch bei unseren direkten Vorfahren auch zum Laufen. Diese Erkennt-

nis haben Forscher ausgenutzt, um Regelungsstrategien zum Greifen und Laufen zu entwickeln. Zunächst wurden Algorithmen zum Greifen entwickelt. Dabei lässt sich ein Kräftegleichgewicht berechnen, welches das Einwirken von Kräften durch jeden einzelnen Finger berechnet und gleichzeitig die auf das gegriffene Objekt wirkende Gravitation berücksichtigt. Forscher, die sich bereits mit der Implementierung von derartigen robotischen Greifstrategien beschäftigt haben, fanden heraus, dass dieselben Algorithmen und Strategien zum Balancieren von mehrbeinigen Laufmaschinen eingesetzt werden können. Dabei lässt sich „einfach“ der Gravitationsvektor herumdrehen und das Kräftegleichgewicht muss erhalten bleiben. Daher kommen dieselben Regelungsstrategien und Algorithmen bei der Entwicklung zweibeiniger humanoider Roboter zur Anwendung, die den Robotern das Laufen lehren sollen. Die Abbildung 4 zeigt genau diese Dualität zwischen Greifen und Laufen. Der einzige Unterschied liegt darin, dass der Gravitationsvektor sein Vorzeichen ändert.

Dennoch ist das Greifen ein sehr komplexer menschlicher Bewegungsablauf, dessen Studien auf viele andere Bewegungsabläufe übertragen, doch immer noch nicht maschinell abgebildet werden können. Eine Abhilfe können neuronale Netze insbesondere ConvNets (engl. Convolutional Neural Nets) schaffen, um komplexe Greifprozesse zu lernen. Daher beschäftigt sich die Robotik-Gruppe der TU Chemnitz1 mit diesem interessanten Forschungsfeld. Noch reichen die Fähigkeiten robotischer Hände nicht an die Fähigkeiten menschlicher Hände heran und der Prozess, menschenähnliche flexible Roboterhände zu erhalten, wird die Wissenschaft noch für einige Zeit beschäftigen.
Anmerkung 1 Online unter www.tu-chemnitz.de/etit/robosys/ (07.08.2017).
Abbildungsnachweis 1 Ulrike Thomas. 2 Wessling-Robotics. Online unter www.wessling-robotics.com. 3 Cutkosky, Mark R.: On grasp choice, grasp models, and the de-
sign of hands for manufacturing tasks. In: IEEE transactions on robotics 5, H. 3 (1989), S. 269–279. 4 Henze, Bernd; Roa, Máximo; Ott, Chritian: Passivity-based whole-body balancing for torque-controlled humanoid robots in multi-contact scenarios. In: The International Journal of Robotics Research 35, H. 12 (2016), S. 1522–1543.

4  Die Gemeinsamkeit zwischen Greifen und Laufen

112

113

Wie man früher den Telefonhörer hielt :
Gesten als Wissensspeicher

Daniel Schöller, Martin Siefkes und Ellen Fricke

Gesten als Wissensspeicher für Objektgebrauch
Wer erinnert sich eigentlich noch an den Gebrauch der Wählscheibentelefone oder wann man wie mit ihnen wählen kann? Dieses Handhabungswissen droht verloren zu gehen, wenn man Geräte nicht in ihren geschichtlichen Gebrauchskontexten dokumentiert. Wie das Beispiel der Telefongeste zeigt, können Gesten das Wissen über frühere Entwicklungsstufen der Geräte speichern, mit denen wir täglich umgehen. Sie bilden damit eine Brücke zur Vergangenheit und machen sichtbar, dass wir unsere Gesten, ge-

nau wie die Lautsprache, von früheren Generationen erben. Unsere Technologien und Produktionsweisen verändern sich fortwährend. Ebenso wie unsere Sprache (man denke an Ausdrücke wie jemanden auf die Schippe nehmen, etwas niet- und nagelfest machen, jemandem etwas einhämmern) können auch Gesten als Wissensspeicher fungieren. Ganz ähnlich wie bei Piktogrammen (siehe Abbildungen 1 bis 3) werden bei visuellen Gesten des Telefonierens insbesondere prägnante Aspekte der Form und darüber hinaus auch der Handhabung von Telefongeräten bewahrt.

1 bis 3  Typische Piktogramme, die auf die Möglichkeit des Telefonierens oder auf eine Telefonnummer hinweisen
114

Auch unsere Kommunikationsformen wandeln sich, aber da sie auf Konventionalität (dem gemeinsamen Gebrauch in einer Sprachgemeinschaft) beruhen, geschieht dies wesentlich langsamer. Die Zeichensysteme, mit denen wir kommunizieren, speichern daher oft noch den Umgang mit früheren Technologien. Sprachliche Ausdrücke bewahren Bestandteile älterer Technik (Hörer, Gabel, Sprechmuschel) oder bestimmte Bedienvorgänge (abnehmen, auflegen) und übertragen diese partiell auf neuere Entwicklungsformen der Technik.
Wir bedienen täglich viele unterschiedliche Geräte, die sich ständig weiterentwickeln, wie beispielsweise den Wasserkocher oder die Kaffeemaschine am Morgen. Wir schalten den Herd noch mit einem Schalter ein oder aber schon mittels Touchpad, wobei zunächst eine bestimmte Tastenkombination für das Entsperren notwendig ist. Dies scheint zunächst trivial, ebenso wie die Bedienung eines Fensters, das wir öffnen, kippen oder schließen wollen. Die Handgriffe und die jeweiligen Funktionsweisen müssen aber gelernt werden.
Unser Wissen über Artefakte und ihre Handhabung beeinflusst auch unsere Gesten. Sie begleiten unser Sprechen, verkörpern innere räumliche und bildliche Vorstellungen und sind ein wichtiger und selbstverständlicher Teil unserer Alltagskommunikation. Wir imitieren mit unseren Händen Gegenstände und auch den Umgang mit diesen, so dass Gesten für uns ein wichtiger visuell-kultureller Wissensspeicher des Objektgebrauchs sind. Unterschiedliche Gesten bilden dann unterschiedliche Erfahrungen mit verschiedenen Geräten ab. An den unterschiedlichen Gestenvarianten fürs Telefonieren können wir beispielsweise

beobachten, wie Handgesten Aspekte alter Geräte bewahren: Die Handgeste mit abgespreiztem kleinen Finger und Daumen stellt einen gebogenen Telefonhörer (siehe Abbildung 4) mit Sprech- und Hörmuschel ikonisch dar.
Diese Geste wird aber auch heute dafür benutzt, um das Telefonieren mit einem Handy zu repräsentieren. Damit bleiben Formaspekte älterer Apparate erhalten, die in diesem Fall auch auf eine Trennung von Funktionen zwischen dem Hörer mit Sprech- und Hörmuschel, der in bestimmter Weise an den Kopf gehalten wird, und dem Rest des Telefons verweisen. Diese eindeutige Form-Funktions-Zuordnung ist heute zwar nicht mehr sichtbar, ist aber dennoch in bestimmten Telefongesten konserviert.
Das Beispiel der Telefongeste zeigt, wie sich die technische Gestaltung von Geräten und unser Gestenrepertoire gegenseitig beeinflussen. Für die Entwicklung neuerer Mensch-Maschine-Schnittstellen mit Gestensteuerung werden zwischenmenschliche Gesten des Alltagsgebrauchs insofern als ein vielversprechender Ansatzpunkt betrachtet, als sie bereits im Gedächtnis verankert sind und nicht neu gelernt werden müssen. Gesten als Wissensspeicher für Formen und Funktionsweisen gewähren uns wiederum Zugang zu Bedienkonzepten, die wir aktuell mit bestimmten Gerättypen verknüpfen und zur Lösung verwandter Probleme womöglich mitaktivieren.
Gesten sind ein Zeichensystem, das auf menschlichen Körperbewegungen beruht. Sie sind daher gut geeignet, um konkrete Bedienungsweisen früherer Geräte zu bewahren und für einige Zeit zu konservieren, selbst wenn sich die Technik bereits weiterentwickelt hat. Welche Formen und Funktionen sich beim Telefon dafür besonders eignen, darum geht es im nächsten Abschnitt.

4  Diese Geste für ‚Ich ruf dich an!‘ oder ‚Lass uns telefonieren!‘ kann redeersetzend oder redebegleitend verwendet werden

Vom Wandtelefon bis zum Tippen auf dem Unterarm
Betrachtet man Telefonapparate in ihrer historischen Entwicklung vom Wandapparat über Tischtelefone mit Wählscheibe oder Tastatur bis zum Handy und modernen Smartphones, werden sie nicht nur immer kleiner, sondern auch beweglicher und leistungsfähiger.1 Welche Form und Funktionsaspekte von Telefonen sind nun in Handgesten abgebildet? Um diese Frage zu beantworten, wollen wir uns in einem kurzen technologischen Abriss zunächst die Entwicklung und bestimmte Formaspekte verschiedener Telefonapparate vergegenwärtigen. Der komplexe technische und physikalische Verbindungsablauf mittels eines Fern-
115

5  Amerikanisches Wandtelefon

6  Amerikanisches Candlestick-Telefon, um 1900

sprechers wird an dieser Stelle jedoch ausgespart, vielmehr interessieren uns die entsprechenden Funktionen und Geräteteile, die für die Handhabung des Apparats ausschlaggebend sind.
Die primäre Funktion des Telefons, das es als technisches Medium2 erfüllt, ist die Überwindung von Distanz für die Kommunikation.3 Wie bei jeder Kommunikationsform ist es grundlegend, dass die Nachricht mittels eines Mediums vom Sender zum Empfänger gelangen muss. Zentral war daher die Entdeckung der Möglichkeit, Schall elek­ trisch zu übertragen und damit weitere Distanzen zu überwinden, als Schallwellen in der Luft es vermögen. Damit überhaupt eine Fernkommunikation möglich wird, ist der Schall durch ein Mikrofon beim Sender in elektronische Signale zu wandeln, um schließlich wieder beim Empfänger als Schallwelle ausgegeben zu werden. Die physikalischen und technischen Aspekte der Informationsübertragung beeinflussen dabei die Form und Gestaltung des Telefons.
Die grundlegende Funktionalität ist dabei immer dieselbe: Jedes Telefon muss so konzipiert sein, dass es etwas gibt, in das hineingesprochen wird und wo der Schall in elek­ trische Signale gewandelt wird, und auch etwas, womit der Schall wieder ausgegeben werden kann. Zugleich bestimmt aber auch der Ablauf eines Telefongesprächs die Handha-

bung der Geräte. Es gibt eine bestimmte Routine, die die Kommunikationsform des Telefongesprächs bestimmt. Dieser Ablauf ist an sich nicht selbstverständlich und muss von Anwendern auch erlernt werden.4 Damit eine Interaktion zwischen zwei Teilnehmern entstehen kann, ist zuerst der Adressat zu wählen und eine Verbindung aufzubauen, die mit Abschluss des Gesprächs auch wieder zu beenden ist. Nicht nur müssen Interaktionsteilnehmer anhand einer Rufnummer adressiert werden und verfügbar sein, sie müssen natürlich auch an das Netz angeschlossen sein. Diese unterschiedlichen Funktionsanforderungen werden bei allen älteren Telefonmodellen einem eigenen Geräteteil zugeordnet. Die Telefongabel für das Belegen und Auslösen des Gesprächs, Ziffernblatt mit Wählscheibe bzw. Ziffertasten zum Wählen der Rufnummer und Sprech- und Hörmuschel zum Senden und Empfangen des akustischen Signals (siehe z. B. die Abbildungen 5, 6 und 8). Mit der Miniaturisierung und Mobilisierung verschmelzen Funktionen und Bestandteile: Die Geräte werden zunehmend kompakter und multifunktionaler: Bei heutigen Mobiltelefonen lassen sich alle Funktionen (Wählen, Gesprächsannahme, Sonderfunktionen wie das Senden von Textnachrichten usw.) über eine Tastatur oder einen Touchscreen bedienen. Wie wir unten sehen werden, zeigt sich dies auch in den Handgesten der

116

7  Imitation einer Telefonierszene in einer alten britischen Telefonzelle

8  Wählscheiben-Telefon von 1928 mit Gabel und klassischem „Knochen“ mit Muschel zum Sprechen und Hören

zwischenmenschlichen Kommunikation. Gesten durchlaufen einen Wandel und konservieren die gängige Handhabung des Artefakts, wobei die Gesten konventionalisiert werden und sich durchsetzen, die auf die gängigen und weitverbreiteten Apparate (bzw. deren Form und die wichtigsten Handgriffe ihrer Nutzung) zurückzuführen sind.
Bis zur Entwicklung mobiler Geräte war das Telefonieren außerdem stark ortsgebunden. Man denke an die Telefonzelle, die lange Zeit öffentliche Plätze prägte und über die, in Abhängigkeit von der stationären Verfügbarkeit, ein Telefongespräch in der Öffentlichkeit geführt wurde. Durch die Anbindung der bis gegen Ende des 20. Jahrhunderts ausschließlich analogen Geräte ans Festnetz waren – mindestens für die breite Öffentlichkeit, obgleich schon zu Beginn des 20. Jahrhunderts mobil per Funk telefoniert werden konnte – die Telefonapparate mehr oder weniger stark an einem Ort fixiert. Die Geräte waren anfangs große Kästen, die fest an der Wand installiert wurden und deren Gestaltung stark auf Mund und Ohr als Organe des Sprechens und Hörens bezogen war5 (siehe Abbildungen 5 und 6). Ein stehender Erwachsener konnte in einen beweglichen Trichter am Kasten hineinsprechen, während die mit dem Apparat per Kabel verbundene Hörmuschel ans Ohr gehalten wurde (vgl. z. B. die verschiedenen Telefonier-Szenen

in Hitchcocks „Der Mann, der zu viel wusste“). Besonders beim Sprechen ist die Körperhaltung dabei stark zum Gerät hin orientiert. Die Mobilisierung der Apparate begann gerade damit, die aufgedrängte Zuwendung zum Gerät zu lösen und die feste Ortsbindung durch längere bewegliche Kabel aufzuheben. Ein Beispiel dafür ist das aus amerikanischen Spielfilmen bekannte „Candlestick“-Telefon (Abbildung 6), bei dem auch die Sprechmuschel abnehmbar ist und zum Mund geführt werden kann, wobei dann beide Hände gebunden sind. Gerade dies betonen beidhändige Gesten, z. B. für die Imitation einer Telefonierszene in einer alten britischen Telefonzelle, die an genannte Filmklassiker erinnert (vgl. Abbildung 7).
Letztlich durchgesetzt hat sich für lange Zeit mit gewissen Designvarianten das „klassische Telefon“, wie es auch auf Piktogrammen Verwendung fand (siehe Abbildung 1 oben). Es handelt sich um den tragbaren (Tisch-)Apparat mit Ziffernblatt und Wählscheibe, einer Gabel für den „Hörer“, in dem nun Sprech- und Hörmuschel in einem greifbaren, handlichen Geräteteil verbunden und im Durchlaufen mehrerer Designs schließlich auch beide Muscheln angeglichen wurden. Dieser in der Fachsprache als „Knochen“ bezeichnete Bauteil des typischen Telefons steht in Piktogrammen oft metonymisch für das Telefon insgesamt

117

(vgl. Abbildung 2 oben). Der Hörer eignet sich auch zur Repräsentation des Telefonierens, da er die Kernfunktion der Kommunikation per Telefon (das Sprechen und Hören) verbindet. Nicht nur auf Piktogrammen, sondern auch in unserer Alltagskommunikation zeigt sich dies, wenn die Hand als Ganzes mit abgespreiztem kleinen Finger und Daumen ein Telefon repräsentiert. Damit konserviert die Geste den Formaspekt des leicht gebogenen Hörers klassischer Telefone und steht dabei als konventionelles emblematisches Zeichen auch für neuere Geräte wie etwa Smartphones, die in ihrer Gestalt völlig verschieden sind und auch auf andere Weise genutzt werden. Abgesehen davon gibt es jedoch auch eine Reihe von weiteren Gesten, die auf verschiedene Teile und Entwicklungsstufen des Telefons Bezug nehmen (siehe unten).
Die Telefonapparate wurden mit der Zeit immer mobiler. Anfangs waren auch bewegliche Apparate noch groß und eher unhandlich, wie etwa tragbare Funktelefone, die auch bald in Automobilen Einsatz fanden. Diese Apparate
9  Älteres mobiles Telefon, das Nokia C-Tel C6

veränderten bald ihre Form im Vergleich zum Tischtelefon, waren aber immer noch mit einem klassischen verkabelten Hörer ausgestattet. Zunächst wurde die Wählscheibe durch eine Nummerntastatur ersetzt, die bei manchen Geräten auch in den Hörer integriert wurde. Telefone mit einem sogenannten Mobilteil kombinierten den Telefonhörer und die Tastatur, der stationäre Teil wurde zunehmend zur reinen Ladestation reduziert. Schließlich verschwand die Trennung in den Apparat und einen separaten Hörer ganz. Die mobilen Endgeräte waren zunächst noch relativ schwergewichtig und groß und blieben das teilweise noch bis zur Jahrtausendwende, sodass die Unterseite des Geräts mit integriertem Mikrofon bis auf die Höhe des Mundes reichte (vgl. Abbildung 9). Bei der Sonderform des Klapphandys wurden sie durch Aufklappen dahin verlängert, was in gewisser Weise wieder an den klassischen Hörer erinnert, der nun allerdings das Telefon als Ganzes beinhaltete.
Auch das Handy wird immer kleiner und kompakter, bis es in die Hosentasche passt. Sprech- und Hörmuschel flachen mit dem Aufkommen der sogenannten Smartphones komplett ab. Im Gegensatz zu heutigen multifunktionalen Handys waren die Geräte bis Mitte der 1990er Jahre ausschließlich zum Telefonieren nutzbar. Mit der Möglichkeit, auch Textnachrichten (SMS) zu versenden, vollzog sich ein weiterer technologischer Durchbruch. Das Handy wird smarter und multifunktional. Moderne Smartphones sind kleine Computer mit berührungssensitiven Bildschirmen. Es gibt auch keine Tasten mehr, sondern die Nummerneingabe erfolgt über den Touchscreen. Verwendungszweck ist keineswegs mehr nur das Telefonieren, es haben sich neue, teils hybride, Kommunikationsformen wie Chatprogramme, IP-Telefonie (Skype) und andere entwickelt. Dies führt dazu, dass das Smartphone während des Telefonierens auch nicht mehr zwangsläufig ans Ohr gehalten werden muss. Mit Verwendung von Kopfhörern kann das Telefon auch vor dem Körper gehalten oder während des Telefonierens in der Jackentasche getragen werden.
Die Geräte sind ständige Begleiter geworden und assistieren bei zahlreichen verschiedenen Tätigkeiten. Neueste Wearables lassen bereits Person und Computer miteinander verschmelzen, was bis dato immer als Science-Fiction gedacht wurde (z. B. Telekommunikation in „Star Trek“ oder „Total Recall“, wo über Brust bzw. Handinnenfläche kommuniziert wird). Ein französisches Start Up soll an einem Armband arbeiten, über das der Unterarm zu einer berührungsempfindlichen Fläche wird, mit der das Smartphone gekoppelt werden kann, um damit Telefonate zu führen.

118

Auch mit Interfaces in Kleidung (smart fabrics) wird bereits experimentiert. Je wichtiger bestimmte Komponenten von Geräten werden und je häufiger wir im Alltag damit zu tun haben, desto wahrscheinlicher ist es, dass wir in unserer Alltagskommunikation mit Gesten darauf Bezug nehmen. Welche Gesten lassen sich nun aber beobachten?
„Ruf mich an!“: Telefongesten im Wandel
Telefongesten treten normalerweise redebegleitend auf, wenn z. B. in einem Gespräch vom Telefonieren die Rede ist. Eine solche Geste wird ausgeführt, wenn über ein Telefongespräch berichtet wird, oder wenn man ein solches Gespräch ankündigt: „Ich ruf dich dann morgen an!“. Es gibt eine ganze Reihe von Gesten, die die Bedeutung ‚Telefonieren‘ haben. Welche Form- und Funktionsaspekte des Telefons speichern die verschiedenen Varianten dieser Geste?

Die klassische Telefongeste
Bei dieser gebräuchlichen Geste für ‚Telefonieren‘ wird eine Hand seitlich neben dem Kopf gehalten (siehe Abbildung 4). Sie repräsentiert dabei die Form des Telefonhörers traditioneller Gabeltelefone, der im Fachjargon aufgrund seiner Form auch als „Knochen“ bezeichnet wird. Eine Hand wird seitlich zwischen Mund und Ohr positioniert. Daumen und kleiner Finger werden abgespreizt und repräsentieren die Hör- und Sprechmuschel, während die anderen drei Finger angewinkelt sind. Diese Geste ist auch heute noch ein Zeichen für Telefonieren, obwohl sich die Gestalt der Apparate mittlerweile verändert hat. Viele Festnetztelefone haben heute ein abnehmbares Mobilteil, das nicht mehr die Knochenform des klassischen Telefonhörers mit Sprech- und Hörmuschel aufweist. Mobiltelefone haben eine gänzlich andere Form und werden auch anders gehalten. Trotzdem ist die Geste weiterhin in Gebrauch und erinnert uns an die klassische Form des Telefons und die prototypische Telefonierhaltung, die sich im 20. Jahrhundert herausgebildet hat.

10  Dominante Hand ahmt mit Zeigefinger das Wählen mit Wählscheibe nach 11  Hand ahmt das Halten des Hörers nach
119

Wählen mit der Wählscheibe

Telefongesten in der Zukunft

Eine weitere Geste stellt das Wählen mit einer Wählscheibe ikonisch dar. Dabei wird das Bedienen eines traditionellen Telefons nachgeahmt, indem vor dem Körper eine imaginäre Wählscheibe bedient wird. Diese Geste wird manchmal auch in Kombination mit der Telefonhörer-Geste ausgeführt (Abbildung 10).
Das Halten des Hörers
Mit einer anderen Variante wird das Telefonieren repräsentiert, indem lediglich mit geballter Faust das Halten des Hörers dargestellt wird (Abbildung 11). Die Hand ahmt die Handlung nach.6 Auch diese Geste kann in Kombination mit der Wählscheiben-Geste ausgeführt werden.

Durch den Siegeszug des Mobiltelefons veränderten sich die Form und der Umgang mit Telefonen erneut. Während in der ersten Dekade des 21. Jahrhunderts das klassische „Handy“ dominierte und der Trend zu immer kleineren Geräten führte, haben sich seit der Einführung des iPhones durch Apple die sogenannten Smartphones durchgesetzt. Es ist daher zu erwarten, dass sich das Repertoire an Telefongesten weiter verändert, da sich, wie wir bereits gesehen haben, Form und Gebrauch von Artefakten auch in Gesten abbilden. Auch unser jetziges Telefonierverhalten mit unseren mobilen Endgeräten verändert sich zunehmend. Mobiltelefone werden anders gehalten als der klassische Telefonhörer. Kleine Handys werden unter Umständen zwischen Daumen und Zeigefinger gehalten, während Smartphones mit allen Fingern umfasst werden. Die Geräte sind flach

12  Mögliche Geste für ‚mit dem Smartphone telefonieren‘
120

13  Mögliche Geste, bei der das Mobiltelefon vor dem Körper gehalten wird

und haben eine rechteckige Form. Abbildung 12 zeigt eine mögliche Geste, die das Telefonieren mit einem Smartphone nachahmt.
Da wir immer häufiger zum Telefonieren das Smartphone vor uns halten, ist es gut möglich, dass daraus eine Telefongeste der zwischenmenschlichen Kommunikation entsteht. Neuerdings verändert sich das Kommunikationsverhalten auch dahin, dass Sprachnachrichten aufgezeichnet und mittels eines Instant-Messengers versandt werden. Dazu werden die Geräte auch gern vor dem Mund oder auf Höhe der Brust gehalten. Durch die Veränderung der Telefongeräte und ihre Handhabung kann sich auch das Gestenrepertoire für Telefonieren in diese Richtung wandeln. Es ist denkbar, dass in Zukunft dieser Aspekt zu einer weiteren Gestenvariante wie in Abbildung 13 führt.
Gestensteuerung und die Zukunft des Telefonierens
Während die klassischen Telefongesten durch die Bedienung eines Telefontyps – etwa das Drehen einer Wählscheibe – motiviert sind, integrieren moderne Geräte Gesten aus dem natürlichen Repertoire des Menschen in ihre Bedienabläufe. Interessanterweise kehrt sich dabei die Richtung der Einflussnahme um. Als Eingabemethode für Touchscreens, die durch Wischen und Tippen mit einem oder mehreren Fingern bedient werden, sind sie Gesten im weiteren Sinn. Das Vergrößern oder Verkleinern von Inhalten wird beispielsweise als „Pinch-to-Zoom-Geste“ bezeichnet. Diese Gesten sind nicht intentionalen Ursprungs, sondern besitzen vielmehr eine kausale Bedienfunktion, ähnlich wie das Drücken eines Knopfes. Die Bedienkonzepte sind dabei abgeleitet aus tatsächlichen Handlungen wie dem Schieben eines Blattes Papier mit dem Zeigefinger oder aber der flachen Hand. Genauso wischen wir mit einem Lappen über die Oberfläche des Tisches, um Krümel zu entfernen. Über dieses schematisierte Handlungswissen lassen sich auch Gesten ableiten, wie z. B. die WEG-Gestenfamilie, wo mittels einer Geste auch Abstrakta „weggewischt“ und damit verneint werden.7 Wenn Geräte keine mechanisch definierten Bewegungsabläufe mehr haben, sondern durch Bewegungsmuster auf Touchscreens oder durch tatsächliche Gestensteuerung bedient werden, kann man dafür auf das Repertoire unserer natürlichen Gesten zurückgreifen.
Das Spektrum der Telefongesten, das oben dargestellt wurde, zeigt, dass technologische Entwicklungen auf menschliche Kommunikationsformen Einfluss nehmen und

diese prägen. Was jedoch geschieht, wenn der technologische Wandel immer schneller voranschreitet? Wie wird es sich auswirken, wenn technische Geräte in Zukunft immer abstrakter und kleiner werden und das Telefonieren möglicherweise verstärkt über Headsets stattfindet? Bislang ist noch nicht genug über diese Zusammenhänge bekannt, um Vorhersagen zu treffen. Wir wissen nicht genau, welche Eigenschaften von Geräten und Interfaces für die Entwicklung spezifischer Gesten entscheidend sind. Es ist denkbar, dass die sehr charakteristische Handbewegung des Wählens mit einer Wählscheibe, die sich stark von anderen Alltagshandlungen unterscheidet, die Entstehung einer entsprechenden Geste begünstigt hat, oder dass die eigenwillige Knochenform des klassischen Telefonhörers die bis heute gebräuchliche entsprechende Geste so prägnant macht. Dagegen unterscheidet sich die Bedienung heutiger Smartphones nicht grundlegend von der eines Tablets oder anderer Touchscreens im Haushalt. Es bleibt daher abzuwarten, ob sie eine ebenso einprägsame Telefongeste hervorbringen wird.
Wir können allerdings davon ausgehen, dass das Telefon und die Gesten für Telefonieren sich auch in Zukunft zusammen weiterentwickeln werden – man könnte von einer Art der kulturellen Koevolution sprechen. Es ist denkbar, dass die flachen quadratischen Formen heutiger Smartphones bald zu einer entsprechenden Geste führen, dass Telefongesten in Zukunft das flache, vor dem Körper oder Mund gehaltene Handy oder sogar das Headset repräsentieren, mit dem heute häufig telefoniert wird, während das eigentliche Gerät in einer Tasche steckt. Vielleicht wird das Telefon der Zukunft eine virtuelle Tastatur haben, die auf die Handfläche oder als Hologramm vor uns in die Luft projiziert wird? Falls es so kommt, könnte sich eine Telefongeste entwickeln, die das Auf-die-Handfläche- oder Indie-Luft-Tippen nachahmt. Denkbar ist aber auch, dass wir die Nummer in Zukunft nur noch aussprechen werden. Was passiert jedoch, sollte sich eine Bedienung des Telefons ohne manuelle Aktivität durchsetzen – etwa per Sprachbefehl oder gar durch bloßes Denken des Steuerbefehls, was bei der Steuerung von Prothesen bereits möglich ist? In diesem Fall ist es gut möglich, dass sich die letzte noch auf einer Handhabung, also einem manuell ausgeführten Bedienvorgang, beruhende Telefongeste dauerhaft erhält.
Eines ist sicher: Wie auch immer wir mit den Maschinen der Zukunft kommunizieren, Gestik wird es auch weiterhin geben, denn sie gehört genau wie Lautsprache und Mimik zu den universellen menschlichen Kommunikationsformen. Es werden also auch in Zukunft Menschen

121

3 Vgl. die Herleitung aus altgr. tēle ‚fern‘ und phōnē ‚Laut, Ton, Stimme‘. Eingeführt wurde der Ausdruck durch den deutschen Physiker Johann Philipp Reis 1861.
4 Vgl. z. B. Schwender, Clemens: Wie benutze ich den Fernsprecher? Die Anleitung zum Telefonieren im Berliner Telefonbuch 1881–1996/97. Berlin / Bern / New York 1997.
5 Vgl. Schönhammer, Rainer: Telefon-Design. Der Körper des Fernsprechers. Kerken 2004.
6 Müller, Cornelia: Gestural modes of representation as techniques of depiction. In: dies. (Hg.): Body – Language – Communication: An International Handbook on Multimodality in Human Interaction. Bd. 2, Berlin / Boston 2014, S. 1691.
7 Vgl. Bressem, Jana; Müller, Cornelia: The family of Away gestures: Negation, refusal, and negative assessment. In: Müller, Cornelia u. a. (Hg.): Body – Language – Communication: An International Handbook on Multimodality in Human Interaction. Bd. 2, Berlin / Boston 2014, S. 1592–1604; sowie Fricke, Ellen; Bressem, Jana; Müller, Cornelia: Gesture families and gestural fields. In: Müller, Cornelia u. a. (Hg.): Body – Language – Communication: An International Handbook on Multimodality in Human Interaction. Bd. 2, Berlin / Boston, 2014, S. 1630–1640.

14  Wie man früher den Telefonhörer hielt: Gesten als Wissensspeicher in der Ausstellung

gestisch ausdrücken, dass sie telefoniert haben oder telefonieren wollen – aber welche Form die entsprechende Geste haben wird, könnte durchaus davon abhängen, was sich die Ingenieure für Morgen ausdenken werden. Allgemein gilt, dass natürliche und künstliche Gesten sich gegenseitig beeinflussen. Wenn wir in Zukunft mit unseren Autos, Küchengeräten oder Handys auch mit Gesten kommunizieren, die für diesen Zweck festgelegt werden, wird dies unsere Gestik verändern und auch auf unsere „natürliche“ Gestik Einfluss nehmen, ähnlich wie Kunstwörter wie ergoogeln Einlass in unsere Sprache finden.
Wie das Beispiel der Telefongeste zeigt, können Gesten das Wissen über frühere Entwicklungsstufen der Geräte speichern, mit denen wir täglich interagieren. Sie schaffen damit eine Brücke zur Vergangenheit und machen sichtbar, dass wir unsere Gesten, genau wie die Lautsprache, von

früheren Generationen erben. Sie schlagen, verknüpft mit Bedienkonzepten, auch eine Brücke zum Morgen, wo sie in Schnittstellen implementiert werden können, die für Menschen als Nutzer „intuitiv“ zugänglich sind.
Anmerkungen 1 Vgl. Kaszynski, Gert; Schönhoff, Jürgen: Fernsprechendgeräte.
Berlin 1991; sowie Becker, Jörg: Fern-Sprechen: Internationale Fernmeldegeschichte, -soziologie und -politik. Berlin 1994. 2 Vgl. Posner, Roland: Kultursemiotik. In: Ansgar and Vera Nünning (Hg.): Konzepte der Kulturwissenschaften: Theoretische Grundlagen – Ansätze – Perspektiven. Stuttgart/Weimar 2003, S. 44.

Abbildungsnachweis 1 www.canstockphoto.de/weinlese-clipart-telefon-12169273.html.
© pedrolieb | Can Stock Photo Inc. 2 https://www.flaticon.com/free-icon/phone-receiver_31247.
© Freepik. 3 https://www.flaticon.com/free-icon/phone-symbol-of-auri-
cular-with-cord_33974. © SimpleIcon. Lizenz: CC 3.0 BY. 4 Zeichnung: Uliana Schöller. 5 https://de.dreamstime.com/lizenzfreie-stockfotografie-al-
tes-wandtelefon-image7684917. © Rambleon | Dreamstime.com. 6 www.dreamstime.com/stock-image-1900-s-candlestick-tele­
phone-white-image4594471. © Holly Kuchera | Dreamstime.com. 7 Youtubevideo BBC Comedy Gameshow QI XL M episode
16, Online unter www.youtube.com/watch?v=axazQ_p6KN4 (Standbild, ca. 10:10). 8 Sächsisches Industriemuseum Chemnitz (SIM wNr. 08/0598  / B7). 9 Foto: Sächsisches Industriemuseum Chemnitz. 10–13 Zeichnungen: Uliana Schöller. 14 Foto: Tobias Naumann.

122

123

IV HÄNDE, DINGE UND GESTEN ÄSTHETISCH REFLEKTIERT: INTERVIEWS UND TEXTE
» Marianne Eisl, Ellen Fricke und Christopher Lindinger Ausgewählte künstlerische Exponate im Überblick: Kurzbeschreibungen

» Interview “People are augmenting their bodies all the time”: An interview with Golan Levin on digital bodies, technology and art

» Interview “Anything that is mechanical is almost retro”:
An interview with Daniel Rozin on art in the digital age

» Werner Jauk Sound-gesture und post-digital culture: Von der symbolisch zeichenhaften „forward back“ zur stimulativ signalhaften körperlichen Interaktion von every body

» Ines Lindner Anette Rose: Captured Motion. Bewegungsnotationen im Raum

» Hannah Groninger und Irene Mittelberg Von Erinnerungen zu Objekten: Motion-Capture-Skulpturen gestischer Raumbeschreibungen

» Mathias Roloff Gesten, Zeichnungen, Dinge

124

125

Ausgewählte künstlerische Exponate im Überblick:
Kurzbeschreibungen

Marianne Eisl, Ellen Fricke und Christopher Lindinger

Künstlerische Forschung als eigenständige Dimension des Experimentierens und Reflektierens auch im Hinblick auf mögliche Zukunftsszenarien war im Forschungsprojekt MANUACT der Technischen Universität Chemnitz und der aus diesem Projekt hervorgegangenen Ausstellung „Gesten – gestern, heute, übermorgen“ von Beginn an angelegt. Wie die Verbindung von Wissenschaft, Kunst und Technologie neue Erfahrungen ermöglichen und zu einem Erkenntnisgewinn führen kann, zeigt exemplarisch als Forschungs- und Ausstellungspartner das Ars Electronica Futurelab (Linz). Aus dem breiten Fundus an Arbeiten, die beim jährlichen Ars Electronica Festival zu sehen sind und für den Wettbewerb eingereicht werden, wurden einige künstlerische Werke speziell für die gemeinsame Gestenausstellung kuratiert. Die Erkundungen an und mit diesen interaktiven Exponaten ermöglichen im Narrativ der Ausstellung, so der Anspruch, Wissenschaft für alle und Kunst für alle. Sie erschließen damit für die Besucherinnen und Besucher spielerisch und an unmittelbare Erfahrungen anknüpfend ein Themengebiet aktueller gesellschaftlicher Relevanz.

Wooden Mirror Daniel Rozin (USA)
Der New Yorker Künstler, Pädagoge und Entwickler Daniel Rozin arbeitet im Bereich der interaktiven digitalen Kunst. Als Künstler schafft er interaktive Installationen und Skulpturen, die auf die Gegenwart des Betrachtenden reagieren und sich mit ihr verändern. Seine bekanntesten Arbeiten erzeugen in Echtzeit ein Abbild des Betrachtenden und machen damit das Publikum zu einem aktiven und kreativen Teil seiner Kunstprojekte. Mit seinen Konstruktionen untersucht Rozin seit Ende der 1990er Jahre die psychologischen und optischen Grundelemente der Bilderzeugung.
Der in der Ausstellung gezeigte „Wooden Mirror“ lässt ein nicht-reflektierendes Material wie Holz zu einem Spiegel werden. Hand- und Körperbewegungen werden von einer Kamera erfasst und computerunterstützt an kleine Motoren weitergegeben, die die insgesamt 830 Holzplättchen bewegen und die „Spiegelung“ erzeugen.
In der Sonderausstellung werden die Besucherinnen und Besucher zu Beginn durch den Wooden Mirror empfangen. Die spielerische Installation erlaubt einen einfachen, leicht verständlichen Zugang zum Thema der berührungslosen Gestensteuerung und stimmt auf den Kontext der Ausstel-

126

1 und 2 ­Daniel Rozin: Wooden Mirror, 2014. Wood, motors, video camera, custom software, microcontroller, 6 × 6 ft / 1.8 × 1.8 m
127

lung ein. Das interaktive Initialexponat schafft ein erstes Bewusstsein für die eigenen Hand- und Körperbewegungen und ihr kommunikatives Potential, das dann in die gesamte Ausstellung zurückreflektiert und in den unterschiedlichen Bereichen wieder aufgegriffen wird.
Der „Wooden Mirror“ ermöglicht so Ausstellungsbesuchern aller Altersstufen ein faszinierendes Spiel mit der Gegensätzlichkeit analoger und digitaler Darstellung und lässt sie darüber hinaus erfahren, wie stark unsere Sinneserfahrung durch bestimmte Objekte vorgeprägt ist.
Augmented Hand Series Golan Levin (USA), Kyle McDonald (USA), Chris Sugrue (USA)
Golan Levin erforscht die Schnittmenge von abstrakter Kommunikation und Interaktivität. Er konzentriert sich vor allem auf das Design von Systemen, die neue Formen des reaktiven Ausdrucks behandeln. Gemeinsam mit Kyle McDonald und Chris Sugrue entwickelte er die Installation „Augmented Hand Series“, die in der Ausstellung im Chemnitzer Industriemuseum zu sehen war.
„Augmented Hand Series“ ist ein interaktives Softwaresystem, das spielerisch traumhafte bis unheimliche Transformationen der Hände seiner Nutzerinnen und Nutzer zustande bringt. Dafür wird die Hand in Echtzeit erfasst, um sie dann auf einem Display in völlig veränderter – und nicht bloß verzerrter – Form wiederzugeben.

Einige der Umwandlungen bewirken strukturelle Veränderungen der Handform, andere wiederum verleihen ihr eine ungewöhnliche Plastizität oder auch eine gewisse Form von Autonomie, dessen Ergebnis eine Mischung aus der tatsächlichen Hand und algorithmisch berechnetem Verhalten ist.
Die Installation bietet rund zwanzig unterschiedliche Transformationen, einige davon sind: –– „Plus One“: Die Hand erhält einen zusätzlichen Finger. –– „Minus One“: Die Hand hat einen Finger weniger. –– „Extra Knuckle“: Jeder Finger erhält ein zusätzliches
Fingerglied. –– „One Knuckle Fewer“: Jeder Finger hat ein Fingerglied
weniger. –– „Two Thumbs“: Ein weiterer Daumen wird an die Seite
des kleinen Fingers kopiert. –– „Transposed Thumb“: Der Daumen wird auf die gegen-
überliegende Seite verschoben. –– „Fractal Hand“: Jeder Finger stellt eine eigene Hand dar. –– „Throbbing Fingers“: Die Finger scheinen dem Herz-
schlag folgend zu pochen. –– „Variable Finger Length“: Die Länge der Finger variiert
über die Zeit hinweg. –– „Meandering Fingers“: Die Finger beginnen ein gewis-
ses Eigenleben. –– „Procrustes“: Alle Finger haben dieselbe Länge. –– „Lissajous“: Die Handinnenfläche wird verkrümmt dar-
gestellt. –– „Breathing Palm“: Die Handinnenfläche vergrößert und
verkleinert sich.

3  Handtransformationen des Exponats „Augmented Hand Series"
128

–– „Vulcan Salute“: Der dritte und vierte Finger wird gespalten dargestellt.
–– „Springers“: Fingerbewegungen werden mittels physischen Berechnungen überzeichnet dargestellt.
Die Besucherinnen und Besucher werden spielerisch animiert, sich mit dem Aussehen und der Funktionalität der Hand zu befassen.
Genau das ist der Schnittpunkt, an dem dieses künstlerische Exponat im Rahmen der Ausstellung einzuordnen ist: Denn die Hand spielt in der Evolution des Menschen eine herausragende Rolle, mit ihrer speziellen Form konnten Primaten beispielsweise im Gegensatz zu den Reptilien Dinge greifen und auch als Werkzeuge verwenden. Das Interface stellt die Transformation der Hand in den Kontext der evolutionären Anthropologie und fordert dazu auf, uns der Vorstellung, die wir von ihr haben, bewusster zu werden.

4  Golan Levin, Kyle McDonald, Cris Sugrue: Augmented Hand Series, 2014

Gesture Jewelry Jennifer Crupi (USA)

Die elegant gestaltete „Gesture Jewelry“ von Jennifer Crupi dient nicht nur dem Körperschmuck. Die handgefertigten Einzelstücke bringen bestimmte Körperhaltungen und Gesten zum Vorschein, die wir in unserem alltäglichen Leben ganz selbstverständlich einnehmen. Drei ihrer Werke bereicherten die Ausstellung im Chemnitzer Industriemuseum, mit dem Ziel ihren Trägern bzw. den Beobachtern bestimmte Gesten bewusst erlebbar zu machen.
„Unguarded Gestures 3” ist eines dieser gezeigten „Schmuckstücke“, mit dessen Hilfe man ganz automatisch eine bestimmte offene Pose, in der die Ellbogen leicht abgewinkelt seitlich vom Körper positioniert werden, einnimmt. Gleichzeitig lässt es dem Träger aber auch bestimmte Freiheitsgrade, um in einem gewissen Spielraum frei artikulieren zu können.
Anders verhält es sich beim Anlegen der „Power Ges­ ture“; hier wird eine Handhaltung forciert, die eine gewisse Macht und Überlegenheit ausstrahlt. Diese Geste wird oftmals in Situationen ganz automatisch eingenommen in denen man das Gefühl hat, die Oberhand zu haben.
Laut Psychologen fühlt man sich, sobald man sich absichtlich in eine bestimmte Pose versetzt, genauso wie wenn man die Pose natürlicherweise eingenommen hätte. Somit können die Besucherinnen und Besucher einfach an sich selbst testen, ob beispielsweise das Halten der „Power Ges­ ture“ tatsächlich ihr Selbstvertrauen stärkt.

5  Jennifer Crupi: Gesture Cuff

129

6  Jennifer Crupi: Unguarded Gestures 3
7  Jennifer Crupi: Power Gesture
130

8  Werner Jauk: Touch the sound 2.0

Touch the sound 2.0 / sound-sculpting Werner Jauk (Österreich)
Klang gilt als nicht begreifbar, dennoch ist er spürbar. Klang gilt als flüchtig und doch ist er stets rund um uns. Klang ist Bewegung und doch nur wahrnehmbar, wenn Schallwellen auf unsere Körper treffen. Nach „touch my sound“ versucht die in der Ausstellung gezeigte Installation „touch the sound 2.0 / sound-sculpting“ von Werner Jauk die Relevanz des Interfaces namens menschlicher Körper erneut ins Zentrum des Hörens zu setzen und erkundet die Wirklichkeitskonstruktionen zweier unterschiedlicher, sensorischer Interaktionsformen: Einerseits geht es um das mechanisch passiv analysierende Hören des flüchtigen Klanges und andererseits um die aktive Handhabung und damit das synthetisierende Sehen. Die systemische Variation beider formt den Klang zu stationären Gestalten – Modelle der körperlich begreifbaren Materialisation von Immaterialität.
Diese aktive Handhabung können Besucher und Besucherinnen erfahren, indem sie mittels bestimmter Bewegungen und Gesten Klang erzeugen und so selbst Teil

dieses Klangerlebnisses werden. Die Gesten haben dabei jedoch keine direkte Verbindung zu dem erzeugten Klang und thematisieren so die oftmals nicht vorhandene Kausalbeziehung der Gestensteuerung in der Mensch-Maschine-Schnittstelle, in der konventionelle Gesten in einen neuen Kontext gestellt werden.
Die Installation wurde im Rahmen des Symposiums von Werner Jauk präsentiert und den Besucher und Besucherinnen rund zehn Tage lang zugänglich gemacht.
Abbildungsnachweis 1–2 Fotos: Bitforms Gallery, New York. 3 Golan Levin, Kyle McDonald, Chris Sugrue. 4 Foto: Cinekid Festival, Gerlinde de Geus. 5–7 Fotos: Christian Luis. 8 Foto: Doris Jauk-Hinz.

131

“People are augmenting their
bodie	 s a	 ll	 the	 time”: An interview with Golan Levin on digital bodies, technology and art1

One of the fascinating things about “The Augmented Hand Series” is that you can actually move your hands freely, but you see them moving in the changed shape.
<LEVIN Yes. The current configuration of the hand is used as the basis for further transformations. This is one of the key innovations of the project: that it always transforms your hand as it is positioned – within certain limits of what the camera system can do. To be perfectly truthful, it treats the hands rather two-dimensionally. It works only if the hand is relatively flat, but within that constraint it always uses the current hand form as a basis for further transformations, such as adding a finger or taking one away.
Could you explain some of the technical details of the piece? It is obviously able to identify specific parts of the hand. Is there a hand model that underlies these transformations?
<LEVIN Yes. In fact, the project took eleven years to make – I first premiered it in 2014 –, and it took so long because one of the key problems was solving how to make a model of the hand. In “The Manual Input Sessions” from 2004, we already had such a model, but it

was just a silhouette. We could know of the silhouette, as a two-dimensional shape, which were the points of high curvature, like the finger tips, and which were the points of negative curvature, like the crevasses between the fingers, but we did not know that this one was the middle finger and this one was the index finger. It was not until the leap motion controller – which is also in the exhibition here – was released that I had a software development kit that could look at the hand and tell me “this is the pinkie, this is the ring finger, this is the thumb”, and it could be quite certain about that. It actually still messes up, which is a pain, but it can most of the time tell me which finger is which.
In “The Augmented Hand Series”, there is also one scene where the hand is somewhat misshapen.
<LEVIN There are several, but that could be a bug, too. It is hard to say (laughs). However, a measure of success of the project, for me, is when I see a person with the hand in the box, and they look into the box – and this happens again and again – to see if something is really happening to their hand. The change is so compelling that they have to know if it is real.

132

1  Golan Levin in the exhibition hall of the Saxon Museum of Industry Chemnitz

Do you feel that the installation is connected to virtual reality and the possibilities it provides for experiencing ourselves in altered ways, for example, in the form of an avatar?

<LEVIN First of all, I think it’s probably closer to augmented reality than to virtual reality. The augmented hands are like your hands, but there is something extra, like an extra finger, or there is some kind of other transformation to what happens. And because the fiction is that you are really seeing your own hand, as opposed to being in a virtual world which is imagined and constructed, there is a sense that there is a lens on your own body, which is showing you your own body but with a transformation. This seems to be closer to augmented reality than to virtual reality, which are very different things.

If you think about biotechnology, we could imagine that in the future, we could actually decide to augment our hands. It seems to be implicit in the title that the augmentation of our hands may become a possibility, and this raises an interesting question. If we should decide, as a species, to change the shape of our hands, what purpose would we augment them for? If we imagine people 200 years ago augmenting their hands, they would maybe have focused on making them stronger, because they had a lot of hard work to do. Today, we have powerful tools and might choose to augment our hands for the work with complex interfaces, for example for using touchscreens. What do you think – should we choose to augment our hands, not knowing what kind of hands future generations would like to have?

<LEVIN Well, first of all people are augmenting their bodies all the time. We augment our bodies with prostheses or glasses, and even a pen could be considered as a kind of prosthesis. There are also people who permanently augment their bodies: they use body modifications such as inserting magnets under their skin in order to give themselves magnetic sensibility. I don’t think this project is intended to model that, I think it is more intended to disrupt the familiarity that you feel with your own body. It is less about biotechnology and about changes to real bodies, more about digital bodies,

133

and here maybe there is a connection to virtual reality, because in virtual reality we can put on costumes and re-imagine ourselves in different ways.
“The Augmented Hand Series” is like a costume, if you like. We can think of doing to our bodies all the kinds of operations that we have in the digital realm. I’m thinking specifically of operations like copy and paste. “The Augmented Hand Series”, when it adds a finger, is actually copying and pasting your finger, but this happens in the logical space of your hand. This prompts us to think about what digital bodies really are, and shows us how they might look.

People with alien hand syndrome feel something like: “there is myself, and then there is this hand which moves under its own control”. “The Augmented Hand Series” is playing with that because in many of the different

Would you like to experience having different hands, if only for a limited period of time – if such a change is imaginable?

<LEVIN Well, “The Augmented Hand Series” arguably is a tool for imagining just that. To some degree, it answers the question what it would be like to have, for example, an extra finger.
Actually, I thought you were going to ask about things like phantom limb syndrome or body dysmorphic syndrome. There are some interesting psychological connections to these syndromes, to the extent to which, by seeing your hand changed in this way, you feel like you actually have this extra finger. In the case of phantom limb syndrome, if a person loses a hand, they still feel it. There is a special mirror box that people use to help recover from this feeling, where they can see and move the virtual hand, using their other hand.
Some very interesting psychological tests have been done with people missing limbs. Not only can they feel the missing limb, but through effort they can actually move the missing limb, and through more effort they can move the missing limb into positions that are impossible. So for example, if I was missing my leg, with effort I can image the missing leg, but the knee facing the other direction, so instead of bending down, I can have it bending up.
A further interesting condition that the project connects to is alien hand syndrome. Peter Sellers has this as Dr. Strangelove in the eponymous Kubrick film. This is a real condition, in which the hand has kind of its own existence, its own mind. There is some extra process running in the person’s mind that is governing the hand in a way that is autonomous from the main cognition.

2  The "Fractal Hand" transformation
scenes, the hand has a kind of autonomy. And when we see it moving on its own, we feel like it is no longer our own hand. There is also another syndrome, which is called Body Integrity Identity Disorder, where you feel like the hand is not you, and you actually want to get rid of it.
There also seems to be an evolutionary perspective to the piece. Could our hands have been different, if evolution had decided to shape our hands in different ways?
<LEVIN Steven Jay Gould has a book called “Eight Little Piggies” in which he talks about how the fact that we have five fingers can be regarded as a biological accident. In this exhibition, replications of hands of several different mammals are on display, and five fingers seems to be something that is quite old – but obviously, at some point it could have been six or it could have been four. “The Augmented Hand Series” definitely questions why it couldn’t have been some other way, and shows some of the other ways it could have been. In fact, we use a base-ten number system because we have ten fingers. If we had evolved differently, we could be using base twelve, which is actually kind of a nicer system (laughs).

134

However, when thinking about these possibilities, it’s hard to imagine a situation where an extra finger would actually be useful. A possible exception can be seen in the film “Gattaca”, where a pianist plays with twelve fingers, which allows him to insert an additional voice from time to time. Musicians may be one of the few professions that could actually make use of an extra finger, but generally, one can get the impression that our hand is already very well designed.
<LEVIN Well, it is certainly evolutionary optimized for doing a bunch of different things, but as Gould points out, it could have been otherwise. You could miss a finger and still do very well at various tasks. However, the project as I’m showing it here in Chemnitz has fourteen different scenes, and in a number of them, the hand could accurately be described as being made useless, for example, because it ceases to be under direct control of the visitor. I haven’t thought about this machine as a utilitarian device.
Our perspective in the MANUACT research project, which resulted in this exhibition, is primarily on gestures as a means of communication. We found that some gestures and body postures that we use in communication are connected with manual actions and traditional crafts. Let us assume a futuristic perspective and suppose that humans will fundamentally change their bodies. Would having differently shaped hands, as you imagine them, influence the way we communicate with our hands?

<LEVIN I think it depends on how different they were. For example, if your hands are not under your direct control, it would make a pretty big imposition on how you communicate with them. I don’t think that my project really has much to do with hands as a means of communication. I think it operates a couple of levels lower than that. Before we begin to make signals with our hands, we have to learn, as a one-year old, that they are a part of me – these things that I feel and see are a part of me. “The Augmented Hand Series” is just toying with this very basic loop we have, this connection with our own body. To be able to interpose new signals in that loop, to change the feedback, is the point. This is nowhere near the point of communicating with the hand, whether with sign language or other kinds of meaningful gestures.

3  The "Springers" hand transformation
135

4  A visitor of the Chemnitz exhibition experiences the hand transformation “Meandering Fingers”

In “The Manual Input Sessions” from 2004, you explored the expressive potential of hand and finger movements. Were you interested in gestures as a means of human communication, or was it more an aesthetic perspective on the human hands and their movements?
136

<LEVIN In some ways, that project was a precursor to “The Augmented Hand Series”, which is again looking at transformations of the hand. “The Manual Input Sessions” uses hands to control audiovisuals, so it is less about seeing the hand in a new way, as this current project is, than it is about using the hands to create expressive sounds and graphics.
Generally I think that gestures are really lovely and I am sure that they sometimes encode explicit meanings. But I also think that there are more abstract qualities of such gestures that you see in dance and that people make in their everyday movement. They are expressive without necessarily being able to be read in a specific way. I think that there is a certain beauty in watching how people move. Even if there is not necessarily meaning in how they are moving, there is a beauty in it, and that is what many of my projects reflect.

Some of your other installations are connected to topics in linguistics and communication. For example, “The Alphabet Synthesis Machine” from 2002 explores the development of alphabet systems, and “Re:MARK” (2002) visualizes the speech of two interlocutors, analyzing the sound according to the phonemes that are spoken. Do you have a specific interest in human communication that motivates your work?

<LEVIN Yes, I would say that I do. In many ways, the subject of my projects is communication itself. The different projects that I have done explore different kinds of communication, often para-linguistic communication such as gestures of the hands or prosody but not speech per se. I’m interested in how people can communicate without words. The abstract alphabets in “The Alphabet Synthesis Machine” that you mentioned are what they call “asemic writing” – a sort of writing without meaning. I am primarily interested in the formal qualities of communication.

Was the connection of the hands and their objects your reason to present “The Augmented Hand Series” here in Chemnitz?
<LEVIN Actually, I was very attracted to the idea of an exhibition which is concerned with gesture and hands. I am looking for situations for the project which are appropriate, where it is situated in a context with other projects related to gesture and hands, and this is certainly the case here.

So it is the expressive dimension, prior to the semantics proper, which is your primary focus?
<LEVIN Yes, I would say that I am not interested in the semantics; I’m interested in the forms, in the shapes. The difference I would say between “The Augmented Hand Series” and “The Manual Input Sessions” from 2004 is that in the earlier project I’m using the hands to expressively control certain sounds and images, while in this project I’m manipulating the image of the hand itself.
When you came up with that idea of manipulating sounds by the hands, was that approach also driven by the fact that, when we speak, we always use our whole body?

Note 1 The artist was interviewed by Martin Siefkes and Jana Bres-
sem on November 16, 2017 in the Saxon Museum of Industry Chemnitz.
Illustrations 1 Video still: Maria Haase. 2–4 Photographs: Tobias Naumann.

<LEVIN I think it stemmed more from the use of the hands as controllers for instruments, like a violin or a piano. In “The Manual Input Sessions”, people use their hands to control a different kind of instrument. In this case, the instrument was via the medium of a camera using shadows that the hands are casting. So the hands had a direct control of the sound, just as when playing a violin – with the difference that a violin is a venerable and very old instrument, and “The Manual Input Sessions” is a kind of a new instrument which is based on shadow.

137

“Anything that is mechanical is almost retro”:
An interview with Daniel Rozin on art in the digital age1

Mr. Rozin, it is fascinating to see how visitors begin to move around, to gesture and to strike a pose in front of the “Wooden Mirror”. A conventional mirror rarely has this effect. Do you think the imperfect reflection offered by the “Wooden Mirror” encourages people to try it out, and to explore their own body in the process?
<ROZIN That’s a really good question, because it allows me to talk about different aspects. Let’s start with the question of abstraction. People often ask me if I like mirrors – in fact, I hate them! I see myself every morning in the mirror, and I don’t like it. I think that I’ve lost some more hair, I’m getting wrinkles – it is not a pleasant experience to see yourself in the mirror, and if I would put a real mirror in a public setting like this, I don’t think it would be necessarily enjoyable for people.
I hope that my mirrors reflect peoples’ souls, and not their details (laughs). In order to do that, you really need to have a level of distraction. There are many ways to abstract things. One of them is by having only about 800 pixels instead of five megapixels as a camera has. You can’t see your blemishes, you only see some kind of abstraction, and you are much more willing to lend your image to me and to the public. And there is also the question of surveillance, because there is a camera in
138

the piece. However, I think people understand that I am not capturing the video. What is reflected back seems to be abstract enough to put people at ease.
Abstraction also describes the creative process. Traditionally, when artists would create paintings, they would start with a blank canvas, and then would add more and more details until they think it’s fine, and hang it on the wall. My work is based on cameras. I start with the perfect image and I take away. I ask myself, have I taken away enough, taking more and more, until I think: Oh, now this is my creation! The flow is very different in both cases: one of them is reduction and the other one is addition.
Furthermore, I want my pieces to be happy, and I want them also to be beautiful, which is actually a useful tool. I capture my viewer on different levels. First of all, there is a beautiful object, so people want to be near it; and then it moves; and then it captures them; and then they see that it is them! By the time I wheel them in with these three or four tricks, they have spent a few seconds with my piece, and maybe then they start thinking: Why did this person spent a year of his life building this thing? Maybe there is something else there. And if they don’t think that, that’s okay also, maybe they just spent some nice seconds before it (laughs).

1  A close-up of the “Wooden Mirror”

What is interesting to us as researchers in respect to the “Wooden Mirror” is the idea of abstraction you mentioned. What is recognizable as a posture or a gesture and when do we reach a point where a sign, be it a posture or gesture, cannot be recognized and understood anymore?

that boundary yet, I can still take away more. You have motion and you have people seeing. We are such amazing seeing machines; we see things even when they are not there. Especially when it is real-time interaction, we immediately see something.

<ROZIN Yes. I think more in terms of image than of gesture, but they are very similar, especially when abstraction comes into play. A lot of my pieces are related to poverty of information. This “Wooden Mirror” has 784 pieces, and the “PomPom Mirror” from 2015 only has 450. I am trying to see in many cases, what is the least amount of information that I can provide and still create an image. And it’s amazing that I haven’t reached
2  The tiles move independently of each other, acting as pixels that create an image

Apart from the image itself, the Wooden Mirror also uses other modalities. For example, it makes a beautiful sound, a bit like the rustling of leaves on a tree. And there’s also a light source which at first you don’t notice, but which is actually needed for producing the image. Are light and sound generally important for your work?
<ROZIN Sound has become an important part of these pieces. I have changed the kind of motors that I’m using in the past ten years from one type which is called servor motors to another kind which is called stepper motors which work really well, but they’re very soft. So I am actually a bit sad that I lost a few of the sound attributes. Some of it I can’t control, but where I can control it, I definitely try to add the sound.
The idea of the directional light, on the other hand, is the basis of one or two of my pieces, but it is not the only physical phenomenon that I like working with. For example, the “Weave Mirror” – a piece that looks like a woven carpet – does not require directional light, its elements hide one behind the other. There is one called the “Penguins Mirror” where there are penguin figures, they have white and black surfaces and rotate them towards the viewer. So the directional light is only one of the mechanisms I use for producing the image.

139

What is interesting is that while your works are mirrors, they not exactly do what people expect from mirrors. They fragment the image; especially some of your Software Mirrors do this in a very explicit way, such as “Mirror Number 5” and “Mirror Number 6”, which employ image-manipulation algorithms to change the visitors’ appearance. Is this a reflection on contemporary consciousness? Do these works, apart from their literal function as mirrors, also “reflect” our growing confusion about ourselves?

3  A visitor of the gesture exhibition watches herself in the Wooden Mirror

<ROZIN I am not sure about fragmentation of our consciousness, I didn’t think about it like that. But I like for all my pieces to have these two scales, which is the macro and the micro. Let’s look at the “Wooden Mirror”. If you first walk in this hall, you may say: Oh there is a video screen that shows people! But when you get closer you will see that it is made of tiles of wood, but you might be too close to see the image. It has to be either one or the other. I love for all my pieces to have that: that you have to decide, am I seeing the details or am I seeing the big picture? And where is the line between the two?
Fragmentation is only one thing about these levels of detail. With the “Trash Mirror” it is very obvious: It is not a good image creator because it is so colourful, but when you get closer to it, it offers a whole world of colour and of content. It has in it things that belonged to me, and things that were discarded. You start thinking about questions like recycling or about the things that we throw away. “Mirror Number 5” is another good example; it is the one that uses little figures that look like Pacmans. I was prompted to make it because I thought of digital images and the way we use them all the time. We understand the value of the digital image, but we don’t love it. I wanted to think about the psychology of the image. Can I give the pixels a personality? That is what I was doing with the Pacmans in “Mirror Number 5”. If you look at it, these Pacmans are always rolling and moving to the right, and they are opening and closing their mouth. It seems like they have a very full life, doing their thing – in order to create the image, they only open their mouth more or less. It seems like creating an image is a by-product of their life; they are very busy doing other stuff. I was thinking about the psychology of the pixel, this idea of the individuality of a pixel versus the collective task of an image, of the mass of pixels.

Is that also a metaphor for our mediatized world, where everything looks fine at a distance, and then when you come too close, you realize that things are often not what they’re supposed to be?
<ROZIN Actually, the “Wooden Mirror” is placed really well in this exhibition. You first see it from far away, and then you get closer, which is very good for this piece. It is important to orchestrate the way that people encounter a piece, which is definitely the case here. You first see the “Wooden Mirror” from a distance, then you advance and it changes, and you are placed in a particular mind-set – maybe you are surprised or maybe you take a further step towards it. This is definitely a narrative or storytelling instrument.
4  The Wooden Mirror “reflects” a hand gesture

140

Thinking of the “Wooden Mirror” and also other pieces you mentioned, is it important for you that the viewers only see their reflections, and that they have to confront their own bodies and movements without any distracting background?

<ROZIN It is important to me that they don’t see any kind of media that is not relevant to the piece. The first ten years of doing these pieces, I made maybe ten different variations of them, and they all had strictly this behaviour. You stand in front of it and see yourself reflected one-to-one, and that’s it. But around the year 2010 I became curious if I can add another layer on top of that. So most of my pieces now have a secondary behaviour that either greets you or that happens when you go away, so I get to create a kind of animation.
For the “Penguins Mirror”, for example, when you stand in front of them you are reflected, and when you walk away they seem to dance. Or the “Rust Mirror”: When you interact with it, the more you interact with it, the piece starts raining and makes a very loud noise, and after a while, it rains so hard that you can’t see yourself anymore. You have to walk out. The piece is crying from too much interacting, and then it calms down and you can come back.
So I don’t mind having a secondary type of media or animation running, but – maybe because I’m an artist – I want it to be mine, and I definitely want it to be relevant to the piece and to the experience.
5  The control panel on the back of the Wooden Mirror

You have used different approaches towards the theme of the mirror, such as the Mechanical Mirrors that use non-reflecting materials, the Software Mirrors that manipulate the reflection of the viewer in specific ways, and even traditional glass mirrors producing fragmented images. What motivates you to connect the centuries-old topic of the mirror with the techniques and possibilities of the digital age?
<ROZIN I was not aware that my pieces are mirrors until maybe three years into doing projects. I was using cameras, and my first piece was called Easel – because you paint with it – and someone came to me and said: “Did you notice that everything you are doing is a mirror?” I hadn’t noticed that, but I understood that it was right! After that, I was very deliberate in creating mirrors and I really widened my investigation to include even the material of the mirror. The material of the mirror is magic. You know, I combine a screen with a camera and I call it a mirror. Actually it is a horrible mirror. If you look at a real mirror, it is magical. If this surface here was a mirror, each one of us would see a different reflection. It is like a hologram. No computer could calculate what a piece of shiny metal can do.
Mirrors for me are a very useful platform to create art. I am curious about mirrors, and mirrors of course also have layers of mythology and preconception and superstition connected with them.
One of my pieces made out of glass mirrors is called “Self Centered Mirror”, in which case I’m actually removing from the mirror what I just described here, that each one of us would see something else. It is a one-hundred percent narcissistic mirror where you will always see yourself. God forbid you’ll see someone else in the mirror! Instead, you‘ll see yourself seventeen times! Some of these pieces are suggestive to me, and some are also interesting in a scientific way, for example, “Self Centered Mirror” is made out of 90-degree corners which have a quality of being retro-reflective, an aspect that I was curious about. I like the conjunctions between the physical, the scientific, and the material aspects.

141

6  Golan Levin explains the Wooden Mirror

Do you think that the line between the physical and the digital world has become blurred, or may become blurred in the future?

Are these works also intended to explore the line between the virtual and the physical world?
<ROZIN Yes, that’s precisely right. I create these pieces using many media, many formats and materials. Some of them are based on software, where you just take a screen and a camera, and you manipulate the image in some way. The interaction would be the same, it would still be a mirror, but such a piece would not necessarily explore the line between physical and virtual. Generally, I find that the idea of mirroring is very useful for me, because I get to do pieces that touch on many subjects that are important to me.
The first of these subjects is participation – the idea of interaction. Someone can move in front of one of my pieces and become part of the creation of the piece. The piece becomes the viewer, or the viewer becomes the piece. And when you think about who created this moment of art, the answer is not me – it’s us, together. That’s a very important concept for me. Another concept is the idea of image. How do we create images, how are images perceived by our eyes, or captured by cameras? All of my pieces use both of these concepts, in one way or the other.

<ROZIN You know, when I started doing these things, digital was a novelty or innovation, it was new for everyone, so it was rare. I think now the physical is rare! Our life is so digital and things happen so wonderfully in the digital form, that when you need to infuse it with physicality, it seems almost like you’re forcing it. It’s cheaper to make a digital display than making a physical one. Now, anything that is mechanical is almost retro.
Things change, but I find that as human beings, we live in the physical world. I believe we still have intuitions and desires that live in the physical world, so we can’t completely go digital – at least I hope not!
Note 1 The artist was interviewed by Martin Siefkes and Jana Bres-
sem on November 16, 2017 in the Saxon Museum of Industry.
Illustrations 1–3 Video stills: Maria Haase. 4–6 Photographs: Tobias Naumann. 7 Photograph: Dietmar Träupmann.

7  The Wooden Mirror reflects gestures, facial expressions, and body movements. The light source above the mirror transforms the moving tiles into bright or dark pixels, creating an image

142

143

Sound-gesture und post-digital culture:
Von der symbolisch zeichenhaften „forward back“ zur stimulativ signalhaften körperlichen Interaktion von every body
Werner Jauk
144

Die Welt des Begreifbaren, die Welt des Sehens, die Welt des Bildes hatten in der rationalen Kultur mechanistischer Vorstellung Dominanz, die Welt des Klanges, des Hörens war nicht nur untergeordnet, sie galt als emotional und verführerisch, als „sozial nicht wahr“.
Verherrlichte die digital culture mit der Fortführung der modernen Idee der Machbarkeit letztlich den mechanischen Körper und sein Erfahrungswissen, wendet sich die post-digital culture einer „alternativen“ Körperlichkeit zu, einer evolutionär „früheren“ Stufe der Körper-Umwelt-Interaktion und der Konstruktion von Welt aus ihrer Erfahrung – das Sehen wird durch das Hören ersetzt. Die Potenzialität zur Transgression des Mechanistischen1 durch die Immaterialität des digitalen Codes stürzt die Dominanz des Dinghaften, Begreifbaren und die gestaltende Kommunikation deren Begrifflichkeit; nicht das reaktive Synthetisieren, sondern das hedonische Analysieren in der Gestaltung aus Kommunikation bestimmt Verhandlung von Wirklichkeiten in einer Erlebnisgesellschaft.
Musik ist darin Medium der Erkenntnis als körperliche Empirie. Die Musikpsychologie erachtet Musik als die Formalisierung des Hörens. Die Ästhetik der Musik ist die Wahrnehmung der auditiven Wahrnehmung. Als hedonische Kultur der erregungsbasierten analysierenden Wahrnehmung ist digital culture eine musikalisierte, eine popmusikalisierte, die die signalhafte körperliche Kommunikation durch Erregung als kulturellen Prozess intensiviert und nicht durch ein cognitives Prinzip des symbolischen Denkens verdrängt.2
Mit der Annahme von Intentionalität jeglicher Körper-Umwelt-Interaktion,3 formuliert als „enactivism“ im Baum der Erkenntnis4 sind Forschungskonzepte gefordert, eine andere Art der Empirie zu entwickeln. Ausgehend von Kunst als forschender Disziplin kann die Beziehung zum Forschungsgegenstand nicht als auszuschaltender Error, sondern als Datum betrachtet werden. Ähnlich der Gegenübertragung werden Deutungen der erregungsbasierten Beziehung zum Gegenstand analysierend vorgenommen – abseits symbolischer Interaktion ist dabei die unvermittelte körperliche Interaktion zu fokussieren, um die mediale Transposition und damit die Reduktion von Erkenntnis vom körperlichen Erleben auf das verbale Verstehen und Kommunizieren zu minimieren. Damit werden die sensorische Transposition vom Hören zum Sehen sowie deren medialen Überformungen vermieden. Die Erfahrbarmachung des Körperwissens wie seine Kommunikation sind heute mit technologischen Medien näher am Körper möglich –

die Reduktion auf die kommunikativen und erkenntnistheoretischen Möglichkeiten des Sich-ein-Bild-Machens und dessen symbolische Bezeichnung sowie auf die Logik des sprachlichen Denkens als „reasoning“, als Generalisierung der Beobachtung von „Schocks und Schüben“5 im Zusammenhang mit der Erfahrung eigener Körper-Umwelt-Interaktion6 und damit der Konstruktion von Zeit und Raum, sind überwunden.
Klang ist ein Artefakt von Bewegung, seine Wahrnehmung die Information über Bewegung vermittelt über die Bewegung von Luft rund um den Körper – die Nicht-Begreifbarkeit und Flüchtigkeit des Mediums haben zur eingeschränkten Vorstellung geführt, Klang sei untouchable, lediglich die Erzeuger von Klang sind berührbar, sie werden über Berührung zum Schwingen gebracht.
Dennoch, die Vorstellung von Klang ist klar an begreifbare Dynamik, an die Welt des Mechanistischen gebunden – selbst dort, wo Digitalität die Erzeugung von Klang von mechanischen Prozessen befreit hat.
Das Zusammenspiel der Abtastrate unseres informationsverarbeitenden Systems und der Frequenz von Schall lässt uns Klang nur als zeitliches Phänomen, als Reihe von psychologischen Momenten wahrnehmen, die wir nur sehend erfassen und als Augenblick bezeichnen. Damit sind auch Veränderungen des Klanges sowohl durch die Schallausbreitung in der Luft als auch durch Reflexion an begrenzenden Flächen wahrnehmbar. Die Erfahrung aus der Wahrnehmung dieser Klangmodulationen führt zu embodiments und daraus zu Denkweisen, zu embodied cognitions. So ist ein dumpfer Klang nicht nur dumpf, sondern auch mit der Wahrnehmung seiner Entfernung zum Körper verbunden, da wir erfahren haben, dass Klang während seiner Ausbreitung gedämpft wird, was zuerst die amplitudenschwächeren oberen Klanganteile betrifft. Aus diesen embodied cognitions resultiert, dass selbst nicht-spatialisierte Klänge allein ob ihrer Klangfarbe als räumlich lokalisiert auf der Medienebene wahrgenommen werden; nicht nur vor uns, wie die durch die eigene Bewegung synthetisierbare Welt des Sehens, sondern rund um uns, auch über und hinter uns – die Richtungsbänder beschreiben die Empirie entsprechender Klangmodulationen.
Empirisch zeigt sich aber auch ein Phänomen, das nicht auf Schallerfahrung beruhen kann: Hohe Töne werden oben verortet, tiefe unten, obwohl sie je indifferent im Raum erklingen. Stevens7 erfasste abseits physikalischer Bezüge die psychische Wahrnehmung von Klängen: Hohe Töne haben hohe „density“ und geringes „volume“, tiefe Töne geringe

145

„density“ und hohes „volume“ in unserer Wahrnehmung. Die Übertragung des Konzeptes der Gravitation auf diese Wahrnehmungen könnte das Höhen-Erleben von Klang und seine verbale Bezeichnung als conceptual metaphor8 erklären.
Allgemein ist es „sharpness“9 korreliert mit „loudness“, die uns Klang und seine Modulation in der Tiefen- und Höhendimension als verortet oder bewegt erleben lässt. Allein auf der Horizontalebene ist Schall durch die Zweiohrigkeit exakt in 3 Prozent diskretem Abstand physisch ortbar.
Nun ist das Hören nicht nur die Analyse der physikalischen Ereignisse rund um den Körper, sondern deren Bedeutung für den Körper. Bedeutung ist dabei nur selten das Erkennen der Schallquelle, sondern der Intensität, der sharp­ness/loudness, die den Körper in Spannung versetzt, die intentional zu einer Körper-Umwelt-Interaktion führt. Für die auditive Welt bedeutet dies, dass Spannung den Oberkörper in Bewegung versetzt und damit die Lungen, deren Luftstrom die Stimmbänder in Erregung versetzt und damit einen Ausdruckslaut erzeugt, beziehungsweise den Körper bewegt, dessen Instrumentarisierung zu Klang führen kann. Vor allem das Tempo und die Form der Bewegung sind mit der Gefühlsdimension „activity“ korreliert. Darin sehen die Anthropologie wie die evolutionäre Psychologie den Ursprung von Musik.
Als bewusste Nutzung dieses signalhaft natürlichen Prozesses gilt die sound-gesture. Cheironomie diente vor der Aufzeichnung des flüchtigen Klanges seiner körperlichen Vermittlung, wobei die Imagination des Klanges als räumliche Bewegung, seine embodiments, nachgezeichnet wurde. Ihre Abbildung und Reduktion auf die zweidimensionale Ebene könnte systematisch als Ursprung der Neumen betrachtet werden, das gridding in time und frequency führte diese geometrische Form über in arithmetische Codes. Mit diesem Mediatisierungsprozess der Wahrnehmung von Klang tritt ein turn vom performativ sonischen Erleben zum visuellen Denken ein,10 der sich in der Musiktheorie als Gegenüberstellung basaler Definitionen von Musik als „beziehendes Denken“11 oder als „Spannung – Lösung“ im Ursatz12 äußert – eine kulturelle Entwicklung, die mit der evolutionären Entwicklung des „zurecht-Denkens“ emotionaler Betroffenheit als Bewältigungs- wie Erkenntnisstrategie13 zusammengedacht werden kann.
Galt dieses dynamische In-Beziehung-Setzen dem Bezeichnen von Augenblicken als nachgeordnet, so haben Maschinisierung und Digitalisierung zu einer Dynamisierung und Codierung unserer Lebenswelten geführt, diese zu einer auditiven Lebenswelt gemacht, in der exploratives Verhalten

nicht von instrumentellem Handeln, sondern von hedonischen Qualitäten geleitet, Erlebniswelten gestaltet. Bereits McLuhan14 nannte den electronic space einen auditory space, in dem der Mensch sich nicht zur Information, sondern diese sich zu ihm bewegt. Damit weicht die Logik des synthetisierenden Sehens dem Fühlen des analysierenden Hörens. Wir argumentieren nicht rational unsere konstruierenden Wahrnehmungen in der all-at-once-ness der dynamischen Datenwelten, wir kommentieren sie emotional.
Die von Materialität gelöste15 immaterielle Virtualität dynamischer Digitalität entzieht sich per definitionem dem mechanischen Körper; nicht aber der Körper werde unnütz,16 sondern der mechanische Körper – die Ordnung des Erlebens geschieht nach homöostatischen Bedingungen der dynamischen Körper-Umwelt-Interaktion. Damit wird die Dominanz des Sehens von Dingen zu einer Welt des Hörens ihres Verhaltens, dessen Erregungswert die Bedeutung für den Körper und damit dessen Interaktion mit der Umwelt und ihre Gestaltung bestimmt – die Welt wird zu einer musikalisierten Welt, in der die Erfahrungen des Hörens formalisiert sind.
Die Aussage „Wir hören im Haus die Tür schlagen und hören niemals akustische Empfindungen“17 überträgt die Welt des Sehens von Dingen und deren Bezeichnungen auf die Welt des Hörens von erregenden Ereignissen. Empirische Studien zeigen anderes: Wir nehmen lediglich wenige Klänge als Index konkreter Bewegungen wahr, wir nehmen sie allgemein als räumliche Bewegungen und deren Erregung für den Körper wahr.
Uns bekannte Klänge werden ikonisch im sonischen „Mimicking“ kommuniziert, abstrakte Klänge werden in Form intentionaler körperspannungsgesteuerter sound-gesture kommuniziert.
Dynamisierung und Digitalisierung der Umwelt haben zur Transgression des Mechanistischen und zur Kultur des Hedonischen geführt (eingebettet in eine neoliberale Kultur des Postulates von Hedonismus, schließlich seiner gewinnbringenden rational perfektionierenden Erarbeitung18). Homöostatisch regelt der Körper seine Interaktionen mit der Umwelt, um ein überlebensnotwendiges optimales Erregungsniveau zu erzeugen. Hedonismus ist Gestaltungskraft in einem Kommunikationssystem nicht von Symbolen, sondern Stimulantien. Nicht der rationale Ursatz vermittelt gestaltend Inhalte, sondern die Relation von Spannung-Lösung stimuliert gestaltendes Verhalten. Sound-gesture ist nicht nur die Basis von Musik, sound-gesture wird in der körpernah hedonischen Ausdrucksform, als Artefakt der

146

physiologischen Spannung des Körpers durch die „affordance“ der Umweltreize, und Kommunikationsform, der „emotional contagion“19 zuerst durch die Verhaltensnachahmung und danach durch die Internalisierung der Erregung als Basis des Ausdrucks, zum Paradigma intuitiver Interfaces kommunikativer Gestaltung20 in einer hedonischen als musikalisierten post-digital Körperkultur abseits der verbalen symbolischen Inhaltsvermittlung.
Es ist dies ein forward back von einer rationalen Informationskultur zu einer hedonischen Kommunikationskultur, in der der Erlebnischarakter interaktionistisches Verhalten als körperliches bestimmt. Bereits seit Morris werden in der Semiologie stimulative Qualitäten der Bedeutungsvermittlung beschrieben, die in moderner Bewertung “more primitive than the symbol” sind, wobei “certain aspects of the object”21 sind “linked with the immediate action”22 und “trigger[s] some reaction on the part of the receiver.”23 Das Signal ist “a physical phenomenon which provokes reactions in […] organisms, without being the cause of these reactions.”24 Das Signal kann als Teil des Zusammenspiels der „affordance“ eines Umweltreizes mit der Intentionalität der Körper-Umwelt-Interaktion25 angenommen werden. Der linguistische turn hat Signale nicht achtend „übersehen“, die hedonische Kultur immaterieller Virtualitäten rückt diese basalen vorsprachlichen Qualitäten ins Zentrum, Musik sei aus diesem Ausdrucksverhalten hervorgegangen und daher mediales Paradigma der Gestaltung immaterieller Virtualitäten. Auch in Musik hat jener turn zu Annahmen der logischen Beziehungen von Codes für Klänge geführt aber auch Zweifel argumentiert. In „Feeling and Form“ bezeichnet Langer26 Musik nicht als re-, sondern als presentative sign emotionaler Expression.
Als Teil explorativen Verhaltens ist ästhetisches und soziales Verhalten erregungsbestimmt, Musik formalisiert musizierendes als sonisch performatives erregungsbasiert analysierendes Verhalten. Abseits „beziehenden Denkens“ gilt Gestaltung aus Erregung, aus „Spannung und Lösung“, als Ursatz der Musik27; kommunikatives Verhalten wurde Musik stets zugesprochen, Polyphonie sei die Objektivation des Wir28. Non-verbale als hedonisch gestische Kommunikation ist wesentlich durch Erregung bestimmt; die sound-gesture verbindet den Nachvollzug des imaginierten physischen Verhaltens der Umwelt mit der Kommunikation ihrer Bedeutung für den Körper als signalhaft emotional ansteckende soziale, als sonisch performative Interaktion. Als vorsprachliche Kommunikationsform geht die „körperliche“

1  Werner Jauk erzeugt mit einer ikonischen Geste des Berührens von Blättern den indexikalischen Klang des Rauschens bewegter Blätter
Bedeutung des Bezeichneten konnotierend in die Prosodie von Sprache ein.
Medienkunst versucht aus Erkenntnisinteresse, Implikationen der Mediatisierung der Interaktion des Körpers auf diesen und die Gestaltung der Umwelt explorierend erfahrbar zu machen. Sie hat den Begriff Interaktion lange am mechanistischen Verständnis festgemacht und in kybernetischem Denken Gestaltung erprobt, das Verständnis der Sozial-/Gruppenpsychologie29 ist vom Ingenieursdenken der MedienkünstlerInnen ignoriert worden. In Fortführung der Kommunikationskünste erscheint dieses später in der Definition von net-arts als kollektives und kollektivierendes Gestalten30 wie ein Zitat aus der Gruppenpsychologie „neu“; intuitive Interaktion in der Interfaceforschung wird damit von der mechanischen zur psychologischen Situation: Nonverbale Bewegung zuerst instrumentellen Tuns im touch wird zur Intentionalität dieses Tuns, seiner erregungsgesteuerten Art und Weise.

147

In einer Welt der Entkörperlichung wurde mechanisches Verhalten ersetzt durch robotics, der hedonische Körper und sein Streben nach optimal evaluativer Erregtheit bleiben und werden in die Interaktion mit einer sich dadurch gestaltenden virtuellen Umwelt integriert. Es sind die digitalen interaktiv partizipativen Künste in virtuellen Welten, die zunehmend in der hedonischen Gestaltung der Musik ihr Vorbild sehen. Aber auch ihrerseits muss sich digitale Musik von der instrumentellen Handlung der mechanischen Klangerzeugung nach der Dominanz einer in Codes vorgeschriebenen Klangfigur und ihrer klanglichen Re-Produktion befreien und der hedonischen Gestaltung des Klanges aus Daten zuwenden.
Befreit von mechanischem Tun, jedoch basiert auf embodied cognitions, auf Denkweisen aus körperlichen Erfahrungen der physischen Interaktion mit materieller Umwelt, ist es die sound-gesture, die als intuitiv hedonische Interaktionsform (das verbale Symbol, das ikonische Bild unterschreitend) zum gestaltenden Paradigma immaterieller Umwelten wird.
Galt Sprache der Medienkunst als Paradigma, wie im Märchen verbal vermittelte vorstellbare Handlungen zu einer materiell nicht vorstellbaren aber medial „machbaren“ Welt verschmelzen, bestimmte das Bild die Vorstellung von Virtualität als willentliche Gestaltung, die sich vom Abbild der Natur abhebt, so ist nun Musik Paradigma dynamisierter Virtualitäten als die Formalisierung der hedonischen Interaktion über sound-gestures; Musik, die als dynamische und codierte Existenz im „Werk“ als Gefüge von „Stimmen“, stets als mediale Erscheinung existent war.
Die Ausdrucksbewegung der basalen hedonischen Interaktion wurde vor den Medienkünsten von Arnulf Rainer in seinen Körper-Übermalungen genutzt. Das Malen aus der körperlichen Geste der Erregung entspricht musizierendem Verhalten. Ausdrucksbewegung wird zunehmend von der Medienindustrie zur I(ch)-Konnotierung von intuitiven devices „gelebt“ und dringt so über Sensibilisierung kritisch31 in eine plural individualisierte Kultur der Diversität, eine hedonische Erlebniskultur, eine sonisch performative Pop-Kultur. Hedonisch intuitives Handeln aus den (Medien-)Künsten dringt in den Alltag des pragmatischen „Kunst leben[s]“32 von every body, während symbolische Interaktion auf Wissen basiert und distinguierend wirkt. Es sind nicht die instrumentellen Handlungen, es ist nicht der Informationsgehalt der verbalen Anweisung, es ist nicht das begreifbare 3-D-Bild, das die digitale Welt von jener der

materiellen entfernt – ihre digitalen Formungen sind letzte (moderne) Annäherungen an deren willentliche Gestaltung.
Die Entkörperlichung durch die Transgression des Mechanistischen findet in der hedonischen Körperlichkeit eine Alternative. Forward back ist diese post-digital culture eine Kultur des Hörens, der Analyse von Ereignissen rund um den Körper nach deren Erregungswert und damit Bedeutung für den Körper – embodiments des mechanischen Körpers sind überschritten, nicht das Synthetisieren von Virtualitäten nach dem Vor-Bild der mechanisch körperlichen Erfahrung und ihrer willentlichen Konstruktionen, sondern das Auswählen von Datenströmen nach hedonischen Bewegtheiten bestimmt das körperliche Leben in Virtualitäten.
Sonische Medienkunst, an der Mediatisierung des körperlichen Hörens orientiert, wird damit nicht nur Lebensparadigma in Virtualitäten, sondern auch Paradigma der Erforschung solcher Wirklichkeiten. Es sind nicht solche, den Körper auf seine mechanischen Interaktionen mit der Umwelt reduzierende und daraus abgeleitete symbolische als „rationale“ Medientechnologien, sondern körpernahe Ex-Tensionen, welche die intentionalen Aspekte der Körper-Umwelt-Interaktion als Basis von Leben erachten. Wie Leben basieren Ästhetik und Empirie auf explorativem Verhalten, das durch Erregung homöostatisch reguliert wird. Konzepte von Wahrnehmung in Kunst33 und Wissenschaft als Erregung optimierendes Zuwendungsverhalten und „Enactivism“ stellen vor das „Was“ das „Wie“ und machen damit auditive Wahrnehmung, die sound-gesture als erregungsbasierte körperliche Ver-Handlungsform, zum Paradigma der Gestaltung einer hedonischen Alltagskultur und ihrer Erforschung.
Anmerkungen 1 Jauk, Werner: The transgression of the mechanistic paradigm
– Music and the New Arts. Dialogue and Universalism 8–9 (2003), S. 179–186. 2 Jauk, Werner: pop/music+medien/kunst. Der musikalisierte Alltag der digital culture. Osnabrück 2009 (Osnabrücker Beiträge zur Systematischen Musikwissenschaft. 15). 3 Gibson, James J.: Wahrnehmung und Umwelt. München 1982. 4 Maturana Humberto; Varela, F. Francisco: The Tree of Knowledge. The Biological Roots of Human Understanding. Boston 1987.

148

5 Lévy, Pierre: Die Metapher des Hypertextes [1990]. In: Pias, Claus u. a. (Hg.): Kursbuch Medienkultur. Die maßgeblichen Theorien von Brecht bis Baudrillard. Stuttgart 2000, S. 525–528.
6 Gibson, James J.: Wahrnehmung und Umwelt. München 1982. 7 Stevens, Stanley Smith u. a.: Loudness, a product of volume
times density. In: Journal of Experimental Psychology 69 (1965), S. 503–510. 8 Lakoff, George; Johnson, Mark: Metaphors We Live By [1980]. London 2003. 9 Bismarck, G.: Sharpness as an attribute of the timbre of steady sounds. In: Acustica 30 (1974), S. 160–172. 10 Jauk, Werner: Beyond semiotics? Music – a phenomenon of mediatization: The extension of the hedonistic body and its communicative aspects. In: Davidovi, Dalibor; Bezi, Nada (Hg.): New Unknown Music. Essays in Honour of Nikša Gligo, Zagreb 2013, S. 407–421. 11 Riemann, Hugo: Ideen zu einer ‚Lehre von den Tonvorstellungen‘. In: Jahrbuch der Musikbibliothek Peters 21/22 (1914/15), S. 1–26. 12 Schenker, Heinrich: Der freie Satz. Wien 1935. 13 Maturana Humberto; Varela, F. Francisco: The Tree of Knowledge. The Biological Roots of Human Understanding. Boston 1987. 14 McLuhan, Marshall u. a.: The Global Village: Der Weg der Mediengesellschaft ins 21. Jahrhundert. Paderborn 1995. 15 Lyotard, Jean-François: Postmoderne für Kinder. Wien 1987. 16 Baudrillard, Jean: Simulacres et simulation. Paris 1981. 17 Heidegger, Martin: Holzwege. Frankfurt a. M. 2003 (Gesamtausgabe. Bd. 5), S. 10. 18 Pfaller, Robert: Wofür es sich zu leben lohnt. Elemente materialistischer Philosophie. Frankfurt a. M. 2011. 19 Hatfield, Elaine et al.: Emotional Contagion. Cambridge 1994. 20 Jauk, Werner: Intuitive gestural interfaces/adaptive environments and mobile devices/apps. Playing music and the musical work as a role model for personalized gestural interaction in social environments. In: ICMWT, Beijing 2014, S. 280–284. 21 Piaget, Jean: Play, Dreams, and Imitation in Childhood. New York 1962, S. 278. 22 Piaget, Jean: Play, Dreams and Imitation in Childhood. New York 1946, S. 19. 23 Sebeok, Thomas: Contributions to the Doctrine of Signs. Laham 1985. 24 Pazukhin, Roscislaw: The concept of signal. In: Lingua Posnaniensis 16 (1972), S. 41. 25 Gibson, James J.: Wahrnehmung und Umwelt. München 1982.

26 Langer, Susanne K.: Feeling and Form. A Theory of Art Developed from Philosophy in a New Key. London 1953.
27 Schenker, Heinrich: Der freie Satz. Wien 1935. 28 Adorno, Theodor W.: Philosophie der neuen Musik. Frankfurt
a. M. 1958, S. 23. 29 Bales, Robert F.: Interaction Process Analysis. Cambridge 1950. 30 Kerckhove, Derrick de: Kunst im World Wide Web. In: Leo-
poldseder, Hannes; Schöpf, Christine (Hg.): Prix Ars Electronica 95. Linz 1995, S. 37. 31 Gill, Rosalind: Empowerment/sexism: Figuring femal sexual agency in contemporary advertising. In: Feminism & Psychology 18 (2008), S. 35–60. 32 Shusterman, Richard: Kunst Leben. Die Ästhetik des Pragmatismus. Frankfurt a. M. 1994. 33 Berlyne, Daniel E.: Aesthetics and Psychobiology. New York 1971.
Abbildungsnachweis 1 Foto: Jana Bressem.

149

1  Anette Rose: Enzyklopädie der Handhabungen. Modul #25 flechten, wirken, weben – motion capturing. Dreikanalvideo, 3 × 2’25”, HD, mit Ton, Loop, 2016

150

151

Anette Rose:
Captured Motion Bewegungsnotationen im Raum
Ines Lindner

Wenn man den abgedunkelten Kubus in der Ausstellung betritt, sieht man sich von magisch leuchtenden Liniengeflechten umgeben. Lichtpunkte und blaue Linien bewegen sich auf zwei Wänden übereck und über den Boden. Eine Stimme ist zu hören, die die Funktionsweise von Maschinen beschreibt. Es ist die Stimme eines Ingenieurs, dessen redebegleitenden Gesten in einem Motion Capture Lab aufgezeichnet wurden.1 Dazu wurde er mit Markern versehen, die von mehreren Infrarotkameras erfasst wurden. Die blauen Linien gehen auf die Markierungen an den Händen zurück, während die orangen Lichtpunkte die jeweilige Position von Kopf, Schultern und Armen wiedergeben.
Das Ausgangsmaterial für die Rauminstallation der Künstlerin geht also auf eine Laborsituation zurück. Während Wissenschaftler sich für die Qualität der dort erhobenen Daten interessieren, beschäftigt sich Anette Rose mit den unterschiedlichen Formen der Visualisierung. Seit Jahren steht die Beobachtung von Arbeits- und Ausdrucks­ gesten im Zentrum ihrer Arbeit. Sie befasst sich mit den hoch differenzierten Bewegungen der Hand sowohl im Umgang mit Werkzeug und Maschinen als auch mit Ausdrucksgesten. Wenn wir etwas erläutern oder erzählen, setzen wir oft zur Verdeutlichung oder Untermalung unsere Hände ein. Anette Rose hat bereits in frühen Arbeiten den

Blick auf die meist unbewussten Gesten gelenkt. Um die eigenen Beobachtungen zu vertiefen, hat sie den Kontakt zu GestenforscherInnen gesucht und mehrfach mit ihnen zusammengearbeitet. Vom Exzellenzcluster der RWTH Aachen wurde sie als Artist in Residence eingeladen, um in verschiedenen Forschungslaboren zu filmen. Bei den Maschinen, die der Ingenieur im Motion Capture Lab der Universität Aachen beschreibt, handelt es sich um verschiedene Textilmaschinen, die Anette Rose für den Werkzyklus „Captured Motion“ gefilmt hat.2 Dieser Zyklus ist der neueste Teil ihrer umfangreichen „Enzyklopädie der Handhabungen“, an der die Künstlerin seit 2006 arbeitet.
Rose filmt dafür in Betrieben unterschiedlicher Art. Sie interessiert sich sowohl für Produktionsprozesse, in denen es eine Interaktion zwischen Hand und Maschine gibt, wie für vollautomatische Herstellungsverfahren. Bevor sie zu filmen beginnt, setzt sie sich intensiv mit Menschen und Maschinen auseinander, die in den Arbeitsablauf involviert sind. Dann entscheidet sie über die Einstellungen der Kamera und die Kadrierung. Sie filmt den Bewegungsablauf stets aus mehreren Perspektiven. Die Projektionen der unterschiedlich kadrierten Einstellungen werden im Raum konfiguriert. In der Installation setzt die Künstlerin die unterschiedlichen Perspektiven so zusammen, dass sich ein visuelles Span-

152

2  Anette Rose: Enzyklopädie der Handhabungen. Modul # 15 verputzen, beischleifen, stanzen, stempeln, ketteln, einziehen, tauchen, ringen, walzen, eindrehen, schleifen. Zweikanalvideo, 2 × 13‘14“, DVCAM, mit Ton, Loop, 2008/2013; Modul #4 entgraten, schleifen, verputzen – automatisiert. Einkanalvideo, 1‘15“, DVCAM, mit Ton, Loop, 2006/2013

nungsverhältnis zwischen den Projektionen ergibt. Für den Betrachter entscheidend ist, dass er sich sowohl der einzelnen Aufnahmesequenz zuwenden kann als auch dem synchronen Zusammenspiel der unterschiedlichen Ansichten.
In Modul #15 der „Enzyklopädie der Handhabungen“ kombiniert Anette Rose zwei separat gefilmte Beobachtungen von Gesicht und Händen von Menschen bei der Arbeit.3 In einer Projektion sieht man den konzentrierten Blick einer Arbeiterin in einer Porzellanmanufaktur und in einer zweiten ihre Hände, die die Wände einer Schüssel glätten. Die übereck gestellten, großen Projektionen erlauben eine Konzentration des Blicks auf das Zusammenspiel von Hand und Auge.
Der Anthropologe André Leroi-Gourhan (1913–2005) sah in diesem Zusammenspiel eine entscheidende Voraussetzung für die menschliche Entwicklung. Eine differenzierte Hand-Auge-Koordination ist die Voraussetzung für den effizienten Einsatz von Werkzeug und die Grundlage für die Entwicklung kognitiver Fähigkeiten. In der In­ stallation fügt Rose zu der Beobachtung von Gesicht und Händen der Porzellanarbeiterin die Aufnahme eines vollautomatischen Tellerroboters hinzu.4 In der Kombination mit dem manuellen Werkprozess wird der Blick auf den Greifarm der Maschine gelenkt, der zwar keinerlei Ähn-

lichkeit mit der Hand hat, jedoch darauf ausgelegt ist, ihre Greif- und Verputzbewegungen nachzuahmen.
Anette Rose hängt nicht an alten Handwerkspraktiken. Ihre Arbeit vermisst Abstände zwischen den unterschiedlichen Produktionsformen. Sie beobachtet die Übergänge von manuellen Arbeitsgesten zur automatisierten Produktion. Der Fokus liegt neuerdings dabei auf der Textilproduktion. Die maschinelle Herstellung von Stoffen reicht bis zum Beginn der Industrialisierung zurück. Der Jacquard-Webstuhl mit seinem Lochkartensystem war am Beginn des 19. Jahrhunderts Hochtechnologie. Heute werden Hightechmaschinen für technische Textilien entwickelt, die als Leichtbauteile für Autos, Flugzeuge und die Raumfahrt eingesetzt werden. Der Radialflechter und die Multiaxialkettenwirkmaschine, deren Funktionsweise der Ingenieur beschreibt, produzieren vollautomatisch solche industriellen Gewebe und Geflechte.
Die Flechtmaschine stand 2016 im Mittelpunkt der Ausstellung „Captured Motion“ im Edith-Russ-Haus in Oldenburg. In einem gewaltigen Rad drehen sich gegenläufig rote und gelbe Spulen, über die Fäden laufen, die sich um ein zentrales Rohr flechten. Die Videoprojektionen der Rauminstallation zeigen das Rad mit den Spulen und ihm gegenüber die Achse, um die herum das Geflecht entsteht.5

153

3  Anette Rose: Enzyklopädie der Handhabungen. Modul # 20.1 – 20.2 flechten – automatisiert. Zweikanalvideo, 0’49”, 3‘45“, HD, mit Ton, Loop, 2016
4  Modul # 22 flechten – Maibaumtanz, Archivfoto, 1920
154

Obwohl das Verfahren hochmodern ist, kann der Betrachter ohne weiteres erkennen, dass die Verflechtung auf alten textilen Praktiken beruht. Die Künstlerin unterstreicht die historisch anthropologische Dimension, indem sie eine Fotografie von einem Maibaumtanz von 1920 als Diaprojektion in die Installation einbezieht. Wie die Spulen drehen sich Männer und Frauen dabei gegeneinander und verflechten die mit einem Ende am Maibaum befestigten Bänder.
Die Übereinstimmung zwischen dem Tanz und dem maschinellen Ablauf ist verblüffend: Ein großes Diagramm auf dem Boden zeigt die Bewegungsbahn der Spulen und beschreibt zugleich die Choreographie des Tanzes (vgl. Abbildung 3).
Neben den zwei großen Videoprojektionen des Radialflechters ist eine Highspeed-Aufnahme der Spulen im Close-up zu sehen. Das Aufzeichnungsverfahren, mit dem die Künstlerin ihr Formvokabular der Bewegungsnotation erweitert, dehnt und verlangsamt die Bewegung der Spulen. Die Hochgeschwindigkeitsaufnahmen machen Abweichungen im Ablauf sichtbar, die mit bloßem Auge nicht wahrzunehmen sind. Die Schwarz-Weiß-Sequenz besticht durch die metallische, skulpturale Form der Spulen vor dem dunklen Hintergrund.6

5  Anette Rose: Enzyklopädie der Handhabungen. Modul # 23 stricken – high speed, Modul #26 flechten – high speed. Einkanalvideos, 6‘12“, 4‘37“, HD, ohne Ton, s/w, Loop, 2016

Die Installation „Captured Motion“ zeigt den Produktionsprozess aus unterschiedlichen Perspektiven und in verschiedenen medialen Übersetzungen. Indem Rose Diagramm, Fotografie, Video und Highspeed-Aufnahmen im Raum konfiguriert, öffnet sie durch diese Vielschichtigkeit visuell einen Erkenntnisraum, der zugleich ein Erfahrungsraum ist. Der Betrachter steht im Getöse der Maschine zwischen den Projektionen und Bildern. Ihre Schönheit ist verblüffend und der Rhythmus des Maschinentakts entfaltet Sogwirkung.
Die Dreikanalinstallation, in der die Gestenspuren des Ingenieurs aus drei Perspektiven zurück in den Raum gezeichnet werden, fügt der visuellen Verdichtung eine weitere Ebene hinzu. Mit der Übersetzung seiner redebegleitenden Gesten in Leuchtspuren referiert die Künstlerin auf die Geschichte visueller Bewegungsstudien und ihre Verwendung in den Arbeitswissenschaften. Bereits am Ende des 19. Jahrhunderts versuchten Eadweard Muybridge (1830–1904) in den USA und Étienne-Jules Marey in Frankreich mit Fotokameras Bewegungsverläufe festzuhalten. Wir können die Bewegung eines Läufers oder eines Pferds zwar sehen, aber sie sind zu schnell, als dass wir uns Rechenschaft über jede Phase der Bewegung geben könnten. Der Einsatz von Medien macht es möglich, das Unsichtbare sichtbar zu machen.

Diese Möglichkeit hat die Künstlerin in ihrem Werk von Anfang an fasziniert. Mit ihrem Medium Video kann sie durch die Wahl von Einstellung und Kadrierung den Blick auf das konzentrieren, was unserer Wahrnehmung entgeht. Im Fall redebegleitender Gesten ist das so interessant, weil weder der Ausführende noch sein Gegenüber sich der Gesten im eigentlichen Sinne bewusst ist. In einer frühen Arbeit hat Rose dafür bereits einen eigenen Visualisierungsmodus entwickelt. In „16 Traumstücke“ von 2001 erzählen sechzehn Frauen ausgefallene Träume, die für sie eine besondere Bedeutung behalten haben.7 Mimik und Gestik zeigen, wie schwierig es ist, das nichtlineare Traumgeschehnen in nachvollziehbare Sätze einer Beschreibung zu übersetzen. Drei Kamerapositionen wurden so gewählt, dass Gesicht und Hände im Ausschnitt zu sehen sind. Durch Begrenzung und Fokussierung herausgestellt, können wir sie bewusst wahrnehmen.
Für die Gestenforschung ist diese Wahrnehmung zentral. Hier überschneiden sich die Interessen der Künstlerin mit denen der WissenschaftlerInnen. Auch sie müssen sich mit Fragen der Darstellung befassen und Modelle der Visualisierung entwickeln. Mit diesen Visualisierungspraktiken hat sich die Künstlerin bei der Erschließung ihrer Themen

155

6  Anette Rose: Enzyklopädie der Handhabungen. 2006–2010. Bildmontage, Seite 96–97, 34 × 24 cm

immer wieder intensiv beschäftigt. Das zeigt ihr Künstlerbuch „Enzyklopädie der Handhabungen. 2006–2010“8. Ein wesentlicher Teil des Buches besteht aus Bildmontagen. Im Bildindex finden sich nicht allein Angaben zur Quelle, sondern auch Zitate, die den Kontext der einzelnen Bilder verdeutlichen. Für die Entwicklung ihrer Herangehensweise wie auch für die Aufzeichnungspraxis im Motion Capture Lab besitzt die Arbeit von Frank Bunker Gilbreth (1868–1924) und seiner Frau Lillian Evelyn Moller Gilbreth (1878–1972) historisch entscheidende Bedeutung. Während Mareys und Muybridges Fotografien allenfalls plane Seitenansichten vor quadrierten Hintergrund geben konnten, benutzten die Gilbreths stereoskopisch filmende Kameras für die Bewegungsaufzeichnung. Der Zugewinn ist, dass bereits mit dieser Methode jeder Raumpunkt der Bewegung vermessen werden kann. Der Ansatz der Gilbreths ist arbeitswissenschaftlich. Ihr Ziel war es, die Erfassung von Arbeitsgesten zu verbessern, um Vorschläge zu ihrer Optimierung machen zu können. Dafür entwickelten sie immer wieder neue Methoden der visuellen Repräsentation.
Anette Rose fasziniert neben den arbeitshistorischen Zusammenhängen, wie über visuelle Formen neue Erkenntnisse generiert werden können. Das ist, was ihre Recher-

chen leitet und die Zusammenarbeit mit Wissenschaftlern für sie interessant macht.
Aus den unzähligen Perspektiven auf den Ingenieur, der den Radialflechter erklärt, hat Anette Rose drei ausgewählt. Durch die drei Projektionen auf Wand und Boden entfaltet sie die synchronen Notationen räumlich und lenkt den Blick auf den Unterschied der erfassten Bewegungsrichtungen (vgl. Abbildung 1). Die frontale Ansicht zeigt die Körpermarkierungen als Pyramide aus fünf Punkten. Die Bewegungslinien der Gesten schwingen hauptsächlich horizontal. Bei der seitlichen Ansicht derselben Bewegung verschieben sich die Körperpunkte zu einer unregelmäßigen Reihe. Die blauen Lichtbahnen markieren die Bewegungen der Hände, wie sie sich in die Tiefe des Raums entfalten. Die Bodenprojektion gibt die Körperpunkte von oben und zeigt das Ausgreifen der Bewegung in Aufsicht. Wie in anderen Arbeiten Anette Roses ist die Isolierung der einzelnen Bewegungssequenzen und ihre räumliche Konfiguration eine analytische und ästhetische Entscheidung zugleich. Die Synchronizität sorgt für die Einheit der einzelnen Projektionen im Raum. Darin unterscheidet sich Roses künstlerische Arbeit von Filmen, in denen Ansichten immer nur nacheinander gezeigt werden können. Die Form der In­stallation erlaubt die

156

Gleichzeitigkeit zeitlicher Abläufe und ihre räumliche Erfassung. Dies ist im Fall der Dreikanalarbeit mit den Aufnahmen aus dem Motion Capture Lab umso schlüssiger, als es um die räumliche Aufschlüsselung im Bewegungsverlauf der Gesten geht.9
Entscheidend für Roses Arbeit ist, dass sie aus der Fülle des Materials auswählt und reduziert. Die Luzidität ihrer Arbeit besteht in einem Formbewusstsein, dass sich nicht wie bei den Minimalisten auf die reine Form beschränkt.10 Der konzeptuelle Ansatz versteht sich auch immer als intellektuelle Durchdringung der Prozesse, mit denen sie sich auseinandersetzt, bevor sie über Auswahl, Position und Einstellung entscheidet. Dieser Prozess setzt sich bei der Bearbeitung des Materials fort. Ziel der Reduktion ist es, eine visuelle Evidenz zu erzeugen, die eine ästhetische Präsenz erzeugt und zugleich dem Erkenntniszusammenhang entspricht.
Anmerkungen 1 Die Aufnahmen entstanden in Kooperation mit Frau Prof.
Dr. Irene Mittelberg, Natural Media Lab, HumTec Centre, RWTH Aachen. 2 Es handelt sich um einen Radialflechter, eine Multiaxialkettenwirkmaschine und eine Greifernadelwebmaschine. 3 Es sind bisher 29 Module, in die sich die „Enzyklopädie der Handhabungen“ von Anette Rose gliedert. Rose, Anette: Enzyklopädie der Handhabungen. 2006–2010, Bielefeld 2011, Modul #15 verputzen, beischleifen, stanzen, stempeln, ketteln, einziehen, tauchen, ringen, walzen, eindrehen, schleifen. 4 Ebd., Modul #4 entgraten, schleifen, verputzen – automatisiert. 5 Ebd., Modul #20.1 – 20.2 flechten – automatisiert. 6 Ebd., Modul #26 flechten – high speed. 7 Rose, Anette: 16 Traumstücke. Video, 51 Min., 16:9, Digi­beta, mit Ton. ZDF – Das kleine Fernsehspiel. 2001. 8 Rose (wie Anm. 4). 9 Ebd., Modul #25 flechten, wirken, weben – motion capturing. 10 Vgl. Lindner, Ines: Minimalism reloaded. Zur Typologie sozialer Tatsachen in Anette Roses „Enzyklopädie der Handhabungen“. In: Rose (wie Anm. 3), S. 6–13.

Abbildungsnachweis 1 Installationsansicht, CAPTURED MOTION, Edith-Russ-Haus
für Medienkunst, Oldenburg 2016; Foto: Anette Rose © VG BildKunst, Bonn. 2 Installationsansicht, Bauhaus-Archiv Berlin 2013; Foto: Thomas Bruns. 3 Installationsansicht, CAPTURED MOTION, Edith-Russ-Haus für Medienkunst, Oldenburg 2016; Foto: Mathis Oesterlen. 4 Oregon State University Special Collections & Archives. Archivfoto, 1920, Corvallis/OR. 5 Installationsansicht, CAPTURED MOTION, Edith-Russ-Haus für Medienkunst, Oldenburg 2016; Foto: Anette Rose © VG BildKunst, Bonn. 6 Kerber Verlag, 2011; Foto: Anette Rose © VG Bild-Kunst, Bonn.
Das Projekt „Captured Motion“ wurde vom Exzellenzcluster „Integrative Produktionstechnik für Hochlohnländer“ der RWTH Aachen gefördert. Die Fertigstellung und Ausstellung in Berlin (Haus am Lützowplatz) und Oldenburg (Edith-Russ-Haus für Medienkunst) 2016 wurde durch ein Stipendium der Stiftung Niedersachsen ermöglicht.
Filmteam der „Enzyklopädie der Handhabungen“: Konzept, Kamera, Montage: Anette Rose | Kamera, Licht: Alexander Gheorghiu, István Imreh | High Speed Kamera: Dipl.-Ing. Achim Hehl, Dipl.-Ing. Viktor Reimer | Ton: Gerrit Lucas, Johannes Schmelzer-Ziringer, Andreas Turnwald, Johannes Varga, Arno Wilms | Schnittberatung: Sala Deinema, Christoph Krüger | Motion Capture Technik: Bela Brenger, Marlon Meuters.
Gefilmt im Institut für Textiltechnik der RWTH Aachen, Motion Capture Laboratory of Gesture Studies (Natural Media Lab, HumTec Centre) der RWTH Aachen.
Besonderer Dank an: Prof. Dr. Irene Mittelberg (Natural Media Lab, HumTec Centre), Adjunct Prof. (Clemson University) Dr.-Ing. Yves-Simon Gloy und Dipl.-Ing. Florian Neumann (Institut für Textiltechnik), Dipl.-Szen. Hannah Groninger und Univ.-Prof. Dipl.-Ing. Thomas H. Schmitz (Lehrstuhl für Bildnerische Gestaltung) der RWTH Aachen.

157

Von Erinnerungen zu Objekten:
Motion-CaptureSkulpturen gestischer Raumbeschreibungen
Hannah Groninger und Irene Mittelberg

„Der Akt der Imagination ist […] ein magischer Akt. Es ist eine Beschwörung, dazu bestimmt, das Objekt, an das man denkt, die Sache, die man begehrt, derart erscheinen zu lassen, dass man sie in Besitz nehmen kann.“ 1
Thematische Annäherung
Im Zuge technologischer Entwicklungen stellt der Mensch, selbst Künstlerinnen und Künstler, Handwerkerinnen und Handwerker, Architektinnen und Architekten, immer weniger Objekte mit der Hand her. Durch hochkomplexe Aufnahme-, Herstellungs- und Produktionsverfahren ist der Homo faber heute in der Hauptsache Nutzer, Greifer und Drücker. Verändert sich damit auch der Akt der Imagination?
Die in der Ausstellung von Hannah Groninger in Zusammenarbeit mit dem Natural Media Lab (Irene Mittelberg) gezeigten Bewegungsskulpturen sind Teile einer künstlerischen Auseinandersetzung, die den Blick von der Künstlerin und dem Künstler zugeschriebenen schaffenden Hand auf die sich dynamisch im Raum bewegende „denkende Hand“ lenkt.2 Gerade wenn Objekte der Vorstellung kommuniziert, im Raum verortet und ihre Proportionen und Lagebeziehungen untereinander beschrieben werden,

kommen – synchron zum lautsprachlichen Diskurs – verstärkt körperlich-räumliche Gesten zum Einsatz. Raumkonstellationen und Zwischenräume werden, zumeist beidhändig, geformt und dargestellt. Sie können als Resultate unmittelbarer Handkonfigurationen und Bewegungen sowohl festgehalten als auch dokumentiert werden. Vor allem bei Dingen, die es noch nicht gibt, die sich also im Prozess der Entwicklung und des Entwurfes befinden, kann in Bezug auf André Leroi-Gourhan – so die These der Autorinnen – die Hand als „Schöpferin von Bildern und Symbolen“ gewissermaßen als eine „Parallele zur gesprochenen Sprache“ fungieren.3 Die Hand kann in Kontakt mit ihrer Außenwelt Objekte aus ihrem Kontext lösen, bspw. eine Tasse von A nach B stellen, sie durch ein Fallenlassen zerbrechen lassen, oder eine Tasse aus Ton modellieren und glasieren. Und sie vermag eine Tasse, virtuell, durch eine einfache Geste flüchtig in den Raum zu stellen, sie in ihren charakteristischen Struktureigenschaften ikonisch zu verkörpern, oder im Übergang von virtuellen und physischen Welten regelrecht immateriell zu entwerfen und auszugestalten.
In den praktischen Disziplinen wird der Entwurf als prozessualer Übergang von der Vorstellung zur Visualisierung bis hin zur Verkörperung und Modellierung seiner Imagination verstanden: Ein Vorgang des Entwickelns,

158

kraft dessen die zunächst vorgestellte Sache nach ihrer Herstellung letztlich tatsächlich physisch existiert und in Besitz genommen werden kann.
Die in der Ausstellung gezeigten Arbeiten reflektieren Positionen der Gestenforschung, welche visuell-räumliche Gesten als sichtbare Verkörperungen des Interagierens mit der gegenständlichen, sozialen und inneren Welt deuten. Gesten sind so gesehen wortwörtlich in den Raum geworfene ephemere Bilder und Modelle, die besonders durch ihre schematische Ikonizität analysierbar und für verschiedene Forschungsansätze interessant werden.4 Durch das händische Agieren5 während des Sprechens tritt zur gestischen Darstellungen von zuvor manipulierten Gegenständen und erlebten Ereignissen eine dynamische Weiterentwicklung von inneren Konzepten und im Entstehen befindlichen Ideen hinzu. Der Gestik kommt somit auch eine epistemische, die Erkenntnis fördernde Funktion zu: so insbesondere bei diagrammatischen Gesten, welche Relationen zwischen Dingen oder Ideen knüpfen und im Raum entstehen lassen.6 Manuelle Gesten sind demnach ein Medium7 und zugleich mediales Handeln an der Schwelle von „Innen und Außen“8 und können, bedingt durch ihre spezifische Medialität, wertvolle Einblicke in kognitive, emotionale und kreative Prozesse gewähren.9
Die hier praktizierte interdisziplinäre Zusammenarbeit an der Schnittstelle von Wissenschaft und künstlerischer Gestaltung untersucht das dynamische Zusammenspiel von Handeln und Denken, von Vor-Stellung als mentaler und als wortwörtlicher äußerer Handhabung von Gedanken – und ihren sich daraus ergebenden Figurationen und Beziehungen. Sie versteht den gestischen Vorgang als eine Art Imaginations-, Sprech-, und Bildakt.10 Um der Frage nachzugehen, ob und wie Gesten als dynamische Medien raumund objektbezogene Vorstellungen fördern und kommunizieren können, wurde eine Studie zu individuell erinnerten Räumen und Erlebnissen von Studierenden der Architektur an der RWTH Aachen durchgeführt. Die diesen Arbeiten zugrundeliegenden Fragen lauteten u. a.: Tragen Gesten unmittelbar, oder auch auf medial und kognitiv vermittelte Weise, Spuren der Erinnerung und der körperlichen Verortung im Raum in sich? Können Gesten Vorstellungen modellhaft nach außen kehren und Gedanken quasi sichtbar machen? Erscheinen Gesten für kurze Momente als Objekte im Raum? Wie sehen diese flüchtigen Objekte aus? Und inwiefern lassen sie sich materialisieren? Für die Teilnehmerinnen und Teilnehmer der Laborstudie lautete die Zielsetzung entsprechend wie folgt: „Es beginnt mit einer

Erinnerung und endet mit einem Objekt“. Die in der Ausstellung exemplarisch gezeigten Bewegungsskulpturen sind Ergebnisse dieser künstlerisch-experimentellen Untersuchung; sie wurden erst durch digitale Aufnahmetechnik und das Zusammenspiel parametrischer Generierungsverfahren mit 3D-Druckverfahren möglich. Erstere hält für einen kurzen Moment die dynamische Bewegung redebegleiteter Gesten in Form von Spuren fest, letztere verleihen ihnen – wie die agierend und gestikulierend Ideen im Raum manifestierende Hand selbst – materielle Gestalt. Ob es sich dabei um eine Materialisierung der Vorstellung oder gar nach Sartre um einen magischen Akt, um eine Besitznahme handelt, bleibt schließlich der Rezeption der Besucherinnen und Besucher der Ausstellung überlassen.
Bewegung und Denken in Bildern
Körperliche Ausdrucksformen stehen historisch betrachtet in engem Verhältnis vor allem zu den der Bildenden Kunst und Architektur nahen Disziplinen wie Theater und Tanz. Das Spiel, die Mimik, die Performanz und Ausdrucksmöglichkeiten der Hände und des gesamten Körpers wurden dort in unterschiedlichen Formen verschiedenster Kulturen erprobt, praktiziert und zur Aufführung gebracht.11 Um diesen oft flüchtigen Bewegungen dauerhaft eine Existenz und Relevanz zu verleihen, ihre Analysierbarkeit zu gewährleisten und sie gleichberechtigt zur Komposition von Musikstücken verwenden zu können, wurde im Jahr 1700 die erste systematische Tanznotationen veröffentlicht.12 Auch im zeitgenössischen Tanz werden aufwendige Aufzeichnungstechniken und methodische Vorgehensweisen verwendet, die im Kontext dieser Ausstellung und der Auseinandersetzung mit Bewegungsskulpturen nicht unerwähnt bleiben sollten: Der Tänzer und Choreograf William Forsythe hat choreografische Tools entwickelt und damit die technischen Möglichkeiten digitaler Aufzeichnungsverfahren ausgelotet. Dabei orientiert er sich an Rudolf Labans Auffassung des Tanzes als „lebendiger Architektur“.13 Es sind Versuche, ein Phänomen zu fassen, das quasi in dem Moment, in dem es entsteht, im Verschwinden begriffen ist: ein Ideenzusammenhang, ein ideales Urbild.14 Dabei interessiert ihn der tanzende Körper als ein Instrument des Denkens.15 Dem redebegleitenden Gestikulieren und dem choreografischen Ausdruck ist hier gemein, dass sie durch Körpertechniken, welche bildliche Formen und Visualisierungen von qualitativen (Raum-)Vorstellungen manuell oder unter Einsatz

159

des ganzen Körpers erzeugen, innere Bilder und emotionale Zustände gleichzeitig mental „begreifbar“ machen. „Begreifbar“ für diejenigen, die gestikulieren, aber auch für die Zuhörer bzw. Zuschauer.

Motion-Capture-Studien im Natural Media Lab der RWTH Aachen

Das Natural Media Lab der RWTH Aachen (Leitung: Prof. Irene Mittelberg) beherbergt eines der wenigen, speziell für die Gestenforschung konfigurierten, optischen Motion-Capture-Systeme, welches in mehrjähriger Zusammenarbeit mit dem Lehrstuhl für Bildnerische Gestaltung (Leitung: Prof. Thomas H. Schmitz) u. a. für die Erstellung von Bewegungsskulpturen nutzbar gemacht wurde. Infrarotkameras sowie Hochgeschwindigkeits- und Videokameras ermöglichen millimeter- und millisekundengenaue Aufnahmen von Handkonfigurationen und -pos­itionen sowie Bewegungsabläufen manueller Gesten. Durch das Isolieren ausgewählter reflektierender Marker können Trajektorien, also die Bewegungsspuren einzelner Finger und Hände, sichtbar und die so generierten Daten für die weitere Bearbeitung nutzbar gemacht werden. Unmittelbar in den Raum skizzierte, in ihrer holistischen Formgestalt normalerweise nicht erfassbare Bildfigurationen werden auf diese Weise objekthaft; sie gewinnen eine neue Materialität und können im gestalterischen Prozess durch den Einsatz zusätzlicher digitaler Technologien und Medien weiterverarbeitet und in andere Medien transformiert werden.16
Um der dreidimensionalen Topologie des Gestenraumes gerecht zu werden und den räumlichen wie temporalen Verlauf von Bewegungen für die Skulpturen aufzugreifen, waren die digitalen dreidimensionalen Bewegungserfassungsmethoden des Natural Media Labs unabdingbar. Hier soll beispielhaft die Entstehungsgeschichte einer der in der Ausstellung gezeigten Gesten­skulpturen nachgezeichnet und illustriert werden: 17 Im Motion-Capture-Labor hatte sich eine Probandin erzählend an ihren Schulweg erinnert. Ihre redebegleiteten Gesten wurden optisch erfasst, um die in den Gestenraum gezeichneten Figuren im Nachhinein als Modelle sichtbar machen zu können. Während der Sichtung des Videomaterials, insbesondere bei den lückenloseren Erinnerungsabschnitten, ließen sich bereits Gesten mit objektartigen Ansätzen erkennen, obwohl die Hände nicht bewusst etwas modellierten, sondern beschreibend agierten. Somit erwies sich diese Sequenz als ein genuines

1  Redebegleitende, beschreibende Gesten, Aufnahmevorgang im Motion Capture Labor, Videostill mit Overlay der Trajektorien
Beispiel für eine der paradigmatischen Thesen der embodiment-orientierten Gestenforschung: Gesten, als körperlich erzeugte Zeichen komplexer Raumstrukturen, Modelle und Bewegungsereignisse, stellen essentielle Eigenschaften von Objekten, zeitlichen Abläufen und Relationen, wie bspw. die Art, Richtung und Geschwindigkeit des Bewegungsablaufs, nicht nur prägnant dar, sondern befördern dabei auch aktiv den Vorgang des Erinnerns.
Die hier gezeigte Geste ist die gestalthafteste Bewegung in dieser Beschreibungssequenz (Abbildung 1, linke Hand). Die Trajektorien der gestischen Bewegungen zeigen das morgendliche Hinunterlaufen einer in der Erinnerung als endlos empfundenen Treppe. Sie entstanden, während die Probandin das Verlassen der elterlichen Wohnung im obersten Stockwerk bis hin zum Verlassen des Hauses im Erdgeschoss beschrieb. Es ist somit eine semiotische Handlung, die das Heruntersausen der Treppenstufen versinnbildlicht. Von dieser ca. neun Sekunden andauernden Sequenz wurden die Daten bereinigt, gefiltert und nach Markern sortiert. Die Liste mit den Koordinatenpunkten (CSV-Datei) wurde dann mit Hilfe eines Skriptes mittels Grashopper eingelesen. Das Grasshopper-Plugin ist ein von Designe-

160

2  3D-Druckvorgang der in Abbildung 1 aufgezeichneten Bewegung

rinnen und Designern, Architektinnen und Architekten genutzter, algorithmischer Grafikeditor, der in direkter Kombination mit den Modellierwerkzeugen des Programms Rhinoceros verwendet wird. Damit konnte die Aufzeichnung in ein 3D-Modell überführt werden, das bearbeitbar wurde, um die notwendigen Schritte zur Vorbereitung auf den 3D-Druck vorzunehmen. Alle offenen Geometrien und Flächen des Modells mussten geschlossen und die Daten erneut eingelesen werden. Das Resultat ist eine gedruckte Bewegungsskulptur mit einer genuin dynamischen Gestalt und Ausdrucksqualität.
Aus Sicht der Verkörperungstheorie (embodiment) kann angenommen werden, dass das durch wiederkehrende Erfahrungen verinnerlichte konzeptuelle Bildschema Spirale die zirkuläre gestische Bewegungsspur unterfüttert.18 Die Darstellung ist subjektiv perspektiviert, indem zwei Blickpunkte auf das Ereignis in der körperlich verankerten Performanz der Sprecherin verschmelzen: Zum einen repräsentiert der nach unten gerichtete Zeigefinger das die Treppe herunterlaufende Kind (und somit die Sprecherin selbst); zum anderen imitiert die Sprecherin die Person, die vom obersten Stock in das tiefe Treppenhaus hinunter blickt.

Diese multimodale Erzähltechnik ist immersiv in dem Sinne, dass sich die Sprecherin in den Ort der Erinnerung versetzt und von dort die architektonische Situation und die darin oft stattgefundene Szene beschreibt.19

161

Die Virtuelle Realität als Ort kreativer Handlungen
Neben dem Motion-Capture-Aufnahmesystem im Natural Media Lab wurde eine weitere Technologie verwendet, die neben der Aufnahme von redebegleitenden Gesten auch als dreidimensionales Zeichentool nutzbar ist. In Kooperation des Lehrstuhls für Bildnerische Gestaltung (Leitung: Univ.-Prof. Thomas H. Schmitz) mit der Virtual Reality Group (Direktor: Univ.-Prof. Torsten Kuhlen, RWTH Aachen University) wurden in der virtuellen Umgebung der aixCAVE das Tool und die Lehrveranstaltung „Virtual Sketching“ entwickelt.20 Die aixCAVE am Rechenzentrum der RWTH Aachen ist eines der größten immersiven Virtual-Reality-Displays, die für interdisziplinäre Forschungen und Anwendungen zum Einsatz kommt, wie z. B. der Gehirnsimulation, der Erforschung und Entwicklung von Tools zur Durchführung von Regional-Anästhesien, Interaktive physikalisch-basierte Sound-Synthese, und Arbeiten im Bereich Computational Engineering Science. Der Raum mit seiner Möglichkeit der 360°-Simulation und seiner Rückprojektionstechnik beträgt 5 × 5 × 3,30 m. Über eine Virtual-Reality-Brille findet eine Bewegungserfassung des Kopfes statt (siehe Abbildung 4), und die Anzeige der berechneten Grafik wird an die Bewegungen des Nutzers angepasst. Der agierende Körper nimmt immersiv den Raum der Simulation an, fühlt, handelt und bewegt sich darin. Auch und gerade in immersiven Umgebungen, in denen man sich mit seinem Bewusstsein in einen anderen räumlichen Kontext hineinzuversetzen vermag, entsteht ein neu zu deutender, in situ durchgeführter Bild- und Imaginationsakt: indem z. B. ein räumlich wie zeitlich in der Ferne liegendes Ob-

jekt im Gestenraum für das Auge sichtbar verhandelt wird. Infolge der aktuell rasant fortschreitenden technologischen Entwicklung im Bereich der VR kann das Tool mittlerweile auch über eine VR-Brille ohne das System der aixCAVE genutzt werden. So ist es bald für jeden auch außerhalb von Forschungsinstitutionen möglich, diese dynamischen, flüchtigen Bewegungen aufzuzeichnen und ihre virtuellen, dreidimensionalen Bewegungsspuren sichtbar zu machen. Die Bewegungsskulpturen, die auf die Studie „Erinnerung wird Objekt“ aufbauen, loten weniger den Zusammenhang von Vorstellung und visueller gestischer Darstellung aus, als vielmehr die Vielfalt der möglichen Bewegungsformen. Dabei kommen Richtungswechsel, Drehungen und sich verändernde Distanzen zwischen den Händen gestalterisch zum Tragen. Da es sich bei dieser Technik um ein Aufnahmesystem mit optischer Kontrolle handelt (d. h. man sieht im Vorgang der Bewegung die entstehende Spur und somit die sich allmählich formende Skulptur), kann bei dieser Methode durchaus von Zeichnen und sichtbarem Modellieren gesprochen werden. Doch inwiefern beeinflusst die optische Kontrolle den gestischen Vorgang? Wie sehen die so generierten Objekte im Vergleich zu anders gestalteten Objekten aus? Mit dieser Methode verlagert sich die Skizziertätigkeit in den realen, den Körper umgebenden Raum, womit sowohl die Freihändigkeit als auch eine intuitive Nutzung der Hände gewährleistet wird.
In der hier präsentierten Arbeit wurde das Virtual Sketching Tool frei gestisch – also als reines Aufnahmemedium stattfindender Bewegungen – verwendet. Beidhändig wurden mithilfe von Flächen Bewegungsskulpturen generiert, die dann wiederum skaliert und in unterschiedlichen Maß-

3  Materialisierte Geste (3D-Druck) der in Abbildung 1 aufgenommenen Bewegung

4 und 5  Bewegungsskulpturen mit optischer Kontrolle in der aixCAVE, RWTH Aachen

162

163

6  Visualisierung einer Ausstellungssituation

auszuschöpfende Potential dieser Zusammenarbeit trat auch dadurch vor Augen, dass aus den Perspektiven der Gestenforschung und bildnerischen Gestaltung ähnliche sowie jeweils anders ansetzende Fragen an den Gegenstand gestellt wurden, um sich dann angesichts der gemeinsam identifizierten Herausforderungen auf die Suche nach wissenschaftlich-empirisch fundierten Antworten und künstlerisch-technischen Lösungen zu machen. Ohne diesen über mehrere Jahre hinweg fortgeführten Dialog wären die in der Ausstellung gezeigten Objekte der Erinnerung wohl nicht entstanden. Vielleicht liegt gerade im gemeinsamen Betreten von Neuland der Impetus für die hier beschriebenen, intuitiv gelenkten kreativen Prozesse. Mit Blick in die Zukunft scheint es lohnend, ähnlich gelagerte Verbindungen von digitalen Technologien und körperbasierten Ansätzen in unterschiedlichen Kontexten von Diskurs, Gestaltung und Performanz für Kunst und Forschung nutzbar zu machen.

stäben verwendet werden konnten. Ein Vorteil der CAVE gegenüber dem Motion-Capture-Labor ist die Möglichkeit der optischen Kontrolle und des Ganzkörpereinsatzes, da das Tool nicht auf den Gestenraum der agierenden Personen beschränkt ist. Das entstehende, simulierte Modell kann nicht nur virtuell gedreht werden, sondern man kann es auch umschreiten. In der Immersion wird die Zeichnung so zum wortwörtlich begreifenden und begreifbaren Modell. Die dargestellten Visualisierungen der Bewegungen zeigen die Ausstellungssituation und präsentieren die Skulpturen frei im Raum schwebend im Maßstab 1 : 1 (siehe Abbildung 6). Durch die Vielfältigkeit der Konturen und Oberflächenstruktur entwickeln die Objekte ihren ganz individuellen Charakter und gewähren durch unterschiedliche Blickwinkel immer wieder neue Eindrücke und Einsichten.
Abschließende Bemerkungen
Wie in diesem Beitrag skizziert, handelt es sich hier um eine Zusammenarbeit zwischen Wissenschaft und künstlerischer Gestaltung, die bewusst aus einem gemeinsamen Erkenntnisinteresse heraus die Grenzen zwischen den beteiligten Disziplinen und Ansätzen auflöst.21 Die hier zum Einsatz gekommenen digitalen Technologien und Methoden haben nicht nur für beide Seiten neue Möglichkeiten der Erfassung, Sichtbarmachung, Nutzung und Analyse kommunizierender und entwerfender Hände eröffnet. Das noch weiter

Anmerkungen 1 Sartre, Jean-Paul: Das Imaginäre. Phänomenologische Psycholo-
gie der Einbildungskraft. Reinbek 1971, S. 205. 2 Pallasmaa, Juhani: The Thinking Hand: Existential and Embo-
died Wisdom in Architecture. West Sussex 2009. 3 Leroi-Gourhan, André: Hand und Wort. Die Evolution von
Technik, Sprache und Kunst. Frankfurt a. M. 1980, S. 237 f. 4 Vgl. Fricke, Ellen: Origo, Geste und Raum. Berlin/New York,
2007 sowie dies.: Grammatik multimodal. Wie Wörter und Gesten zusammenwirken. Berlin/Boston 2012 sowie Mittelberg, Irene; Schüller Daniel: Kulturwissenschaftliche Orientierung in der Gestenforschung. In: Jäger, Ludwig; Krapp, Peter; Weber, Samuel (Hg.): Language – Culture – Communication. An International Handbook of Linguistics as Cultural Study. Berlin/ New York 2016, S. 871–884 sowie Müller, Cornelia: Redebegleitende Gesten. Geschichte – Theorie – Sprachvergleich. Berlin 1998 sowie Müller, Cornelia u. a. (Hg.): Body – Language – Communication: An International Handbook on Multimodality in Human Interaction. Bd. 1, Berlin/Boston 2013. 5 Vgl. Streeck, Jürgen: Gesture-craft. Amsterdam/Philadelphia 2009, S. 151. 6 Vgl. Schüller, Daniel; Mittelberg, Irene: Diagramme von Gesten. Eine zeichentheoretische Analyse digitaler Bewegungsspuren. In: Zeitschrift für Semiotik 38 (2017). 7 Vgl. Müller (wie Anm. 4).

164

8 Mittelberg, Irene: Balancing acts: Image schemas and force dynamics as experiential essence in pictures by Paul Klee and their gestural enactments. In: Borkent, Mike; Dancygier, Barbara; Hinnell, Jennifer (Hg.): Language and the Creative Mind. Stanford 2013, S. 325–346.
9 LeBaron, Curtis; Streeck, Jürgen: Gesture, knowledge and the world. In: McNeill, David (Hg.): Language and Gesture. Cambridge 2000, S. 118–138 sowie Streeck, Jürgen: Gesture-craft. Amsterdam/Philadelphia 2009 sowie Mittelberg, Irene: Ars memorativa, Architektur und Grammatik. Denkfiguren und Raumstrukturen in Merkbildern und spontanen Gesten. In: Schmitz, Thomas H.; Groninger, Hannah (Hg.): Werkzeug – Denkzeug. Manuelle Intelligenz und Transmedialität kreativer Prozesse. Bielefeld 2012, S. 191–221.
10 Bredekamp, Horst: Theorie des Bildaktes. Frankfurt a. M. 2010. 11 Vgl. Wulf, Christoph: Bilder des Menschen. Imaginäre und
performative Grundlagen der Kultur. Bielefeld 2014 sowie Wulf, Christoph; Fischer-Lichte, Erika (Hg.): Gesten – Inszenierung, Aufführung, Praxis. Paderborn 2010. 12 Vgl. z. B. Raoul Auger Feuillets, vgl. Maar, Kirsten: Topographien des Flüchtigen. In: Schmitz, Thomas H.; Groninger, Hannah (Hg.): Werkzeug – Denkzeug. Manuelle Intelligenz und Transmedialität kreativer Prozesse. Bielefeld 2011, S. 75–94 sowie Brandstetter, Gabriele: Choreografie. In: Fischer-Lichte, Erika; Kolesch, Doris; Warstat, Matthias (Hg.): Metzler Lexikon der Theatertheorie. Stuttgart/Weimar 2005, S. 52–55. 13 Laban, Rudolf von: Choreutik. Grundlagen der Raum-Harmonielehre des Tanzes. Wilhelmshaven 1991, S. 14. 14 Vgl. Gerald, Siegmund (Hg.): William Forsythe. Denken in Bewegung. Berlin 2004, S. 51. 15 Vgl. ebd., S. 59. 16 Vgl. Jäger, Ludwig; Fehrmann, Gisela; Adam, Meike (Hg.): Medienbewegungen. Praktiken der Bezugnahme. München, 2012 sowie Schmitz, Thomas H.; Groninger, Hannah (Hg.): Werkzeug – Denkzeug. Manuelle Intelligenz und Transmedialität kreativer Prozesse. Bielefeld 2012. 17 Siehe Mittelberg, Irene; Schmitz, Thomas H.; Groninger, Hannah: Operative Manufakte. Gesten als unmittelbare Skizzen in frühen Stadien des Entwurfsprozesses. In: Hinterwaldner, Inge; Ammon, Sabine (Hg.): Bildlichkeit im Zeitalter der Modellierung. Operative Artefakte in Entwurfsprozessen der Architektur und des Ingenieurwesens. München 2017, S. 55–89 für Details und theoretische Einbettung. 18 Vgl. Krois, John M.: Körperbilder und Bildschemata. Aufsätze zur Verkörperungstheorie ikonischer Formen. Berlin 2011 sowie Mittelberg (wie Anm. 8) sowie dies.: Gestures and iconicity. In: Müller, Cornelia u. a. (Hg.): Body – Language – Communi-

cation: An International Handbook on Multimodality in Human Interaction. Bd. 2, Berlin/Boston 2014, S. 1712–1732. 19 Vgl. Mittelberg und Schmitz und Groninger (wie Anm. 17) sowie Mittelberg, Irene: Experiencing and construing spatial artifacts from within: Simulated artifact immersion as a multimodal viewpoint strategy. In: Dancygier, Barbara; Vandelanotte, Lieven (Hg.): Viewpoint Phenomena in Multimodal Communication. Cognitive Linguistics. Namur 2017. 20 Das Forschungsmodul Virtual Sketching war eine Veranstaltung im Architektur-Masterstudiengang der RWTH Aachen und durch Lehre+-Gelder gefördert. Es wurde ausgezeichnet mit dem Lehrpreis in der Kategorie Projekt der RWTH Aachen University 2016. 21 Mit Dank an die Studierenden Anna Kielbassa und Svenja Wehrend für ihre Daten und Bilder sowie an den Fotografen Ivo Mayr und das Fabri-Lab der Fakultät für Architektur an der RWTH Aachen.
Abbildungsnachweis 1 Natural Media Lab, RWTH Aachen. 2 Foto: Ivo Mayr, Fabri Lab, RWTH Aachen. 3 Foto: Ivo Mayr, Projekt von Anna Kielbassa, Lehrstuhl für
Bildnerische Gestaltung, RWTH Aachen. 4–5 Fotos: Hannah Groninger, aixCAVE, Lehrstuhl für Bildne-
rische Gestaltung, RWTH Aachen. 6 Visualisierung von Svenja Wehrend.

165

Gesten, 		Zeichnungen, 							Dinge

Mathias Roloff

Die Zeichnung nimmt seit Beginn meiner künstlerischen Laufbahn eine maßgebende Rolle in meiner Arbeit ein. Sie diente anfangs vor allem als Mittel zum Erfassen von Situationen und Objekten. Es entstanden in erster Linie Arbeiten, die Proportionen und räumliche Zusammenhänge klären sollten oder nach Möglichkeiten suchten, verschiedene Stofflichkeiten und Oberflächenstrukturen abzubilden. In diesem Zusammenhang erprobte ich den Einsatz vielfältiger Zeichenmittel und Materialien. Neben der Untersuchung der äußerlichen Gegebenheiten von Objekten rückte nach und nach die Visualisierung innerer Gemütszustände in den Fokus, die weniger über den Bildgegenstand selbst als über die Art des Zeichnens vermittelt werden sollten. Prägend waren hierbei zahlreiche intensive Studien des Akt- und Portraitzeichnens. In ihrem Rahmen versuchte ich, nicht nur den Habitus des Modells, sondern auch dessen Ausdruck zeichnerisch festzuhalten. Es zeigte sich, dass es selten nur eine einzelne Befindlichkeit ist, die durch das abzubildende Individuum transportiert wird. Der ständige Wechsel von Gefühlsregungen, der in vielen Situationen erlebt und geäußert wird, kann verglichen werden mit dem leichten Hin- und Herschwanken beim Stehen auf einem labilen Untergrund. Durch die tiefergehende Auseinandersetzung mit derart flüchtigen Zuständen, nicht nur in der

Bildenden Kunst, fand ich einen thematischen Schwerpunkt für meine künstlerische Arbeit und suche seitdem nach Möglichkeiten in der Malerei und Grafik, diese situierte Vielschichtigkeit von menschlichen Gefühlen, Affekten und inneren Zuständen auszudrücken.
Durch die Zusammenarbeit mit wissenschaftlichen Disziplinen, insbesondere der modernen Gestenforschung, und im Rahmen meiner breit gefächerten Projektarbeit, bot sich mir die Möglichkeit, meinen eigenen künstlerischen Ansatz in den wissenschaftlichen Kontext einzubringen. Die Zeichnungen, die ich seit einigen Jahren im Auftrag der modernen Gestenforschung anfertige, weisen formale Ähnlichkeiten zu meinen künstlerischen Arbeiten auf. Sich überlagernde Bewegungen und zeitliche Abläufe stehen thematisch im Vordergrund dieser Zeichnungen. Sie können als ähnlich unstete Zustände betrachtet werden wie die oben beschriebenen, sich ständig wandeln­den Gemütszustände. Folglich ergibt sich auch eine Verwandtschaft in ihrer zeichnerischen Darstellungsweise. Abstufungen in der Reduzierung des Strichs und in den Helligkeiten sowie mehrschichtige Strichlagen können beispielhaft als grafische Stilmittel genannt werden.
Die Auseinandersetzung mit den Inhalten moderner Gestenforschung beeinflusst zudem meine eigene Arbeit, da

166

167

sie zu weitergehenden Überlegungen um eine Erweiterung des Zeichnungsbegriffs anregt. Das gestische Zeichnen mit der Hand oder dem Finger in der Luft basiert auf der ganz ursprünglichen Handlung des Zeichnens im Sand, ist jedoch vergänglich, hinterlässt keine Spuren und kann nur durch Beschreibung oder Aufnahme dokumentiert werden – wie bei einer Performance. Ähnlich verhält es sich beim Zeichnen auf dem Tablet, welches dieselbe Ursprungshandlung aufweist sowie verwandte Formen und Qualitäten in den Bewegungsabläufen zeigt. Dennoch entstehen mit der Entwicklung neuer technischer Geräte andere Möglichkeiten zu zeichnen, bei denen zwar kaum direkte Spuren auf dem Zeichenuntergrund selbst hinterlassen, jedoch technische Prozesse initiiert werden, die eine virtuelle Form der Zeichnung erzeugen. Das zeichnende Objekt ist hier Impulsgeber für einen komplexen Vorgang.
Aus diesen Beobachtungen erwuchs eine erweiterte Perspektive auf die Zeichnung als ein essentielles, gesellschaftsrelevantes Medium, das nicht nur dem kreativen Ausdruck dient, in Form einer Grafitzeichnung auf Papier, sondern welches maßgeblich die Kommunikation und den Umgang mit technischen Geräten im Alltag mitbestimmt.
Die Ausstellung „Gesten – gestern, heute, übermorgen“ bewegt sich in eben diesem Spannungsfeld zwischen künstlerischem, wissenschaftlichem und technischem Schaffen und stellt auf anschauliche Weise Berührungspunkte dieser gesellschaftlichen Bereiche vor. Die Zusammenführung von Exponaten aus den Bereichen Kunst, Wissenschaft und Technik verweist auch auf die große Relevanz der Zeichnung als Medium in Kunst und Alltag: von der grafischen Arbeit als einer spontanen und direkten künstlerische Äußerung über die Untersuchung von gestischer Zeichnung, die zunehmend eine Rolle spielt im Bereich Mensch-Maschine-Interaktion und mittels derer bereits technische Geräte gesteuert werden können, bis hin zu Prozessen, in denen mit grafischen Stilmitteln das Gegenüber abgebildet wird, vollautomatisch und gesteuert durch Motoren. Die Ausstellung präsentiert eine große Bandbreite an möglichen Formen der Zeichnung, die auf ihre gesellschaftliche Bedeutung schließen lässt – als abbildendes, beschreibendes und kommunikatives Medium – und neben kontrastierenden Momenten Schnittmengen zwischen den Disziplinen offenbart.

Zeichnungen: Mathias Roloff.

168

169

V INDUSTRIEKULTUR IM WANDEL: VOM HANDGRIFF ZUR GESTENSTEUERUNG
» Angelika Bullinger-Hoffmann und Thomas Seeling Mehr als „winke, winke“ – Gestenbedienung von Maschinen in modernen Arbeits- und Lebenswelten
» Ellen Fricke Hand, Mensch, Maschine: Die erweiterte und reduzierte Hand

» Manuel Schramm Das Hämmern und Schmieden

» Manuel Schramm Das Spinnen

» Manuel Schramm Das Töpfern

» Ellen Fricke Von der Handlung zur Geste und zurück: Analoges und virtuelles
Modellieren am Beispiel des Töpferns

» Manuel Schramm Industrieller Fortschritt: Hoffnungen und Ängste

» Georg Jahn

„Nach Ihnen“ – Verkörperte digitale Technologien in

Hybridgesellschaften der Zukunft

170

171

Mehr als „winke, winke“ –
Gesten­bedienung von Maschinen in modernen Arbeits						 und Lebenswelten

Angelika Bullinger-Hoffmann und Thomas Seeling

Sich zurücklehnen und Zeitung lesen während der Firmen­ wagen uns durch den Straßenverkehr zum nächsten Meeting manövriert, oder den Transportroboter im Logistikzentrum damit beauftragen, Waren automatisiert von Regal zu Regal zu bugsieren: selbstfahrende Fahrzeuge sind längst keine Zukunftsmusik mehr, sie erleichtern uns Arbeit und Freizeit. Dennoch lauern an der Schnittstelle zwischen Mensch und Maschine Gefahrenquellen. Können selbstfahrende Fahrzeuge Menschen und deren Absichten etwa anhand ihrer Hand- oder Körpergesten erkennen und als Befehle korrekt interpretieren? Ist das der Fall, dann sind nicht nur Zusammenstöße mit querenden Personen ausgeschlossen, sondern auch Möglichkeiten zur wechselseitigen Kommunikation gegeben – zur Kommunikation zwischen Menschen und Maschinen als deren Arbeitsmittel forscht die Arbeitswissenschaft. Dabei nimmt sie auch in den Blick, wie die Mensch-Maschine-K­ ommunikation mittels Gesten besser gelingen kann.

Mensch-Maschine-Interaktion im Wandel: von der Lochkarte über Kommandozeilen zu Gestenkommandos
Ein Blick zurück in die 1960er Jahre zeigt, dass zu dieser Zeit noch keine digitalen Schnittstellen zwischen Nutzern und Maschinen im eigentlichen Sinn, wie wir sie heute kennen, existierten. Die Eingaben der Nutzer vollzogen sich mechanisch mittels Lochkarten aus Karton, die Ausgabe erfolgte über lärmende Zeilendrucker. Ab Ende der 1960er bis zu Beginn der 1980er Jahre wurden Eingaben vornehmlich über Kommandozeilen an den Computer übermittelt, Tastaturen waren dafür das Mittel der Wahl. Die Ausgabe erfolgte flimmernd über alphanumerische Displays, also über Monitore, die Zahlen und Buchstaben darstellen konnten. Aus dieser Zeit haben sich bis heute so genannte grafische Benutzerschnittstellen durchgesetzt: Fenster, Symbole, Menüs und Mauszeiger bilden Grundprinzipien unserer Interaktion mit Desktop-Computern als maschinelle Arbeitsmittel.1 Apple und Microsoft machten das Konzept der Desktopmetapher, also die Anzeige eines virtuellen Schreibtisches, auf dem allerlei Funktionen und Werkzeuge dargestellt werden, weltweit populär und sorgten dafür, dass wir heute noch mehrheitlich mit Maus und Tastatur durch Fenster navigieren und über das Klicken auf

172

Symbole Dokumente anlegen, sortieren oder wieder löschen.
Seit Mitte der Neunziger Jahre ist zu beobachten, dass sich die Konzepte von Interaktionen mit computerisierten Arbeitsmitteln weiterentwickeln: weg von der Eingabe mit Maus und Tastatur hin zu Sprach-und Gestensteuerung.2 Diese aktuellen Technologieentwicklungen zeigen, dass sich der Umgang mit Maschinen an den Umgang mit unseren Mitmenschen annähert und insofern mehr und mehr „intuitiv“ wird.3 Der Vorteil dieser „Intuitivität“ der Schnittstellen liegt v. a. darin, dass wir die Kommunikation mit Menschen aus dem Effeff beherrschen, den Umgang und die Kommunikation mit Interaktionskonzepten von interaktiven Arbeitsmitteln jedoch erst erlernen müssen. Die Vielzahl an Menüs, abstrakter zweidimensionaler Darstellungen von Funktionen und technischer Eingabegeräte sorgen für ein oft langandauerndes Einüben.4 Nicht umsonst gab und gibt es trotz oder gerade wegen der rasanten Technologieentwicklung unzählige Ratgeber zum effizienten und effektiven Umgang mit Schnittstellen.
Intuitive Benutzerschnittstellen versprechen hier Besserung – das gilt zumindest in der Theorie. Bei diesen Schnittstellen, die auch als Natural User Interfaces bezeichnet werden, interagieren wir als Nutzer mit uns bekannten und vertrauten Interaktionsformen.5 Sprache und Gesten etwa müssen nicht erlernt werden. Weil sie uns aus der Alltagskommunikation bekannt sind, entfällt das Hineindenken in abstrakte Metaphern. Gesten sind Bestandteil unseres Alltagslebens seit Kindesbeinen an. Schon im Frühkindesalter ist zu beobachten, dass Zeigegesten benutzt werden, um das Gegenüber zur Handlung aufzufordern.6 Intuitive Schnittstellen versprechen mit der Adaption dieser Alltagsgesten für die Interaktion zwischen Mensch und Maschine auch beeinträchtigungsfreie Bedienungen.

zeitlich und räumlich optimiert anzuordnen. Die Optimierung dieser Faktoren vollzieht sich unter den Leitzielen Rationalisierung und Humanisierung der Arbeitswelt. Was bedeutet das genau? Die Ergebnisse der Arbeit sollen hinsichtlich ihrer Verwertbarkeit optimal ausfallen und dabei gleichzeitig die physiologische, also die körperliche sowie psychologische, und damit die geistige Leistungsfähigkeit der Menschen möglichst wenig beeinträchtigen.8 Wir sollen als Arbeitspersonen insofern die bestmöglichen Arbeitsergebnisse erzielen und dabei gesund bleiben.
Auch aufgrund der zunehmenden Durchdringung der Arbeitswelt mit interaktiven Maschinen, bei denen wir als arbeitende Menschen in Wechselwirkung mit Computersystemen als unseren Arbeitsmitteln stehen, tritt die Gestaltung gebrauchstauglicher Mensch-Maschine-­Schnittstellen als Teildisziplin der Software-Ergonomie in den Vordergrund.9 Die Software-Ergonomie nimmt insbesondere die informatorisch-mentale Gestaltung von Arbeitsmitteln in den Blick.10 Als Teildisziplin der Ergonomie hält sie eine Vielzahl von Methoden und Theorien zur Analyse, Gestaltung und Bewertung von interaktiven Computersystemen bereit, um Arbeitsmittel gebrauchstauglich an den Bedürfnissen und Fähigkeiten der Nutzer zu orientieren und zu gestalten, so dass negative Beanspruchungen vermieden oder verringert werden können.11 Was ein gebrauchstaugliches Arbeitsmittel ausmacht, ist in einer internationalen Norm festgeschrieben und wie folgt definiert: Gebrauchstauglichkeit ist das „Ausmaß, in dem ein Produkt, System oder ein Dienst durch bestimmte Benutzer in einem bestimmten Anwendungskontext genutzt werden kann, um bestimmte Ziele effektiv, effizient und zufriedenstellend zu erreichen.“12
Schlechte Gebrauchstauglichkeit gleich schlechte Arbeit

Softwareergonomie als Disziplin, wie der Mensch und interaktive Systeme zueinander finden
Computerisierte Maschinen unterliegen einer rasanten technologischen Weiterentwicklung, insbesondere was die Handhabbarkeit und ihren Funktionsumfang als Arbeitsmittel anbelangt. In der Folge hat sich die wissenschaftliche Disziplin der Ergonomie als „Wissenschaft von der Anpassung der Technik an den Menschen zur Erleichterung der Arbeit“7 herausgebildet. Ziel der Ergonomie ist es u. a. Arbeitsmittel, Arbeitsprozesse und Arbeitsbedingungen

Vor allem sind es psychische Belastungen, die an nicht oder nur eingeschränkt gebrauchstauglichen Schnittstellen von Mensch und Maschine auf uns wirken. Gerade bei komplexen, unklaren oder sich abändernden Funktions- und Informationsstrukturen von Computersystemen müssen wir uns als Nutzer stets neu orientieren, woraus hohe Konzentrationsanforderungen und Belastungen des Gedächtnisses resultieren können.13 Die Bewältigung der Arbeitsaufgaben ermüdet und dauert länger an. Fehlbedienungen und Frustration sind die Folge. Können wir Aufgaben nicht mehr dauerhaft effizient und effektiv bearbeiten, sinkt die Produktivität. Für uns persönlich entsteht Stress und unsere

173

Gesundheit wird temporär, schlimmstenfalls dauerhaft ge- hauptsächlich gesteuert werden können. Die Anwendung

schädigt.14

von Gesten als Steuerungsmodalität ist jedoch nicht auf

den Bereich der Unterhaltung beschränkt. Insbesondere die

Leicht von der Hand oder schwer zu begreifen? Fallstricke einer intuitiven Gestenbedienung

multimodale Interaktion zwischen Mensch und Roboter ist in den letzten Jahren in den Blick von Ergonomie und Arbeitswissenschaft geraten. Dabei werden u. a. Fragestel-

lungen verfolgt, wie Schwenkarme von Montager­obotern in

Sind Maschinen, die mit Gesten bedient werden, nun ge- der Fertigung mittels Gestenkommandos gesteuert werden

brauchstauglicher als ein Desktop-PC? Nicht jedes System, können oder Roboter im Pflegebereich die Absichten von

das mit Gesten bedient werden kann, erfüllt die Bedin- Patienten erkennen und auf Grundlage multimodaler Ein-

gungen eines effizienten, effektiven und zufriedenstellen- gaben unterstützende Servicedienstleistungen erbringen.

den Arbeitens und kann demnach tatsächlich als intuitiv Vor dem Hintergrund des fortschreitenden demografischen

bezeichnet werden. Wie jede Schnittstelle verlangen auch Wandels und der geringen Attraktivität von Pflegeberufen

gestenbasierte Schnittstellen uns als Nutzern ab, die gel- aufgrund hoher physischer und psychischer Belastungen ist

tenden Interaktionskonzepte, Regeln und Rahmenbedin- es geboten, Pflegepersonal bei ihren vielfältigen Aufgaben

gungen, die für dieses System Gültigkeit besitzen, zu ver- mittels (Teil-)Autonomer Service-Roboter zu unterstützen.

innerlichen.15 Die Häufigkeit der Nutzung gestenbasierter Aktuell wird der Einsatz dieser bei Tätigkeiten mit hoher

Mensch-Maschine-Schnittstellen sowie die Entsprechung Wiederholhäufigkeit, wie beispielsweise das Bereitstel-

der im interaktiven System eingelassenen Gesten-Sets zu len von Speisen sowie das Aktivieren des Patienten durch

im Alltag verankerten Objektgebrauchsgesten sind dabei Bereitstellung von Informationen und Unterhaltungsange-

wesentliche Faktoren, die die Dauer dieses Prozesses für uns boten, erforscht und erprobt.19 Um akzeptiert zu werden,

als Nutzer maßgeblich bestimmen. Weisen die implemen- müssen Service-Roboter zukünftig dialogfähige Interak-

tierten Gestenkommandos Übereinstimmungen mit Ob- tionspartner der Menschen in ihrem häuslichen Umfeld

1

jektgebrauchsgesten des Alltags auf, wird das Bedienen von oder in Pflegeumgebungen sein. Das setzt voraus, dass sie

uns eher als intuitiv erlebt.16 Sind Gesten-Sets außerdem die Intention des Menschen richtig interpretieren. Eine

für identische Aufgaben über verschiedene interaktive Sys- Herausforderung diesbezüglich ist es, dass unsere Absichten,

teme hinweg gleich gestaltet und können wir dadurch auf die wir mittels Sprache, Gestik oder Mimik an den Roboter

bekannte Bedienkonzepte zurückgreifen, die zusätzlich auf übermitteln, von ihm als Interaktionspartner „auf Augen-

Gesten des alltäglichen Objektgebrauchs basieren, können höhe“ auch verstanden werden. Deswegen ist es erforder-

die Einübungsphasen in neuartige Systeme verkürzt werden, lich, dass Emotionen und Situationen zukünftig korrekt

was zur Verringerung negativer Beeinträchtigungen bei der erkannt werden und der Roboter stets in der Lage ist, aus

Bedienung, zur Akzeptanz und letztlich zur intuitiven Nut- diesen multimodalen Informationen die richtigen Schluss-

zung dieser Schnittstellen führen kann.17 Damit der intuiti- folgerungen zu ziehen: Eine vertikal zum Roboter positio-

ve Gebrauch und somit der Erfolg von Maschinen, die auf nierte Handgeste muss, ähnlich wie von Menschen, auch

berührungsloser Interaktion gründen, gewährleistet werden von einem humanoiden Roboter als „keinen Schritt wei-

kann, ist es demnach sinnvoll, Nutzer in den Entwicklungs- ter“ verstanden werden. Auch für den Bereich der Mensch-

prozess von gestischen Schnittstellen einzubeziehen – ein Roboter-Interaktion ist anzunehmen, dass die Kommunika-

Ansatz, den das Forschungsprojekt MANUACT mit der Er- tion mit einem Roboter fehlerfreier vonstattengeht, die auf

stellung eines Gestenmanuals für Entwickler verfolgte.18

implementierten Gesten analog zu Objektgebrauchsgesten,

wie wir sie aus dem Alltag kennen, basiert.

Moderne Handhabungen in Anwendung

Darüber hinaus ist der klinische Bereich ein weiteres Anwendungsfeld. Vor allem die Steuerung von medizinischen

Instrumenten durch Gestenkommandos stellt ein relevan-

Dass sich Schnittstellenbedienung über Gesten längst tes Forschungsfeld dar. Das Fraunhofer-Institut am Hein-

etabliert hat, zeigt u. a. der Erfolg der Spielekonsolen von rich-Hertz-Institut (HHI) entwickelte etwa eine berührungs-

Nintendo und Microsoft. Beide verfügen über Sensoren lose Interaktion im OP. Das System zeigt dabei verschiedene

zur Erkennung von Gestenbefehlen, mit denen die Spiele personenbezogene Daten wie Röntgen-, Ultraschall-, MRT-

2

174

175

3 1 bis 3  Industrie 4.0: Gestenbedienung zur Behebung einer Maschinenstörung (Demonstrator)

oder CT-Bilder des Patienten an, die während der Operation berührungslos vom Chefarzt oder der Krankenschwester angewählt und manipuliert werden können. Der Vorteil dieser berührungslosen Technologie liegt dabei darin, dass die Operation, zum Beispiel für das vergrößerte Betrachten von Bildmaterial, nicht unterbrochen werden muss.20
Zusammenfassung und Ausblick
Gezeigt wurde, dass nicht jede Maschine, die mit Gesten bedient werden kann, zwangsläufig gebrauchstauglicher ist als etwa ein herkömmlicher Desktop-PC. Bedingungen, wie etwa die Passung der im System implementierten Gesten zu unseren Objektgebrauchsgesten des Alltags, wurden benannt. Die Entwicklungen in diesem Bereich werden darüber hinaus maßgeblich davon abhängig sein, ob die sensorische Detektion unserer Gesten korrekt erfolgt, sodass Missverständnisse zwischen Mensch und Maschine auch aus technologischer Sicht ausgeschlossen werden können.

Nur wenn wir uns sicher sein können, dass das autonom fahrende Fahrzeug tatsächlich stoppt, wenn wir mit einer Geste anzeigen, seine Bahn zu queren, oder dass sich der Pflegeroboter nur so weit nähert, wie wir das mit unserer Handgeste anzeigen, werden Gestenbedienungen unsere Arbeits- und Lebenswelten tatsächlich erleichtern und bereichern können. Für die Zukunft muss gelten, dass die Entwicklung der mit Gesten zu bedienenden Schnittstellen sich nicht allein am technisch Machbaren orientieren darf, sondern der „Faktor“ Mensch stärker gewürdigt wird: Unsere Bedarfe, Nutzungsgewohnheiten und kulturellen Hintergründe sind im Sinne eines tatsächlich nutzerzentrierten Entwicklungsprozesses strukturiert und regelgeleitet einzubeziehen. Wichtig ist es deshalb, weitere Anwendungsfälle zu erproben und ergonomische Gestaltungsrichtlinien für Gestenbedienungen zu entwickeln. Ein generisches Ges­ tenmanual für Basisgesten einer intuitiven Mensch-Maschine-Interaktion, wie es im Rahmen des Forschungsprojekts MANUACT entwickelt wurde, liefert in dieser Hinsicht bereits einen wichtigen Beitrag.

176

Anmerkungen 1 Ausführlich u. a. in Dachselt, Raimund; Preim, Bernhard: In-
teraktive Systeme. Band 1: Grundlagen, Graphical User Interfaces, Informationsvisualisierung. Berlin/Heidelberg 2010 sowie Myers, Brad, Hudson, Scott E.; Pausch, Randy: Past, present, and future of user interface software tools. In: ACM TOCHI 7 (2000), S. 3–28. 2 Vgl. Dachselt, Raimund; Preim, Bernhard: Interaktive Systeme. Band 2: User Interface Engineering, 3D-Interaktion, Natural User Interfaces. Berlin/Heidelberg 2015. 3 Vgl. Wigdor, Daniel; Wixon, Dennis: Brave NUI World: Designing Natural User Interfaces for Touch and Gesture. Amsterdam u. a. 2011. 4 Vgl. Saffer, Dan: Designing Gestural Interfaces: Touchscreens and Interactive. Beijing u. a. 2009. 5 Wigdor und Wixon (wie Anm. 3). 6 Vgl. Bates, Elisabeth u. a.: Integrating language and gesture in infancy. In: Developmental Psychology 25 (1989), S. 1004–1019. 7 Bullinger, Hans-Jörg: Ergonomie: Produkt- und Arbeitsplatzgestaltung. Stuttgart 1993, S. 4. 8 Vgl. Schlick, Christopher M.; Bruder, Ralph; Luczak, Holger: Arbeitswissenschaft. Berlin/Heidelberg 2010. 9 Vgl. Herczeg, Michael: Software-Ergonomie. Theorien, Modelle und Kriterien für gebrauchstaugliche interaktive Computersysteme. München 2009. 10 Vgl. Schlick u. a. (wie Anm. 8). 11 Vgl. Bullinger (wie Anm. 7). 12 DIN EN ISO 9241–11: Ergonomie der Mensch-System-Inter­ aktion – Teil 11: Gebrauchstauglichkeit: Begriffe und Konz­ epte. 2006. 13 Vgl. Nielsen, Jakob: Usability Inspection Methods. New York u. a. 1994. 14 Vgl. Schmauder, Martin; Spanner-Ulmer, Birgit: Ergonomie. Grundlagen zur Interaktion von Mensch, Technik und Organisation. München 2014 sowie Herczeg (wie Anm. 9). 15 Vgl. Dachselt und Preim (wie Anm. 2) sowie Ullrich, Daniel: Komponenten und Einflussfaktoren der intuitiven Interaktion: Ein integratives Modell. In: i-com – Zeitschrift für interaktive und kooperative Medien, 12 (2013), S. 44–53. 16 Vgl. Fricke, Ellen u. a.: Gesture, virtual globes and technological innovation: Metaphorical concepts as basis for gesturally steering Google Earth with Leap Motion. In: Gesture – Creativity – Multimodality, Tagungsband 7th Conference of the International Society for Gesture Studies (ISGS), Paris 2016. 17 Vgl. O'Hara, Kenton u. a.: On the Naturalness of Touchless: Putting the Interaction Back into NUI. In: ACM Trans. Comput.-Hum. Interaction 20 (2013), S. 1–25 sowie Saffer (wie Anm. 4).

18 Vgl. Seeling, Thomas u. a.: Natürliche User Interfaces durch das Einbeziehen von Nutzern gestalten. Implikationen für ein Entwickler-Gestenmanual. Mensch-Technik-Interaktion im Industrie 4.0 Zeitalter. Tagungsband 8. VDI/VDE Fachtagung USEWARE, Dresden 2016, S. 65–81.
19 Vgl. u. a. Fraunhofer IPA: Care-O-bot. Online unter www.fraunhofer.de/de/forschung/forschungsfelder/gesundheit-umwelt/ assistenzsysteme/service-roboter-care-o-bot.html (04.08.2017).
20 Vgl. Fraunhofer HHI: OP-Informationssystem. Online unter www.hhi.fraunhofer.de/abteilungen/vit/forschungsgruppen/ immersive-medien-und-kommunikation/forschungsthemen/ contact-free-interaction/projekte/op-informationssystem.html (04.08.2017).
Abbildungsnachweis 1–3 Fotos: Tobias Naumann.

177

Hand, Mensch, Maschine:
Die erweiterte und reduzierte Hand

Ellen Fricke

Die Evolution von Werkzeugen und ihrer Handhabung

Die Erweiterung und Reduktion der Hand

In seinem Buch „Le geste et la parole“ umreißt der französische Anthropologe André Leroi-Gourhan die Evolution von Werkzeugen und ihren Handhabungen folgendermaßen: „Am Anfang war die Hand eine Zange zum Festhalten von Steinen, der Triumph des Menschen hat sie zur immer geschickteren Dienerin seiner Produktionsvorstellungen gemacht. Vom oberen Paläolithikum bis ins 19. Jahrhundert hat sie einen endlosen Höhenflug hinter sich gebracht. In der Industrie spielt sie noch eine wesentliche Rolle bei wenigen Werkzeugmachern, die jene Teile der Maschinen herstellen, vor denen die Masse der Arbeiter nur noch einen Greifer mit fünf Fingern hat, der das Rohmaterial verteilt, oder einen Zeigefinger, der auf Knöpfe drückt. Noch handelt es sich um ein Übergangsstadium, denn es kann kein Zweifel bestehen, daß die nicht mechanisierten Phasen in der Herstellung von Maschinen nach und nach ausgeschaltet werden.“1 Stehen wir nunmehr als Individuen und als menschliche Gattung „vor dem Problem einer Regression der Hand“,2 wie Leroi-Gourhan befürchtet?

Entwicklungsgeschichtlich sind bei den frühen manipulativen Tätigkeiten wie beim Formen, Zermahlen, Zupfen oder Graben, die Handhabung und ihr „Werkzeug“ noch ungeschieden. Sie wandert erst in einem zweiten Schritt in das Werkzeug selbst aus. Bei einem Faustkeil als Universalwerkzeug sind Hand und Werkzeug bereits voneinander abgelöst, Hand und Arm steuern nur noch die motorische Kraft – sozusagen den Antrieb – bei (siehe Abbildung 1). Dies ist auch bei ausdifferenzierteren Schlagwerkzeugen, wie dem späteren Hammer der Fall, dessen Form einer spezifischen Funktion folgt und der über den Stiel die motorische Kraft des menschlichen Arms verstärkt (siehe Abbildung 2). Mit einer zunehmenden Vielfalt der handwerklichen Tätigkeiten, z. B. innerhalb des Schmiedehandwerks,3 gingen auch Variationen des Hammers in Abhängigkeit vom Verwendungszweck einher. Ein Goldschmied benutzte einen filigraneren Hammertyp als beispielsweise ein Waffenschmied. Mit der Mechanisierung des Schmiedens wie etwa beim Federhammer (siehe Abbildung 3), bei dem die ursprüngliche Handhammerform noch erkennbar ist, oder bei den späteren Dampfhämmern, wird der motorische Prozess durch den Menschen nur noch ausgelöst.

Eine Reduktion der Handhabungen findet jedoch nicht nur im Rahmen einer spezifischen handwerklichen Tätigkeit über funktionale Abstraktionsprozesse und eine daraus resultierende Auslagerung einzelner manueller Komponenten an die Maschine statt, sondern über die Kurbel, den Knopfdruck oder das Fußpedal als Auslöser werden ganz unterschiedliche Handhabungstypen wie Schmieden, Töpfern oder Spinnen (siehe Abbildungen 7 bis 10) mit zunehmender Automatisierung im Hinblick auf die menschliche Bedienung manuell vereinheitlicht. Mit der Erweiterung 1 der Hand durch die Maschine und der Auslagerung einzelner isolierter Wirkungen der Hand an die Maschine ist zugleich eine Reduktion der menschlichen Handhabungsvariabilität auf ein begrenztes Set manueller Aktivitäten wie beispielsweise das Drücken eines Schalters verbunden. Für viele Tätigkeiten, die den arbeitenden Menschen körperlich stark beanspruchen, bringt diese Reduktion eine große Erleichterung und Entlastung. Eine Kehrseite ist, dass die Vielfalt der manuellen Aktivitäten, die das alltägliche Leben prägen, abnimmt und sich auch über die enge Verbindung von Hand und Gehirn, so die These Leroi-Gourhans, auf die kognitiven Prozesse des Menschen auswirkt und diese 2 verändert: „Mit seinen Händen nicht denken können, bedeutet einen Teil seines phylogenetisch menschlichen Denkens verlieren.“4
Interessant ist nun, dass einhergehend mit der digitalen Gestensteuerung sich sowohl wieder das Variabilitätsspek­ trum als auch die Menge von interface-orientierten Gesten zu erweitern scheinen, wenn auch auf einer neuen abstrakten Ebene und (noch) ohne haptisches Feedback. Insofern diese interface-orientierten Konstruktgesten von Gesten der zwischenmenschlichen Alltagskommunikation ihren Ausgangs­punkt nehmen, da diese nicht vollkommen neu gelernt werden müssen und im menschlichen Gedächtn­ is niederlegt sind, können sie so variabel und komplex sein wie der 3 ihnen zugrundeliegende Kode es zulässt. Sie gehorchen einer „Grammatik“, die in ihren formbezogenen Abstraktionsund Stilisierungsprozessen Parallelen zur Exteriorisierung manueller Komponenten in automatisierten Fertigungsprozessen aufweist. Vom Faustkeil als Universalwerkzeug zu zweck­optimierten Hammervarianten, von spontanen rede-

1  Der Faustkeil als Universalwerkzeug

2  Der Handhammer als spezifisches Schlagwerkzeug

3  Der Federhammer als Mechanisierung des Handhammers 4  Berührungslose Handhabungsgeste, die das Hämmern nachahmt

4

178

179

begleitenden Handbewegungen zu Gesten und Gebärden mit klar ausgeprägten kommunikativen, semantischen und grammatischen Funktionen (siehe die von der Handhabung des Hämmern abgeleitete Handhabungsgeste in Abbildung 4). Welcher Zusammenhang besteht zwischen Handhabungen, Handhabungsgesten und der Handhabbar­machung von Mensch-Maschine-Schnittstellen mittels Gestensteuerung?
Transformation statt Regression: Handhabung, Handhabungsgeste und Handhabbarmachung

automatisierte Prozess ausgelöst. Entscheidend ist jedoch die Möglichkeit, dass Maschinen aufgrund ihrer „Kenntnis“ menschlicher Kodes und Sprachen entsprechend reagieren und einen Vorgang anhalten. Weil Menschen mit den Händen nicht nur Objekte gebrauchen und bearbeiten, sondern auch mit ihren Händen sprechen können, wird händische Komplexität auf einer höheren semiotischen Abstraktionsebene dadurch wieder re-etabliert. Damit würde die Hand in ihrem Bewegungs- und Handhabungsspektrum nicht regredieren, sondern sich lediglich transf­ormieren.

Das oben genannte Relationsgefüge zwischen Handhabung, Handhabungsgeste und Handhabbarm­ achung lässt sich anschaulich am Beispiel der Stoppgeste erläutern:5 Diese Geste ist aus einer Handlung des Weghaltens oder Wegschiebens abgeleitet, bei der die Krafteinwirkung der Hand das Fernbleiben des Objekts verursacht. Bei einer Geste als Zeichen für ‚Stopp‘ bewirkt nicht die stilisierte Handbewegung das Fernbleiben eines Objekts oder einer Person, sondern ein Mensch als Adressat der Geste versteht deren Bedeutung und die kommunikative Absicht des Senders und kommt aufgrund seiner Kenntnis des gestischen Zeichens nicht näher. Es besteht erstens eine konventionalisierte Beziehung zwischen Form und Inhalt für eine bestimmte Kulturgemeinschaft, zweitens stehen einzelne Gesten darüber hinaus in Relation zu anderen Gesten, von denen sie sich in Form und Inhalt unterscheiden. Was geschieht nun, wenn ein Knopfdruck durch eine Geste für ‚Stopp‘ ersetzt wird? Zunächst scheint der Unterschied nicht sehr auffällig zu sein. In beiden Fällen wird gegebenenfalls immer noch derselbe

Menschen und Maschinen in Hybridgemeinschaften: Koevolution und Transformation
Mit der Wiedergewinnung händischer Komplexität im Kontext der berührungslosen Gestens­teu­erung ist ein weiterer Schritt der Exteriorisierung verbunden, der zukünftig in Hybridgemeinschaften von Menschen und Maschinen münden wird:6 Ausgelagert werden sensorische und kognitive Funktionen des Gehirns, die sich in autonomen Maschinen ihre eigenen „verkörperten“ technologischen Agenten schaffen, welche mit Menschen nicht nur Umgebungen und öffentliche Räume, sondern auch Repertoires kommunikativer Zeichen wie beispielweise Gesten teilen, die es wechselseitig erlauben, sich zu koordinieren, die Aufmerksamkeit auf die geteilte Umgebung zu lenken und die jeweiligen Handlungsabsichten zu erschließen. Wie wirken diese Gesten, die Roboter und andere autonome Agenten adressieren, auf menschliche Handlungen und die zwischenm­ enschliche Kommunikation zurück? Wie verändert sich unser Begriff

7  Gestisch bewahrtes Handhabungswissen: das Verdrehen eines Fadens

5 und 6  Mensch-Maschine-Interaktion: der berührungssensitive Roboterarm als „Haustier“
180

8  Das Drehen des Handrads als Handhabung der Spinning Jenny
181

9  Gestisch bewahrtes Bedienungswissen: die nachahmende Kurbelgeste
10  Die Bedienung des Handrads beim „Wagenspinner“ (Halbselfaktor)
182

des Adressierens? Werden wir zukünftig zwischen Gesten, die sich an Roboter, und solchen, die sich an Menschen wenden, unterscheiden? Wie können gemeinsame Kodes und Zeichen entstehen? Ein sinnvoller Ausgangsp­ unkt für die Gestaltung eines solchen Szenarios könnte das Konzept der Koevolution von Mensch und Haustier sein, das die Probleme einer zu ausgeprägten Anthropomorphisierung umgeht.7 So nähert sich beispielsweise eine Ausstellungsbesucherin einem berührungssensitiven Roboterarm als sei dieser der Körper oder ein Körperteil eines Haustiers (siehe Abbildungen 5 und 6). Die Annahme von koevolutionären Prozessen auch in der Dimension von Zeichenproduktion und -rezeption vermag beispielsweise zu erklären, warum Primaten keine menschlichen Zeigegesten verstehen, Hunde als Haustiere aber sehr wohl.8

Abbildungsnachweis 1 Foto: Tobias Naumann. 2–4 Fotos: Maria Haase. 5–6 Fotos: Dietmar Träupmann. 7 –8 Fotos: Tobias Naumann. 9–10 Fotos: Maria Haase.

Anmerkungen 1 Leroi-Gourhan, André: Hand und Wort. Die Evolution von
Sprache, Technik und Kunst. Frankfurt a. M. 1980, S. 319 f. 2 Leroi-Gourhan (wie Anm. 1), S. 320. 3 Siehe auch den Beitrag „Industriekultur im Wandel: das
Hämmern und Schmieden“ von Manuel Schramm, in diesem Band. 4 Leroi-Gourhan (wie Anm. 2). 5 Siehe den Beitrag „Von der Kugel zu Google Earth: Wie handhabe ich einen virtuellen Globus“ von Ellen Fricke, in diesem Band. 6 Siehe den Beitrag „‚Nach Ihnen‘ – Verkörperte digitale Technologien in Hybridgesellschaften der Zukunft“ von Georg Jahn, in diesem Band. 7 Fricke, Ellen: Wie entstehen Gesten? Und was kann das in Bezug auf die Interaktion mit fahrerlosen Autos in der Zukunft bedeuten? Mercedes-Benz Future Talk „Robotics“. Berlin, 30.06. bis 02.07.2014. Online unter www.youtube. com/watch?v=rUQmeQ0cgQs&t=134s (13.03.2019) sowie die Beiträge „‚Nach Ihnen‘ – Verkörperte digitale Technologien in Hybridgesellschaften der Zukunft“ von Georg Jahn und „Menschen, Affen, Hunde und die Evolution von Gesten“ von Susanne Grassmann, in diesem Band. 8 Siehe den Beitrag von Susanne Grassmann (wie in Anm. 7).

183

Das Hämmern und Schmieden

Manuel Schramm

Das Hämmern oder Schlagen mit dem Hammer kann zu verschiedenen Zwecken erfolgen. In den Technikwissenschaften spricht man vom Schmieden als Druckumformtechnik mit gegeneinander bewegten Werkzeugen. Es handelt sich dabei um das älteste Formgebungsverfahren für Metalle. Unterschieden wird zwischen Freiformschmieden und Gesenkschmieden, bei dem in ein Formwerkzeug (Gesenk) geschmiedet wird.1
Das Verwenden von Werkzeugen zum Hämmern oder Schmieden begann schon in der Steinzeit. Damals stellte der Faustkeil ein Universalwerkzeug dar, das auch zum Schlagen verwendet werden konnte (vgl. Abbildung 1). Daraus entwickelten sich zunächst Steinhämmer und später Hämmer aus Metall. Die Form des Hammers wurde schnell dem jeweiligen Zweck angepasst. Bereits in den antiken Hochkulturen existierten zahlreiche unterschiedliche Hammerformen.2
Die Ausdifferenzierung der Hammerformen nach Verwendungszweck setzte sich in den mittelalterlichen und frühneuzeitlichen Zünften fort. Anders als auf dem Land, wo es meist nur einen Dorfschmied gab, der alle Aufgaben der Metallbearbeitung übernahm, differenzierte sich das Schmiedehandwerk aus. Das Ständebuch von Jost Amman von 1568 kennt nicht weniger als sieben verschiedene

1  Mögliche Verwendung eines Faustkeils

184

2  Ein Schmied im 16. Jahrhundert

Schmiedeberufe: Goldschmied, Kupferschmied, Messerschmied, Rotschmied, Schmied, Sensenschmied, Zirkelschmied. Daneben verwendeten auch andere Berufe einen Hammer, wie z. B. Beckenschläger, Bildhauer, Plattner, Glaser, Laternenmacher, Münzmeister, Nagler, Schellenmacher, Schlosser, Seiler, Steinmetz oder Uhrmacher.3 In dem Ständebuch des Christoph Weigel von 1698 werden folgende zehn Schmiedeberufe erwähnt: Ahlenschmied, Ankerschmied, Eberschmied, Kettenschmied, Kupferhammerschmied, Kupferschmied, Messerschmied, Rotschmied, Schmied oder Huf- und Waffenschmied, Zirkelschmied.4 Auch hier war eine Vielzahl von Handwerksberufen abgebildet, die bei ihrer Ausübung einen Hammer benutzten, z. B. Plattner oder Harnischmacher, Bildhauer, Trompetenmacher, Münzmeister, Goldarbeiter, Silberarbeiter, Goldschläger, Messingschläger, Beckenschläger, Flinderschläger, Gürtler, Clausurmacher, Geschmeidmacher, Schellenmacher, Fingerhutmacher, Zeiner, Windenmacher, Ring- oder Taschenbeschlagmacher, Feilenhauer, Nadler, Flaschner, Sporer, Nagler, Steinbrecher, Steinmetz, Zimmermann, Fassbinder, Nestler.5
Das handwerkliche Schmieden veränderte sich im Lauf der Zeit kaum. Die Grundausrüstung einer römischen Schmiede, einer Schmiede um 1000 und einer handwerkli-

chen Schmiede heute ist sehr ähnlich.6 Das Schmieden musste nicht von einem Handwerker allein durchgeführt werden, sondern es konnten auch mehrere Personen mit unterschiedlichen Hämmern an einem Werkstück arbeiten. In diesem Fall war eine gute Zusammenarbeit erforderlich.7
Der Beruf des Schmieds war seit der Antike stark mythologisch aufgeladen. Der griechische Gott Hephaistos (römisch Vulcanus) war Schmied, und als Handwerker eine Ausnahmeerscheinung unter den Göttern. Er stellte Waffen und Gerätschaften für die anderen Götter her, wie die Blitze des Jupiters (vgl. Abbildung 3). Vielleicht lag es an seiner Rolle als Waffenproduzent, die ihm besondere Macht verlieh, vielleicht am Werkstoff Metall, das den Menschen lange Zeit unheimlich erschien, dass das Schmieden eine mythische Bedeutung hatte, die anderen Handwerken nicht zukam.8 Jedenfalls handelte es sich um eine spezifisch männliche Tätigkeit. Frauen konnten zwar Nebentätigkeiten in der Werkstatt verrichten, die Zunftordnungen des 16. Jahrhunderts reservierten jedoch die Arbeit mit Hammer und Amboss für den männlichen Schmiedegesellen oder Meister.9
Die Mechanisierung des Schmiedens setzte lange vor der Industrialisierung ein. Mit der Erfindung der Nockenwelle im 10. Jahrhundert wurde es möglich, große Hämmer

185

3  Peter Paul Rubens, Vulkan schmiedet die Blitze des Jupiters, 1636
186

mit Wasserkraft zu betreiben. Solche Hammerwerke wurden bis in das 19. Jahrhundert hinein genutzt, zum Beispiel zum Sensenschmieden. Sie verbreiteten sich vor allem seit dem 13. Jahrhundert. Mitte des 19. Jahrhunderts waren allein in Sachsen 80 Hämmer in der Eisenindustrie in Betrieb.10 Die Form des Hammers war dabei durchaus dem Handhammer nachempfunden. Er wurde aber nicht mehr von Hand bewegt, sondern durch Wasserkraft angehoben und fiel durch sein Eigengewicht herunter. Schwere Wasserhämmer hatten ein Fallgewicht von bis zu 5 t und eine Betriebskraft von ca. 30 PS.11 Die Wasserhämmer brachten wichtige Veränderungen im Arbeitsprozess mit sich, da der Schmied traditionell sowohl Werkstück als auch Werkzeug (Hammer) bewegte. In den Hammerwerken konnte der Hammer aber nur in eine Richtung (vertikal) und mit konstanter Kraft bewegt werden. Das Werkstück musste daher mit Kraft und Geschick so geführt werden, dass es die richtige Bearbeitung erhielt.12
Mit der Industrialisierung war das Schmieden der Kon­ kurrenz anderer Umformverfahren ausgesetzt. Für die Eisen- und Stahlerzeugung wurde bereits seit dem späten 18. Jahrhundert das Schmieden durch das Walzen ersetzt. Mit Wasserrädern betriebene Walzwerke konnten bereits in den 1790er Jahren einen mehrfach höheren Ausstoß erreichen als die traditionellen Hammerwerke. Für bestimmte Produkte blieb jedoch das Schmieden unerlässlich.13 Ende des 19. Jahrhunderts begannen hydraulische Pressen den mechanischen Hämmern Konkurrenz zu machen. Die Pressen konnten mit ihrem gleichmäßigen starken Druck das Material viel besser durcharbeiten als der Hammer.14
Die industrielle Zeit brachte jedoch auch neue Entwicklungen im Bereich des Schmiedens. So kamen um 1840 die ersten Dampfhämmer auf, nachdem James Watt bereits 1784 eine entsprechende Idee geäußert hatte. Sie konnten zum einen größere Werkstücke schmieden, was vor allem im Schiffsbau des 19. Jahrhunderts nötig war. Zum anderen konnte der Druck nicht mehr nur über die Fallhöhe des Hammerbärs reguliert, sondern gegebenenfalls durch Dampfkraft verstärkt oder abgeschwächt werden.15 Der englische Ingenieur James Nasmyth erkannte, dass es zur Leistungssteigerung der mechanischen Hämmer notwendig war, von der konventionellen Hammerform abzugehen und stattdessen einen Eisenblock direkt aus einer bestimmten Höhe auf das Werkstück fallen zu lassen.16 Dampfhämmer waren in der zweiten Hälfte des 19. Jahrhunderts weit verbreitet, bis sie von den hydraulischen Pressen verdrängt wurden.

Ganz neu war dieser Gedanke allerdings nicht. Bereits im 16. Jahrhundert waren Fallhämmer bekannt, bei denen das Gewicht entweder durch Wasserkraft oder durch Muskelkraft mit einer Seilwinde angehoben wurde. Sie wurden z. B. zum Zerkleinern von Schwarzkupfer eingesetzt.17
Neben den Dampfhämmern existierten im 19. Jahrhundert mechanische Hämmer, die sich in ihrer Form stärker an den traditionellen Handhämmern orientierten. Es handelte sich um Federhämmer, bei denen das Fallgewicht des Hammerbärs durch eine Federspannung auf das 2,5–3fache verstärkt wurde (vgl. Abbildung 6). Ein solcher Hammer wurde erstmals auf der Pariser Weltausstellung von 1867 vorgestellt und verbreitete sich sehr schnell. Aufgrund ihrer einfachen Konstruktion und leichten Bedienbarkeit waren Federhämmer vor allem bei kleineren Betrieben des metallverarbeitenden Gewerbes sehr beliebt. Der Nachteil bestand in der geringen Haltbarkeit der Federn. Die Span-

4  Ein Hammerwerk im 17. Jahrhundert

5  Dampfhämmer, 1894
187

nung der Feder erfolgte mittels einer externen Kraftquelle, meist eines Elektromotors.18
Der Federhammer ist ein faszinierendes Beispiel für die Mechanisierung von Arbeitsgesten. Schon Anfang der 1870er Jahre konnten Federhämmer bis zu 450-mal in der Minute schlagen und verfügten über Fallgewichte von 7,5 kg bis 400 kg.19 Was die Schlagkraft anging, wurden sie natürlich schon im 19. Jahrhundert von den Dampfhämmern in den Schatten gestellt. Der Dampfhammer „Fritz“ der Krupp-Werke Essen erreichte schon 1861 ein Fallgewicht von 50 Tonnen, der 1877 in Dienst gestellte Dampfhammer im französischen Le Creusot 80 bis 100 Tonnen.20 Im industriellen Bereich ging man zudem mehr und mehr zur Verwendung hydraulischer Pressen über. Aber lange Zeit behielten die Federhämmer ihren Platz in kleinen Schmiedebetrieben oder Reparaturwerkstätten, da sie flexibler einsetzbar und bestimmte Werkstoffe für die Pressen nicht geeignet waren.21

Anmerkungen 1 Vgl. Hoffmann, Hartmut; Neugebauer, Reinhold; Spur, Gün-
ter: Handbuch Umformen. München 2012, S. 208 und 244. 2 Vgl. Pichol, Karl: Von der Arbeit mit Handhämmern und
Hammerwerken. In: Reith, Reinhold (Hg.): Praxis der Arbeit. Probleme und Perspektiven der handwerksgeschichtlichen Forschung, Frankfurt/New York 1998, S. 117–146. 3 Vgl. Amman, Jost: Das Ständebuch. Hg. von Manfred Lemmer. Leipzig 1989, S. 23, 26, 28, 31, 61–63, 65, 67–71, 73 f., 80, 85, 95. 4 Vgl. Weigel, Christoph: Abbildung und Beschreibung der gemein-nützlichen Hauptstände, Regensburg 1698 (Faksimile-Ausgabe Nördlingen 1987), S. 98, 307, 309, 323, 357, 360, 365, 368, 377, 386. 5 Vgl. ebd., S. 53, 194, 236, 274, 287, 292, 300, 318 f., 322, 335, 340 f., 344 f., 349, 354, 360, 364, 375, 381, 386, 390, 410 f., 438, 445, 643. 6 Vgl. Doege, Eckart; Behrens, Bernd-Arno: Handbuch Umformtechnik, Berlin 2010, S. 2. 7 Vgl. Pichol (wie Anm. 2), S. 123.

6  Federhammer mit Elektromotor, um 1910
188

8 Vgl. Türk, Klaus: Bilder der Arbeit. Eine ikonographische Antho- 3 Bildarchiv Preußischer Kulturbesitz; Bild-Nr. 00007809; Co-

logie. Wiesbaden 2000, S. 73–77 sowie Daxelmüller, Chris-

pyright bpk / Lutz Braun.

toph: Der Schmied in der Mythologie von der Antike bis ins 4 Weigel, Christoph: Abbildung und Beschreibung der ge-

Mittelalter. In: Ferrum 77 (2005), S. 17.

mein-nützlichen Hauptstände. Regensburg 1698 (Faksimi-

9 Vgl. Simon-Muscheid, Katharina: „Was nützt die Schuste-

le-Ausgabe Nördlingen 1987), S. 348.

rin dem Schmied?“ Schmiedinnen als Abbild der verkehrten 5 Brockhaus Konversations-Lexikon. Bd. 4, Leipzig u. a. 1894,

Welt und „reale“ Frauenarbeit im mittelalterlichen und früh-

S. 722 b.

neuzeitlichen Schmiedehandwerk. In: Ferrum 77 (2005), S. 53. 6 Bestand Sächsisches Industriemuseum Chemnitz, Foto: Diet-

10 Vgl. Mende, Michael: Wasserhämmer. In: Westfälisches Frei-

mar Träupmann.

lichtmuseum Hagen (Hg.): Vom heißen Eisen. Zur Kulturge-

schichte des Schmiedens. Hagen 1993, S. 44.

11 Vgl. ebd., S. 46.

12 Vgl. Pichol (wie Anm. 2), S. 126 f.

13 Vgl. Paulinyi, Akos; Troitzsch, Ulrich: Mechanisierung und

Maschinisierung. 1600 bis 1840, Berlin 1997, (Propyläen Tech-

nikgeschichte, Bd. 3), S. 402–405.

14 Vgl. Matschoss, Conrad: Ein Jahrhundert deutscher Maschi-

nenbau. Von der Mechanischen Werkstätte bis zur Deutschen Ma-

schinenfabrik 1819–1919. Berlin 1919, S. 123 f.

15 Vgl. Paulinyi und Troitzsch (wie Anm. 13), S. 341 f.

16 Vgl. Rowlandson, T. S.: History of the Steam Hammer. Man-

chester 1875, S. 3 f.

17 Vgl. Wedel, Ernst von: Die geschichtliche Entwicklung des Um-

formens in Gesenken. Berlin Dissertation 1960, S. 134–138.

18 Vgl. o. A.: Federhammer von L. A. Riedinger. In: Dinglers

Polytechnisches Journal 12 (1874), S. 194 f. sowie Lueger, Otto:

Lexikon der gesamten Technik und ihrer Hilfswissenschaften. Bd.

6, Stuttgart/Leipzig, 1908, S. 4 f. sowie Fuchs, Otto: Schmie-

dehämmer. Ein Leitfaden für die Konstruktion und den Betrieb,

Berlin/Heidelberg 1922, S. 45–52.

19 Vgl. Federhammer von L. A. Riedinger (wie Anm. 18), S. 195.

20 Vgl. American Society of Mechanical Engineers: The Creusot

Steam Hammer. An International Historic Mechanical Enginee-

ring Landmark. New York 1981, S. 2 f.

21 Vgl. Fuchs (wie Anm. 18), S. 6 f.

Abbildungsnachweis 1 Wikimedia Commons: https://commons.wikimedia.org/wiki/
File:Agarre_de_un_bifaz.png (14.05.2017); Autor: José-Manuel Benito Alvarez. 2 Amman, Jost: Das Ständebuch. Hg. von Manfred Lemmer. Leipzig 1989, S. 72.
189

Das Spinnen

Manuel Schramm

Das Spinnen ist eine uralte und in vielen Kulturen verbreitete handwerkliche Tätigkeit. Es dient der Herstellung von Garn für die Weiterverarbeitung zu textilen Flächengebilden durch Weben, Wirken oder andere Techniken. Da es somit zur Herstellung von Kleidung beiträgt, befriedigt es ein menschliches Grundbedürfnis. Möglicherweise ist es deswegen stark mythisch aufgeladen. In vielen Märchen nimmt es einen besonderen Platz ein: Dornröschen sticht sich an einer Spindel und fällt in einen hundertjährigen Schlaf, und die Goldmarie gelangt nur zu Frau Holle, weil sie in den Brunnen springt, in den ihre Spindel gefallen war. In der griechischen und römischen Mythologie waren es die Moiren oder Parzen, in der Edda dagegen die Nornen, die als Schicksalsgöttinnen die Lebensfäden der Menschen spannen.1
Das Spinnen ist häufig Symbol des Fleißes, aber Spinnen hat offensichtlich im deutschen Sprachraum auch eine negative Bedeutung (‚Du spinnst wohl‘ oder ‚Du Spinner‘). Woher diese kommt, ist nicht geklärt, möglicherweise von Spintisieren oder Gedanken spinnen.2 Ein Zusammenhang zu den Spinnhäusern der Frühen Neuzeit, die eine Art Besserungsanstalt für kriminelle Frauen darstellten, ist ebenfalls vermutet worden, lässt sich aber nicht nachweisen. Im Englischen bezeichnet ‚spinster‘ sowohl eine Spinnerin als auch eine unverheiratete Frau (mit abwertender Bedeutung).3

1  Die Nornen unter dem Weltenbaum

190

Bis zur Industrialisierung war das Spinnen eindeutig Frauenarbeit. Frauen aller Schichten stellten damit entweder das Garn her, das sie selbst weiter verarbeiteten, oder trugen durch Verkauf des Garns zum Familieneinkommen bei. Spinnen war traditionell Heimarbeit. Allerdings kam es vor, dass mehrere Frauen sich in Spinnstuben zusammenfanden, um Gesellschaft zu haben und um Energie zu sparen. Erst mit der Industrialisierung verlor das Spinnen seinen Charakter als Frauenarbeit. An den Spinnmaschinen des 19. Jahrhunderts waren überwiegend Männer beschäftigt, die zur Bedienung der meist halbautomatischen Maschinen Kraft und Geschicklichkeit aufbringen mussten. In den frühen Fabriken bildeten sie eine Art Arbeiteraristokratie. Erst mit der zunehmenden Mechanisierung verloren sie ihre herausgehobene Stellung.4 Da die Baumwollspinnerei die erste moderne Industrie darstellte, lassen sich an diesem Beispiel besonders gut die Veränderungen im Übergang von der Hand- zur Maschinenarbeit beobachten.
Spinnen ist natürlich keine einzelne Handbewegung. Vielmehr besteht es aus drei Teilen: dem Strecken des Vorfadens, dem Verdrehen oder Verdrillen und dem Aufwickeln des Garns. Je nach verwendetem Spinnverfahren werden diese Phasen gleichzeitig oder nacheinander ausgeführt. Die älteste Form ist das Spinnen mit der Handspindel, mit oder ohne Spinnrocken. Dabei wird das Spinngut mit der linken Hand herausgezogen und verdrillt, während die rechte Hand die vertikal hängende Spindel in Bewegung setzt und weiter Spinngut zuführt. Daumen und Zeigefinger der linken Hand kontrollieren die Zuführung und klemmen den Faden nach kurzer Zeit ab. Zum Aufwickeln muss der Spinnvorgang unterbrochen werden.5
Diese Form des Spinnens existiert seit vorgeschichtlicher Zeit. Die erste Verbesserung war die Einführung des Handspinnrades, die nach dem Jahr 1.000 n. Chr. erfolgte. Das Handspinnrad mechanisierte den Spinnvorgang insofern, als die nunmehr horizontal gelagerte Spindel durch das Drehen eines Handrades in Bewegung gesetzt wurde. Der Spinner oder die Spinnerin bediente mit einer Hand das Rad (meist mit der rechten Hand) und hielt mit der anderen Hand das Faserbüschel (vgl. Abbildung 2). Das Spinnen musste unterbrochen werden, wenn der Arm nicht mehr weiter von der Spindel weggeführt werden konnte. Dann erfolgte das Aufwickeln, wofür das Handrad kurz zurück- und dann wieder vorgedreht wurde, während der Faden parallel zur Spindelachse hin und her bewegt werden musste. Durch die verschiedenen Bewegungen der rechten und linken Hand ergaben sich Koordinationsprobleme, die

Konzentration und Geschick erforderten. Das Spinnen mit dem Handspinnrad war ungefähr doppelt so schnell wie mit der Handspindel, aber es war eine monotone und anstrengende Arbeit, die zudem qualitativ schlechteres Garn lieferte.6
Das Handspinnrad oder Spindelspinnrad war auch in anderen Kulturen verbreitet, z. B. in Indien, wo es „Charkha“ genannt wurde.7 Während der indischen Unabhängigkeitsbewegung stieg es zum Nationalsymbol auf, da es wirtschaftliche Unabhängigkeit von Großbritannien verkörpern sollte. Es kam in verschiedenen Größen vor und konnte auch horizontal angeordnet sein. Der Spinnprozess verlief genauso wie bei dem europäischen Handspinnrad.
Das Handspinnrad blieb bis zur Erfindung verschiedener Spinnmaschinen in der frühen Industrialisierung weit verbreitet. In der Tat wird vermutet, dass James Hargreaves, der Erfinder der „Jenny“, ein solches Handspinnrad weiterentwickeln wollte. Daneben war allerdings bereits seit dem 15. Jahrhundert in Europa das Flügelspinnrad in Gebrauch gekommen, dem um 1530 der Fußantrieb hinzugefügt wurde. Der Erfinder ist, wie häufig in dieser Zeit, unbekannt. Die älteste Abbildung eines Flügelspinnrads stammt aus dem Mittelalterlichen Hausbuch von Schloss Wolfegg um 1480.8
Das Flügelspinnrad unterscheidet sich vom einfachen Handspinnrad dadurch, dass Spinnen und Aufwinden nun in einem Arbeitsgang erfolgen. Wird der Faden straff gehalten, so sind Spindel und Flügel gekuppelt, so dass der Faden nur gedreht und nicht aufgewunden wird. Wird der Faden jedoch locker gehalten, schleppt die Spindel nach und der Faden wird aufgewickelt. Bei einer geübten Spinnerin gehen diese beiden Phasen ineinander über, so dass gleichzeitig gesponnen und aufgewickelt wird. Der Nachteil besteht in der größeren Belastung des Fadens, so dass sich diese Methode vor allem für längere Fasern eignet, wie Leinen oder gekämmte Wolle, und weniger für Baumwolle.9
Die Handhabung des Flügelspinnrads ist einfacher, da das Spinnen nicht mehr abgesetzt in zwei Phasen erfolgt, sondern kontinuierlich. Bei dem weit verbreiteten Tretspinnrad erfolgt der Antrieb per Fuß, so dass die Hände sich auf die Zuführung des Fadens konzentrieren können. Eine Hand zieht dabei Fasern aus dem Faserbündel, die andere Hand steuert die Zuführung. Eine geübte Spinnerin benötigt hierbei keine volle Konzentration mehr. Außerdem gerät das Garn gleichmäßiger. Die Produktivität ist allerdings nicht höher als bei dem größeren Handspinnrad, obwohl die Phase des Aufwickelns wegfällt. Jedoch ist die Drehgeschwindigkeit der Spindel begrenzt, da sonst der

191

2  Indisches Handspinnrad
Faden reißen kann. Somit ist das große Handspinnrad ungefähr doppelt so produktiv wie das Flügelspinnrad. Allerdings standen die beiden nicht direkt in Konkurrenz, da sie für unterschiedliche Garnsorten verwendet wurden.10
Die Industrialisierung des Spinnens knüpfte an beide Spinnarten an, die abgesetzte (Handspinnrad) und die kontinuierliche (Flügelspinnrad). Die von James Hargreaves in den 1760er Jahren erfundene „Jenny“ ging eindeutig auf das Handspinnrad zurück. Es ist unsicher, ob Hargreaves, der weder lesen noch schreiben konnte, das Flügelspinnrad überhaupt kannte. Die ursprüngliche „Jenny“ glich eher einem umgekippten Handrad: Das Rad war horizontal angeordnet und die Spindeln vertikal. In der Tat soll Hargreaves die Idee zu seiner Maschine gehabt haben, als eines Tages ein Handspinnrad in seinem Haus umfiel und sowohl das Rad als auch die Spindel sich weiter drehten.11 Die „Jenny“ wurde zunächst mit acht, in der Patentanmeldung von 1770 bereits mit 16, später mit über 100 Spindeln betrieben. Die Produktivität des Spinnens erhöhte sich damit um ein Mehrfaches.12
Die „Jenny“ ist ein gutes Beispiel dafür, wie Bewegungen von der menschlichen Hand auf eine Maschine übergehen. Hargreaves hatte in der Tat versucht, das Handspinnen (mit dem großen Spinnrad) zu mechanisieren, den Prozess aber weitestgehend beizubehalten. Das führte dazu, dass die Hand des Spinners, die die Fäden hält, durch eine mechanische „Klaue“ (aus zwei horizontalen Holzstangen) ersetzt wurde. Die Bedienung der Jenny war allerdings keineswegs einfach, sondern erforderte viel Geschick. Mit der rechten Hand bediente der (meist männliche) Spinner das Handrad

und mit der linken Hand den Wagen mit der „Klaue“. Zum Aufwinden musste er mit der rechten Hand das Rad drehen, mit der linken Hand den Wagen vorwärts schieben und mit einer Zehe den Umfaller anheben (vgl. Abbildung 5).13
Eine Weiterentwicklung der „Jenny“ war der 1779 von Samuel Crompton erfundene „Mule“ (Maulesel). Crompton übernahm von der „Jenny“ sowohl das Handrad und den Wagen, ordnete aber die Spindeln anders als Hargreaves auf dem Wagen an, und ersetzte die „Klaue“ durch ein Streckwerk mit Walzenpaaren. Die Bedienung blieb aber ganz ähnlich: Es handelte sich um ein abgesetztes Spinnverfahren mit Ausfahrt des Wagens zum Spinnen und Einfahrt zum Aufwinden. Insbesondere die Einfahrt erforderte großes Geschick, da sonst die Gefahr bestand, dass Hunderte von Fäden rissen. Cromptons „Mule“ hatte den Vorteil, dass wesentlich weichere und feinere Garne gesponnen werden konnten. Damit war auch die maschinelle Herstellung von Kettgarn möglich, während die „Jenny“ nur Schussgarn produziert hatte.14 Crompton hatte auf seinem „Mule“ ursprünglich 20 bis 30 Spindeln angebracht, aber weitere Verbesserungen in der Konstruktion machten es möglich, um 1800 bereits Maschinen mit 400 und um 1830 solche mit 1200 Spindeln zu betreiben. 1800 war damit bereits die 170fache Produktivität des Handspinnrades erreicht.15
Bereits kurz nach Erfindung des „Mule“ setzten Bemühungen ein, die Maschine weiter zu automatisieren. 1790 gelang es, die Wagenausfahrt über einen externen Kraftantrieb (Wasserkraft oder Dampfmaschine) zu betreiben.16 Die halbautomatischen Maschinen wurden „Halbselfaktor“ oder „Handmule“ genannt und dominierten zwischen 1800 und 1860 die industrielle Spinnerei. Die Wageneinfahrt erwies sich als schwieriger zu automatisieren, da die Geschwindigkeit des Wagens mit der Drehung der durch das Aufwinden kontinuierlich größer werdenden Kötzer koordiniert werden musste. Erst Richard Roberts gelang 1830 die Lösung dieses technischen Problems.17 Das machte allerdings die Arbeit des Spinners keineswegs überflüssig. Vielmehr bestand seine Aufgabe nunmehr darin, die Maschine zu warten und zu bedienen und im richtigen Moment durch Drehung einer Schraube Anpassungen vorzunehmen. Erst um 1880 war der Selfaktor so weit verbessert, dass er tatsächlich vollautomatisch laufen konnte.18
Ein anderer Weg zur Automatisierung des Spinnens setzte bei der Flügelspindel an. Ungefähr gleichzeitig mit Hargreaves „Jenny“ erfand Richard Arkwright seine Flügelspinnmaschine (waterframe, throstle, Drossel). Er kombinierte dabei die Flügelspindeln mit einem Streckwerk aus

3  Carl Ludwig Jessen, Alte Frau am Spinnrad, 1866

192

193

4  Spinning Jenny

mehreren Walzenpaaren. Der Vorteil lag in der Zeitersparnis von 25 bis 35 Prozent gegenüber der „Jenny“, da genau wie bei dem Flügelspinnrad gleichzeitig gesponnen und aufgewunden wurde. Der Nachteil lag darin, dass der Faden stärker belastet wurde, wodurch die Maschine nur für gröbere und festere Garnsorten geeignet war. Noch 1947 galt das abgesetzte Spinnverfahren aus diesem Grund als technologisch überlegen.19
Die Flügelspinnmaschine funktionierte von Beginn an vollautomatisch, so dass der Spinnerin (hier wurden meist Frauen und Kinder eingesetzt) nur die Überwachung, Wartung und Bedienung der Maschine übrig blieb, insbesondere Anknüpfen gerissener Fäden oder Wechseln der Garnspulen.20 Die Aufgabe der Hand übernahm das Streckwerk. Eine Weiterentwicklung der Flügelspinnmaschine war die 1828 in den USA erfundene Ringspinnmaschine, bei der der Faden durch eine Öse (auch Läufer oder traveller genannt) geführt wurde, die dieselbe Funktion erfüllte wie der Flügel. Der Vorteil lag in dem geringeren Gewicht des Läufers und der geringeren Belastung des Fadens. Damit wurde es möglich, auch feinere Garne zu spinnen.21 Die Ringspinnmaschine setzte sich gegen Ende des 19. Jahrhunderts durch und ist auch heute noch die meistverwendete Spinnmaschine. Daneben wird heute für gröbere Garnsorten auch das Rotorspinnverfahren verwendet, das die Produktivität noch einmal erheblich auf ungefähr das Dreifache steigert.22 Es wurde 1967 in der Tschechoslowakei entwickelt und beruht auf einem völlig anderen Prinzip. Hierbei wird durch eine

Luftströmung das kardierte Vorgarn einem Rotor zugeführt, der ähnlich wie eine Wäscheschleuder funktioniert und das Garn in eine Rille drückt. Der entstehende Faden sieht allerdings ganz anders aus als der im Ringspinnverfahren erzeugte.23 Das Spinnen hat sich damit von der menschlichen Hand emanzipiert, die hier auch nicht mehr maschinell simuliert wird, während bei Ringspinnmaschinen nach wie vor der Einsatz eines Streckwerks üblich ist. Auch das Rotorspinnen läuft vollautomatisch, so dass nur noch die Kannen mit dem Vorgarn eingesetzt und die vollen Spulen abgenommen werden müssen.24
Anmerkungen 1 Vgl. Simrock, Karl: Handbuch der deutschen Mythologie. Bonn
1869, S. 331 sowie Grimm, Jacob und Wilhelm: Deutsches Wörterbuch. Bd. 16, Leipzig 1905, Sp. 2522. 2 Vgl. Küpper, Heinz: Wörterbuch der deutschen Umgangssprache. Stuttgart 1997, S. 783 sowie Grimm (wie Anm. 1), Sp. 2525. 3 Vgl. Cambridge Dictionary: Spinster. Online unter http:// dictionar y.cambridge.org/dictionar y/english/spinster (06.03.2017). 4 Vgl. Winstanley, Michael: The Factory Workforce. In: Rose, Mary (Hg.): The Lancashire Cotton Industry. A History since 1700, Preston 1996, 124–126 sowie Marsden, Richard: Cotton Spinning. London 1903, S. 224 f.

194

5  Spinnerin an Rotorspinnmaschine, Werdau 1987

6  Spinning Jenny in der Sonderausstellung im Industriemuseum Chemnitz

5 Vgl. Bohnsack, Almut: Spinnen und Weben. Entwicklung von Technik und Arbeit im Textilgewerbe. Bramsche 2002, S. 32 f. sowie vgl. Bleeptrack: Spinnen mit der Handspindel. Online unter www.youtube.com/watch?v=68W-vYhxCoc (06.03.2017).
6 Vgl. Bohnsack (wie Anm. 5), S. 62–69. 7 Vgl. Baines, Edward: History of the Cotton Manufacture in
Great Britain. London 1835, S. 68 sowie Bohnsack (wie Anm. 5), S. 164–66. 8 Vgl. Waldburg Wolfegg, Christoph zu (Hg.): Das mittelalterliche Hausbuch, München 1997. 9 Vgl. Bohnsack (wie Anm. 5), S. 115–117. 10 Vgl. ebd., S. 119–123. 11 Vgl. Aspin, Chris; Chapman, Stanley D.: James Hargreaves and the Spinning Jenny. Helmshore 1964, S. 14. 12 Bohnsack (wie Anm. 5), S. 152, schätzt die Produktivität der „Jenny“ auf das Sechsfache der Handspindel bzw. das Dreifache des Handspinnrads. Dieser Schätzung liegt aber die ursprüngliche „Jenny“ mit acht Spindeln zugrunde, die in der Folge rasch verbessert wurde. Der tatsächliche Produktivitätsgewinn dürfte weit höher gewesen sein. 13 Vgl. Aspin und Chapman (wie Anm. 11), S. 44. 14 Vgl. Bohnsack (wie Anm. 5), S. 179–181 sowie Baines (wie Anm. 7), S. 198 f. 15 Vgl. Bohnsack (wie Anm. 5), S. 183. 16 Vgl. Lazonick, William: Industrial relations and technical change. The case of the self-acting mule. In: Cambridge Journal of Economics 3 (1979), S. 236. 17 Vgl. ebd., S. 242. 18 Vgl. Catling, Harold: The Spinning Mule. Preston 1986, S. 10.

19 Vgl. Johannsen, Otto: Handbuch der Baumwollspinnerei. Bd. 4, Leipzig 1947, S. 388.
20 Vgl. Bohnsack (wie Anm. 5), S. 168–170 sowie Johannsen (wie Anm. 19), Bd. 2, S. 292.
21 Vgl. Bohnsack (wie Anm. 5), S. 184 f. sowie Johannsen (wie Anm. 19), S. 507.
22 Vgl. Freeze, Karen Johnson: Innovation and technology transfer during the Cold War. The case of the open end spinning machine from communist Czechoslovakia. In: Technology and Culture 48 (2007), S. 263.
23 Vgl. Arbeitgeberkreis Gesamttextil: Ausbildungsmittel Unterrichtshilfen Textiltechnik. Spinnereitechnik. Dreizylinder- und Rotorspinnerei, Eschborn 1995, S. 343.
24 Vgl. ebd., S. 363.
Abbildungsnachweis 1 Sander, Fredrik: Edda Sämund den Vises, Stockholm 1893. 2 Baines, Edward: History of the Cotton Manufacture in Great
Britain, London 1835, S. 68. 3 Wikimedia Commons: https://commons.wikimedia.org/
wiki/File:1866_Jessen_Alte_Frau_am_Spinnrad_anagoria.jpg (24.05.2017). 4 Byrn, Edward: The Progress of Invention in the 19th Century, New York 1900, S. 421. 5 Bundesarchiv, Bild Nr. 183-1987-1009-003; Autor: Wolfgang Thieme. 6 Foto: Dietmar Träupmann.

195

Das Töpfern

Manuel Schramm

Das Töpfern ist, ähnlich wie das Spinnen, eine uralte Handwerkstechnik. Die ältesten keramischen Erzeugnisse sind ca. 25.000 bis 29.000 Jahre alt. Es handelt sich dabei um frei modellierte Tonfiguren, z. B. die bekannte elf Zentimeter große „Venus von Dolní Vestonice“ (vgl. Abbildung 1).1 Ob es sich hierbei um ein Fruchtbarkeitssymbol oder die Darstellung einer Göttin handelt, ist unbekannt.2 Die ältesten bekannten Tongefäße wurden in China gefunden und sind ca. 20.000 Jahre alt.3 Das Töpfern auf der Töpferscheibe ist dagegen vergleichsweise jung: Es entstand um 3.000 v. Chr. in Mesopotamien. Es ist allerdings möglich, dass es in Indien oder Ägypten bereits vorher praktiziert wurde.4 Vorher verwendete man die Wülst- oder Aufbautechnik, mit der Gefäße aus von Hand gedrehten Wülsten aufgebaut wurden. In der Antike war außerdem auch das Gießen mit Hilfe von gebrannten Tonformen bekannt.5 Das Drehen auf der Töpferscheibe war somit nur eine, wenn auch wichtige, Form der Keramikproduktion neben dem freien Modellieren und dem Gießen.
Aus heutiger Sicht wirkt das Drehen auf der Töpferscheibe als ursprünglich, als eine Technik, die die Jahrtausende unverändert überdauert hat. Darin mag ein Reiz der Arbeit an der Scheibe liegen. Die Töpferscheibe erscheint in einer leicht romantischen Sichtweise als „Urgerät mensch-

1  Die Venus von Dolní Věstonice

196

2  Töpferdarstellungen aus Beni Hasan, ca. 2.000 v. Chr.
licher Handfertigkeit“.6 Zwar ist es richtig, dass die Handgriffe beim Drehen auf der Scheibe im Wesentlichen dieselben bleiben. Dabei wird allerdings übersehen, dass auch die Töpferscheibe eine lange Entwicklungsgeschichte hinter sich hat. Eine der ältesten Abbildungen aus Ägypten zeigt eine niedrig gelagerte Töpferscheibe, an der ein Töpfer sitzt oder kniet. Angetrieben wurde sie offenbar mit der Hand (vgl. Abbildung 2).
Mit dem Fuß angetriebene Töpferscheiben sind seit dem 3. Jahrhundert v. Chr. im Mittelmeerraum nachweisbar. In der römischen Antike war dagegen die mit einem Stab angetriebene Scheibe gebräuchlich. Sie war auch in Deutschland (z. B. in der Eifel) bis um 1900 in Gebrauch und wird heute noch in manchen Gegenden der Welt (z. B. Indien oder Nepal) verwendet.7 Dabei wird die Scheibe mit Hilfe eines fast zwei Meter langen Holzstabes in Betrieb gesetzt, der in ein Loch im Scheibenrand eingreift.8
Die fußgetriebene Scheibe hat gegenüber der Stabscheibe einige Vorteile (vgl. Abbildung 3). So kann kontinuierlich gearbeitet werden, ohne die Formgebung zum Schwungholen unterbrechen zu müssen. Außerdem wurde es möglich, die Arbeitsscheibe vom Schwungkörper zu trennen und nach oben zu verlagern, was eine bequemere Arbeitshaltung ermöglichte. Zudem änderte sich die Drehrichtung von rechts nach links. Allerdings war die niedrig gelagerte Stabscheibe für das Aufziehen großer Gefäße besser geeignet.9 Die fußgetriebene Scheibe setzte sich letztlich in Form der Blockscheibe (oder Sprossenscheibe) durch, die seit dem 13. Jahrhundert nachweisbar ist und ebenfalls bis in das 19. Jahrhundert verwendet wurde.10

Die moderne und am besten bekannte Töpferscheibe ist die so genannte Spindelscheibe, bei der das niedrig gelegene Schwungrad durch eine starre Achse (Spindel) mit dem Arbeitsteller verbunden ist (vgl. Abbildung 4). Sie hat eine größere Schwungkraft als die Blockscheibe, wodurch der Töpfer seinen Fuß von der Scheibe nehmen kann, während er bei der Blockscheibe immer einen Fuß auf der Schwungscheibe hatte.11 Es wird angenommen, dass die Spindelscheibe aus dem Orient nach Europa kam. In Deutschland ist sie im 18. Jahrhundert nachgewiesen, in Italien bereits im 16. Jahrhundert.12
Trotz aller Veränderungen der Drehscheibe bleiben die Handbewegungen im Wesentlichen dieselben, auch wenn heute die Töpferei an der Scheibe nur noch als Kunstgewerbe ausgeübt wird.13 Für die Herstellung von Gebrauchsgütern (Tassen, Teller etc.) ist sie durch moderne Verfahren der Massenproduktion verdrängt worden. Von der Arbeit des Töpfers an der Drehscheibe scheint eine besondere Faszination auszugehen, der sich nur wenige entziehen kön-
3  Töpfer an einer Blockscheibe, 16. Jahrhundert

197

4  Töpfer an der Spindelscheibe, Italien, 16. Jahrhundert

nen. So schrieb der Schriftsteller Edgar Hahnewald 1926: „Man sieht das alles entstehen, aber man errät nicht, wie es gemacht wird. Scheinbar dieselben Handgriffe erzeugen alle Formen. Leichtes bildendes Anschmiegen der Finger, manchmal nur ein Hintippen für eine schnelle Umdrehung verwandelt die Gestalt. Eine Verwandlung geht in die andere über; der Ton scheint unter der Hand des Töpfers zu fließen […] Ja, es scheint kaum die menschliche Hand zu sein, die alle diese Wandlungen bewirkt […]“14
Die Handbewegungen variieren je nach Gefäß, aber es lassen sich doch verschiedene Phasen identifizieren: das Zentrieren des Tonklumpens auf der Scheibe, das Aufbrechen mit beiden Daumen, das Hochziehen der Wände und das weitere Ausformen. Die weitere Formgebung kann außer mit den Händen auch durch verschiedene Werkzeuge wie Wirkspäne, Schienen oder Flaschenknechte erfolgen. Am Ende wird das Gefäß mit einem Draht von der Scheibe abgeschnitten.15
Bei allen Gemeinsamkeiten gibt es in der konkreten Ausführung von Handbewegungen sowohl individuelle Unterschiede als auch solche nach dem Übungsgrad des Töpfers. Eine Untersuchung bei indischen Töpfern ergab, dass z. B. symmetrische Bewegungen (beide Hände tun dasselbe) offenbar als natürlicher empfunden werden als komplementäre (die Hände ergänzen sich durch die Ausführung unterschiedlicher Bewegungen). Mit zunehmendem Ausbil-

dungsgrad nimmt die Zahl der symmetrischen Bewegungen daher ab.16 Gleichzeitig konnte festgestellt werden, dass in der Phase des Hochziehens der Wände im Wesentlichen nur zwei verschiedene Handlungssequenzen verwendet wurden und die befragten Töpfer jeweils eine klare Präferenz für eine der beiden Sequenzen äußerten. In der Phase der Formgebung gab es keine eindeutig identifizierbaren Sequenzen, sondern zahlreiche Varianten. Auch die Zahl der ausgeführten Einzelhandlungen hing nicht nur von der Art des Gefäßes ab, sondern auch von anderen Faktoren wie der Sorgfalt des Töpfers oder der Sorgfalt in der vorhergehenden Phase des Hochziehens. Letztlich besteht die Schwierigkeit aber weniger in der Ausführung einzelner Handlungsteile oder in der Handlungssequenz, sondern in der Ausübung des richtigen Drucks in der jeweiligen Phase.17
Heutzutage werden keramische Erzeugnisse auf sehr verschiedene Art und Weise hergestellt, u. a. durch Gießen, Pressen, Drehen oder Ziehen. Dem Drehen auf der Töpferscheibe kommt das industrielle Drehen am nächsten. Dabei wird zunächst eine Vorform, ein so genannter Hubel, in der Vakuumstrangpresse hergestellt. Der eigentliche Drehvorgang geschieht auf einer drehbaren Spindel, auf der mithilfe eines ebenfalls rotierenden Rollerkopfs die Masse in oder auf eine Gips- oder Kunststoffform gedrückt wird (vgl. Abbildung 5).18 Die Hände des Töpfers werden also ersetzt durch einerseits den Rollerkopf, andererseits die Form. Der

198

5  Maschinelles Drehen mit Rollerkopf
Vorgang ist aber keine Nachbildung der Handbewegungen des Töpfers, sondern erfolgt nach einem anderen Prinzip. Das Töpfern auf der Scheibe wird heutzutage nur noch als Kunstgewerbe betrieben.

ker; Sauermann, Dietmar (Hg.): Volkskunde im Spannungsfeld zwischen Universität und Museum. Münster 1997, S. 193. 8 Vgl. Rieth (wie Anm. 4), S. 48, 54 sowie Czysz, Wolfgang: Geschichte und Konstruktion alter Töpferscheiben. In: Fansa, Mamoun (Hg.): Experimentelle Archäologie in Deutschland. Oldenburg 1990 (Archäologische Mitteilungen aus Nordwestdeutschland, Beiheft 4), S. 309 f. 9 Vgl. Czysz (wie Anm. 8), S. 311 sowie Kerkhoff-Hader (wie Anm. 7, 1), S. 135, 140 f. 10 Vgl. Kerkhoff-Hader, Töpferscheiben und -räder, S. 183; Czysz (wie Anm. 8), S. 311. 11 Vgl. Rieth (wie Anm. 4), S. 57. 12 Vgl. ebd., S. 61 sowie Czysz (wie Anm. 8), S. 313. 13 Vgl. Rieth (wie Anm. 4), S. 72. 14 Vgl. Hahnewald (wie Anm. 6), S. 104. 15 Vgl. Weiß u. a. (wie Anm. 1), S. 86 f. sowie Kerkhoff-Hader (wie Anm. 7, 1), S. 139 f. sowie Roux, Valentine: The Potter’s Wheel. Craft Specialization and Technical Competence. New Delhi 1989, S. 12. 16 Vgl. Roux (wie Anm. 15), S. 42. 17 Vgl. ebd., S. 127. 18 Vgl. Salmang, Hermann; Horst Scholze: Keramik. Berlin/ Heidelberg 2007, S. 606 sowie Hülsenberg, Dagmar: Keramik. Wie ein alter Werkstoff hochmodern wird. Berlin/Heidelberg 2014, S. 46.

Anmerkungen 1 Vgl. Weiß, Gustav u. a.: Reclams Handbuch der künstlerischen
Techniken. Bd. 3, Stuttgart 1986, S. 81, 98. 2 Vgl. Nesbitt, Shawntelle: Venus figurines of the Upper Paleo-
lithic. In: Totem. The University of Western Ontario Journal of Anthropology 9 (2001), S. 53–64. 3 Vgl. Wu, Xiaohing u. a.: Early pottery at 20,000 years ago in Xinrendong Cave, China. In: Science 336 (2012), S. 1696–1700. 4 Vgl. Rieth, Adolf: 5000 Jahre Töpferscheibe. Konstanz 1960, S. 23. 5 Vgl. Weiß u. a. (wie Anm. 1), S. 84. 6 Hahnewald, Edgar: Betrachtungen in einer Töpferei. In: Mitteilungen des Landesvereins Sächsischer Heimatschutz 15 (1926), H. 3–4, S. 103. 7 Vgl. Kerkhoff-Hader, Bärbel: Lebens- und Arbeitsformen der Töpfer in der Südwesteifel. Bonn 1980, S. 132 sowie dies.: Töpferscheiben und -räder in rheinischen Werkstätten des 17.– 20. Jahrhunderts. In: Mohrmann, Ruth-E.; Rodekamp, Vol-

Abbildungsnachweis 1 Wikimedia Commons: https://commons.wikimedia.org wiki/
File:Vestonicka_venuse_edit.jpg (24.05.2017); Autor: Petr Novák. 2 Newberry, Percy E.: Beni Hasan. Bd. 1, London 1893,
Tafel XI. 3 Amman, Jost: Das Ständebuch. Hg. von Manfred Lemmer.
Leipzig 1989, S. 82. 4 Piccolpasso, Cipriano: The Three Books of Potter’s Art. London
1934, Tafel XIV. 5 Foto: Julius Lippert GmbH & Co. KG, Pressath, Online unter
www.lippert.de.

199

