Cognitive Linguistics: Basic Readings
≥

Cognitive Linguistics Research 34
Editors Dirk Geeraerts
Rene´ Dirven John R. Taylor Honorary editor Ronald W. Langacker
Mouton de Gruyter Berlin · New York

Cognitive Linguistics: Basic Readings
Edited by Dirk Geeraerts
Mouton de Gruyter Berlin · New York

Mouton de Gruyter (formerly Mouton, The Hague) is a Division of Walter de Gruyter GmbH & Co. KG, Berlin
Țȍ Printed on acid-free paper
which falls within the guidelines of the ANSI to ensure permanence and durability.
Library of Congress Cataloging-in-Publication Data
Cognitive linguistics : basic readings / edited by Dirk Geeraerts. p. cm. Ϫ (Cognitive linguistics research ; 34)
Includes bibliographical references. ISBN-13: 978-3-11-019084-7 (hardcover : alk. paper) ISBN-10: 3-11-019084-2 (hardcover : alk. paper) ISBN-13: 978-3-11-019085-4 (pbk. : alk. paper) ISBN-10: 3-11-019085-0 (pbk. : alk. paper) 1. Cognitive grammar. I. Geeraerts, Dirk, 1955Ϫ P165.C6424 2006 415Ϫdc22
2006023786
Bibliographic information published by the Deutsche Nationalbibliothek The Deutsche Nationalbibliothek lists this publication in the Deutsche Nationalbibliografie;
detailed bibliographic data are available in the Internet at http://dnb.d-nb.de.
ISBN-13: 978-3-11-019084-7 ISBN-10: 3-11-019084-2 ISSN 1861-4132
Ą Copyright 2006 by Walter de Gruyter GmbH & Co. KG, D-10785 Berlin All rights reserved, including those of translation into foreign languages. No part of this book may be reproduced or transmitted in any form or by any means, electronic or mechanical, including photocopy, recording, or any information storage and retrieval system, without
permission in writing from the publisher. Typesetting: Selignow Verlagsservice, Berlin
Printed in Germany

Contents

Introduction

A rough guide to Cognitive Linguistics

Dirk Geeraerts

1

Chapter 1

Cognitive Grammar

Introduction to Concept, Image, and Symbol

Ronald W. Langacker

29

Chapter 2

Grammatical construal

The relation of grammar to cognition

Leonard Talmy

69

Chapter 3

Radial network

Cognitive topology and lexical networks

Claudia Brugman and George Lakoff

109

Chapter 4

Prototype theory

Prospects and problems of prototype theory

Dirk Geeraerts

141

Chapter 5

Schematic network

Ambiguity, polysemy, and vagueness

David Tuggy

167

Chapter 6

Conceptual metaphor

The contemporary theory of metaphor

George Lakoff

185

Chapter 7

Image schema

The cognitive psychological reality of image schemas and their

transformations

Raymond W. Gibbs, Jr. and Herbert L. Colston

239

vi Contents

Chapter 8

Metonymy

The role of domains in the interpretation of metaphors and metonymies

William Croft

269

Chapter 9

Mental spaces

Conceptual integration networks

Gilles Fauconnier and Mark Turner

303

Chapter 10

Frame semantics

Frame semantics

Charles J. Fillmore

373

Chapter 11

Construction Grammar

The inherent semantics of argument structure: The case of the English

ditransitive construction

Adele E. Goldberg

401

Chapter 12

Usage-based linguistics

First steps toward a usage-based theory of language acquisition

Michael Tomasello

439

Epilogue

Trajectories for further reading

Dirk Geeraerts

459

Publication sources
Chapter 1. Cognitive Grammar
Ronald W. Langacker 1990 Chapter 1. Introduction in Concept, Image, and Symbol: The Cognitive Basis of Grammar, Ronald W. Langacker, 1–32. Berlin/New York: Mouton de Gruyter. (Reprint of An introduction to cognitive grammar. Cognitive Science 10(1): 1–40. 1986.)
Chapter 2. Grammatical construal
Leonard Talmy 1988 The relation of grammar to cognition. In Topics in Cognitive Linguistics, Brygida Rudzka-Ostyn (ed.), 165–205. Amsterdam/Philadelphia: John Benjamins.
Chapter 3. Radial network
Claudia Brugman and George Lakoff 1988 Cognitive topology and lexical networks. In Lexical Ambiguity Resolution: Perspectives from Psycholinguistics, Neuropsychology, and Artiﬁcial Intelligence, Steven L. Small, Garrison W. Cottrell, and Michael K. Tanenhaus (eds.), 477–508. San Mateo, CA: Morgan Kaufmann.
Chapter 4. Prototype theory
Dirk Geeraerts 1989 Prospects and problems of prototype theory. Linguistics 27(4): 587–612.
Chapter 5. Schematic network
David Tuggy 1993 Ambiguity, polysemy, and vagueness. Cognitive Linguistics 4(3): 273–290.
Chapter 6. Conceptual metaphor
George Lakoff 1993 The contemporary theory of metaphor. In Metaphor and Thought, Andrew Ortony (ed.), 202–251. Cambridge: Cambridge University Press.

viii Publication sources
Chapter 7. Image schema
Raymond W. Gibbs, Jr. and Herbert L. Colston 1995 The cognitive psychological reality of image schemas and their transformations. Cognitive Linguistics 6(4): 347–378.
Chapter 8. Metonymy
William Croft 1993 The role of domains in the interpretation of metaphors and metonymies. Cognitive Linguistics 4(4): 335–370.
Chapter 9. Mental spaces
Gilles Fauconnier and Mark Turner 1998 Conceptual integration networks. Cognitive Science 22(2): 133–187.
Chapter 10. Frame semantics
Charles J. Fillmore 1982 Frame semantics. In Linguistics in the Morning Calm, Linguistic Society of Korea (ed.), 111–137. Seoul: Hanshin Publishing Company.
Chapter 11. Construction Grammar
Adele E. Goldberg 1992 The inherent semantics of argument structure: The case of the English ditransitive construction. Cognitive Linguistics 3(1): 37–74.
Chapter 12. Usage-based linguistics
Michael Tomasello 2000 First steps toward a usage-based theory of language acquisition. Cognitive Linguistics 11(1/2): 61–82.
The papers are reprinted with permission. They appear in their original form, except for the following changes: bibliographical entries, section numberings and other typographical elements have been added adjusted to the Mouton style, temporary and incomplete references have been updated, and cross-references to the original volumes have been deleted.

Introduction A rough guide to Cognitive Linguistics
Dirk Geeraerts
So this is the ﬁrst time you visit the ﬁeld of Cognitive Linguistics, no? You may need a guide then. Sure, when you move through the following chapters of this volume, you get to see a top twelve of sights that you should not miss: a delightful dozen of articles written by authorities in the ﬁeld that each introduce one of the conceptual cornerstones of the theoretical framework of Cognitive Linguistics. Still, to give you a ﬁrm reference point for your tour, you may need some initiation to what Cognitive Linguistics is about. That’s what the present chapter is for: it provides you with a roadmap and a travel book to Cognitive Linguistics. It’s only a rough guide, to be sure: it gives you the minimal amount of background that you need to ﬁgure out the steps to be taken and to make sure that you are not recognized as a total foreigner or a naïve apprentice, but it does not pretend to supply more than that.
To understand what you may expect to ﬁnd in this brief travel guide, we need to introduce one of the characteristic ideas of Cognitive Linguistics ﬁrst – the idea, that is, that we should not just describe concepts and categories by means of an abstract deﬁnition, but that we should also take into account the things that the deﬁnition is about, if we are to achieve an adequate level of knowledge. Take birds: you can deﬁne birds as a certain type of animal with certain characteristics (like having wings, being able to ﬂy, and being born from eggs), but if you want to get a good cognitive grip on what birds are, you will want to have a look at some typical birds like robins and sparrows and doves, and then maybe also at some less typical ones, like chickens and ostriches.
It’s no different when you are dealing with linguistic theories. You have to know about the scientiﬁc content of the theory, that is to say, the abstract deﬁnition of the approach: the topics it deals with, the speciﬁc perspective it takes, and the observations it makes. But you also have to know about the sociology of the theory: the people it involves, the conferences where they meet, the channels in which they publish. Introductions to linguistics tend to focus on the ﬁrst perspective only, but the present guide will take the second into account just as much as the ﬁrst.

2 Dirk Geeraerts
1. What is so special about this place?
Theories in linguistics tend to be fairly insular affairs: each theoretical framework tends to constitute a conceptual and sociological entity in its own right, with only a limited number of bridges, market places or even battlegrounds shared with other approaches. Cognitive Linguistics, when considered in the light of this metaphor, takes the form of an archipelago rather than an island. It is not one clearly delimited large territory, but rather a conglomerate of more or less extensive, more or less active centers of linguistic research that are closely knit together by a shared perspective, but that are not (yet) brought together under the common rule of a well-deﬁned theory. The present volume contains an introduction to twelve fundamental parts of that theoretical conglomerate – a tour of twelve central islands, if you wish: Cognitive Grammar, grammatical construal, radial network, prototype theory, schematic network, conceptual metaphor, image schema, metonymy, mental spaces, frame semantics, construction grammar, and usage-based linguistics.
We will deﬁne in a moment what links hold these concepts together and why each of them separately is important, but at this point, the chief thing is to realize that there is no single, uniform theoretical doctrine according to which these research topics belong together: Cognitive Linguistics is a ﬂexible framework rather than a single theory of language. From the point of view of category structure (one of the standard topics for analysis in Cognitive Linguistics), this recognition is again one way in which Cognitive Linguistics illustrates its own concepts. As we mentioned a moment ago, Cognitive Linguistics emphasizes the fact that deﬁning a category may involve describing some of its principal members rather than just giving an abstract deﬁnition. But it also stresses that the abstract deﬁnition need not consist of a single set of deﬁning characteristics that belong uniquely and distinctively to that category. Think of birds again: when we describe the features of birds, we soon notice that the features we would like to think of as deﬁnitional for birds are not shared by all members of the species: we may even ﬁnd birds like the penguin or the kiwi, that have no wings to speak of, cannot ﬂy, and don’t have feathers but that are rather covered with some kind of ﬂuff. In such cases, we say that a category has a family resemblance structure: different types of birds resemble each other like the members of a family would, but there is no single set of attributes that necessarily shows up in all the members of the family. Again, it is no different with a linguistic framework like Cognitive Linguistics: it constitutes a cluster of many partially overlapping approaches rather than a single well-deﬁned theory that identiﬁes in an all-or-none fashion whether something belongs to Cognitive Linguistics or not.
Then again, the recognition that Cognitive Linguistics has not yet stabilized into a single uniform theory should not prevent us from looking for fundamental

Introduction: A rough guide to Cognitive Linguistics 3
common features and shared perspectives among the many forms of research that come together under the label of Cognitive Linguistics. An obvious question to start from relates to the ‘cognitive’ aspect of Cognitive Linguistics: in what sense exactly is Cognitive Linguistics a cognitive approach to the study of language?
Terminologically speaking, we now need to make a distinction between Cognitive Linguistics (the approach represented in this reader), and uncapitalized cognitive linguistics – referring to all approaches in which natural language is studied as a mental phenomenon. Cognitive Linguistics is but one form of cognitive linguistics, to be distinguished from, for instance, generative grammar and many other forms of linguistic research within the ﬁeld of cognitive science. What, then, determines the speciﬁcity of Cognitive Linguistics within cognitive linguistics?
There are a number of characteristics that need to be mentioned: one basic principle that is really, really foundational, and four tenets that spell out this fundamental notion. The foundational point is simply that language is all about meaning. As it says in the Editorial Statement of the very ﬁrst issue of the journal Cognitive Linguistics, published in 1990, this approach sees language ‘as an instrument for organizing, processing, and conveying information’ – as something primarily semantic, in other words. Now, it may seem self-evident to you that a ‘cognitive’ approach to language focuses on meaning, but if you are familiar with generative grammar (i.e. Chomskyan linguistics), you will know that this is a theory that thinks of language primarily in formal terms: as a collection of formal, syntactic structures and rules (or constraints on such structures and rules). And generative grammar is deﬁnitely also a ‘cognitive’ conception of language, one that attributes a mental status to the language. So we have to be careful with the term cognitive in Cognitive Linguistics. It does not only signal that language is a psychologically real phenomenon (and that linguistics is part of the cognitive sciences), but also that the processing and storage of information is a crucial design feature of language. Linguistics is not just about knowledge of the language (that’s the focus of generative grammar), but language itself is a form of knowledge – and has to be analyzed accordingly, with a focus on meaning.
Conversely, Cognitive Linguistics is not the only linguistic approach focusing on meaning: there are diverse forms of functional approaches to language that go in the same direction. And further, formal semantics is clearly a semantically oriented approach as well. It lies beyond the scope of this introduction to provide a systematic comparison with these other semantic approaches, but you will certainly be interested in what is particular about the way in which Cognitive Linguistics deals with meaning. So that brings us to the four speciﬁc characteristics that we announced earlier: each of them says something speciﬁc about the way Cognitive Linguistics thinks about meaning. (By the way, the captions we use to introduce the features may sound formidable, but don’t worry: an explanation follows.)

4 Dirk Geeraerts
LINGUISTIC¬MEANING¬IS¬PERSPECTIVAL
Meaning is not just an objective reﬂection of the outside world, it is a way of shaping that world. You might say that it construes the world in a particular way, that it embodies a perspective onto the world. The easiest way to understand the point is to think of spatial perspectives showing up in linguistic expressions, and the way in which the same objective situation can be construed linguistically in different ways. Think of a situation in which you are standing in your back garden and you want to express where you left your bicycle. You could then both say It’s behind the house and It’s in front of the house. These would seem to be contradictory statements, except that they embody different perspectives.
In the ﬁrst expression, the perspective is determined by the way you look: the object that is situated in the direction of your gaze is in front of you, but if there is an obstacle along that direction, the thing is behind that obstacle. In this case, you’re looking in the direction of your bicycle from the back garden, but the house blocks the view, and so the bike is behind the house.
In the second expression, however, the point of view is that of the house: a house has a canonical direction, with a front that is similar to the face of a person. The way a house is facing, then, is determined by its front, and the second expression takes the point of view of the house rather than the speaker, as if the house were a person looking in a certain direction. Such multiple perspectivizations (and not just spatial ones!) are everywhere in the language, and Cognitive Linguistics attempts to analyze them.
LINGUISTIC¬MEANING¬IS¬DYNAMIC¬AND¬mEXIBLE
Meanings change, and there is a good reason for that: meaning has to do with shaping our world, but we have to deal with a changing world. New experiences and changes in our environment require that we adapt our semantic categories to transformations of the circumstances, and that we leave room for nuances and slightly deviant cases. For a theory of language, this means that we cannot just think of language as a more or less rigid and stable structure – a tendency that is quite outspoken in twentieth century linguistics. If meaning is the hallmark of linguistic structure, then we should think of those structures as ﬂexible. Again, we don’t have to look far for an example. Think back to what we said about birds: there is no single, rigid set of deﬁning features that applies to all and only birds, but we have a ﬂexible family resemblance structure that is able to deal with marginal cases.
LINGUISTIC¬MEANING¬IS¬ENCYCLOPEDIC¬AND¬NONAUTONOMOUS
If meaning has to do with the way in which we interact with the world, it is natural to assume that our whole person is involved. The meaning we construct in

Introduction: A rough guide to Cognitive Linguistics 5
and through the language is not a separate and independent module of the mind, but it reﬂects our overall experience as human beings. Linguistic meaning is not separate from other forms of knowledge of the world that we have, and in that sense it is encyclopedic and non-autonomous: it involves knowledge of the world that is integrated with our other cognitive capacities. There are at least two main aspects to this broader experiential grounding of linguistic meaning.
First, we are embodied beings, not pure minds. Our organic nature inﬂuences our experience of the world, and this experience is reﬂected in the language we use. The behind/in front of example again provides a clear and simple illustration: the perspectives we use to conceptualize the scene derive from the fact that our bodies and our gaze have a natural orientation, an orientation that deﬁnes what is in front of us and that we can project onto other entities, like houses.
Second, however, we are not just biological entities: we also have a cultural and social identity, and our language may reveal that identity, i.e. languages may embody the historical and cultural experience of groups of speakers (and individuals). Again, think of birds. The encyclopedic nature of language implies that we have to take into account the actual familiarity that people have with birds: it is not just the general deﬁnition of bird that counts, but also what we know about sparrows and penguins and ostriches etc. But these experiences will differ from culture to culture: the typical, most familiar birds in one culture will be different from those in another, and that will affect the knowledge people associate with a category like ‘bird’.
LINGUISTIC¬MEANING¬IS¬BASED¬ON¬USAGE¬AND¬EXPERIENCE
The idea that linguistic meaning is non-autonomously integrated with the rest of experience is sometimes formulated by saying that meaning is experientially grounded – rooted in experience. The experiential nature of linguistic knowledge can be speciﬁed in yet another way, by pointing to the importance of language use for our knowledge of a language.
Note that there is a lot of abstract structure in a language: think for instance of the pattern Subject – Verb – Direct Object – Indirect Object that you ﬁnd in a sentence like Mary sent Peter a message. In many languages, such structures are not directly observable: what we do observe, i.e. what constitutes the experiential basis for our knowledge of the language, is merely a succession of words (and even that is not entirely without problems, but let’s pass over those). So the question arises: how does this more concrete level of words relate to the abstract level where you ﬁnd functional categories like Subject and Direct Object? In more traditional terms, the question reads: how does the lexicon relate to the syntax?
But if we think of grammatical patterns as having an experiential basis in concrete, observable strings of words, there is yet another step we have to take: the ‘observable strings of words’ do not exist in the abstract; they are always part

6 Dirk Geeraerts
of actual utterances and actual conversations. The experience of language is an experience of actual language use, not of words like you would ﬁnd them in a dictionary or sentence patterns like you would ﬁnd them in a grammar. That is why we say that Cognitive Linguistics is a usage-based model of grammar: if we take the experiential nature of grammar seriously, we will have to take the actual experience of language seriously, and that is experience of actual language use. Again, from the point of view of mainstream twentieth century linguistics, that is a fairly revolutionary approach. An existing tradition tended to impose a distinction between the level of language structure and the level of language use – in the terms of Ferdinand de Saussure (generally known as the founder of modern linguistics), between langue and parole. Generally (and speciﬁcally in the tradition of generative grammar), parole would be relatively unimportant: the structural level would be essential, the usage level epiphenomenal. In a usagebased model that considers the knowledge of language to be experientially based in actual speech, that hierarchy of values is obviously rejected.
2. What does the tour include?
You are right, of course: the ﬁrst exploration of Cognitive Linguistics in the previous section remains somewhat superﬁcial and abstract. You now have a general idea of what type of scenery to expect in the Cognitive Linguistics archipelago, but you would like to get acquainted with the speciﬁc islands, i.e. you now know what the overall perspective of Cognitive Linguistics entails, but you hardly know how it is put into practice. In this section, we will have a look at the twelve basic concepts that are introduced by the dozen articles in this collection, and we will show how these concepts relate to the overall picture that was drawn in the previous pages.
As a preliminary step, let us observe that each of the characteristics that we discussed earlier deﬁnes a number of speciﬁc questions for Cognitive Linguistics. The perspectival nature of meaning raises questions about the speciﬁc mechanisms of construal present in a language: what kinds of semantic construal, imagery, conceptual perspectivization do languages implement? The dynamic nature of meaning raises questions about the process of meaning extension: what are the mechanisms of semantic ﬂexibility, and how do the various readings of a linguistic expression relate to each other? The encyclopedic nature of meaning raises questions about the interdisciplinary links of language to the other cognitive capacities: to what extent are the cognitive mechanisms at work in natural language shared by other cognitive systems? And the usage-based nature of meaning raises questions about the relationship between syntax and lexicon, and the acquisition of language: what kind of experience do children need to learn a language?

Introduction: A rough guide to Cognitive Linguistics 7
These questions are illustrated in various ways by the articles in the collection, but before we can make that explicit, we need to introduce the articles separately, and say something about the way in which they are grouped together. Roughly, there are four groups of concepts and articles, corresponding to the four features that we identiﬁed before. The following pages pay speciﬁc attention to the logic behind the basic concepts that we introduce: why is it that these concepts are so important to Cognitive Linguistics? What you should see, in particular, is how they turn the fundamental features that we discussed in the previous section, into a concrete practice of linguistic description. Reading through the following pages will give you an initial idea of what you can expect in the volume, but of course, until you get there yourself, you will never really know what it is about.
2.1. The perspectival nature of grammar
The ﬁrst two concepts, COGNITIVE¬GRAMMAR and GRAMMATICAL¬CONSTRUAL, illustrate the overall organization of a grammar that focuses on meaning. If conceptual perspectivization is the central function of a grammar, the typical formal categories of grammatical description (like word classes or inﬂection) will have to be reinterpreted from a semantic point of view. In the context of Cognitive Linguistics, two authorities in particular are systematically exploring these phenomena: Ronald W. Langacker, and Len Talmy. The two initial papers in the volume will introduce you to the thought of these two major thinkers – towering ﬁgures in the context of Cognitive Linguistics, who have both provided the approach with some of its basic vocabulary.
COGNITIVE¬GRAMMAR
Cognitive Grammar is the speciﬁc name that Langacker uses for his theory of language. The paper included in the present volume originates from 1986, but is here reprinted in the form in which it was published in 1990. It speciﬁes a number of basic features of Cognitive Grammar that are still valid, and that form an interesting backdrop for the rest of the articles in the present collection. Langacker starts off with the very idea of a perspectival grammar – although he uses a slightly different terminology: he talks about grammar as conceptualization and imagery. He introduces a number of high level general features of grammatical ‘imagery’ (proﬁling, speciﬁcity, scope, salience) and then tackles the key question how to build a descriptive framework for a grammar that starts from the assumption, simplistically, that language is meaning and that meaning is conceptualization.
Central to his answer is the idea that a grammar is not built up out of grammatical rules on the one hand and a lexicon on the other (the idea that you traditionally ﬁnd in generative grammar). Rather, a grammar consists of ‘symbolic

8 Dirk Geeraerts
units’, where a symbolical unit is a conventional pairing of a form and a meaning. You can obviously think of lexical items here, but symbolic units can be more abstract than that, like when nouns are claimed to instantiate the abstract notion ‘thing’, and verbs the abstract notion ‘process’. Given that you take the notion of symbolic unit as the basis for a grammar, there are two questions that immediately crop up, and Langacker does not fail to address them.
First, what could be the notional, conceptual characterization of abstract entities like word classes? What do we mean when we say that the meaning of nouns is ‘thing’ and that of verb is ‘process’? On conceptual grounds, Langacker distinguishes between a number of basic classes of predications: entities and things versus relations, and within the relational predicates, stative relations, complex atemporal relations, and processes. The formal word classes of a language will typically express a basic type of predication. For instance, while nouns express the notion of ‘thing’ (a bounded entity in some domain), adjectives will typically be stative relational predicates.
Second, if you have a grammar with no rules but only symbolic units, how do you achieve compositionality, i.e. how do you ensure that different symbolic units may be combined to build larger units, like phrases or sentences? Here, the trick is to recognize that many predicates have open slots. If, for instance, the meaning of above is deﬁned in terms of a stative relationship between what Langacker calls a ‘trajector’ and a ‘landmark’, the trajector and the landmark are only included schematically, as an open slot, in the meaning of above. Filling out the slots with other predicates then compositionally yields phrases like the lamp above the table.
In the course of Langacker’s paper, you will come across a number of concepts that will play a central role in some of the other chapters included in the present collection: the schematic network idea (which will come to the fore in Chapter 5), the notion of domain matrix (which will play an essential role in Chapter 8), and the concept of a construction and a continuum between lexicon and grammar (which will constitute the focus of Chapter 11 and Chapter 12).
GRAMMATICAL¬CONSTRUAL
Talmy never suggested a speciﬁc label for his approach to grammatical description, but the label grammatical construal captures very well what he is doing: what are the forms and patterns of construal (in the sense of conceptual perspectivization through language) that are realized by the grammatical structure of a language? This adjective grammatical is quite important here: Talmy focuses on the speciﬁc types of conceptual construal that are expressed by those aspects of natural language that have to do with syntax and morphology, rather than the lexicon. In Langacker’s article, we noticed a speciﬁc interest in the relationship between the

Introduction: A rough guide to Cognitive Linguistics 9
lexical dimension of the language, and the structural dimension – the syntax and the morphology. Talmy notes that there are some forms of conceptual construal that are hardly ever expressed by the grammatical structure (like color), whereas others (like the distinction between singular and plural) are typically expressed by syntax and morphology. The bulk of Talmy’s paper, then, provides an overview of different types of conceptual construal systems that are typical for the structural, grammatical rather than the lexical subsystem of natural languages.
2.2. The dynamic nature of grammar
If natural language signs are ﬂexible, we will need a model to describe how the different readings of the expressions relate to each other. Several such models for the polysemic architecture of expressions have been proposed by Cognitive Linguistics, and the three concepts in this group describe the most important of them.
RADIAL¬NETWORK
The radial network model describes a category structure in which a central case of the category radiates towards novel instances: less central category uses are extended from the center. The paper featured in this collection, ‘Cognitive topology and lexical networks’ by Claudia Brugman and George Lakoff is based on Brugman’s seminal analysis of the preposition over. The study was seminal not just in the sense that it popularized the radial network model, but also because it spawned a whole literature on the analysis of prepositions (more on this in the Further reading chapter). Brugman suggests the ‘above and across’ reading of over (as in the plane ﬂew over) as central, and then shows how less central readings extend from the central case. These can be concrete extensions, as in a ‘coverage’ reading (the board is over the hole), but also metaphorical ones, as in temporal uses (over a period of time).
PROTOTYPE¬THEORY
Radial categories constitute but one type of a broader set of models that fall under the heading of prototype theory. For instance, the importance of speciﬁc birds in the category structure of bird (this is a point we drew the attention to before) belongs in the same set of phenomena as the radial set idea. The paper ‘Prospects and problems of prototype theory’ by Dirk Geeraerts presents a systematic overview of the different prototype-theoretical phenomena that are mentioned in the literature. Speciﬁc attention is paid to the mutual relations that exist among these phenomena: it is argued that prototype is itself a prototypically structured

10 Dirk Geeraerts
concept, i.e. that there is no single deﬁnition that captures all and only the diverse forms of ‘prototypicality’ that linguists have been talking about.
SCHEMATIC¬NETWORK
Prototype theory as described in the previous article is a generalization over the radial network model. But there is another generalization to introduce: the schematic network model. What this adds to the radial network and prototype models is the idea that the dynamism of meaning may also involve a shift along a taxonomical dimension. This may need some explanation. Note that we can think of birds at different levels of conceptual abstraction (or schematicity, as it is also called). At one level, we have a prototypical idea of birds as living beings that have feathers and wings and that can ﬂy. If we stay on this level, we can move from the central prototype cases (the ones that correspond to the central concept) to peripheral cases, like birds without feathers and wings (we mentioned penguins and kiwis before). But there are other levels at which you can think of birds: more speciﬁc ones (as when you think about individual birds, like your great-uncle’s parrot) and more general ones (like when you group bird species into categories like ‘fowl’, ‘birds of prey’, ‘water birds’ etc.).
Moving from a more speciﬁc to a more general level is called ‘schematization’, and the resulting model of readings for an expression is called a schematic network. The idea of schematic networks is implicit in prototype theory, but it has been made most explicit by Ronald W. Langacker. The concept plays an important role in construction grammar (see below), but here, in David Tuggy’s paper ‘Ambiguity, polysemy and vagueness’, it is applied to a crucial question about meaning: the relationship between vagueness and polysemy: in a schematic network, you accept that what is polysemy (different meanings) at one level is vagueness (a less speciﬁed meaning potential) at an other, more schematic level. In a very clear and graphical way, Tuggy shows how this shift between levels is a contextual effect: in one situation we may use an expression rather more vaguely, in another we use it at a more speciﬁc, polysemous level.
The consequences for our conception of semantic dynamism are tremendous. The dynamism of meaning does not just imply that it is easy to add new meanings to the semantic inventory of an expression, but also that we should not think of this overall structure of meanings as stable. The semantics of lexical and constructional units is not a bag of meanings, but is a (prototypically and schematically) structured meaning potential that is sensitive to contextual effects.

Introduction: A rough guide to Cognitive Linguistics 11
2.3. The non-autonomy of grammar
If meaning is non-autonomous and encyclopedic, it is important to investigate the way in which different types of experience interact with each other. How for instance does our bodily experience of a sensory or motor kind relate to our more abstract thought, and are there any conceptual mechanisms that cut across the sensorimotor and the abstract mode of human knowledge? The four papers brought together in this group show how Cognitive Linguistics deals with the encyclopedic entrenchment of linguistic meaning, from both perspectives: what is the role of general cognitive mechanisms, and how do speciﬁc domains of experience interact?
Two of the four concepts that will be introduced are not speciﬁc for Cognitive Linguistics: metaphor and metonymy are traditional concepts in natural language semantics. Cognitive Linguistics has however brought new perspectives to the study of both metaphor and metonymy, and we will see in what sense. The other two concepts were newly introduced by Cognitive Linguistics. Incidentally, the fact that metaphor and metonymy are traditionally known as mechanisms of semantic change, makes clear that there is a certain degree of overlap between the present group of concepts and the previous one: some of the concepts mentioned here may also be seen as illustrations of the dynamic nature of meaning.
CONCEPTUAL¬METAPHOR
Conceptual metaphor is probably the best known aspect of Cognitive Linguistics: if you’ve heard only vaguely about Cognitive Linguistics, conceptual metaphor is likely to be the notion that you’ve come across. You will have learnt by now that there is much more to Cognitive Linguistics, but still, Conceptual Metaphor Theory occupies a major place in the cognitive linguistic research program. Conceptual Metaphor Theory rests on the recognition that a given metaphor need not be restricted to a single lexical item, but may generalize over different expressions. Such general patterns may then be summarized in an overall statement like LOVE¬ IS¬WAR, a pattern that ranges over expressions like the following:
He is known for his many rapid conquests. She fought for him, but his mistress won out. He ﬂed from her advances. She pursued him relentlessly. He is slowly gaining ground with her. He won her hand in marriage. He overpowered her. She is besieged by suitors. He has to fend them off. He enlisted the aid of her friends. He made an ally of her mother. Theirs is a misalliance if I’ve ever seen one.
This way of thinking about metaphor was introduced in George Lakoff’s and Mark Johnson’s book Metaphors we live by of 1980, a book that has achieved something of a bestseller status. The article included here, Lakoff’s ‘The contem-

12 Dirk Geeraerts
porary theory of metaphors’ gives a systematic overview of the theoretical and practical features of Conceptual Metaphor Theory.
You will notice how the two aspects of non-autonomy that were mentioned earlier show up in conceptual metaphor theory. First, metaphor is treated as a general cognitive mechanism, not as a speciﬁcally linguistic one that works on the level of individual expressions. Second, metaphor involves the interaction between different domains of experience: a source domain (in the example, war) and a target domain (love). This notion of domain will turn out to be crucially important for the other concepts in this group as well.
IMAGE¬SCHEMA
An image schema is a regular pattern that recurs as a source domain (or a structuring part of a source domain) for different target domains. Typical image schema’s include containment, path, scales, verticality, and center-periphery. The recurrence of image schemas may be illustrated by a closer look at the containment schema. It occurs in conceptual metaphors in which containment is the source domain for widely diverse target domains like the visual ﬁeld (in sight, out of sight, go out of view, inside someone’s ﬁeld of vision), time (in two hours, he’s into the ﬁrst year of his retirement, do something in a short period), difﬁculties (get yourself into difﬁculties, we’re in this together, how do we get out of this, to be in a mess), obligations (what are you getting into, no way out, can he get out of it), and the self as contained in the body (withdraw into oneself, a young man in an old man’s body, there’s an insecure person inside).
Characteristically, image schemas involve some form of sensory or motor experience, like a spatial conﬁguration in the case of containment. In that sense, the appearance of image schemas in metaphors is typical for the encyclopedic, non-autonomous nature of meaning: prelinguistic domains, like the sensorimotor or spatial ones are mapped onto more abstract domains, providing them with structure. The notion of image schema, like the notion of conceptual metaphor, was introduced into Cognitive Linguistics by George Lakoff in his collaboration with the philosopher Mark Johnson. The paper included here, ‘The cognitive psychological reality of image schemas and their transformations’ by Ray Gibbs and Herb Colston, examines the psychological reality of image schemas: how can you prove, by means of experimental methods, that image schemas do indeed have a psychological reality?
In this sense, the paper is not just important as an illustration of the notion of image schema, but also for methodological reasons. The particular theoretical perspective of Cognitive Linguistics has a number of far-reaching methodological consequences. For one thing, treating meaning as a mental phenomenon and focusing on language as a cognitive tool implies that a rapprochement with the methodology of psychological research is obvious: experimental methods should

Introduction: A rough guide to Cognitive Linguistics 13
bear fruit in Cognitive Linguistics just like they do in psychology. For another, the idea that grammar is usage-based implies that the analysis of actual usage data (as in corpora, speciﬁcally) should play an important role in Cognitive Linguistics. The paper by Gibbs and Colston is an example of such an experimental approach. An example of a corpus-based methodology is presented in Tomasello’s paper in this volume.
However, neither the use of an experimental method nor the use of corpus data is as yet a dominant methodology in Cognitive Linguistics. They constitute emerging tendencies that are likely to gain in importance in the course of the following years, but a lot of the work done in Cognitive Linguistics is still based on a more traditional analytic methodology.
METONYMY
There is yet another way in which thinking in terms of domains plays a role in Cognitive Linguistics, viz. in the analysis of metonymy. In the tradition of lexical semantics, metaphor and metonymy are distinguished on the basis of the type of semantic association they involve. Metaphor is supposed to be based on similarity (if love is war, it is like war in a number of respects), whereas metonymy is said to be based on contiguity – a somewhat vague notion that could be clariﬁed in terms of ‘actual proximity or association’. For instance, when you ﬁll up your car, you don’t ﬁll the entire vehicle with fuel, but only the gas tank. The name of the whole comes to stand for the part, and part and whole are associated in reality.
Now, metonymy research in Cognitive Linguistics received an important impetus from the recognition that metonymy could receive a deﬁnition that is nicely complementary to that of metaphor. If metaphor is seen as a mapping from one domain to the other, metonymy can be seen as a mapping within a single domain. The shift from whole to part in car is a shift within the physical, spatial domain. This view on the relationship between metaphor and metonymy was already made in Lakoff and Johnson’s Metaphors we live by, but the article ‘The role of domains in the interpretation of metaphors and metonymies’ by William Croft adds an innovative perspective. The relevant shift, Croft argues, is not necessarily one within a single domain, but it may be a shift within a domain matrix.
The domain matrix is a notion introduced by Ronald W. Langacker: it captures the idea that a concept may be simultaneously deﬁned in various domains. For instance, Shakespeare is not only deﬁned as a physical person, but also in the literary domain, as an author. So, when you say that you have read the whole of Shakespeare, you metonymically mean the entirety of his literary production, rather than the person. What Croft suggests, then, is to deﬁne metonymy overall in terms of such a domain matrix.

14 Dirk Geeraerts
MENTAL¬SPACES
If metaphor is analyzed as a mapping from one domain to another, the question arises how such mappings take place: how does the structure of the source domain get mapped onto the target domain? The notion of conceptual integration developed by Gilles Fauconnier, and represented here by the paper ‘Conceptual integration networks’ by Gilles Fauconnier and Mark Turner, provides a descriptive framework to answer that question. It distinguishes between four spaces: a source input space, a target input space, a blend between both, and a so-called generic space. For instance (to use an example ﬁrst described by Seana Coulson), you can think of ‘trashcan basketball’ as a game in which you throw crumpled pieces of paper into a trashcan, as you might do in an ofﬁce environment or in a student dorm. The game of basketball is one input space, and the ofﬁce or the dorm situation the other. The mapping between the two spaces associates the ball with the piece of paper, the basket with the trashcan, the players with the students or the ofﬁce people, and further elaborations are possible. This mapping creates a blended space, and the relevant features of the blend are not just directly derived from the original input spaces. On the contrary, you may ﬁnd emergent structure that is speciﬁc to the blended space: the fact that the trashcan would normally be placed on the ground, in contrast with a basketball ring, would certainly inﬂuence the way the game is played. The fourth type of space, the generic space, contains the common structure of the input spaces; in this case, it would be the space of someone throwing an object into a container.
The description of the four spaces may also explain some of the alternative names that the conceptual integration approach is known by: the blending or the mental spaces approach. As mentioned, the conceptual integration approach clearly links up with the analysis of metaphor as mapping across domains: one might say that the trashcan example elaborates the metaphor ‘a trashcan is a basketball ring’. However, the blending analysis is more general than the study of metaphor. Conceptual integration has proved to be useful in a wide variety of phenomena, many of which are not even remotely associated with metaphorical processes. Counterfactuals are a case in point. If Beethoven were alive, he would use a synthesizer creates a blended space between the present-day musical situation and the historical space of Beethoven as an innovative composer, but you cannot really say that the conceptual process is a metaphorical one.
2.4. The experiential grounding of grammar
You will remember that the experiential nature of language raised the question of the relationship between lexicon and syntax. Cognitive Linguistics provides a speciﬁc answer to that question that links up with what we said about prototype

Introduction: A rough guide to Cognitive Linguistics 15
theory and schematic networks: we can think of a grammar as a schematic network with abstract patterns at the schematic level, and the lexicalized instantiations of those patterns (the words and strings of words that ﬁll the patterns) at a more speciﬁc level. From the point of view of mainstream twentieth century linguistics, this is a bit of a strange idea. If you assume (as generative grammar so vehemently stressed) that grammar is a set of rules, the lexical items instantiating those roles are not all that important: you basically need an inventory of items, but the real work is done by the rules.
However, Ronald W. Langacker has pointed out that there is a fallacy here: the so-called rule/list fallacy, i.e. the idea that what can be handled by rules should not be listed. If you start from that assumption, you get a strict separation between lexicon and syntax. But if you think in terms of schematic networks, such a separation is not necessary at all: you can both describe abstract patterns and their concrete lexicalizations. In fact, you have to, because there are prototypicality effects that you may need to describe. An indirect object construction of the type Subject – Verb – Direct Object – Indirect Object is typically ﬁlled by verbs like give or tell, and less typically so by verbs like envy. It is part of our grammatical knowledge that we recognize those typicalities (just like we recognize blackbirds as more typical birds than ostriches).
The speciﬁc form in which this idea is realized in Cognitive Linguistics, is in the form of construction grammars. The plural is deliberate here: since there are various forms of construction grammar, Construction Grammar is a family of theories rather than a single well-deﬁned approach. The three papers in this group all involve Construction Grammar, but it is the paper by Goldberg (Chapter 11, the second one in the group) that introduces the approach most directly. The ﬁrst paper in the group presents frame semantics, which is one of the important sources for Construction Grammar. The ﬁnal paper show how the principles of Construction Grammar can be applied in language acquisition research.
FRAME¬SEMANTICS
Frame semantics is the speciﬁc approach to natural language semantics developed by Charles Fillmore. The article included here, ‘Frame semantics’, sets out the basics of the theory. One essential starting-point is the idea that one cannot understand the meaning of a word (or a linguistic expression in general) without access to all the encyclopedic knowledge that relates to that word. This obviously ties in with the non-autonomous nature of natural language semantics: that meaning in natural language is not separated from other forms of knowledge implies that it is not very useful to maintain a strict separation between world knowledge and knowledge of linguistic meaning. While this recognition would be shared by all forms of semantics in Cognitive Linguistics, the individual identity of

16 Dirk Geeraerts
frame semantics involves the speciﬁc structures of encyclopedic knowledge that it invokes. Basically, these ‘frames’ are things happening and occurring together in reality. For example, in order to understand the word sell, you need to have world knowledge about the situation of commercial transfer. This comprises, apart from the act of selling, a person who sells, a person who buys, goods to be sold, money or another form of payment, and so on.
A semantic frame of this type is a coherent structure of related concepts where the relations have to do with the way the concepts co-occur in real world situations. Knowledge of the frame is necessary for an adequate knowledge of the words referring to the concepts in the frame: a word activates the frame, highlights individual concepts within the frame, and often determines a certain perspective in which the frame is viewed. In the standard commercial transaction example, for instance, sell construes the situation from the perspective of the seller and buy from the perspective of the buyer.
Although frame semantics was originally applied predominantly to the semantic description of words, there is a close relationship with Construction Grammar. Words like sell come with their own set of constructions (like sell something to someone or sell something for a certain price), and the different constructions reﬂect different ways in which the frame can be highlighted. In this way, frame semantics can be integrated with Construction Grammar as one way of specifying the semantics of constructions. Overall, we can now see that frame semantics occupies a transitional position in our grouping of concepts. On the one hand, if we focus on the way in which it uses structured encyclopedic knowledge as the background for the description of meanings in natural language, it belongs with the previous group of papers: it describes one of the ways in which conceptual knowledge of an encyclopedic (i.e. not speciﬁcally linguistic) nature is structured. On the other hand, if we concentrate on the input that frame semantics provides for the description of construction types, it links up with the present group of articles.
CONSTRUCTION¬GRAMMAR
Simplistically, a grammatical construction is any string of words or morphemes exhibiting a coherent pattern, whether it be an entire sentence or a clause or a phrase (like a noun phrase or a verb phrase) or a complex lexeme (like a phrasal verb). And of course, the abstract pattern itself may also be called a ‘construction’. In classical contemporary grammars, an indirect object pattern of the type Subject – Predicate – Indirect Object – Direct Object would be considered a derived structure, built up from the functional classes Subject, Predicate etc. That is to say, the rules of the grammar would be deﬁned in such a way that a grammatical pattern of the form Subject – Predicate – Indirect Object – Direct Object could

Introduction: A rough guide to Cognitive Linguistics 17
be assembled on the basis of the relevant functional building blocks. In Cognitive Linguistics, a pattern of this type is considered to be non-derived, i.e. is taken to be a sign of the language, or, if you wish, an (abstract) expression in its own right.
As you can read in Adele Goldberg’s paper ‘The inherent semantics of argument structure: The case of the English ditransitive construction’, there are a number of advantages to such an approach, two of which may be mentioned here, to give you a ﬁrst idea of why thinking in terms of constructions may be interesting. First, if a construction is treated as an entity in its own right, it is possible that the whole has characteristics that cannot be straightforwardly derived from the constituent components. This is a property known as non-compositionality: the meaning of the whole is not necessarily a compositional function of the meaning of the parts. Second, if any construction is a distinct element of the inventory of linguistic signs for a given language, you can treat constructions like any other category – according to the usual practice of Cognitive Linguistics. That is to say, it will then be quite normal to describe not just the meaning and the form of the category, but also its salient members. In the case of constructions, we may then think primarily of the lexical elements that can ﬁll the slots of the construction (like the verbs that occupy the predicate role in the indirect object construction). Or in other words: describing grammar as a schematic network with lexical elements at the bottom and more abstract patterns higher up in the network is completely congenial to a construction grammar approach.
USAGEBASED¬LINGUISTICS
Deﬁning Cognitive Linguistics as a usage-based model of language has a number of consequences, like the straightforward methodological conclusion that cognitive linguists will have to invest in the analysis of real language use if they are to live up to their self-declared status. You would expect a lot of corpus research in Cognitive Linguistics, then, but to be honest, this is a trend that is clearly emerging, but that has not yet gained as prominent a status as one would expect.
Using corpora of observed speech is natural in language acquisition research, though: if you wish to study how children acquire their language, you will obviously want to observe and analyze their developing language. Also, language acquisition is a domain par excellence to test a usage-based model of language that believes that our experience of actual speech determines how we come by more abstract patterns. In fact, if our more schematic knowledge is based on our more concrete knowledge of lexical instantiations of such patterns, you should be able to observe ‘lexical bootstrapping’ effects: the speciﬁc words in which we begin to learn certain constructions, determine how we learn the construction. That is exactly what Michael Tomasello investigates in his paper ‘First Steps toward a Usage-based Theory of Language Acquisition’, which is part of a long-

18 Dirk Geeraerts
term research effort to develop a theory of language acquisition that ties in with Cognitive Linguistics and Construction Grammar.
If you are familiar with the history of contemporary linguistics, you will appreciate how important such an attempt is. The generative grammar idea that language is a separate module of the mind is very much based on an argument from language acquisition: if we do not assume that language is genetically wired in, the argument goes, we couldn’t explain at all how the acquisition of language proceeds so quickly as it actually does. This is particularly the case, the argument continues, because the input children get (the language they are exposed to) is not sufﬁcient to explain how they could learn all the intricacies of natural language syntax. This is the ‘poverty of stimulus’ argument. Obviously, if Tomasello succeeds in his attempt to explain how children can learn language through abstraction from the actual input they get, a central tenet of generative grammar will be overturned.
2.5. A conceptual map
Let us summarize. What we have shown in this (somewhat detailed) introduction to the tour of twelve papers is how they introduce, discuss, illustrate concepts that follow logically from the central characteristics of Cognitive Linguistics that we learned about in the previous section. It will not come as a surprise to you that these twelve concepts are far from being the only relevant or interesting ones that have been developed in the context of Cognitive Linguistics – but they are certainly among the most basic ones. When you read the individual papers, it may be wise to refer back once in a while to the characterizations that you ﬁnd in the foregoing pages: they will help you not to lose track and to interpret the conspicuous features of the papers.
In Figure 1, the relations between the various papers are graphically represented. The fundamental features of Cognitive Linguistics (the perspectival, dynamic, non-autonomous, experiential nature of natural language) are mentioned in the corners of the ﬁgure. Intermediate between these cornerstones and the twelve central concepts, you will ﬁnd six ﬁelds of research that emerged in the foregoing discussion as the logical link between the fundamental features and the central concepts: the conceptual characterization of the grammar, the search for models of polysemy, the analysis of mechanisms of polysemy, the importance of thinking in terms of domains of experience, the relationship between grammar and lexicon, and the relationship between structure and usage. The arrows in the ﬁgure indicate how each more speciﬁc concept is motivated by a more general one for instance: looking at mechanisms of categorial polysemy is one way of getting a grip on the dynamic nature of linguistic meaning, and in a next step, conceptual metaphor is one of the speciﬁc mechanisms of categorial polysemy.

Introduction: A rough guide to Cognitive Linguistics 19 Figure 1. A conceptual map of Cognitive Linguistics

20 Dirk Geeraerts
Adding the intermediate level with the six ﬁelds of research brings in extra subtlety in the overview. We can now make clear, for instance, that Langacker’s paper with which the collection opens, not only illustrates the perspectival nature of grammar, but also deals with the relationship between lexical structure and morpho-syntax. In the same way, the ﬁgure illustrates how the experiential nature of the grammar does not only involve questions about the acquisition and the architecture of the grammar, but also links up with thinking in terms of domains and their mutual relations.
3. Where do you go next?
Let us assume that, after roaming the present introductory volume, you really like the look and feel of Cognitive Linguistics. It’s a safe assumption, in fact: you are bound to be drawn in by an intellectual climate that is both hospitable and inspiring, open-minded and exciting, wide-ranging and innovative. But where do you go after the initial tour d’horizon that has won your heart? Let’s go over a few trajectories that might cater to your personal interests.
A ﬁrst thing to do would be to complete your initiation by reading the companion volume to the present collection. In several ways, Cognitive Linguistics: Current Applications and Future Perspectives (edited by Gitte Kristiansen, Michel Achard, René Dirven and Francisco J. Ruiz de Mendoza) is deliberately complementary to the book that you are holding in your hands: it does not focus on Cognitive Linguistics basics, but rather describes the contemporary state of affairs in the main ﬁelds of application of Cognitive Linguistics. Also, it does not consist of existing papers, but only contains newly written articles that have the explicit purpose of presenting current discussions and domains. Taken together, the two volumes will thoroughly familiarize you with Cognitive Linguistics, way beyond the fragmented and uncertain knowledge that an incidental visit would impart.
From that point on, you may want to go beyond the level of introductions, and you may, with the acquired conﬁdence of the experienced traveler, do some journeying on your own. However, in case your self-assurance has not reached an optimal level and you would want to boost it with an additional round of introductory reading, there are some good book-length introductions to Cognitive Linguistics that may help you. Here’s a list of commendable texts.
• Friedrich Ungerer and Hans-Jörg Schmid. 1996. An Introduction to Cognitive Linguistics. London/New York: Longman.
• Violi, Patrizia. 2001. Meaning and Experience. Bloomington: Indiana University Press.
• John R. Taylor. 2003. Linguistic Categorization. Third Edition. Oxford: Oxford University Press.

Introduction: A rough guide to Cognitive Linguistics 21
• René Dirven and Marjolijn Verspoor. 2004. Cognitive Exploration of Language and Linguistics. Second Revised Edition. Amsterdam, Philadelphia: John Benjamins.
• William Croft and D. Alan Cruse. 2004. Cognitive Linguistics. Cambridge: Cambridge University Press.
• Vyvian Evans and Melanie Green. 2006. Cognitive Linguistics. An Introduction. Edinburgh: Edinburgh University Press.
Once you are ready to leave the introductory level, there are basically two things to do: deepen your understanding of the existing body of work in Cognitive Linguistics, and keep aware of current developments. With regard to the former, a ﬁrst set of routes to explore is provided by the present volume itself: accompanying each of the chapters included in the collection, you ﬁnd a broadly conceived set of suggestions for further reading in the Epilogue. They will direct you to elaborations and discussions of the basic concepts that are presented here – and to some of the less basic (but no less important) concepts developed in the ﬁeld of Cognitive Linguistics. Alternatively (or in parallel), you could have a look at the forthcoming Handbook of Cognitive Linguistics, edited by Dirk Geeraerts and Hubert Cuyckens and published by Oxford University Press. It’s a collection of some ﬁfty commissioned articles that each offer an in-depth treatment of one of the manifold aspects of Cognitive Linguistics.
To keep in touch with new work, you would certainly want to be aware of new publications. So, what are the journals and the book series that you need to keep an eye on? Note that a lot of studies in Cognitive Linguistics are now being published in general publication channels and by a wide variety of international publishers. Here, only journals and book series that are speciﬁcally dedicated to Cognitive Linguistics are mentioned.
Two journals need to be cited: Cognitive Linguistics, and the Annual Review of Cognitive Linguistics. The former, published by Mouton De Gruyter, is the ofﬁcial journal of the International Cognitive Linguistics Association (more about which in the next section). The journal was founded by Dirk Geeraerts in 1990. Consecutive editors-in-chief so far were Arie Verhagen and Adele Goldberg. The latter journal, published by the John Benjamins Publishing Company under the auspices of the Spanish Cognitive Linguistics Association, ﬁrst appeared in 2003. It is led by Francisco Ruiz de Mendoza. The journal Cognitive Linguistics is not only the most reputable journal in the ﬁeld, it also comes with a considerable bonus. A subscription to Cognitive Linguistics includes a copy of the digital Bibliography of Cognitive Linguistics – and indispensable bibliographical tool compiled through the relentless efforts René Dirven (undoubtedly the major organizational force behind the entire Cognitive Linguistics enterprise). The bibliography now covers 7000 publications (no, you won’t have to read them all

22 Dirk Geeraerts
to be recognized as an accomplished cognitive linguist), and it will be regularly updated in the following years.
Five book series speciﬁcally dedicated to work in Cognitive Linguistics need to be mentioned. Cognitive Linguistic Research or CLR is the oldest and most complete series. Published by Mouton de Gruyter of Berlin, it was launched at the same time as the journal Cognitive Linguistics, and now numbers over thirty volumes. Recently, Cognitive Linguistic Research (with Dirk Geeraerts as managing editor) has received a companion series in the form of Applications of Cognitive Linguistics or ACL (managed by Gitte Kristiansen) – a series that will focus on the descriptive applications of Cognitive Linguistics, while Cognitive Linguistic Research harbors the more theoretically relevant studies. The other main publisher for Cognitive Linguistics, the John Benjamins Publishing Company of Amsterdam, features three speciﬁcally relevant (but as yet less extensive) series. While Human Cognitive Processing (edited by Marcelo Dascal, Raymond W. Gibbs and Jan Nuyts) has a broad cognitive orientation, the two other series are more speciﬁc: Cognitive Linguistics in Practice (edited by Günter Radden) covers the ﬁeld from a textbook oriented perspective, and Constructional Approaches to Language (edited by Mirjam Fried and Jan-Ola Östman) speciﬁcally deals with Construction Grammar.
If you are interested in following what is going on in Cognitive Linguistics, note that the book series are not just monograph series. A lot of what is being published in the series consists of collective volumes with thematically interconnected articles. In many cases, these constitute selections of papers presented at Cognitive Linguistics conferences. Because quite a lot of relevant work is being published in such collective volumes, you will proﬁt from keeping an eye on them once you’ve become a Cognitive Linguistics aﬁcionado.
When you’ve reached this stage, you will be ready to take a step into the world and take part in some real life Cognitive Linguistics activities. Where would you go? All self-respecting cities and countries have their own festivals and ﬁesta, and becoming part of the crowd involves participating in the celebrations. In Cognitive Linguistics, the main community event is without any doubt the biannual ICLC or Cognitive Linguistics Conference. The ﬁrst ICLC took place in 1989 in Duisburg, Germany. It was one of the so-called LAUD symposia (where LAUD stands for Linguistic Agency of the University of Duisburg) that had been organized by René Dirven since 1977 and where some of the world’s most distinguished linguists were invited to present their work. The Duisburg conference was of crucial importance for the institutionalization and the international expansion of Cognitive Linguistics: it was there and then that the International Cognitive Linguistics Association or ICLA was founded (the conference was accordingly rebaptized as the First International Cognitive Linguistics Conference), that plans were made to launch the journal Cognitive Linguistics, and that the monograph

Introduction: A rough guide to Cognitive Linguistics 23
series Cognitive Linguistics Research was announced. Cognitive Linguistics as an intellectual movement is too self-critical to recognize any historical sites or places of pilgrimage, but if ever a commemorative plate were to be considered, Duisburg would be a likely candidate.
The following ICLC conferences were consecutively held in Santa Cruz, US (1991, organized by Gene Casad), Leuven, Belgium (1993, organized by Dirk Geeraerts), Albuquerque, US (1995, organized by Sherman Wilcox), Amsterdam, The Netherlands (1997, organized by Theo Jansen and Gisela Redeker), Stockholm, Sweden (1999, organized by Erling Wande), Santa Barbara, US (2001, organized by Ronald W. Langacker), Logroño, Spain (2003, organized by Francisco J. Ruiz De Mendoza), and Seoul, South Korea (2005, organized by Hyon-Sook Shin). The tenth ICLC in 2007, organized by Elzbieta Tabakowska, has its venue at the Jagiellonian University of Krakow in Poland.
Next to the ICLC’s, there are a number of local events that you may consider attending. The LAUD conferences are now being organized bi-annually in Landau, Germany, in the year between the ICLC conferences. That holds for a number of other regular meetings, like the US-based Cognitive Structure, Discourse and Language conference, which reached its eighth edition in 2006; or the International Conference on Construction Grammar, which had its fourth edition in 2006.
An important part in the organization of workshops and symposia in Cognitive Linguistics is currently played by the ICLA afﬁliates. These are ICLA branches deﬁned by region or country (and occasionally by language). The ﬁrst one to be founded was the Spanish Cognitive Linguistics Association, whose afﬁliation was formally approved at the 1999 ICLC. The year 2001 saw the afﬁliation of the Finnish, the Polish, and the Slavic Cognitive Linguistics Associations. Further afﬁliates include the Russian Association of Cognitive Linguists (2004), the German Cognitive Linguistics Association (2005), the Discourse and Cognitive Linguistics Association of Korea (2005), the Association Française de Linguistique Cognitive (2005), the Japanese Cognitive Linguistics Association (2005), the Conceptual Structure, Discourse and Language Association (2005), and the UK Cognitive Linguistics Association (2006). Further local branches are likely to emerge, and all of them are likely to organize regular meetings. If you are interested in following what is on the agenda, you may want to consult the ICLA website: it contains a calendar of Cognitive Linguistics events, and supplies links to the individual websites of the ICLA afﬁliates. This is the ICLA address: http:// www.cognitivelinguistics.org/
Meetings, lectures, workshops, symposia, and conferences are also announced on Cogling, a mailing list for disseminating ICLA news, queries, and discussions of interest to cognitive linguists. Again, details about subscribing may be found on the ICLA website. Incidentally, the website also offers an overview of

24 Dirk Geeraerts
the courses or programs in Cognitive Linguistics that are offered at many places around the globe.
Once you get to one of the conferences, who would you be likely and/or eager to meet? Thinking in terms of people, the key ﬁgures of Cognitive Linguistics are George Lakoff, Ronald W. Langacker, and Leonard Talmy. Round this core of founding fathers, who originated Cognitive Linguistics in the late 1970s and the early 1980s, two chronologically widening circles of cognitive linguists may be discerned. (The lists that follow are obviously indicative only: they are not meant to exclude anyone, but only to give you an idea of the different ‘generations’ of cognitive linguists.)
A ﬁrst wave, coming to the fore in the second half of the 1980s and the beginning of the 1990s, consists of the early collaborators and colleagues of the key ﬁgures, together with a ﬁrst generation of students. Names that come to mind include those of Gilles Fauconnier, Eve Sweetser, Mark Johnson, Mark Turner, Raymond W. Gibbs, William Croft, Adele Goldberg, Dave Tuggy, Gene Casad, Laura Janda, Suzanne Kemmer, Sally Rice, Ricardo Maldonado, Karen Van Hoek, Geoff Nathan, Margaret Winters, Sherman and Phyllis Wilcox, Margaret Freeman.
Simultaneously, a number of people in mostly Western and Central Europe took up the ideas of Cognitive Linguistics and contributed to their international dissemination. Names include those of René Dirven (to repeat: his instrumental role in the expansion of Cognitive Linguistics can hardly be overestimated), Brygida RudzkaOstyn, John Taylor, Zoltan Kövecses, Chris Sinha, Brigitte Nerlich, Arie Verhagen, Barbara Lewandowska-Tomaszczyk, Elzbieta Tabakowska, Peter Harder, Günter Radden, Susanne Niemeier, Martin Pütz, Hans-Jörg Schmid, Hubert Cuyckens and the author of the present introduction.
The mid 1990s and later witnessed a second wave of expansion, with second generation students and a further geographical spread directed largely towards Asia and the rest of Europe. Names include those of Alan Cienki, Michel Achard, Joe Grady, Tim Rohrer, Seana Coulson, Todd Oakley, Gary Palmer, Jose M. GarciaMiguel, Antonio Barcelona, Francisco Ruiz de Mendoza, Carlos Inchaurralde, Andrej Kibrik, Ekaterina Rakhilina, Michael Tomasello, Ted Sanders, Wilbert Spooren, Gerard Steen, Stefan Grondelaers, Stefan Gries, Anatol Stefanowitsch, Yo Matsumoto.
In addition, you might proﬁt from the occasion to rub elbows with people who would perhaps not describe themselves unreservedly as cognitive linguists (coming as they do from other theoretical families or other disciplines, or simply because they like their independence), but who would show up at the Cognitive Linguistics conferences because they have relevant things to say: linguists like Charles Fillmore, Joan Bybee, Elizabeth Traugott, Östen Dahl, Jan Nuyts, or psychologists like Melissa Bowerman, Dedre Gentner, and Dan Slobin.

Introduction: A rough guide to Cognitive Linguistics 25
4. Why would you want to come back?
So now you know your way around in Cognitive Linguistics. You can walk the walk and talk the talk, and there’s no way that you’d be exposed as a novice. But why would you be coming back? What would be a good reason to become a permanent resident? An obvious but relatively superﬁcial motivation would be the diversity of the panorama: there’s a lot to be found in the Cognitive Linguistics archipelago, and the framework is not so strict as to stiﬂe creativity. It’s a lively, colorful, varied environment, and you’re likely to ﬁnd some corner of special signiﬁcance to you, where you can do your thing and meet people with similar interests. But beyond that? What would be the long-term importance of Cognitive Linguistics?
Let us try to take a bird’s eye view of the history of linguistics, and see exactly where Cognitive Linguistics ﬁts in, and why it could be important for the future of linguistics. Agreed, you can only achieve this sort of extreme synthesis if you allow for massive simpliﬁcation: let us try to keep that in mind as a proviso when we do the exercise.
The development of linguistics in the twentieth century, then, is characterized by a succession of two dominant approaches: the structuralist one, and the generativist one. Currently, in the ﬁrst decade of the 21st century, the generativist paradigm is no longer the principal framework, but there clearly is no new central approach yet. If one looks at Cognitive Linguistics from this perspective, there are indications that Cognitive Linguistics combines a number of tendencies that may also be found in other contemporary developments in theoretical linguistics – viz. in the broad range of functionalist approaches to linguistics. By combining these tendencies, Cognitive Linguistics taps directly into the undercurrent of contemporary developments. Speciﬁcally, if we recognize that decontextualization is a fundamental underlying characteristic of the development of grammatical theory in twentieth century linguistics, Cognitive Linguistics strongly embodies the recontextualizing tendency that is shared by most functionalist approaches.
The logic behind the decontextualization of twentieth century grammar may be grasped if we take our starting-point in De Saussure, the founding father of the structuralist approach. The Saussurean distinction between langue (the language system) and parole (the use of the language system in actual usage) creates an internally divided grammar, a conception of language with, so to speak, a hole in the middle. On the one hand, langue is deﬁned by De Saussure as a social system, a set of collective conventions, a common code shared by a community. On the other hand, parole is an individual, psychological activity that consists of producing speciﬁc combinations from the elements that are present in the code. When langue and parole are deﬁned in this way, there is a gap between both: what is the factor that bridges the distance between the social and the psychological,

26 Dirk Geeraerts
between the community and the individual, between the system and the application of the system, between the code and the actual use of the code?
The father of generative grammar, Noam Chomsky, provided an answer by introducing a distinction between competence and performance: the missing link between social code and individual usage is the individual’s knowledge of the code. Performance, in the Chomskyan sense, is basically equivalent with Saussurean parole, but competence interiorizes the notion of the linguistic system. Competence is the internal grammar of the language user, the knowledge that the language user has of the linguistic system and that he or she puts to use in actual performance.
Remarkably, however, Chomsky introduces a new gap into the system. Rather than the threefold classiﬁcation that one might expect, he restricts his conception of language to a new dichotomy: the social aspects of language are largely ignored. In comparison with a ternary distinction distinguishing between langue, competence, and parole/performance (between social system, individual knowledge of the system, and individual use of the system), the binary distinction between competence and performance creates a new empty slot, leaving the social aspects of language largely out of sight.
This apparent lack of interest for language as a social sign system links up logically with the Chomskyan emphasis on the genetic nature of natural language. Where, in fact, does the individual knowledge of the language come from? If the source of linguistic knowledge is not social, what else can it be than an innate and universal endowment? If the language is not learned through acculturation in a linguistic community, what other source could there be for linguistic knowledge except genetics?
Further restrictions follow. Meanings constitute the variable, contextual, cultural aspects of language par excellence. Because social interaction, the exchange of ideas, changing conceptions of the world are primarily reﬂected in the meaning of linguistic expressions, meanings are less interesting from a genetic point of view. Also, if the lexicon is the main repository of linguistically encoded meaning, studying the lexicon is of secondary importance: the focus will fall on the abstract syntactic patterns. And ﬁnally, if linguistics focuses on formal rule systems, the application of the rule systems in actual usage is relatively uninteresting. If the rules deﬁne the grammar, it is hard to see what added value could be derived from studying the way in which the rules are actually put to use. The study of performance, in other words, is just as secondary as research into the lexicon.
In short, generative grammar led to a severe decontextualization of the grammar, separating the autonomous grammatical module from different forms of context: through the basic Chomskyan shift from langue to competence, linguistics is separated from the social context of language as a social code; through the focus on the genetic aspects of the language, linguistics is separated from the cognitive

Introduction: A rough guide to Cognitive Linguistics 27
context of lived individual experience; through the focus on formal rule systems, linguistics is separated from the situational context of actual language use.
Compared to this, Cognitive Linguistics is very much a recontextualizing approach. First, it is an outspoken attempt to give meaning a central position in the architecture of the grammar. Second, in contrast with formal semantics, the conception of meaning that lies at the basis of this approach is not restricted to a referential, truth-functional type of meaning – the type of meaning that you could express in logical terms. Linguistic structures are thought to express conceptualizations, and conceptualization goes further than mere reference. As we have seen, it involves imagery in the broadest sense of the word: ways of making sense, of imposing meaning. Also, the conceptualizations that are expressed in natural language have an experiential basis, i.e., they link up with the way in which human beings experience reality, both culturally and physiologically. In this sense, Cognitive Linguistics embodies a fully contextualized conception of meaning. Third, the link between linguistic performance and grammar is reestablished by the view that language is usage-based, i.e. that there is a dialectic relationship between langue and parole.
We can observe, then, that the various characteristics of Cognitive Linguistics that you learned about in the ﬁrst section of this introductory chapter and that were further spelled out in twelve crucial concepts, can be summarized under one general denominator: the recontextualization of grammar. If we assume, next, that this recontextualizing tendency is an underlying trend in contemporary cognitive-functionalist linguistics, Cognitive Linguistics is probably one of the most outspoken representatives of this tendency. Surely, it is not the only one, and there are whole disciplines in linguistics that are devoted to the exploration of speciﬁc forms of context, like sociolinguistics dealing with the social context, or pragmatics and text linguistics dealing with the level of parole. But Cognitive Linguistics is speciﬁc in the extent to which it tries to integrate these different tendencies into an overall model of language.
All of this does not mean, however, that Cognitive Linguistics has reached its goal yet. To begin with, because it is far from being alone in pursuing a recontextualized line of linguistic research, one of the major tasks for its future development will be to systematically confront similar approaches within the broad cognitivefunctionalist domain and see to what extent theoretical and empirical convergences are possible. That is not going to be self-evident, given that Cognitive Linguistics is not even a theoretically uniform framework on its own account.
Further, we cannot say that Cognitive Linguistics has already realized all the consequences of the decontextualizing stance. For one thing, seeing language in the context of the mind at large would seem to imply a lively interdisciplinary interaction with the other sciences of the mind, but that is a trend that is only gradually emerging in mainstream cognitive linguistic circles. For an other, recontextual-

28 Dirk Geeraerts
izing language in its social context implies an awareness of the variation that is inherent in the social life of language. Here again, sociolinguistically oriented studies inspired by Cognitive Linguistics are only beginning to come into view.
In short, there is still a quite a lot to be done. Ultimately, that may well be the best reason for coming back: not what has already been achieved, but what still has to be done – all the exciting, inviting paths for further exploration. So we will meet there, right?

Chapter 1 Cognitive Grammar
Introduction to Concept, Image, and Symbol Ronald W. Langacker
Despite the diversity of contemporary linguistic theory, certain fundamental views are widely accepted without serious question. Points of widespread agreement include the following: (i) language is a self-contained system amenable to algorithmic characterization, with sufﬁcient autonomy to be studied in essential isolation from broader cognitive concerns; (ii) grammar (syntax in particular) is an independent aspect of linguistic structure distinct from both lexicon and semantics; and (iii) if meaning falls within the purview of linguistic analysis, it is properly described by some type of formal logic based on truth conditions. Individual theorists would doubtlessly qualify their assent in various ways, but (i) –(iii) certainly come closer than their denials to representing majority opinion.
Since 1976, I have been developing a linguistic theory that departs quite radically from these assumptions. Called “cognitive grammar” (alias “space grammar”), this model assumes that language is neither self-contained nor describable without essential reference to cognitive processing (regardless of whether one posits a special faculté de langage). Grammatical structures do not constitute an autonomous formal system or level of representation: they are claimed instead to be inherently symbolic, providing for the structuring and conventional symbolization of conceptual content. Lexicon, morphology, and syntax form a continuum of symbolic units, divided only arbitrarily into separate components; it is ultimately as pointless to analyze grammatical units without reference to their semantic value as to write a dictionary which omits the meanings of its lexical items. Moreover, a formal semantics based on truth conditions is deemed inadequate for describing the meaning of linguistic expressions. One reason is that semantic structures are characterized relative to knowledge systems whose scope is essentially openended. A second is that their value reﬂects not only the content of a conceived situation, but also how this content is structured and construed.
Cognitive grammar is therefore quite distinct from any version of generative theory. Moreover, it departs from most varieties of traditional and formal semantics, as well as the newer “situation semantics” of Barwise and Perry (1983), by
Originally published in 1990 as Chapter 1. Introduction in Concept, Image, Symbol: The Cognitive Basis of Grammar, Ronald W. Langacker, 1–32. Berlin/New York: Mouton de Gruyter. (Reprinted with permission from An introduction to cognitive grammar. Cognitive Science 10(1): 1–40. 1986).

30 Ronald W. Langacker
equating meaning with conceptualization (or cognitive processing). It agrees in this regard with the “procedural semantics” of Miller and Johnson-Laird (1976) and Johnson-Laird (1983), and with the linguistic theories of Chafe (1970) and Jackendoff (1983); however, it is very different from all of these in its conception of grammatical organization and its speciﬁc proposals concerning semantic structure. Although cognitive grammar is not a direct outgrowth or a variant of any other linguistic theory, I do consider it compatible with a variety of ongoing research programs. Among these are Lakoff’s work on categorization (1982, 1987); Fauconnier’s study of mental spaces (1985); Haiman’s ideas on iconicity and encyclopedic semantics (1980, 1983, 1985); Talmy’s research on spatial terms, force dynamics, and the meanings of grammatical elements (1975, 1977, 1978, 1983, 1985a, 1985b, 1988a, 1988b); the proposals of Moore and Carling concerning the nonautonomy of linguistic structure (1982); Fillmore’s conception of frame semantics (1982); Wierzbicka’s insightful investigation into the semantics of grammar (1988); the growing body of research on metaphor and image schemas (Johnson 1987; Lakoff and Johnson 1980; Lakoff and Turner 1989; Sweetser 1984, 1987); recent studies of grammaticization (Bybee 1988; Kemmer 1988; Sweetser 1988; Traugott 1982, 1986, 1988); and the rich, multifaceted work in a “functional” vein by scholars too numerous to cite individually (though Givón 1979, 1984, 1989 must certainly be mentioned).
This chapter affords an overview of cognitive grammar as I myself conceive it. The topics it brieﬂy covers will all be taken up again in later chapters of Langacker (1991a) and examined in greater detail. Readers interested in still further discussion and illustration of the theory will ﬁnd it in the following works: Casad 1982, 1988; Cook 1988, 1989; Hawkins 1984, 1988; Janda 1984, 1988, 1993; Langacker 1981, 1982, 1985, 1987, 1988a, 1988b, 1991b; Lindner 1981, 1982; Poteet 1987; Rice 1987a, 1987b, 1988; Smith 1985a, 1985b, 1987, 1989; Tuggy 1980, 1981, 1986, 1988, 1989; Vandeloise 1984.
1. Linguistic semantics
Meaning is equated with conceptualization. Linguistic semantics must therefore attempt the structural analysis and explicit description of abstract entities like thoughts and concepts. The term conceptualization is interpreted quite broadly: it encompasses novel conceptions as well as ﬁxed concepts; sensory, kinesthetic, and emotive experience; recognition of the immediate context (social, physical, and linguistic); and so on. Because conceptualization resides in cognitive processing, our ultimate objective must be to characterize the types of cognitive events whose occurrence constitutes a given mental experience. The remoteness of this goal is not a valid argument for denying the conceptual basis of meaning.

Chapter 1: Cognitive Grammar 31
Most lexical items have a considerable array of interrelated senses, which deﬁne the range of their conventionally sanctioned usage. These alternate senses are conveniently represented in network form; Figure 1 depicts a fragment of the network associated with the noun ring. Certain senses are “schematic” relative to others, as indicated by the solid arrows. Some represent “extensions” from others (i.e. there is some conﬂict in speciﬁcations), as indicated by the dashed-line arrows. The nodes and categorizing relationships in such a network differ in their degree of entrenchment and cognitive salience – for instance, the heavy-line box in Figure 1 corresponds to the category prototype. The precise conﬁguration of such a network is less important than recognizing the inadequacy of any reductionist description of lexical meaning. A speaker’s knowledge of the conventional value of a lexical item cannot in general be reduced to a single structure, such as the prototype or the highest-level schema. For one thing, not every lexical category has a single, clearly determined prototype, nor can we invariably assume a highlevel schema fully compatible with the speciﬁcations of every node in the network (none is shown in Figure 1). Even if such a structure is posited, moreover, there is no way to predict precisely which array of extensions and elaborations – out of all those that are conceivable and linguistically plausible – have in fact achieved conventional status. The conventional meaning of a lexical item must be equaled with the entire network, not with any single node.
Figure 1.
Because polysemy is not our central concern, we will nevertheless focus on individual nodes. What is required to adequately characterize any particular sense of a linguistic expression? Speciﬁcally rejected is the idea that a semantic structure reduces to a bundle of features or semantic markers (cf. Katz and Fodor 1963). Rejected as well is the notion that all meanings are described directly in terms of semantic primitives. It is claimed instead that semantic structures (which I call “predications”) are characterized relative to “cognitive domains”, where a domain can be any sort of conceptualization: a perceptual experience, a concept, a conceptual complex, an elaborate knowledge system, etc. The semantic description of an expression therefore takes for its starting point an integrated conception of arbitrary complexity and possibly encyclopedic scope. The basic observation

32 Ronald W. Langacker
supporting this position is that certain conceptions presuppose others for their characterization. We can thus posit hierarchies of conceptual complexity, where structures at a given level arise through cognitive operations (including simple coordination) performed on the structures at lower levels. Crucially, the cognitive domains required by linguistic predications can occur at any level in such hierarchies.
Consider some examples. The notion hypotenuse is readily characterized given the prior conception of a right triangle, but incoherent without it; right triangle therefore functions as the cognitive domain for hypotenuse. Central to the value of elbow is the position of the designated entity relative to the overall conﬁguration of the human arm (try explaining what an elbow is without referring in any way to an arm!), so arm is a domain for elbow. Similarly, tip presupposes the conception of an elongated object, and April, of the calendrical cycle devised to plot the passage of a year. A meaningful description of shortstop or sacriﬁce ﬂy is possible only granted substantial knowledge of the rules and objectives of baseball. The implications of this position are apparent: the full and deﬁnitive characterization of a semantic structure must incorporate a comparable description of its domain, and ultimately of the entire hierarchy of more fundamental conceptions on which it depends. Pushing things to their logical conclusion, we must recognize that linguistic semantics is not an autonomous enterprise, and that a complete analysis of meaning is tantamount to a complete account of developmental cognition. This consequence is terribly inconvenient for linguistic theorists imprinted on autonomous formal systems, but that is not a legitimate argument against its validity.
What occupies the lowest level in conceptual hierarchies? I am neutral as to the possible existence of innately speciﬁed conceptual primitives. It is however necessary to posit a number of “basic domains”, i.e. cognitively irreducible representational spaces or ﬁelds of conceptual potential. Among these basic domains are the experience of time and our capacity for dealing with two- and threedimensional spatial conﬁgurations. There are basic domains associated with the various senses: color space (an array of possible color sensations), coordinated with the extension of the visual ﬁeld; the pitch scale; a range of possible temperature sensations (coordinated with positions on the body); and so on. Emotive domains must also be assumed. It is possible that certain linguistic predications are characterized solely in relation to one or more basic domains, e.g. time for before, color space for red, or time and the pitch scale for beep. However most expressions pertain to higher levels of conceptual organization and presuppose nonbasic domains for their semantic characterization.
Most predications also require more than one domain for their full description, in which case I refer to the set as a “complex matrix”, as illustrated for knife in Figure 2. One dimension of its characterization is a shape speciﬁcation (or a family

Chapter 1: Cognitive Grammar 33
of such speciﬁcations). Another is the canonical role of a knife in the process of cutting. Additional properties are its inclusion in a typical place setting with other pieces of silverware; speciﬁcations of size, weight, and material; information about the manufacture of knives; the existence of knife-throwing acts in circuses; and so on indeﬁnitely. Obviously these speciﬁcations are not all on a par. They differ greatly in their degree of “centrality”, i.e. the likelihood of their activation on a given occasion of the expression’s use. Moreover, some are probably incorporated as components of others – for instance, Figure 2 plausibly suggests that a shape speciﬁcation is typically included in the conceptions constituting other domains of the complex matrix. I do however adopt an “encyclopedic” view of semantics (Haiman 1980). There is no sharp dividing line such that all speciﬁcations on one side are linguistically relevant and all those on the other side clearly irrelevant. Any facet of our knowledge of an entity is capable in principle of playing a role in determining the linguistic behavior of an expression that designates it (e.g. in semantic extension, or in its combination with other expressions).
Figure 2.
If we succeed in identifying and describing the domain or complex matrix invoked by a linguistic predication, we have not yet ﬁnished its characterization. Equally signiﬁcant for semantic structure is the “conventional imagery” inherent in the meaning of an expression. By imagery, I do not mean sensory images à la Shepard (1978) or Kosslyn (1980), though sensory images – as one type of conceptualization – are quite important for semantic analysis. I refer instead to our manifest capacity to structure or construe the content of a domain in alternate ways. This multifaceted ability is far too often neglected in semantic studies. Let us explore its dimensions and brieﬂy note their grammatical signiﬁcance.

34 Ronald W. Langacker
2. Dimensions of imagery
The ﬁrst dimension of imagery, observed in every linguistic predication, is the imposition of a “proﬁle” on a “base”. The base of a predication is its domain (or each domain in a complex matrix). Its proﬁle is a substructure elevated to a special level of prominence within the base, namely that substructure which the expression “designates”.1 Some examples are sketched in Figure 3, with the proﬁle given in heavy lines. The base (or domain) for the characterization of hypotenuse is the conception of a right triangle; for tip, the base is the conception of an elongated object; and for uncle, a set of individuals linked by kinship relations. The base is obviously essential to the semantic value of each predication, but it does not per se constitute that value: a hypotenuse is not a right triangle, a tip is not an elongated object, and an uncle is not a kinship network. The meaning of hypotenuse, tip, and uncle is in each case given only by the selection of a particular substructure within the base for the distinctive prominence characteristic of a proﬁle. An expression’s semantic value does not reside in either the base or the proﬁle individually, but rather in the relationship between the two.
Figure 3.
Some further examples will demonstrate both the descriptive utility and the grammatical import of these constructs. The predications in question represent speciﬁc senses of go, away, and gone, namely those illustrated in (1):
(1) a. I think you should go now. b. China is very far away. c. When I arrived, he was already gone.
Consider ﬁrst the particular sense of go that is diagramed in Figure 4(a). This is a relational rather than a nominal predication, i.e. it proﬁles the “interconnections” among conceived entities; these interconnections are indicated in Figure 4 by

Chapter 1: Cognitive Grammar 35
the heavy dashed lines. The relevant domains are space and time. With the passage of time, one individual, referred to here as the “trajector” (tr), moves from a position within the neighborhood of another individual, the “landmark” (lm), to a ﬁnal position outside that neighborhood. Only four states of the process are shown explicitly, but they represent a continuous series. The dotted lines indicate that the trajectors “correspond” from one state to the next (i.e. they are construed as identical), as do the landmarks. Away proﬁles a relationship that is identical to the ﬁnal state of go: the trajector is situated outside the vicinity of the landmark. Observe now that the participle gone proﬁles this same relationship, but it does so with respect to a different base. The base for away is simply the spatial domain, but the base for gone is the process proﬁled by go – something cannot be gone except by virtue of the process of going. The semantic contribution of the past participial inﬂection is to restrict the proﬁle of the stem, in this case go, to its ﬁnal state. Gone thus differs from go by virtue of its proﬁle, and from away by virtue of its base.
A second dimension of imagery is the “level of speciﬁcity” at which a situation is construed. For example, the same situation might be described by any of the sentences in (2):
Figure 4.
(2) a. That player is tall. b. That defensive player is over 6’ tall. c. That linebacker is about 6’ 5" tall. d. That middle linebacker is precisely 6’ 5" tall.
Each of these sentences can be regarded as schematic for the one that follows, which elaborates its speciﬁcations and conﬁnes their possible values to a narrower range. It is well known that lexical items form hierarchies with respect to level of speciﬁcity, e.g. animal ĺ reptile ĺ snake ĺrattlesnake ĺsidewinder. Relationships of schematicity are also important for grammatical structure. Consider the

36 Ronald W. Langacker
combination of break and the cup to form the composite expression break the cup. As part of its internal structure, the predicate break makes schematic reference to two central participants. The combination of break and the cup is effected through a correspondence established between one of these participants (its landmark) and the entity proﬁled by the cup, which is characterized with far greater speciﬁcity. One of the component expressions thus elaborates a schematic substructure within the other, as is typically the case in a grammatical construction.
A third dimension of imagery pertains to the “scale” and “scope of predication”. The scope of a predication is the extent of its coverage in relevant domains. A predication’s scope is not always sharply delimited or explicitly indicated, but the construct is nonetheless of considerable structural signiﬁcance (cf. Langacker 1991a: Chapter 2). Consider the notion island with respect to the various scopes indicated in Figure 5. The outer box, scope (a), is presumably sufﬁcient to establish the land mass as an island, but scope (b) is at best problematic. There is no precise requirement on how extensive the body of water surrounding an island must be, but the narrow strip of water included in (b) does not have the necessary expanse (e.g. it could simply be a moat, and the land inside a moat is not thought of as an island). Similarly, the ﬁnger of land projecting out into the water qualiﬁes as a peninsula given scope (c), but not (d); only from the former can we determine that the overall land mass is quite large relative to the ﬁnger-like projection. We can see that predications often imply a particular scale by noting the infelicity of using island to designate a handful of mud lying in the middle of a puddle. In my own speech, bay and cove are quite comparable in meaning except that bay speciﬁes the requisite conﬁguration of land and water on a larger scale.
Figure 5.
Body-part terms illustrate the semantic and structural signiﬁcance of these constructs. Essential to the characterization of terms like head, arm, and leg is the position of the proﬁled entity relative to the body as a whole, whose conception

Chapter 1: Cognitive Grammar 37
thus functions as their domain and immediate scope of predication. Each of these designated entities functions in turn as immediate scope of predication for other body-part terms deﬁned on a smaller scale, e.g. hand, elbow, and forearm in the case of arm. Hand then furnishes the immediate scope of predication for palm, thumb, and ﬁnger, on a still smaller scale, and ﬁnger for knuckle, ﬁngertip, and ﬁngernail. This hierarchical organization has structural consequences. For example, sentences like those in (3), where have pertains to part-whole relationships, are most felicitous (other things being equal) when the subject designates the immediate scope of predication for the object (cf. Bever and Rosenbaum 1970; Cruse 1979).
(3) a. A ﬁnger has 3 knuckles and 1 nail. b. ??An arm has 14 knuckles and 5 nails. c. ???A body has 56 knuckles and 20 nails.
A similar restriction can be observed with noun compounds. We ﬁnd numerous terms like ﬁngertip, ﬁngernail, toenail, eyelash, and eyelid, where the ﬁrst element of the compound constitutes the immediate scope of predication for the second.2 Compare this to the nonexistence and oddity of expressions like *bodytip, *armnail, *footnail, *facelash, and *headlid to designate the same entities.
In certain grammatical constructions the scope of predication plays a speciﬁc structural role. A case in point is the “nested locative” construction exempliﬁed in (4).
(4) a. The quilt is upstairs in the bedroom in the closet on the top shelf behind the boxes.
b. The rake is in the yard by the back fence near the gate.
Each locative expression conﬁnes the subject to a speciﬁc “search domain”, which then constitutes the scope of predication for the locative that follows. Thus in (4a) the locative upstairs conﬁnes the quilt to an upper story, and in the bedroom is construed relative to this restricted region – only an upstairs bedroom need be considered. The search domain imposed by this second locative functions in turn as the scope of predication for in the closet, and so on. Formally, these relationships are handled by positing a correspondence between the search domain of each locative and the scope of predication of its successor. Apart from the abstractness of the entities concerned, this correspondence is just like that found in any instance of grammatical combination (e.g. between the landmark of break and the proﬁle of the cup in break the cup).
The relative salience of a predication’s substructures constitutes a fourth dimension of imagery. Salience is of course a very general notion, so its descriptive

38 Ronald W. Langacker
signiﬁcance depends on our ability to sort out the various contributing factors. One factor is the special prominence associated with proﬁling (considered previously). A number of others can be discerned, but only two will be discussed: the relative prominence of relational participants, and the enhanced salience of elements that are explicitly mentioned.
Relational predications normally manifest an asymmetry in the portrayal of the relational participants. This asymmetry is not strictly dependent on the content of the predication, and is consequently observable even for expressions designating symmetrical relationships, e.g. resemble. I maintain that X resembles Y and Y resembles X are semantically distinct (even granting their truth-conditional equivalence): the former characterizes X with reference to Y, and the latter describes Y with reference to X. We can similarly employ either X is above Y or Y is below X to describe precisely the same conceived situation, but they differ in how they construe this situation; in the former, Y functions as a point of reference – a kind of landmark – for locating X, whereas the latter reverses these roles. The subtlety of the contrast with predications like these hardly diminishes its signiﬁcance for linguistic semantics and grammatical structure. The asymmetry is more apparent in cases like go, hit, enter, and approach, where one participant moves in relation to another (which is stationary so far as the verb itself is concerned), but its characterization must be abstract enough to accommodate the full range of relational expressions.
I attribute this inherent asymmetry to ﬁgure/ground organization (for discussion, see Langacker 1987: Chapter 6). A relational predication elevates one of its participants to the status of ﬁgure. I refer to this participant as its “trajector”; other salient participants are referred to as “landmarks”. This terminology is inspired by prototypical action verbs, where the trajector is usually the initial or primary mover, but the deﬁnitions make no speciﬁc reference to motion and are therefore applicable to any relational expression. The trajector/landmark asymmetry underlies the subject/object distinction, but the former notions have considerably broader application. In particular, a schematic trajector and landmark are imputed to a relational predication’s internal structure, regardless of whether these entities receive (or are capable of receiving) separate expression. The verb read consequently has a trajector and a landmark in all the sentences of (5), despite the fact that both are made explicit (by elaborative noun phrases) only in (5a):
(5) a. David read a new book. b. David is reading. c. The best way to learn is to read.
The terms subject and object are generally reserved for overt noun phrases that elaborate a relational trajector and primary landmark at the clausal level. By con-

Chapter 1: Cognitive Grammar 39
trast, trajector/landmark asymmetry is characteristic of relational predications at any level of organization, even if left implicit.
The enhanced salience of explicitly mentioned elements can be illustrated by the semantic contrast between pairs of expressions like the following: father vs. male parent; pork vs. pig meat; oak vs. oak tree; triangle vs. three-sided polygon; and sink vs. passively descend through a medium under the force of gravity. I am not concerned here with differences in connotation or information content – for sake of discussion, let us accept the members of each pair as equivalent in these respects. My claim is that the paired expressions nevertheless contrast semantically because the second expression in each case explicitly mentions certain semantic components and thereby renders them more prominent than they would otherwise be. Even for a speaker who knows perfectly well that pork comes from pigs, the expression pig meat renders this provenience more salient than does pork, simply because the former incorporates a symbolic unit that speciﬁcally designates this source. In similar fashion, the inclusion of the designated entity in a broader class of geometrical ﬁgures is highlighted by three-sided polygon, but remains latent in the case of triangle.
A linguistically appropriate characterization of meaning should accommodate such differences. Cognitive grammar deﬁnes the meaning of a complex expression as including not only the semantic structure that represents its composite sense, but also its “compositional path”: the hierarchy of semantic structures reﬂecting its progressive assembly from the meanings of component expressions. Let us assume, for example, that the composite semantic values of pork and pig meat are identical. As an unanalyzable morpheme, pork symbolizes this notion directly, so its compositional path consists of the single semantic structure [PORK]. However pig meat is “analyzable”, i.e. speakers recognize the semantic contribution of its component morphemes. The meaning of pig meat therefore incorporates not only the composite structure ;PORK], but also the individually symbolized components [PIG] and [MEAT], together with the relationship that each of them bears to the composite value. The two expressions arrive at the same composite value through different compositional paths (a degenerate path in the case of pork), with the consequence that they differ in meaning.
Besides accounting for the semantic contrast between simple and composite expressions, this conception of meaning has the advantage of resolving a classic problem of truth-conditional semantics. The problem is posed by semantically anomalous expressions, e.g. * perspicacious neutrino and *truculent spoon, which lack truth conditions and thus ought to be meaningless and semantically equivalent. Not only is this counterintuitive, but it also predicts – quite incorrectly – the semantic anomaly of sentences like those in (6), which contain anomalous constituents.

40 Ronald W. Langacker
(6) a. There is no such thing as a perspicacious neutrino. b. It is meaningless to speak of a truculent spoon.
In the present framework, anomalous expressions are indeed both meaningful and nonsynonymous. Though a coherent composite conceptualization fails to emerge for *perspicacious neutrino, it has a semantic value, consisting of the meanings of its components together with their speciﬁed mode of combination (as determined by the grammatical construction). The same is true for *truculent spoon, and because its components are different from those of *perspicacious neutrino, so is its semantic value. Lacking a coherent composite sense, these meanings are defective, but they are meanings nonetheless. Sentences like (6) are semantically well-formed precisely because they comment on the anomaly of a constituent.
I will mention two more dimensions of imagery only in passing, though each is multifaceted and merits extended discussion. One is the construal of a situation relative to different background assumptions and expectations. To take just one example, either (7a) or (7b) might be used to describe the same state of affairs:
(7) a. He has a few friends in high places. b. He has few friends in high places. c. Few people have any friends in high places. d. *A few people have any friends in high places.
Intuitively, the difference between few and a few is that the former is somehow negative, and the latter more positive. This is corroborated by (7c) and (7d): any, which requires a negative context (cf. Klima 1964), is compatible with few, but not with a few. Analytically, I suggest that few construes the speciﬁed quantity as being less than some implicit norm, whereas a few construes the quantity relative to a baseline of zero. These respective predications therefore indicate departure from an implicit reference point in a negative vs. a positive direction.
The ﬁnal dimension of imagery is perspective, which subsumes a number of more speciﬁc factors: orientation, assumed vantage point, directionality, and how objectively an entity is construed. Orientation and vantage point are well known from the ambiguity of sentences like (8a). The contrast between (8b) and (8c) shows the importance of directionality, even for situations that appear to involve no motion.
(8) a. Brian is sitting to the left of Sally. b. The fall falls gently to the bank of the river. c. The hill rises gently from the bank of the river. d. The balloon rose swiftly.

Chapter 1: Cognitive Grammar 41
I suggest, though, that (8b)–(8d) all involve motion in an abstract sense of the term (see Langacker 1991a: Chapter 5). Described in (8d) is physical motion on the part of a mover construed “objectively”, by which I mean that it is solely an object of conceptualization, maximally differentiated from the conceptualizer (i.e. the speaker and/or hearer). Motion along a similar trajectory is implied in (8c), but in this case the movement is abstract and the mover is construed “subjectively”: the mover is none other than the conceptualizer, in his role as the agent (rather than the object) of conceptualization. Gradations between physical and abstract motion on the one hand, and between objective and subjective construal of conceived entities on the other, are important to the analysis of numerous linguistic phenomena.3
3. Grammar as image
Lexicon and grammar form a continuum of symbolic elements. Like lexicon, grammar provides for the structuring and symbolization of conceptual content, and is thus imagic in character. When we use a particular construction or grammatical morpheme, we thereby select a particular image to structure the conceived situation for communicative purposes. Because languages differ in their grammatical structure, they differ in the imagery that speakers employ when conforming to linguistic convention. This relativistic view does not per se imply that lexicogrammatical structure imposes any signiﬁcant constraints on our thought processes – in fact I suspect its impact to be rather superﬁcial (cf. Langacker 1976). The symbolic resources of a language generally provide an array of alternative images for describing a given scene, and we shift from one to another with great facility, often within the conﬁnes of a single sentence. The conventional imagery invoked for linguistic expression is a ﬂeeting thing that neither deﬁnes nor constrains the contents of our thoughts.
The most obvious contribution of grammar to the construal of a scene pertains to designation. Grammatical constructions have the effect of imposing a particular proﬁle on their composite semantic value. When a head combines with a modiﬁer, for example, it is the proﬁle of the head that prevails at the composite structure level. Consider a simple situation in which a lamp is suspended over a table. Starting from such simple expressions as the lamp, the table, above, and below, we can combine them in alternate ways to form composite expressions that proﬁle different facets of the scene. The lamp above the table naturally designates the lamp. By choosing the table for the head, and appropriately adjusting the prepositional phrase modiﬁer, we obtain instead the table below the lamp, which proﬁles the table. Another option is to add the proper form of be to the prepositional phrase, converting it into a process predication designating the extension of the locative

42 Ronald W. Langacker
relationship through a span of conceived time, e.g. is above the table. When a subject is then supplied, the resulting sentence The lamp is above the table also proﬁles the temporally extended locative relationship.
Let us further explore the sense in which grammar embodies conventional imagery by considering the semantic contrast between (9a) and (9b).
(9) a. Bill sent a walrus to Joyce. b. Bill sent Joyce a walrus.
The standard transformational analysis of these sentences treats them as synonymous and derives them from a common deep structure; depending on the particular choice of deep structure, to is either deleted or inserted transformationally, and the nonsubject nominals are permuted in the course of deriving the surface form of either (9a) or (9b). Cognitive grammar does not posit abstract deep structures, and neither sentence type is derived from the other – they are claimed instead to represent alternate construals of the proﬁled event. Examples (9a) and (9b) differ in meaning because they employ subtly different images to structure the same conceived situation.
Figure 6.
The essentials of the analysis are sketched in Figure 6, where the small circles represent Bill, Joyce, and the walrus; the large circles stand for the regions over which Bill and Joyce exercise dominion; and heavy lines indicate a certain degree of relative prominence. Up to a point the sentences are semantically equivalent. Each symbolizes a conception in which a walrus originates in the domain under Bill’s control and – at Bill’s instigation – follows a path that results in its eventual location within the region under Joyce’s control. The semantic contrast resides in the relative salience of certain facets of this complex scene. In (9a), the morpheme to speciﬁcally designates the path followed by the walrus, thereby rendering this aspect of the conceptualization more prominent than it would otherwise be, as indicated in Figure 6(a). In (9b), on the other hand, to is absent, but the juxtaposition of two unmarked nominals (Joyce and a walrus) after the verb symbolizes a possessive relationship between the ﬁrst nominal and the second. Consequently

Chapter 1: Cognitive Grammar 43
(9b) lends added prominence to the conﬁguration that results when the walrus completes its trajectory, namely that which ﬁnds it in Joyce’s possession, as indicated in Figure 6(b).
All of the content present in one conception may be presumed to ﬁgure in the other as well – what differs is the relative salience of substructures. This subtle difference in imagery has an impact on the felicity of using to or the double-object construction for certain types of situations.4 Consider the data in (10):
(10) a. I sent a walrus to Antarctica. b. ?I sent Antarctica a walrus. c. I sent the zoo a walrus.
Example (10a) is fully acceptable because to emphasizes the path traversed by the walrus, and a continent can perfectly well be construed as the endpoint of a path. However, it is harder to construe a continent as a possessor exercising control over other entities, so (l0b), which speciﬁcally places Antarctica in a possessor role, is felt to be marginal. The status of (l0c) depends on the construal of zoo. If the zoo is simply construed as a place, it is difﬁcult to view it as a possessor, and (10c) is questionable for the same reason as (10b). But a zoo is also an institution, and it is conventional in English to treat institutions as being analogous to people, which allows them to function linguistically as agents, possessors, and so forth. Example (10c) is consequently well formed to the extent that this second construal prevails. As viewed in the present framework, then, judgments of well-formedness often hinge on the interplay and compatibility of images, and are inﬂuenced by subtle shifts in context, intended meaning, or how a speaker chooses to structure and interpret a situation.
The examples in (11)–(13) provide further illustration.
(11) a. I gave the fence a new coat of paint. b. ?I gave a new coat of paint to the fence.
(12) a. I cleared the ﬂoor for Bill. b. ?I cleared Bill the ﬂoor. c. I cleared Bill a place to sleep on the ﬂoor.
(13) a. I baked her a cake. b. ?I mowed her the lawn.
It is conventional in English to employ possessive locutions for part-whole relations, so construing a fence as the possessor of a new coat of paint, in the manner of (11a), is quite natural. It is more difﬁcult to envisage a coat of paint moving

44 Ronald W. Langacker
along a path to the fence; (11b) is thus a bit less natural, because to renders the path more prominent than the eventual possessive relationship.5 The sentences in (12)–(13) bring out another consequence of the analysis. Because the two constructions are claimed to be parallel (i.e. neither is derived from the other) and semantically distinct, it is to be expected that the double-object construction – having no intrinsic connection with to – might serve as an alternative to other prepositions also. It is well known from transformational studies (where the fact has long been problematic) that the double-object construction alternates with for as well as to. With for also the double-object construction is restricted to instances where the ﬁrst object is plausibly construed as winding up in possession of the second. In (12), for example, Bill does not come to possess the ﬂoor just because I clear it for him, so (12b) is peculiar; (12c) is perfectly acceptable, however, since the additional context provided by the second nominal (a place to sleep on the ﬂoor) makes it apparent that the spot in question effectively comes under Bill’s control and lies at his disposal by virtue of the act of clearing it. The data in (13) is similarly explained. Baking someone a cake puts the cake at that person’s disposal, but mowing a lawn can hardly have a comparable effect under normal circumstances.
4. Grammatical organization
The ultimate goal of linguistic description is to characterize, in a cognitively realistic fashion, those structures and abilities that constitute a speaker’s grasp of linguistic convention. A speaker’s linguistic knowledge is procedural rather than declarative, and the internalized grammar representing this knowledge is simply a “structured inventory of conventional linguistic units”. The term “unit” is employed in a technical sense to indicate a thoroughly mastered structure, i.e. one that a speaker can activate as a preassembled whole without attending to the speciﬁcs of its internal composition. A unit can therefore be regarded as a cognitive routine. The inventory of conventional units is “structured” in the sense that some units function as components of others (i.e. they constitute subroutines).
I speak of an “inventory” of conventional units to indicate that a grammar is nongenerative and nonconstructive. That is, I reject the standard notion that a grammar is properly conceived as an algorithmic device giving a well-deﬁned class of expressions (“all and only the grammatical sentences of a language”) as output. This conception is viable only if one imposes arbitrary restrictions on the scope of linguistic structure and makes gratuitous assumptions about its character. It is commonly assumed, for example, that judgments of grammaticality are categorical rather than matters of degree; that ﬁgurative language is properly excluded from the domain of linguistic description; and that a motivated distinc-

Chapter 1: Cognitive Grammar 45
tion can be made between semantics and pragmatics. Although such assumptions support the notion that language is self-contained and cognitively autonomous, there is little factual basis for their adoption.
Instead, I conceive the grammar of a language as merely providing the speaker with an inventory of symbolic resources, among them schematic templates representing established patterns in the assembly of complex symbolic structures. Speakers employ these symbolic units as standards of comparison in assessing the conventionality of novel expressions and usages, whether of their own creation or supplied by other speakers. The novel symbolic structures evaluated in this fashion are not a well-deﬁned set and cannot be algorithmically derived by the limited mechanisms of an autonomous grammar. Rather their construction is attributed to problem-solving activity on the part of the language user, who brings to bear in this task not only his grasp of linguistic convention, but also his appreciation of the context, his communicative objectives, his esthetic sensibilities, and any aspect of his general knowledge that might prove relevant. The resulting symbolic structures are generally more speciﬁc than anything computable from linguistic units alone, and often conﬂict with conventional expectations (e.g. in metaphor and semantic extension). Assessing their conventionality (or “well-formedness”) is a matter of categorization: categorizing judgments either sanction them as elaborations of schematic units or recognize them as departing from linguistic convention as currently established.
Only three basic types of units are posited: semantic, phonological, and symbolic. A symbolic unit is said to be “bipolar”, consisting of a semantic unit deﬁning one pole and a phonological unit deﬁning the other: [[SEM]/[PHON]]. That lexical units have this bipolar character is uncontroversial; pencil, for example, has the form [[PENCIL]/[pencil]], where capital letters abbreviate a semantic structure (of indeﬁnite internal complexity), and a phonological structure is represented orthographically. A pivotal claim of cognitive grammar is that grammatical units are also intrinsically symbolic. I maintain, in other words, that grammatical morphemes, categories, and constructions all take the form of symbolic units, and that nothing else is required for the description of grammatical structure.
Symbolic units vary along the parameters of complexity and speciﬁcity. With respect to the former, a unit is minimal (a “morpheme”) if it contains no other symbolic units as components. For instance, despite its internal complexity at both the semantic and the phonological poles, the morpheme sharp is minimal from the symbolic standpoint, whereas sharpen, sharpener, and pencil sharpener are progressively more complex. With respect to the second parameter, symbolic units run the gamut from the highly speciﬁc to the maximally schematic. Each sense of ring depicted in Figure 1, for example, combines with the phonological unit [ring] to constitute a symbolic unit. Some of these senses are schematic relative to others, so the symbolic units in question vary in their level of speciﬁcity at the

46 Ronald W. Langacker
semantic pole. Basic grammatical categories (e.g. noun, verb, adjective, adverb) are represented in the grammar by symbolic units that are maximally schematic at both the semantic and the phonological poles. A noun, for instance, is claimed to instantiate the schema [[THING]/[X]], and a verb the schema [[PROCESS]/[Y]], where [THING] and [PROCESS] are abstract notions to be described later, and [X] and [Y] are highly schematic phonological structures (i.e. they specify little more than the presence of “some phonological content”).
A grammatical rule or construction is represented in the grammar by a symbolic unit that is both complex and schematic. For example, the morphological rule illustrated by the deverbal nominalizations teacher, helper, hiker, thinker, diver, etc. consists in a complex unit that incorporates as components the verb schema [[PROCESS]/[Y]] and the grammatical morpheme [[ER]/[er]] (i.e. the sufﬁx -er, which is attributed substantial though schematic semantic content). This unit further speciﬁes how the component structures are integrated, conceptually and phonologically, to form a composite symbolic structure. Using “-” to indicate this integration (examined later), we can write the constructional schema as follows: [[[PROCESS]/[Y]]-[[ER]/[er]]]. Its internal structure is exactly parallel to that of an instantiating expression, e.g. [[[TEACH]/[teach]]-[[ER]/[er]]], except that in lieu of a speciﬁc verb stem it contains the schema for the verb-stem category.
One constructional schema can be incorporated as a component of another. In the top portion of Figure 7(a), the schema just described combines with the noun schema [[THING]/[X]] to form a higher-order constructional schema, which speakers presumably extract to represent the commonality of pencil sharpener, lawn mower, mountain climber, back scratcher, taxi driver, and so on. The lower portion of 7(a) represents the lexical unit pencil sharpener, which conforms to the speciﬁcations of this schema but elaborates it greatly. The arrow labeled (a) indicates that the upper structure as a whole is judged schematic for the overall expression; this categorizing relationship is what speciﬁes the membership of the expression in the class that the schema characterizes. This global categorizing relationship is based on local categorizations between component structures: relationship (b) identiﬁes pencil as a member of the noun class; (c) categorizes sharpener as a deverbal nominalization derived by -er; and (d) classes sharpen as a verb.6 The full set of categorizing relationships of this sort constitutes the expression’s “structural description”. Observe that pencil sharpener has a conventional meaning which is considerably more speciﬁc than anything derivable compositionally from the meanings of its parts – a pencil sharpener is not simply ’something that sharpens pencils’. Given the nonconstructive nature of the present model, we can nevertheless accept the expression as a valid instantiation of the construction in question, without relegating the unpredictable semantic speciﬁcations to the realm of extralinguistic knowledge. The constructional schema is not responsible for assembling the expression, but only for its categorization.

Chapter 1: Cognitive Grammar 47
Figure 7.
All of the structures and categorizing relationships in Figure 7(a) have the status of units, which I indicate by enclosing them in boxes or square brackets. What about a novel expression on the same model, for example chalk sharpener? Its organization is sketched in Figure 7(b), where a closed curve (as opposed to a box) indicates a structure that does not yet constitute a unit. The assembly of this novel symbolic structure is largely preﬁgured by existing units, including the constructional schema, the components chalk and sharpener, and the categorization of chalk as a noun. Taken as a whole, however, neither the full expression chalk sharpener nor its categorization by the constructional schema (relationship (a)) has unit status. It does not matter for our purposes whether a speaker employs the existing units to construct or simply to understand the novel expression – in either case, all of the structures and relationships in 7(b) ﬁgure in its composition and structural description, and in either case its contextual meaning may incorporate speciﬁcations that are obvious from the situation being described (which functions as the domain for the composite expression) but are not supplied by the conventional meanings of its components. Despite this lack of full compositionality, the expression may well recur with sufﬁcient frequency to become established as a conventional unit parallel to pencil sharpener, lawn mower, etc. If so, its contextual meaning (in an appropriately schematized form) becomes the conventional meaning of the new lexical unit. Full semantic compositionality is therefore not a hallmark of either novel expressions as they are actually understood or the ﬁxed expressions which result from their conventionalization.
This conception of grammar makes it possible to impose the following restriction on linguistic analyses: the only units permitted in the grammar of a language are (i) semantic, phonological, and symbolic structures that occur overtly in linguistic expressions; (ii) structures that are schematic for those in (i); and (iii) categorizing relationships involving the structures in (i) and (ii). I call this the “content requirement”, and consider it to be intrinsically more restrictive (at least

48 Ronald W. Langacker
in a certain, possibly nontechnical sense) than the constraints generally imposed on algorithmic models. Essentially, it rules out all arbitrary descriptive devices, i.e. those with no direct grounding in phonetic or semantic reality. Among the devices excluded are contentless features or arbitrary diacritics; syntactic dummies with neither semantic nor phonological content, introduced solely to drive the formal machinery of autonomous syntax (cf. Perlmutter 1978); and the derivation of overt structures from abstract, underlying structures of a substantially different character (e.g. the derivation of passives from actives – see Langacker (1991a: Chapter 4) for an alternative account).
5. Grammatical classes
The content requirement proscribes the use of diacritic features. How, then, does a grammar indicate the behavior and class membership of conventional units? Some classes are characterized on the basis of intrinsic semantic and/or phonological content. In this event, a schematic unit is extracted to represent the shared content, and class membership is indicated by categorizing units reﬂecting the judgment that individual members instantiate the schema. The vowel [i], for example, is classed as a high vowel by virtue of the categorizing unit [[HIGH¬VOWEL]ĺ[i]], where [HIGH¬VOWEL] is a schematic phonological structure which neutralizes the properties that distinguish one high vowel from another. Similarly, among the categorizing units depicted in Figure 7(a), relationships (b) and (d) identify pencil and sharpen as a noun and a verb respectively, whereas relationship (a) identiﬁes pencil sharpener as an instance of the grammatical construction characterized by the overall schema. Only symbolic structures with actual semantic and phonological content ﬁgure in these relationships.
Obviously, though, the membership of many grammatical classes is not fully predictable on the basis of semantic or phonological properties, e.g. the class of nouns that voice f to v in the plural (leaf/leaves, but reef/reefs), or the class of verbs that conventionally occur in the double-object construction described earlier (cf. Green 1974; Oehrle 1977). The fact that morphological and syntactic behavior is often not fully predictable is generally taken as establishing the independence of grammar as a distinct aspect of linguistic structure. However, this conclusion does not actually follow from the observation – the tacit reasoning behind it confounds two issues that are in principle distinct: (i) what KINDS¬of structures there are; and (ii) the PREDICTABILITY of their behavior. The present framework accommodates unpredictable behavior without positing arbitrary diacritics or rule features. To say that leaf (but not reef) voices f to v in the plural is simply to say that the composite symbolic structure leaves (but not reeves) is included among the conventional units of the grammar. Similarly, to say that send participates in the double-object

Chapter 1: Cognitive Grammar 49
construction amounts to positing the constructional schema [send NP NP], where the verb is speciﬁc but the two noun phrases are characterized only schematically. The nonoccurrence of transfer in this construction is reﬂected in the grammar by the nonexistence of the parallel symbolic unit [transfer NP NP].7
Crucial to the claim that grammatical structure resides in symbolic units alone is the possibility of providing a notional characterization of basic grammatical categories, nouns and verbs in particular. The impossibility of such a characterization is a fundamental dogma of modern linguistics, but the standard arguments that appear to support it are not immune to criticism. For one thing, they presuppose an objectivist view of meaning, and thus fail to acknowledge sufﬁciently our capacity to construe a conceived situation in alternate ways. Consider the argument based on verb/noun pairs which refer to the same process, e.g. extract and extraction. Such pairs demonstrate the impossibility of a notional deﬁnition only if one assumes that they are semantically identical, yet this is not a necessary assumption when meaning is treated as a subjective phenomenon. It is perfectly coherent to suggest that the nominalization of extract involves a conceptual reiﬁcation of the designated process, i.e. the verb and noun construe it by means of contrasting images. Another type of argument against a notional characterization pivots on the confusion of prototypes with abstract schemas. In the case of nouns, for instance, discussions of notional deﬁnitions generally focus on physical objects (or perhaps “persons, places, and things”), which are clearly prototypical; the existence of nouns like extraction, which do not conform to this prototype, is then taken as demonstrating that nouns are not a semantic class. Obviously, a schematic characterization of the class – one compatible with the speciﬁcations of all class members – cannot be identiﬁed with the category prototype representing typical instances. If a schematic characterization is possible at all, it must be quite abstract, accommodating both physical objects and many other sorts of entities as special cases.
Cognitive grammar posits a number of basic classes that differ in the nature of their proﬁle (see Langacker 1991a: Chapter 3 for extensive discussion). As previously indicated, a noun is a symbolic structure that designates a thing, where “thing” is a technical term deﬁned as a “region in some domain”; in the case of count nouns, the proﬁled region is further speciﬁed as being “bounded”. Because physical objects occupy bounded regions in three-dimensional space, expressions which designate such objects qualify as count nouns, but the deﬁnition does not speciﬁcally refer to them or to the spatial domain in particular. Examples of count nouns characterized with respect to other domains include moment (a bounded region in time), paragraph (a delimited portion of a written work), and B-ﬂat (a minimal, point-like region on the musical scale). Observe that the bounding implied by a count noun need not be sharp or precise, and it may be imposed

50 Ronald W. Langacker
as a matter of construal when objective factors do not suggest any demarcation. Where, for instance, does one’s midriff begin or end?
Contrasting with nouns are “relational” expressions, which proﬁle the “interconnections” among conceived entities. The term “entity” is employed in a maximally general way, and subsumes anything we might have occasion to refer to for analytic purposes: things, relations, boundaries, points on a scale, and so on. Interconnections can be regarded as cognitive operations that assess the relative position of entities within the scope of predication. It is speculated that only four basic types of assessment are necessary, provided that cognitive domains have been properly described: inclusion (INCL), coincidence (COINC), separation (SEP), and proximity (PROX). Signiﬁcantly, the interconnecting operations deﬁning a relational conception commonly associate entities other than the major relational participants (trajector and primary landmark), or associate selected facets of these participants rather than treating them as undifferentiated wholes.
By way of illustration, consider the predicate [ABOVE], sketched in Figure 8. Its domain is space organized in terms of vertical and horizontal dimensions, including an implicit reference point Ov (the vertical origin). The major relational participants are both things, characterized only schematically; one is further identiﬁed as the trajector (relational ﬁgure).8 Among the entities invoked by speciﬁcations of this predicate are the horizontal and vertical projections of the trajector (ht, vt) and of the landmark (h1, v1). The expression above is optimally employed when the horizontal projections of the trajector and landmark coincide, i.e. [ht COINC h1], but is tolerated so long as they remain in proximity to one another: [ht PROX h1]. With respect to the vertical dimension, on the other hand, their projections must not coincide – the speciﬁcation [vt SEP v1] is obligatory. The pivotal speciﬁcation of [ABOVE] is provided by an operation interconnecting two entities that are still more abstract. Let [Ov > vt] be the operation which registers the displacement of the trajector from the vertical origin, and [Ov > vl] that of the landmark. The speciﬁcation in question resides in a higher-order operation assessing the relative magnitudes of the component operations: [(Ov > vt) INCL (Ov > vl)].
Figure 8.

Chapter 1: Cognitive Grammar 51
Interconnecting operations of roughly this sort must somehow ﬁgure in the cognitive representation of a relational notion (though I take no position on the speciﬁcs of their implementation). [ABOVE] is a “simple atemporal relation” (or “stative” relation), in the sense that its speciﬁcations portray a single, internally consistent conﬁguration. We must also recognize “complex” atemporal relations, where such is not the case. Consider the contrast between (14a) and (14b).
(14) a. There is a bridge across the river. b. A hiker waded across the river.
Distinct senses of across are involved, diagramed in Figures 9(a) and (b). In 9(a), the trajector (in this case the bridge) simultaneously occupies all the points on a path leading from one side of the primary landmark (the river) to the other. In 9(b), on the other hand, the trajector still occupies all the points on the path leading from one side of the landmark to the other, but does so only successively through time. The proﬁled relationship involves indeﬁnitely many distinct conﬁgurations (or states), of which only a few are represented diagramatically. This sense of across is consequently a complex atemporal relation.9
Figure 9.
Atemporal relations contrast with “processes”, which deﬁne the class of verbs. The distinction between a process and a complex atemporal relation involves the contrast between “sequential” and “summary scanning” (see Langacker 1991a: Chapter 3). Sequential scanning is the mode of processing we employ when watching a motion picture or observing a ball as it ﬂies through the air. The successive states of the conceived event are activated serially and more or less instantaneously, so that the activation of one state begins to decline as that of its successor is initiated; essentially, we follow along from one state to the next as the event unfolds.10 On the other hand, summary scanning is what we employ in mentally reconstructing the trajectory a ball has followed (e.g. in identifying a

52 Ronald W. Langacker
pitch as a curve, fastball, or slider and diagraming its degree of curvature). The component states are activated successively but cumulatively (i.e. once activated they remain active throughout), so that eventually they are all coactivated as a simultaneously accessible whole. The difference between a complex atemporal relation (like across) and the corresponding verb (cross) is therefore attributed not to their intrinsic content, but rather to the mode of scanning employed in their activation – a matter of conventional imagery.
Abbreviatory notations for the basic classes of predications are presented in Figure 10. A circle is the natural choice to represent a thing. A simple atemporal (or stative) relation proﬁles the interconnections between two or more conceived entities, where an entity can be either a thing or another relation. (Dashed lines represent these interconnections, and by convention the uppermost of the interconnected entities will be taken as the trajector unless otherwise indicated.) A complex atemporal relation consists of a sequence of stative relations scanned in summary fashion. A process is comparable to a complex atemporal relation in proﬁling a sequence of relational conﬁgurations, but has certain other properties as well: (i) the component states are conceived as being distributed through time; (ii) these states are scanned in sequential fashion; and (iii) the trajector is always a thing (never a relation). The arrow in Figure 10(e) stands for conceived time, and the heavy-line bar along this arrow indicates that the component states are scanned sequentially through processing time.
Figure 10.
6. Grammatical constructions
Grammar resides in patterns for the successive combination of symbolic structures to form more and more elaborate symbolic expressions. It is described by a structured inventory of “grammatical constructions”, each of which speciﬁes the

Chapter 1: Cognitive Grammar 53
relation between two or more “component” structures and the “composite” structure resulting from their integration. The essential structures and relationships in a grammatical construction are spelled out in Figure 11, where [SEM3/PHON3] is the composite structure formed by integrating the component expressions [SEM 1/¬ PHON 1] and [SEM 2/¬PHON 2]. The two diagrams are notational variants: 11(b) is an “exploded” version of 11(a); it shows the component and composite structures separately at each pole.
Four symbolic relationships are indicated in Figure 11. The ones labeled s1 and s2 hold between the semantic and the phonological poles of each component expression, whereas s3 indicates that the composite phonological structure symbolizes the composite semantic structure. The fourth relationship, si, reveals an important sense in which grammar is said to be inherently symbolic: the integration of component structures at the phonological pole serves to symbolize the integration of the corresponding component structures at the semantic pole. Consider the plural noun walls. At the phonological pole, the component structures are integrated by the sufﬁxation of -s to wall, which involves the appropriate temporal sequencing, syllabic organization, and minor phonetic adjustments. It is precisely the fact that -s sufﬁxes to wall (and not to some other noun stem) which symbolizes the fact that the plurality it expresses is predicated of the notion wall in particular (rather than the thing designated by some other noun in the sentence). Or to put it in other terms, the symbolic association si, does not hold between a semantic and a phonological structure per se – instead it associates the RELATIONSHIPS¬ between two semantic and two phonological structures.
Figure 11.
Integration and composition work in essentially the same way at the phonological pole and the semantic pole, but we will conﬁne our attention to the latter. I suggest that the integration of two component structures always involves “cor-

54 Ronald W. Langacker
respondences” being established between certain of their substructures. The corresponding substructures provide points of overlap between the component predications, which are necessary if a coherent composite conception is to emerge. The composite structure is obtained by superimposing the speciﬁcations of corresponding substructures. In those instances where there is some conﬂict in their speciﬁcations, a fully consistent composite notion cannot be formed, and the result is what we perceive as semantic anomaly (or the violation of “selectional restrictions”).
The semantic pole of a typical construction is sketched in Figure 12(a), which diagrams the integration of above and the table to form the prepositional phrase above the table (I will ignore the semantic contribution of the deﬁnite article). [ABOVE] proﬁles a stative relation in oriented space between two things, each characterized only schematically. [TABLE] proﬁles a thing characterized in far greater detail with respect to numerous domains; purely for sake of diagramatic convenience, it is represented by a mnemonic shape speciﬁcation. The integration of these component predications is effected by a correspondence established between the landmark of [ABOVE] and the proﬁle of [TABLE] (correspondences are represented by dotted lines). By superimposing the speciﬁcations of these corresponding substructures, and adopting the relational proﬁle of [ABOVE], we obtain the composite predication (ABOVE -¬TABLE), which designates a stative relation involving a schematic trajector and a speciﬁc landmark. Note that the compositional process results in “vertical” correspondences between elements of the component and composite structures, in addition to the “horizontal” correspondence(s) linking the components.11
Figure 12.
Semantics is not fully compositional. When ﬁrst assembled, an expression’s composite structure may invoke a domain or incorporate speciﬁcations (e.g. the orien-

Chapter 1: Cognitive Grammar 55
tation of the table) that are not predictable from the component structures or other conventional units. Because such speciﬁcations are part of how the expression is actually understood in context, and may well be included in its conventional semantic value should the expression be established as a unit, it is arbitrary to exclude them from the purview of semantic analysis. There are nevertheless conventional patterns of composition that determine central aspects of a composite structure’s organization. These are represented in the grammar by constructional schemas, whose internal structure is parallel to that of the speciﬁc expressions which instantiate them. For example, the grammar of English includes a schema for the prepositional-phrase construction. Its phonological pole speciﬁes the contiguity and linear ordering of the preposition and its noun-phrase object; its semantic pole, given in Figure 12(b), is precisely analogous to 12(a) except that the component and composite structures are schematic rather than speciﬁc. The ﬁrst component is schematic for the class of prepositions. Basically, it is identiﬁed only as a stative relation whose trajector and primary landmark are both things. The other component is the noun-phrase schema: it proﬁles a thing, and implies additional content (labeled X), but does not itself specify the nature of this content. As in the speciﬁc structure 12(a), a correspondence holds between the landmark of P and the proﬁle of NP, and the composite structure is formed by superimposing the speciﬁcations of these correspondents (and adopting the relational proﬁle of P). Speakers can employ this constructional schema in the computation and evaluation of novel expressions. It serves as the structural description of any expression which it categorizes when so employed.
This construction has various properties that can be regarded as prototypical. There are just two component structures, one of them relational and the other nominal. A correspondence holds between two highly prominent substructures: the proﬁle of the nominal predication, and the primary landmark (one facet of the proﬁle) of the relational predication. Moreover, there is a substantial asymmetry in the degree of speciﬁcity at which the predications characterize the corresponding elements – the landmark of [ABOVE] is quite schematic, whereas by comparison the proﬁle of [TABLE] is speciﬁed in considerable detail. I have indicated this diagramatically by an arrow (standing for a relationship of schematicity) between [ABOVE]’s landmark and the other predication as a whole. Finally, it is the relational predication which lends its proﬁle to the composite structure (i.e. above the table designates a stative relation, not a thing). I thus refer to [ABOVE] in 12(a) as the construction’s “proﬁle determinant”, and make this role explicit by putting the box enclosing this predication in heavy lines.
None of the properties just cited is invariant except the existence of at least one correspondence between substructures of the components. By recognizing these properties as prototypical rather than imposing them as absolute requirements, we obtain the ﬂexibility needed to accommodate the full range of attested

56 Ronald W. Langacker
construction types. It is probably necessary, for example, to allow more than just two component structures at a particular level of constituency (e.g. for coordinate expressions such as X, Y, and Z). It need not be the case that one component structure is relational and the other nominal – in fact, there need be no relational component at all. Appositional constructions involving two nominal predications, e.g. my good friend Ollie North, are straightforwardly accommodated in this framework by means of a correspondence established between the nominal proﬁles. In all the examples cited so far, the corresponding elements have been things that either constitute or are included within the proﬁle of the component structure. Often, however, the correspondents are relational substructures, and they need not be in proﬁle. Consider once more the sense of gone diagramed in Figure 4(c). The component structures are [GO], which designates a process, and one particular semantic variant of the past-participial morpheme. This particular predication proﬁles the ﬁnal state of an otherwise unproﬁled process that constitutes its base. The participial morpheme itself characterizes this process quite schematically; only in combination with a verb stem is the nature of the process made speciﬁc. Their integration is effected by a correspondence between the speciﬁc process proﬁled by [GO] and the schematic process functioning as the base within the participial predication. By superimposing their speciﬁcations, and adopting the proﬁle contributed by the grammatical morpheme, we obtain a composite structure that proﬁles just the ﬁnal state of the process [GO].
Figure 13.
A factor we have not yet considered is “constituency”, which pertains to the order in which symbolic structures are progressively assembled into larger and larger

Chapter 1: Cognitive Grammar 57
composite expressions. Clearly, the composite structure resulting from the integration of component structures at one level of organization can itself be employed as a component structure at the next higher level, and so on indeﬁnitely. In Figure 13, for example, the composite structure (ABOVE-TABLE) from Figure 12(a) functions as a component structure, combining with [LAMP] to derive the composite semantic value of the noun phrase the lamp above the table. At this second level of organization, it is the schematic trajector of the relational predication that is put in correspondence with the proﬁle of the nominal predication; moreover, it is this latter which functions as the construction’s proﬁle determinant. The composite structure (LAMP-ABOVE-TABLE) consequently designates the lamp, not its locative relationship vis-à-vis the table, though this relationship is included as a prominent facet of its base.
Some grammatically signiﬁcant observations can be made on the basis of these examples. For one thing, we see that either a relational or a nominal predication is capable of serving as the proﬁle determinant in a construction. In Figure 12, it is the relation [ABOVE] which contributes the proﬁle of the composite expression, whereas in Figure 13 it is the nominal [LAMP]. Moreover, the constructs now at our disposal permit workable and revealing characterizations of certain fundamental grammatical notions that have long been problematic, namely “head”, “modiﬁer”, and “complement”. At a given level of organization, a construction’s head can be identiﬁed with its proﬁle determinant. Above is thus the head within the prepositional phrase above the table, whereas lamp is the head within the noun phrase the lamp above the table. In appositional expressions like my good friend Ollie North there is no real basis for singling out either component noun phrase as the head. But that is precisely what we expect: because their proﬁles correspond, and each corresponds to the proﬁle of the composite structure, it is arbitrary to say that the latter inherits its proﬁle from either one of the component structures (as opposed to the other).
To the extent that one component structure, taken as a whole, serves to elaborate a salient substructure within the other, I will speak of the elaborating component as being “conceptually autonomous”, and the elaborated component as “conceptually dependent”. In Figure 12(a), then, [TABLE] is conceptually autonomous with respect to [ABOVE] because it elaborates the latter’s schematic landmark. In Figure 13, similarly, [LAMP] is autonomous by virtue of elaborating the schematic trajector of the dependent predication (ABOVE-TABLE). The notions modiﬁer and complement can now be characterized explicitly in a way that reconstructs the normal usage of these traditional terms: a “modiﬁer” is a conceptually dependent predication that combines with a head, whereas a “complement” is a conceptually autonomous predication that combines with a head. The table is consequently a complement (or “argument”) of above in above the table, and this entire prepositional phrase functions as a modiﬁer of lamp in the lamp above the table. What

58 Ronald W. Langacker
about appositional constructions? Because there is no basis for recognizing either component structure as the head (and often no autonomous/dependent asymmetry), the deﬁnitions are correctly found to be inapplicable. In my good friend Ollie North, neither my good friend nor Ollie North is considered a modiﬁer or a complement of the other.
This conception of grammatical structure has numerous descriptive advantages, only a few of which will be noted at this juncture. One advantage is that it readily accommodates variability of constituency, which is in fact quite common. The present framework does not posit phrase trees of the sort familiar from generative studies, nor does it rely on phrase structure conﬁgurations for the deﬁnition of grammatical relations. Constituency is simply the sequence in which component symbolic structures are progressively assembled into more and more elaborate composite expressions. Though a speciﬁc order of assembly commonly becomes conventionalized as the sole or default-case sequence, the choice is not inherently critical in this model, because alternate constituencies often permit the same composite structure to be derived. Moreover, because grammatical relations are not deﬁned in conﬁgurational terms, a unique constituency is not essential. What identiﬁes the table as the object of above in above the table, for example, is the fact that the noun phrase elaborates the preposition’s landmark. Though constituency happens to be invariant in this case, the critical factor in deﬁning the prepositional-object relation is the correspondence established between the landmark of the preposition and the proﬁle of the noun phrase.
We can better appreciate these points with regard to sentences like the ones in (15).
(15) a. Alice likes liver. b. Liver Alice likes. c. Alice likes, but most people really hate, braised liver.
Sentence (15a) exhibits the normal, default-case NP + VP constituency of English clauses: liver elaborates the schematic landmark of likes at the ﬁrst level of constituency, yielding a processual predication with a speciﬁed landmark and schematic trajector; Alice then elaborates the trajector of likes liver at the second level to derive a process predication whose trajector and landmark are both speciﬁc. It should be apparent, however, that the same composite structure will result if the constituents combine in the opposite order, with Alice elaborating the schematic trajector of likes, and then liver the schematic landmark of Alice likes. This alternative constituency is available for exploitation, with no effect on grammatical relations, whenever special factors motivate departure from the defaultcase arrangement. Two such factors are illustrated here. In (15b) we observe the topicalization of the direct-object noun phrase, normally described as a movement

Chapter 1: Cognitive Grammar 59
transformation. There is no need in this framework to derive this sentence type by transformation – it can be assembled directly through the alternate compositional path. The second type of situation arises in conjoined structures when two verbs have different subjects but share the same object, as in (15c). In lieu of the transformational process of “Right Node Raising”, which supposedly derives this type of sentence from conjoined clauses of normal NP + VP constituency, we can once again assemble the overt structure directly. The two subject-verb constituents are put together ﬁrst and then combined in a coordinate structure. A direct object NP is subsequently added, being integrated simultaneously with each conjunct through a correspondence between its proﬁle and the conjunct’s relational landmark.
Also eliminable in this framework is the raising rule needed in certain transformational accounts (e.g. Keyser and Postal 1976) to handle agreement between a subject and an auxiliary verb, as in (16).
(16) The lamp is above the table.
The rationale for a raising rule goes something like this: (i) a verb is assumed to agree with its own subject; (ii) the lamp is not the logical subject of be, which – if anything – has a clause for its underlying subject; (iii) hence, to account for agreement, some rule must raise the lamp from its position as subject of above and make it the subject of be. However the need for such a rule is obviated given a proper analysis of be and a suitably ﬂexible conception of grammatical constructions.
The semantic pole of (16) is outlined in Figure 14.12 Pivotal to the analysis is the semantic value attributed to be, of which three main features are relevant. First, be is a true verb, i.e. a symbolic expression that proﬁles a process. Second, all the component states of the designated process are construed as being identical; this is indicated by the dotted correspondence lines internal to [BE] that link the three states which are explicitly represented (additional correspondence lines specify that the trajector is the same from one state to the next, as is the landmark). Third, apart from this speciﬁcation of identity, the proﬁled process is maximally schematic. Be is one of numerous verbs in English which designate a process consisting of the extension through time of a stable situation (see Langacker 1991a: Chapter 3) – others include have, resemble, like, know, contain, slope, exist, and so on – but it abstracts away from the speciﬁc content that distinguishes these predications from one another. In summary, [BE] follows through time, by means of sequential scanning, the evolution of a situation that is construed as being stable but not further speciﬁed (except for its relational character).
Any single component state of [BE] constitutes a schematic stative relation. At the ﬁrst level of constituency in Figure 14, the more speciﬁc stative relation (ABOVE-TABLE) is put in correspondence with a representative state of [BE], the

60 Ronald W. Langacker
latter serving as proﬁle determinant. The result is the composite predication (BE-ABOVE-TABLE), which is like [BE] except that all the speciﬁcations inherited from (ABOVE-TABLE) are attributed to the situation followed sequentially through time. Observe that the landmark of (BE-ABOVE-TABLE) is now speciﬁc, whereas its trajector remains schematic. At the second level of constituency, this schematic trajector is elaborated by [LAMP] to derive the composite structure (LAMP-BEABOVE-TABLE), which represents the composite meaning of the full sentence. It proﬁles the extension through time of a stable situation in which the lamp and the table participate in a particular locative relationship.
Figure 14.
Observe that the sentence is assembled directly, in accordance with its surface constituency. In particular, there is no “raising” rule which derives it from a hypothetical underlying structure by changing the grammatical relation of the subject NP. But does the lamp function as the subject of be, as their agreement

Chapter 1: Cognitive Grammar 61
presumably requires? It certainly does, given the way grammatical relations are deﬁned in this framework. A subject NP is one which elaborates the schematic trajector of a relational predication by virtue of a correspondence established between that trajector and its own proﬁle. With respect to Figure 14, note ﬁrst that [BE] does in fact have a schematic trajector, characterized as both a thing (not a clause) and a relational participant. Moreover, [BE]’s trajector does correspond to the proﬁle of the lamp, when both horizontal and vertical correspondences are taken into account: the proﬁle of [LAMP] corresponds to the trajector of (BEABOVE-TABLE), which in turn corresponds vertically to the trajector of [BE]. It is simply incorrect, in this analysis, to claim that be has no nonclausal subject, or that the lamp is not its “logical” subject in (16). With no special apparatus, the analysis establishes a relationship between the lamp and be which is perfectly adequate as a basis for agreement.
Finally, the analysis permits a simple and natural account of sentences like (17b), in which an auxiliary verb functions as a pro form:
(17) a. Q: What is above the table? b. A: The lamp is.
As highly schematic process predications, auxiliary verbs are perfectly suited to this role, and sentences of this type are derivable without any deletion operation. Because constituency is potentially variable in this framework, we can derive (17b) just by combining the lamp and be directly. A correspondence is established between the proﬁle of the former and the schematic trajector of the latter. Be is the proﬁle determinant, so the composite structure designates a process involving the evolution of a stable situation through time. Apart from its trajector, identiﬁed as the lamp, this situation is characterized only schematically.
7. Conclusion
This initial presentation of cognitive grammar has itself been quite schematic. I do however hope to have shown that currently predominant linguistic theories do not represent the only possible way of conceiving the nature of language structure and linguistic investigation. By taking a radically different perspective on questions of meaning and grammar, it is possible to formulate a coherent descriptive framework which promises to be both cognitively realistic and linguistically well-motivated.

62 Ronald W. Langacker
Notes
1. Observe that designation, in my technical sense of the term, does not pertain to the relation between a linguistic expression and the world – rather it is a relationship holding between a cognitive domain as a whole and certain of its subparts. I do not know whether proﬁling reduces to any independently established cognitive phenomenon. Possibly it constitutes one level of ﬁgure/ground organization, but not every ﬁgure is a designatum.
2. In these expressions eye is evidently construed as the eye region, not the eyeball itself.
3. The constructs needed to make this notion of subjectivity/objectivity precise are introduced in Langacker 1985 and 1987, Chapters 3 and 7. For vantage point and orientation, see Langacker (1991a: Chapter 2) and Vandeloise 1984.
4. Goldsmith 1980 presents a very similar analysis. 5. The importance of conventionality should be emphasized. Often a speaker is led to
employ a particular image simply because an alternative construction, which might seem more appropriate, happens not to be conventionally established. For instance, many verbs of transfer (e.g. transfer itself) are not employed in the double-object construction; the to-construction represents the speaker’s only option with such verbs. 6. At this level of organization, we can ignore the fact that sharpen is morphematically complex. The double-headed arrow labeled (e) in Figure 7 indicates identity of the associated structures. 7. Fuller discussion is provided in Langacker (1991a: Chapter 10). (See also Langacker 1987: Chapter 11.) 8. By reversing the trajectory/landmark assignation, we obtain the predicate [BELOW]. 9. I omit the dashed line standing for the proﬁled interconnections, because the nature of these interconnections is implicit in the position of the major participants within the diagrams. Note that I regard these diagrams as heuristic in character, not as formal objects. They are analogous to the sketch a biologist might draw to illustrate the major components of a cell and their relative position within it. 10. Only for convenience do I speak of discrete states – a process is more accurately viewed as continuous. 11. The component structures are enclosed in boxes, to indicate that above and the table have the status of units. Closed curves surround the composite structure and the construction as a whole on the presumption that above the table is a novel expression (in the text, parentheses serve this purpose). 12. Omitted are the semantic contributions of the deﬁnite article and the verb inﬂection on be. Note that our concern is not the nature of agreement (cf. Langacker 1991a: Chapter 11), but rather the issue of whether the lamp can be considered the subject of be in accordance with assumption (i).

Chapter 1: Cognitive Grammar 63
References
Barwise, Jon and John Perry 1983 Situations and Attitudes. Cambridge, MA, and London: MIT Press/Bradford.
Bever, Thomas G. and Peter S. Rosenbaum 1970 Some lexical structures and their empirical validity. In Readings in English Transformational Grammar, Roderick A. Jacobs and Peter S. Rosenbaum (eds.), 3–19. Waltham, MA: Ginn.
Bybee, Joan L. 1988 Semantic substance vs. contrast in the development of grammatical meaning. In Proceedings of the Annual Meeting of the Berkeley Linguistics Society 14: 247–264.
Casad, Eugene H. 1982 Cora locationals and structured imagery. Unpublished Ph.D. dissertation, University of California, San Diego. 1988 Conventionalization of Cora locationals. In Topics in Cognitive Linguistics, Brygida Rudzka-Ostyn (ed.), 345–378. Amsterdam/Philadelphia: Benjamins.
Chafe, Wallace L. 1970 Meaning and the Structure of Language. Chicago: University of Chicago Press.
Cook, Kenneth W. 1988 A cognitive analysis of grammatical relations, case, and transitivity in Samoan. Unpublished Ph.D. dissertation, University of California, San Diego. 1989 A cognitive account of the Samoan lavea and galo verbs. Linguistic Agency University of Duisburg.
Cruse, D.Allan 1979 On the transitivity of the part-whole relation. Journal of Linguistics 15: 29–38.
Fauconnier, Gilles 1985 Mental Spaces: Aspects of Meaning Construction in Natural Language. Cambridge, MA and London: MIT Press/Bradford.
Fillmore, Charles J. 1982 Frame Semantics. In Linguistics in the Morning Calm, Linguistic Society of Korea (ed.), 111–137. Seoul: Hanshin.
Givón, Talmy 1979 The time-axis phenomenon. Language 49: 890–925. 1984 Syntax: A Functional-Typological Introduction. Volume 1. Amsterdam/Philadelphia: Benjamins. 1989 Mind, Code, and Context: Essays in Pragmatics. Hillsdale, NJ: Erlbaum.
Green, Georgia M. 1974 Semantics and Syntactic Regularity. Bloomington: Indiana University Press.
Haiman, John 1980 Dictionaries and encyclopedias. Lingua 50: 329–357. 1983 Iconic and economic motivation. Language 59: 781–819.

64 Ronald W. Langacker
1985 Natural Syntax: Iconicity and Erosion. Cambridge: Cambridge University Press.
Hawkins, Bruce W. 1984 The semantics of English spatial prepositions. Unpublished Ph.D. dissertation, University of California, San Diego. 1988 The natural category MEDIUM: An alternative to selection restrictions and similar constructs. In Topics in Cognitive Linguistics, Brygida Rudzka-Ostyn (ed.), 231–270. Amsterdam/Philadelphia: Benjamins.
Jackendoff, Ray 1983 Semantics and Cognition. (Current Studies in Linguistics 8.) Cambridge, MA: MIT Press.
Janda, Laura A. 1984 A semantic analysis of the Russian verbal preﬁxes za-, pere-, do-, and ot-. Unpublished Ph.D. dissertation, University of California, Los Angeles. 1988 The mapping of elements of cognitive space onto grammatical relations: An example from Russian verbal preﬁxation. In Topics in Cognitive Linguistics, Brygida Rudzka-Ostyn (ed.), 327–343. Amsterdam/Philadelphia: Benjamins. 1993 A Geography of Case Semantics: The Czech Dative and the Russian Instrumental. Berlin/New York: Mouton de Gruyter.
Johnson, Mark 1987 The Body in the Mind: The Bodily Basis of Meaning, Imagination, and Reason. Chicago/London: University of Chicago Press.
Johnson-Laird, Philip N. 1983 Mental Models. Cambridge, MA: Harvard University Press.
Katz, Jerrold J. and Jerry A. Fodor 1963 The structure of a semantic theory. Language 39: 170–210.
Kemmer, Suzanne E. 1988 The middle voice: A typological and diachronic study. Unpublished Ph.D. dissertation, Stanford University.
Keyser, Samuel Jay and Paul M. Postal 1976 Beginning English Grammar. New York: Harper & Row.
Klima, Edward S. 1964 Negation in English. In The Structure of Language: Readings in the Philosophy of Language, Jerry A. Fodor and Jerrold J. Katz (eds.), 246–323. Englewood Cliffs, NJ: Prentice-Hall.
Kosslyn, Stephen Michael 1980 Image and Mind. Cambridge, MA: Harvard University Press.
Lakoff, George 1982 Categories: An essay in cognitive linguistics. In Linguistics in the Morning Calm, Linguistic Society of Korea (ed.), 139–193. Seoul: Hanshin. 1987 Women, Fire, and Dangerous Things: What Categories Reveal about the Mind. Chicago/London: University of Chicago Press.
Lakoff, George and Mark Johnson 1980 Metaphors We Live By. Chicago/London: University of Chicago Press.

Chapter 1: Cognitive Grammar 65
Lakoff, George and Mark Turner 1989 More than Cool Reason: A Field Guide to Poetic Metaphor. Chicago/London: University of Chicago Press.
Langacker, Ronald W. 1976 Semantic representations and the linguistic relativity hypothesis. Foundations of Language 14: 307–357. 1981 The integration of grammar and grammatical change. Indian Linguistics 42: 82–135. 1982 Remarks on English aspect. In Tense-Aspect: Between Semantics and Pragmatics, Paul J. Hopper (ed.), 265–304. (Typological Studies in Language 1.) Amsterdam/Philadelphia: Benjamins. 1985 Observations and speculations on subjectivity. In Iconicity in Syntax, John Haiman (ed.), 109–150. (Typological Studies in Language 6.) Amsterdam/ Philadelphia: Benjamins. 1987 Foundations of Cognitive Grammar. Volume 1: Theoretical Prerequisites. Stanford: Stanford University Press. 1988a An overview of cognitive grammar. In Topics in Cognitive Linguistics, Brygida Rudzka-Ostyn (ed.), 3–48. Amsterdam/Philadelphia: Benjamins. 1988b A view of linguistic semantics. In Topics in Cognitive Linguistics, Brygida Rudzka-Ostyn (ed.), 49–90. Amsterdam/Philadelphia: Benjamins. 1991a Concept, Image, and Symbol. The Cognitive Basis of Grammar. Berlin/New York: Mouton de Gruyter. 1991b Foundations of Cognitive Grammar. Volume 2: Descriptive Application. Stanford: Stanford University Press.
Lindner, Susan 1981 A lexico-semantic analysis of English verb-particle constructions with UP and OUT. Unpublished Ph.D. dissertation, University of California, San Diego. 1982 What goes up doesn’t necessarily come down: The ins and outs of opposites. In Papers from the Regional Meeting of the Chicago Linguistic Society 18: 305–323.
Miller, George A. and Philip N. Johnson-Laird 1976 Language and Perception. Cambridge, MA: Harvard/Belknap.
Moore, Terence and Christine Carling 1982 Language Understanding: Towards a Post-Chomskyan Linguistics. New York: St. Martin’s Press.
Oehrle, Richard T. 1977 Review of Green 1974. Language 53: 198–208.
Perlmutter, David M. 1978 Impersonal passives and the unaccusative hypothesis. In Proceedings of the Annual Meeting of the Berkeley Linguistics Society 4: 157–189.
Poteet, Stephen 1987 Paths through different domains: A cognitive grammar analysis of Mandarin dào. In Proceedings of the Annual Meeting of the Berkeley Linguistics Society 13: 408–421.
Rice, Sally 1987a Towards a transitive prototype: Evidence from some atypical English passives.

66 Ronald W. Langacker
In Proceedings of the Annual Meeting of the Berkeley Linguistics Society 13: 422–434. 1987b Towards a cognitive model of transitivity. Unpublished Ph.D. dissertation, University of California, San Diego. 1988 Unlikely lexical entries. In Proceedings of the Annual Meeting of the Berkeley Linguistics Society 14: 202–212. Shepard, Roger N. 1978 The mental image. American Psychologist 33: 125–137. Smith, Michael B. 1985a An analysis of German dummy subject constructions. In Proceedings of the Annual Meeting of the Paciﬁc Linguistics Conference 1: 412–425. 1985b Event chains, grammatical relations, and the semantics of case in German. In Papers from the Regional Meeting of the Chicago Linguistic Society 21: 388–407. 1987 The semantics of dative and accusative in German: An investigation in cognitive grammar. Unpublished Ph.D. dissertation, University of California, San Diego. 1989 Cases from conceptual categories: Evidence from German. Linguistic Agency University of Duisburg. Sweetser, Eve E. 1984 Semantic structure and semantic change: A cognitive linguistic study of modality, perception, speech acts, and logical relations. Unpublished Ph.D. dissertation, University of California, Berkeley. 1987 Metaphorical models of thought and speech: A comparison of historical directions and metaphorical mappings in two domains. In Proceedings of the Annual Meeting of the Berkeley Linguistics Society 13: 446–459. 1988 Grammaticalization and semantic bleaching. In Proceedings of the Annual Meeting of the Berkeley Linguistics Society 14: 389–405. Talmy, Leonard 1975 Sematic and syntax in motion. In Syntax and Semantics 4, John Kimball (ed.), 181–238. New York: Academic Press. 1977 Rubber-sheet cognition in language. In Papers from the Regional Meeting of the Chicago Linguistic Society 13: 612–628. 1978 Figure and ground in complex sentences. In Universals of Human Language, volume 4: Syntax, Joseph H. Greenberg (ed.), 625–649. Stanford: Stanford University Press. 1983 How language structures space. In Spatial Orientation: Theory, Research, and Application, Herbert Pick and Linda Acredolo (eds.), 225–282. New York: Plenum Press. 1985a Force dynamics in language and thought. In Papers from the Parasession on Causatives and Agentivity, William H. Eilfort et al. (eds.), 293–337. Chicago: Chicago Linguistic Society. 1985b Lexicalization patterns: Semantic structure in lexical forms. In Language Typology and Syntactic Description. Volume 3: Grammatical Categories and the Lexicon, Timothy Shopen (ed.), 57–149. Cambridge: Cambridge University Press.

Chapter 1: Cognitive Grammar 67
1988a Force dynamics in language and cognition. Cognitive Science 12: 49–100. 1988b The relation of grammar to cognition. In Topics in Cognitive Linguistics, Bry-
gida Rudzka-Ostyn (ed.), 165–205. Amsterdam/Philadelphia: Benjamins. Traugott, Elizabeth C.
1982 From propositional to textual and expressive meanings: Some semantic-pragmatic aspects of grammaticalization. In Perspectives on Historical Linguistics, Winfred P. Lehmann and Yakov Malkiel (eds.), 245–271. Amsterdam/Philadelphia: Benjamins.
1986 From polysemy to internal semantic reconstruction. In Proceedings of the Annual Meeting of the Berkeley Linguistics Society 12: 539–550.
1988 Pragmatic strengthening and grammaticalization. In Proceedings of the Annual Meeting of the Berkeley Linguistics Society 14: 406–416.
Tuggy, David 1980 ¡Ethical dative and possessor omission sí, possessor ascension no! In Work Papers of the Summer Institute of Linguistics, University of North Dakota 24: 97–141. 1981 The transitivity-related morphology of Tetelcingo Nahuatl: An exploration in space grammar. Unpublished Ph.D. dissertation, University of California, San Diego. 1986 Noun incorporations in Nahuatl. In Proceedings of the Annual Meeting of the Paciﬁc Linguistics Conference 2: 455–469. 1988 Náhuatl causative/applicatives in cognitive grammar. In Topics in Cognitive Linguistics, Brygida Rudzka-Ostyn (ed.), 587–618. Amsterdam/Philadelphia: Benjamins. 1989 The afﬁx-stem distinction in Orizaba Náhuatl. Linguistic Agency University of Duisburg.
Vandeloise, Claude 1984 Description of space in French. Unpublished Ph.D. dissertation, University of California, San Diego.
Wierzbicka, Anna 1988 The Semantics of Grammar. (Studies in Language Companion Series 18.) Amsterdam/Philadelphia: Benjamins.

Chapter 2 Grammatical construal
The relation of grammar to cognition1 Leonard Talmy
0. Introduction
A fundamental design feature of language is that it has two subsystems which can be designated as the grammatical and the lexical (as these are characterized below). Why is there this universal bifurcation when, in principle, a language could be conceived having only a single system, the lexical? The explanation in this paper is that the two subsystems have distinct semantic functions, ones that are indispensable and complementary. To develop this account further, we must ﬁrst note that we take a sentence (or other portion of discourse) to evoke in the listener a particular kind of experiential complex, here to be termed a “cognitive representation” or “CR”.2 Now, the grammatical and lexical subsystems in a sentence seem generally to specify different portions of a CR. Together, the grammatical elements of a sentence determine the majority of the structure of the CR, while the lexical elements together contribute the majority of its content. Lexical elements do incorporate some of the same structural indications that grammatical elements express, but when the two are in association or in conﬂict within a sentence, it is generally always the grammatical elements’ speciﬁcations of structure that are determinative.3 The grammatical speciﬁcations in a sentence, thus, provide a conceptual framework or, imagistically, a skeletal structure or scaffolding, for the conceptual material that is lexically speciﬁed.
More generally, across the spectrum of languages, the grammatical elements that are encountered, taken together, specify a crucial set of concepts. This set is highly restricted: only certain concepts appear in it, and not others, as seen below. The purport of the present paper is that this set of grammatically speciﬁed notions collectively constitutes the fundamental conceptual structuring system of language. That is, this cross-linguistically select set of grammatically speciﬁed concepts provides the basic schematic framework for conceptual organization within the cognitive domain of language.
Thus, grammar, broadly conceived, is the determinant of conceptual structure within one cognitive domain, language, and as such is the main object of
Originally published in 1988 in Topics in Cognitive Linguistics, Brygida Rudzka-Ostyn (ed.), 165–205. Amsterdam/Philadelphia: John Benjamins. Reprinted with permission.

70 Leonard Talmy
this paper’s study. But such a study directly opens out into a broader investigation across other cognitive domains, such as visual perception and reasoning, as discussed at the end of the paper. That is, the greater issue, toward which the present study ultimately aims, is the general character of conceptual structure in human cognition.
The present investigation into the semantics of grammar is of a scope that follows in a progression from previous types of study. These have mostly been either an in-depth semantic analysis of a selected grammatical element (or class of elements) of particular interest within a language, e.g., the Turkish evidential sufﬁx -mis (Slobin and Aksu 1982); or an exposition of the meanings and functions of all the grammatical elements of a single language, say, as in a grammar of Dyirbal (Dixon 1972); or a cross-linguistic typology of the different kinds of grammatical devices used for a single semantic function, say, to indicate the interrogative (Ultan 1978). Some previous work has also treated broader issues of grammatical meaning (Sapir 1921; Boas 1938; Whorf 1956, Jakobson 1971). But the present study is perhaps the ﬁrst to address grammatical expression in language at the superordinate level, with the aim of determining the semantic and cognitive properties and functions of this structural component of language as a whole.4
The terms “grammatical” and “lexical” as employed here require some immediate elaboration. The distinction between the two is made formally – i.e., without reference to meaning – on the basis of the traditional linguistic distinction between “open-class” and “closed-class”. A class of morphemes is considered open if it is quite large and readily augmentable relative to other classes. A class is considered closed if it is relatively small and ﬁxed in membership. We can identify the particular classes belonging to these two types. The open classes of elements – i.e., the lexical classes – are the roots of nouns, verbs, and adjectives.5 Everything else is closed-class – and is here considered to be, quite generally, “grammatical”. Among the overt elements of this type are such bound forms as inﬂections and derivations, such free forms as determiners, prepositions, conjunctions, and particles, and perhaps also such suprasegmental forms as intonation patterns. Included among abstract, or implicit, closed-class forms are grammatical categories and grammatical relations, word order, and perhaps also paradigms and “zero” forms. Additionally here are regular combinations of simpler closedclass forms, tending to have a uniﬁed or integrated semantic function – what are below called “grammatical complexes”, including grammatical constructions and syntactic structures.6
The issues presented in this introduction are treated below in three sections. Section 1 examines the notions speciﬁed by a heuristic sampling of grammatical elements, outlines the kinds of constraints on such notions, proposes a property held in common by such notions but largely absent from excluded notions, and

Chapter 2: Grammatical construal 71
contrasts such grammatically speciﬁed notions with ones that are lexically speciﬁed. Section 2 presents a number of categories in which grammatically speciﬁed notions are seen to pattern, as well as broader conceptual systems in which these categories in turn participate, ending with the identiﬁcation of four comprehensive “imaging systems”. This section, further, examines the interactions of grammatical speciﬁcations with lexical speciﬁcations within categories and the nesting of such interactions across categories, as well as the cognitive processes that accompany these interactions. And Section 3 presents an explanation of the function of grammatical speciﬁcation, as well as possibilities of its relations to other cognitive systems.
1. The nature of grammatically speciﬁed notions
In this section we examine a small sampling of grammatical forms for the particular component notions that they specify. The sample will give a heuristic indication of the kinds of notions that get grammatically speciﬁed as well as of the kinds of notions that possibly never do. By contrast, it will be seen that the excluded kinds can be readily speciﬁed by lexical elements. A particular property will be seen to run through most of the grammatical notions. To indicate this property at the outset, it is preponderantly the case that grammatical speciﬁcations of structure are relativistic or topology-like, and exclude the absolute or the metrically Euclidean. Finally, a systematic difference is shown between the characteristics of grammatically speciﬁed notions and of lexically speciﬁed ones.
We begin with a simple demonstration that the concepts speciﬁed by grammatical forms are constrained in two ways: as to their categories and as to the membership of these categories. Many languages have inﬂections on the noun that specify the “number” of the object referred to by the noun, for example its ‘singularity’ or ‘plurality’, like the English -෬ and -s. By contrast, no languages appear to have inﬂections that specify the “color” of the object referred to by a noun, e.g., its ‘redness’ or ‘blueness’. Here, single quotes enclose “notions”, while double quotes enclose categories of notions. The “number” category can be speciﬁed grammatically and in that form is readily seen to play a structuring role in a CR.7 The “color” category is perhaps never found speciﬁed by grammatical elements, though it is readily found speciﬁed by lexical elements, e.g., English red and blue. Further, though, even within a conceptual category acceptable for grammatical expression, there are great constraints on the particular notions that can be speciﬁed. Thus, “number” notions that are expressed grammatically include little more than ‘singular’, ‘dual’, ‘trial’, ‘plural’, and ‘paucal’. They apparently never include, say, ‘even’, ‘odd’, ‘dozen’, or ‘numerable’, whereas such notions, again, can be speciﬁed lexically, as shown by the words just used.

72 Leonard Talmy
Given such constraints on grammatically speciﬁable notions, we can seek properties that hold in common for included notions but need not apply to excluded notions. In this regard, consider a deictic like the English this or that as in This/ That chair is broken. A closed-class element of this type speciﬁes the location of an indicated object as being, in effect, on the speaker-side or the non-speaker-side of a conceptual partition drawn through space (or time or other qualitative dimension). This integral speciﬁcation can be analyzed as containing the component notions enclosed by quotes in (I):
(1) (a, b) a ‘partition’ that divides a space into ‘regions’/‘sides’ (c–e) the ‘locatedness’ (a particular relation) of a ‘point’ (or object idealizable as a point) ‘within’ a region (f, g) (a side that is the) ‘same as’ or ‘different from’ (h, i) a ‘currently indicated’ object and a ‘currently communicating’ entity
Notions that might at ﬁrst be ascribed to such deictics, such as of distance or perhaps size, prove not to apply, on the evidence of sentence-pairs like (2):
(2) a. This speck is smaller than that speck. b. This planet is smaller than that planet.
The scenes referred to by (2a) and (b) differ greatly, involving tiny objects millimeters apart or huge objects parsecs apart. But the sentences differ only lexically, not grammatically. Hence, the scenes’ differences as to the magnitude of size or distance must arise from the lexical elements, they cannot be traced to the deictics (or other grammatical elements) in the sentences. Thus, the notions speciﬁed by a this or a that are abstracted away from any particularities of magnitude and so, to this extent, are genuinely topological. Their speciﬁcation of a conceptual partition remains constant, but this partition’s distance can – by the characterization of topology as “rubber-sheet geometry” – be “stretched” indeﬁnitely without challenge to any semantic constraints of the deictics. This ﬁnding about deictics alerts us to noticing whether any grammatical elements make speciﬁcations about magnitude. A spot check through English and various other languages suggests that – while there are grammatical speciﬁcations for relative magnitude8 – there are possibly never any for absolute or quantiﬁed magnitude, whether of size, distance, or other parameters. We can provisionally conclude that the referents of grammatical elements have the topological property of being “magnitude-neutral”.
For another case, consider the type of adposition that speciﬁes, for a moving object, certain characteristics of path and of reference-point or -frame. An example of this type is English through as used, for instance, in I walked through

Chapter 2: Grammatical construal 73
the woods. In this usage, through speciﬁes, broadly, ‘motion along a line that is within a medium’. The component notions contained here include those in (3):
(3) (a) ‘motion’ (b–e) which can be understood as ‘one-to-one correspondences’ between ‘adjacent’ points of ‘space’ and adjacent points of ‘time’ (f) motion that describes a ‘line’ (i.e., a ‘linear extent’) (g) the locatedness of a line within a ‘medium’ (h, i) a medium, i.e., a region of three-dimensional space set apart by the locatedness within it of ‘material’ that is in a ‘pattern of distribution’ with properties and a range of variation still to be determined
It can be ﬁrst observed, from a sentence-pair like (4), that the concept speciﬁed by through is indifferent to particulars of shape or contour in the linear path described by the moving object. This is evident here because, as before, the two sentences differ only lexically, not grammatically – they both use through while referring to different path contours. Another cross-linguistic spot check of closedclass elements suggests that they largely have this further topological property of being “shape-neutral”.
(4) a. I zig-zagged through the woods. b. I circled through the woods.
With a sentence pair like (5), it can be further determined that the ‘rate’ of motion is not speciﬁed by through, a ﬁnding that also appears quite general among grammatical elements. And (6) shows that through, again like grammatical elements generally, excludes speciﬁcation of the ‘kind of material’ involved – here, comprising the “medium” – and of the ‘sensorimotor characteristics’ attendant on executing the action involved – as, here, those attendant on wading in liquid vs. weaving amidst obstacles. Thus, it can be further held that grammatical elements are generally rate-neutral, material-neutral, and sense/motor-neutral.
(5) (a/b) I crept / dashed through the woods. (6) (a/b) I walked through the water / woods.
In the aim of ascertaining any properties common to grammatically speciﬁed notions, the notions examined above are gathered together in (7). For heuristic purposes, the notions are provisionally divided into two groups on the basis of their relation to topology. In group (a) are combined the notions that properly belong to the speciﬁc mathematical system of topology and, with them, the intuitively comparable notions that might belong to a language-based system of topology – one

74 Leonard Talmy

that perhaps could serve as the model for the construction of a new topology-like mathematical system.9 In group (b) are the notions that fall outside any usual conception of topological properties. The number of notions in the ﬁrst group is fourteen, while the second has six – an indication of a preponderant propensity for grammatical elements to specify quasi-topological notions. The ratio in this direction is in fact improved if we consider that even several notions in group (b) – the bottom three – resemble topological ones in the sense of involving relativistic relationships between quantities rather than absolutely ﬁxed quantities.

(7) some notions found to be speciﬁed by grammatical elements

a. topological or topology-like

b. non-topological

point linear extent locatedness within region side partition

singularity plurality same different „adjacency“ of points one-to-one correspondence pattern of distribution

material space time motion medium entity currently
indicated/communicating

In the complementary aim of ascertaining any properties excluded from grammatical speciﬁcation, the categories of notions found above not to be speciﬁed by the elements investigated are listed in (8). Rather than topological, topology-like, or relativistic, these notions involve Euclidean-geometric concepts – e.g., ﬁxed distance, size, contour, and angle – as well as quantiﬁed measure, and various particularities of a quantity: in sum, characteristics that are absolute or ﬁxed.

(8) some categories of notions seemingly rarely or never speciﬁed by grammatical elements

absolute/quantiﬁed magnitude (of distance, size, etc.) shape/contour of line rate

kind of material sensorimotor characteristics color

The provisional conclusion to be drawn from these ﬁndings is that, if grammatical speciﬁcations generally correspond to (linguistic-) cognitive structuring, then the nature of that structure is largely relativistic or topological rather than absolute or Euclidean.
This preponderant requirement for conceptual neutralities among closed-class elements is in sharp contrast with the referential freedom of lexical items, which can express not only structural abstractions but also wide-ranging speciﬁcities. For example, speciﬁcity as to magnitude is seen in nouns like inch and mile; as

Chapter 2: Grammatical construal 75
to shape, in nouns like circle, adjectives like square, and verbs like ricochet; as to rate, in verbs like dawdle and hurry; in material, in a noun and verb like iron and bleed; as to sensorimotor characteristics in watch and wade; and, of course, as to color by such adjectives as red and blue.
To elaborate further the contrast between the grammatical and the lexical type of speciﬁcation, consider the full complement of both element-types in a single whole sentence, viz., that selected in (9):
(9) A rustler lassoed the steers.

We ﬁrst list the grammatical elements present in the sentence and the notions that they specify in (10):

(10)

a.

-ed

b.

the

c. a

d. -s

e.

a...-Ø

f.

the grammatical category

of “verb” for lasso

g/h. the grammatical category

of “noun” for rustlerlsteer

i/j- the grammatical relations

of “subject’V’object” for

rustlerlsteer

k. active voice

1.

intonation, word order,

pattern of auxiliaries

‘occurring at a time before that of the present communication’ ‘has ready identiﬁability for the addressee’ ‘not before in discussion or otherwise readily identiﬁable for the addressee’ ‘multiple instantiation of object’ ‘unitary instantiation of object’ ‘event character’
‘entity character’
‘agent’/’patient’ (among the possibilities)
‘point-of-view at the agent’ ‘the Speaker “knows” the Situation to be true and asserts it’

The lexical items in the sentence have speciﬁcations that can be characterized as in (11):

76 Leonard Talmy
(11) a complex of concepts involving:
a. rustler: a person, property ownership, illegality, mode of activity b. steer: object of particular appearance, physical makeup, etc.
relation to animal kingdom castration institution of breeding for human consumption c. lasso: certain objects (a body and a lasso) in particular conﬁgurations certain movement sequences accompanying cognitive intending, directing, monitoring, etc.
In surveying the two lists, we can see these differences emerge: The grammatical elements are more numerous, and their speciﬁcations seem more spare and simpler, and more structural in function. Together, their speciﬁcations seem to establish the main delineations of the scene organization and communicative setting of the CR evoked by the sentence. The lexical elements are fewer in number, but their speciﬁcations are greater in quantity and complexity, and function more to contribute content than structure. The lexical speciﬁcations are greater in three ways: compared to a grammatical speciﬁcation, each has a) more total information, b) greater intricacy of information, and c) more different types of information together. Taken together, their speciﬁcations comprise most of the conceptual content of the CR scene that is evoked by the sentence.
These grammatical-lexical differences can be set into further relief by in turn varying each element-type while keeping the other constant. Thus, varying only the grammatical elements of (9), as is done in (12), seems to alter the scene organization and discourse properties of the referent event but to leave its basic contents intact:
(12) Will the rustlers lasso a steer?
By contrast, varying only (9)’s lexical elements, as in (13), shifts us to a new scene altogether, and yet the basic breakup of the scene and of its communicative setting seems to remain the same:
(13) A machine stamped the envelopes.

Chapter 2: Grammatical construal 77
2. Categories of grammatically speciﬁed notions
The preceding sampling of grammatical elements has yielded a set of notions helpful toward discovering common semantic properties. But the set has been small and unstructured. With a broader and more systematic investigation, patterns of organization among the notions become evident. Grammatically speciﬁed notions can be seen to pattern in categories, and the categories, in turn, in integrated systems, as presented below. And within these notional patterns can be seen certain regularities of function and process. These patterns and regularities constitute principal features of conceptual organization in language.
Several such features are brought forward below. One feature is an extensive homology between the representation of space and that of time. The ﬁrst category, “dimension”, includes this space-time homology, and largely crosscuts the remaining categories. These categories will, in the majority, apply to both space and time, and parallel examples from each dimension will be presented side by side.
Another feature is that, of the member notions of any category represented in a language, often each notion will be incorporated in at least some lexical items. Correlatively, the language will often contain grammatical forms that interact with each lexicalization type in a way that yields the expression of another notion of the category. Each such type of interaction can be regarded as a type of cognitive operation that converts the indication of one notion to that of another within the same category. A corollary feature is that a language with grammatical forms for converting from notion A to notion B frequently has forms as well for conversion in the reverse direction – that is, it can also trigger the reverse cognitive operation.10
Some of the grammatical forms in a language function speciﬁcally to perform a particular conversion operation. Others simply make structural speciﬁcations that can come into conﬂict with the speciﬁcation of a neighboring lexical item. In such cases, the basic pattern is that the grammatical form’s speciﬁcation always takes precedence, and triggers a kind of operation, a “shift”, in the lexical item’s referent that brings it into accord.”
As a note on methodology in what follows, efforts were made to determine categories on the basis of particular grammatical meanings encountered, rather than to posit the categories as part of an a priori schema which then sought corroborative examples. In the research leading to this paper, grammatical forms were sampled from a range of languages, but an effort has been made to take most of the exempliﬁcation from English.

78 Leonard Talmy

2.1. Dimension
The category of “dimension” has two principal member notions, ‘space’ and ‘time’. The kind of entity that exists in space is – in respectively continuous or discrete form – ‘matter’ or ‘objects’. The kind of entity existing in time is, correspondingly, ‘action’ or ‘events’ – terms here used neutrally as to whether the entity is static or changing. These notions thus relate as in (14):12

(14) dimension space: time:

continuous matter action

discrete objects events

Homologies between the linguistic structuring of space and of time will be indicated in the categories that follow. But here we can indicate operations of conversion between these two main members of the dimension category. Thus, a verb root that lexicalizes expression of an event or of action as a temporal quantity can be associated with grammatical forms, including nominalizations, that signal a cognitive operation of “reiﬁcation”. By the semantic effect of this operation, the referent becomes conceptualized as an object or a mass, one that can participate in many of the same activities (such as being given or gotten) as a physical quantity, as well as in many of the corresponding syntactic constructions (including pluralization and modiﬁcation: ...gave me two quick calls), as exempliﬁed in (15). (A way of representing the grammatical complexes involved here and in the next operation is presented in connection with the following category.)

(15)

an event:

John called me. I was called by John.

reiﬁed as an object:
John gave me a call. I got a call from John.

action:
John helped me. I was helped by John.

reiﬁed as mass:
John gave me some help. I got some help from John.

The reverse conversion also occurs. A noun referring to an object or mass can be associated with grammatical forms, including verb-forming derivations, that signal a cognitive operation of “actionalizing”. By this operation, the physical referent is melded together with some of the activity in which it participates, with the semantic effect that much of the referent’s tangible concrete character is backgrounded, subordinated to a conceptualization in terms of a process of occurrence, as illustrated in (16):

Chapter 2: Grammatical construal 79

(16)

object(s)lmass:

actionalized as:

Hail(stones) came in through

It hailed in through

the window

the window.

Ice is forming over the windshield. It is icing up over the windshield.

I removed the pit from the cherry. I pitted the cherry.

2.2. Plexity
The category here to be termed “plexity” is a quantity’s state of articulation into equivalent elements. Where the quantity consists of only one such element, it is “uniplex”, and where it consists of more than one, it is “multiplex”. When the quantity involved is matter, plexity is, of course, equivalent to the traditional linguistic category of “number” with its component notions “singular” and “plural”. But the present notions are intended to capture the generalization from matter over to action, which the traditional notions do not do.13
Speciﬁcations as to plexity are made by both lexical items and grammatical elements, and there is interplay between the two when they are both in association. Example English lexical items that basically specify a uniplex referent are – for matter and action, respectively – bird and (to) sigh. They can occur with grammatical elements that themselves specify a uniplexity, like those italicized in (17a) (many languages have here a more regular, overt system of markers than English). But they can also occur with grammatical elements that specify a multiplexity, as in (17b). In this association, such elements can be thought to trigger a particular cognitive operation, one of “multiplexing”. By this operation, an original solo referent is, in effect, copied onto various points of space or time.

(17) a. uniplex b. multiplex

matter A bird ﬂew in. Birds ﬂew in.

action He sighed (once). He kept sighing.

The reverse of the preceding pattern is also found in language. First, there are lexical items that intrinsically specify a multiplexity. English examples are furniture or timber (i.e., ‘standing trees’) for matter and breathe for action, as used in (18a). And, too, there are grammatical forms able to appear in association with these, as in (18b), that signal an operation the reverse of multiplexing – one that can be called “unit-excerpting”. By this operation, a single instance of the speciﬁed equivalent units is taken and set in the foreground of attention.

80 Leonard Talmy

(18) a. multiplex b. uniplex

matter action
Furniture overturned in the earthquake. She breathed without pain.
A piece of furniture overturned in the earthquake. She took a breath / breathed in without pain.

The English grammatical forms seen above that signaled multiplexing – -s and keep -ing – consisted solely of explicit morphemes. The forms that signal unitexcerpting differ in that they also include abstract elements: particular grammatical categories that require the insertion of one out of a certain set of lexical items, as represented in (19c,d). The forms can, moreover, contain two or more independent elements. These forms are here considered to be “grammatical complexes”, comparable to other grammatical constructions or indeed to lexical complexes (collocations): they combine distinct elements within a structural whole serving a single overall semantic function. Actually, by one analysis, all grammatical forms are complexes, merely ranked along a dine of elaborateness. Under this analysis, a grammatical form includes not only any explicit and generic elements, but also the semantic and syntactic category memberships of its input and output forms, as represented throughout (19). Thus, the English multiplexing forms, in (19a,b), are merely at the simpler end of a continuum:

(19)

e.g., sigh: keep sighing

Chapter 2: Grammatical construal 81

Support is lent to the thesis that a more elaborate grammatical complex can have a semantic unity by the existence, within the same or another language, of a simpler form with the same semantic function. As an example of just this circumstance, the English unit-excerpting complex for nouns, which is rather elaborate, is paralleled in function by a simple sufﬁx in Yiddish, either -l or -ele (otherwise indicating diminutives), as illustrated in (20):

(20) zamd ‘sand’: groz ‘grass’: shney ‘snow’:

zemdl ‘grain of sand’ grezl ‘blade of grass’ shneyele ‘snowﬂake’

2.3. State of boundedness
When a quantity is speciﬁed as “unbounded”, it is conceived as continuing on indeﬁnitely with no necessary characteristic of ﬁniteness intrinsic to it. When a quantity is speciﬁed as “bounded”, it is conceived to be demarcated as an individuated unit entity. In application to nouns, these notions largely correspond to the traditional linguistic distinction between “mass” and “count”, and in appli-

82 Leonard Talmy

cation to verbs they can correspond to “imperfective” and “perfective”, among other terms (the closeness of these correspondences varies with different usages of the traditional terms). However, as with plexity, the concepts designated by the new terms are intended to capture the commonality between the space and time dimensions and to generalize over their usually separate analyses.
Among English examples of lexical items, water and (to) sleep basically specify unbounded quantities, whereas sea and (to) dress basically specify bounded ones. These speciﬁcations are demonstrated by the fact that these words are, respectively, unacceptable and acceptable in construction with the grammatical complex “in NPextent-of-time”, which itself speciﬁes boundedness, as seen in (21):

(21) a. b.

matter action
unbounded *We ﬂew over water in 1 hr. *She slept in 8hrs.
bounded We ﬂew over a sea in 1 hr. She dressed in 8mins.

As with plexity, there exist grammatical elements that can, in construction with a lexical item, shift its basic speciﬁcation for state of boundedness to the opposite value. Those acting in this way on an unbounded-type lexical item, in effect, trigger a cognitive operation of “bounding”, or “portion-excerpting”. By this operation, a portion of the speciﬁed unbounded quantity is demarcated and placed in the foreground of attention. Examples of such grammatical elements in English are shown in (22).
The reverse of the preceding pattern also exists. The English nouns shrub and panel each refer intrinsically to a bounded entity. But the grammatical elements -ery and -ing can be added to them, yielding shrubbery and paneling, forms which now refer to unbounded quantities. In effect, the grammatical elements have triggered a cognitive operation of “debounding” whereby the quantity formerly within bounds is now conceptualized in a form with indeﬁnite extension. In English, however, such elements are not productive; they cannot, for example, be used with sea to yield the meaning ‘pelagic water’, nor with (a) tear to yield ‘lachrymal ﬂuid’.14

Chapter 2: Grammatical construal 83
(22)
2.4. State of dividedness The category of “state of dividedness” refers to a quantity’s internal segmentation. A quantity is “discrete” (or “particulate”) if it is conceptualized as having breaks, or interruptions, through its composition. Otherwise, the quantity is conceptualized as “continuous”.15
Both lexical and grammatical elements are sensitive, in their speciﬁcations, to the distinctions of this category. But there appear to be no grammatical elements that solely specify discreteness or continuity for a quantity, nor any that signal an operation for reversing a quantity’s lexically speciﬁed state of dividedness. If forms of the latter type existed, we can describe how they would behave. A grammatical form for a continuous-type lexical item would signal an operation of “discretizing”, whereby the originally continuous referent would become conceptualized as a particulate aggregation. Conversely, a grammatical form for a discrete-type lexical item would trigger an operation of “melding”, whereby the separate elements of the original referent would be conceptualized as having fused together into a continuum.
Although such grammatical forms seem lacking, there do exist certain indirect or inexplicit mechanisms for these operations. Thus, the continuity speciﬁed by the noun water can be reconceptualized as discrete with the locution particles of, as in: Water / Particles of water ﬁlled the vessel. However, the grammatical complex used here does not directly specify this shift but, like the complexes in Sections 2.5. and 2.13., comprises a several-stage sequence of other cognitive operations. In the reverse direction, there appears to be a general conceptual tendency for a basically discrete-type referent of a lexical root to undergo at least some degree of spontaneous melding, without the addition of any explicit grammatical forms.

84 Leonard Talmy
Thus, foliage, timber, and furniture, as contrasted with leaves, trees, and pieces of furniture, tend to evoke referents with a degree of blurring and fusion across their component elements.
Because the category of dividedness has limited realization by itself, further treatment of it will be deferred until the next section, where it can be seen in interaction with the other categories. 2.5. The disposition of a quantity: A system of categories The preceding four categories of attributes – dimension, plexity, boundedness, and dividedness – all pertain to a quantity simultaneously and, taken together, can be considered to constitute a system of attributes that may be termed a quantity’s “disposition”. The intersections of these categories form an array that can be schematized as in (23). (23)
+ the distinction between matter and action, which crosscuts all of the above16
Each intersection of attributes indicated here is speciﬁed by various lexical items (although one, a bounded multiplexity for action, is quite minimally represented in English). An example or two (most seen earlier) is given for each intersection in (24) :17

Chapter 2: Grammatical construal 85

(24) A’: timber/furniture

B’: water

(to) breathe

(to) sleep

A: (a) family

B: (a) sea/panel

(to) molt

(to) empty

(The bird molted.)

(The tank emptied.)

a: (a) bird

(to) sigh

Now if the particular contentful referent for which one chooses a lexical item happens to be wedded, by that lexical item, to an unwanted set of structural speciﬁcations, there generally are grammatical means available for converting this to a desired set. Such means range in directness from specifying the single relevant operation to involving a circuitous sequence of operations (cf. Section 2.13. on “nesting”). A number of starting- and ending-points for such conversions, and the means for accomplishing them, are indicated in (25):

(25) A’ ĺ A A’ ĺ a Aĺa A ĺ A’
a ĺ A’ aĺA

a stand of timber

B’ ĺ B a body of water

breathe for an hour

sleep for an hour

a piece of furniture ----

take a breath / breathe in

a member of a family ----

?molt a single feather

members of a family B ĺ B’ paneling

(A ĺ a ĺ A’)

molt and molt

empty and empty

trees

----

keep sighing

a stand of trees

----

(aĺ A’ ĺ A)

sigh for a while

2.6. Degree of extension
Implicit in the vertical dimension of the schematic arrangement in (23) is a further category that can be called “degree of extension”. This category has three principal member notions, terms for which are given in (26) together with schematic representations of the notions for the linear case. Lexical items referring to either matter or action may be taken to incorporate speciﬁcations as to their referent’s basic degree of extension, and three examples of these for the linear spatial case are also shown in (26) :18

86 Leonard Talmy
(26)
Now a lexical referent that is perhaps most basically conceived as of one particular degree of extension can, by various grammatical speciﬁcations that induce a shift, be reconceptualized as of some other degree of extension. For a ﬁrst example, consider the event referent of climb a ladder, which seems basically of bounded linear extent in the temporal dimension, as is in fact manifested in (27) in conjunction with the grammatical element “in + NPextent-of-time”:
(27) She climbed up the ﬁre-ladder in 5 minutes.
With a different accompanying grammatical form, like the “at + NPpoint-of-time” in (28), (as well as different contextual speciﬁcations), the event referent of the preceding can be shifted toward a conceptual schematization as a point of time – i.e., as being point-durational:
(28) Moving along on the training course, she climbed the ﬁre-ladder at exactly midday.
This shift in the cognized extension of the event can be thought to involve a cognitive operation of “reduction” or, alternatively, “adoption of a long-range perspective”. This shift can also go in the other direction. The event referent can be conceptually schematized as an unbounded extent by the effect of grammatical forms like “keep -ing”, “-er and -er”, and “as + S”, as in (29):
(29) She kept climbing higher and higher up the ﬁre-ladder as we watched.
Here there would seem to have taken place a cognitive operation of “magniﬁcation”, or “adoption of a close-up perspective”. By this operation, a perspective point is established from which the existence of any exterior bounds falls outside of view and attention – or, at most, is asymptotically approachable.
The preceding event referent was continuous, but a discrete case can exhibit the same shifts in extension. One such case, perhaps to be considered as most basically of bounded extent, is shown with that degree of extension in (30a). But the referent can also be idealized as a point, as in (30b) (clearly, the cows would not all have died at the same moment, and yet the spread of their death times is conceptually collapsed into such a single moment). Or, the referent can be schematized as an unbounded extent, as in (30c):

Chapter 2: Grammatical construal 87

(30) a. The cows all died in a month. b. When the cows all died, we sold our farm. c. The cows kept dying (and dying) until they were all gone.

The alternative schematizations of extension just seen as speciﬁable for an event referent are generally also available for an object referent. Thus, e.g., the referent of (a) box can be speciﬁed for idealization as a point or as a bounded extent (of area or volume). Some grammatical elements making such speciﬁcations are illustrated in (31). Also set forth here are the homologies between these and the event-speciﬁc elements:

(31) point bounded extent (point within) bounded extent

The box is 20 feet away from the wall. I read the book 20 years ago. The box is 2 feet across. I read the book in 2 hours. The ball is in the box. She left while I read the letter.

2.7. Pattern of distribution
The pattern of distribution of matter through space or of action through time is a further category of notions that can be both grammatically and lexically speciﬁed.19 For action through time – the only dimension we will be looking at here – this category together with the preceding one largely constitute the traditional category of “aspect”.
Several of the main patterns of distribution for action through time are shown schematically in (32) (the dots here, which represent situatedness in complementary states, should really be adjacent, but they are sketched apart with a connecting line to show the crossing of state-interfaces). Also shown are illustrative English verbs, both non-agentive and agentive, that incorporate these patterns.
(32)

88 Leonard Talmy
One can determine that these verbs incorporate the speciﬁcations indicated by noting the grammatical forms with which they can and cannot occur (or, to put the latter case in our terms: ...grammatical forms toward whose speciﬁcations they will not [readily] shift). A full demonstration is not in order here, but a few examples show the principle: The resettable type of a one-way event is distinguished from the non-resettable type by its compatibility with iterative expressions, as in: He fell 3 times; the non-resettable type cannot occur here: *He died 3 times. This same one-way form is distinguished from a full-cycle form by its ability to appear in sentences like: He fell and then got up, which the latter cannot do: *The beacon ﬂashed and then went off. A gradient type can appear with adverbs of augmentation, as in The river progressively widened, unlike a steadystate type: * She progressively slept. And so on.
Grammatical elements can, of course, also specify differing patterns of temporal distribution, and the present form of diagramming can readily reveal some of their distinctions. Thus, the closed-class elements back and again, singly and in combination, can indicate versions of full-cycle, sesqui-cycle, and double-cycle patterns, as shown in (33):
(33)
Now consider the circumstance where a verb of one distribution type appears with grammatical forms of another type. The resultant seems invariably to be that the verb shifts its speciﬁcations into conformity with those of the grammatical forms. For an example we again take die, whose basic speciﬁcations can be adjudged as point-durational one-way non-resettable – schematizable, now more precisely, as: ƔƔ. This verb is used with its basic speciﬁcations in a sentence like (34a). But in a sentence like (34b), the grammatical form “be + -ing” induces a shift. In effect, the inﬁnitesimal interval between the two states involved for die – viz., ‘aliveness’ and ‘deadness’ – is spread out, with the creation thereby of an extentdurational gradient. This is the shift in the distribution pattern’s structural type. But concomitantly, a shift in the basic contentful referent is engendered. Instead of ‘dying’, the new gradient refers to ‘moribundity’. The distinction becomes clear in noting that, as the conception is structured linguistically, one can have been dying without having died, and, correlatively, one can have died without having been dying.20

Chapter 2: Grammatical construal 89
(34) a. He died as she looked on. b. He was (slowly) dying as she looked on.

2.8. Axiality

The adjectives in a pair like well/sick behave contrarily when in association with grammatical forms specifying degree like slightly and almost, as seen in (35a), and they select for different readings of temporal forms like “in + NPextent-oftime”, as seen in (35b). In this, perhaps surprisingly, they parallel the behavior of certain kinds of expressions that specify spatial relations, e.g., at the border I past the border: (35)

a.

{ } He’s slightly

sick / past the border. *well / *at the border.

{ } He’s almost

well / at the border. ?sick / ?past the border.

b. He got well / to the border in 5 days. – i.e., progressively in the course of He got sick / past the border in 5 days. – i.e., ﬁrst after the elapse of

This behavior can be accounted for by positing that such adjectives, in referring to a more generic notional parameter, such as that of ‘health’, are not simply “opposites” but, rather, presuppose a schematic axis that is structured and directed in a particular way. Each adjective, then, labels a different portion of that axis. The adjectives here seem in particular to presuppose a directed line bounded at one end; well refers to the end-point while sick refers to the remainder of the line, correlating greater magnitude with greater distance along the line. These are the “axial properties”, or “axiality”, of the lexical items, i.e., the speciﬁc relations each has to a particular conceptual axis and to other lexical items with referents along the same axis. It is the lexicalization of such axiality that can align adjectives with expressions of spatial relation. Grammatical forms like the ones just above also have axial properties, and these can function in consonance with those of a lexical item, as in the acceptable cases of (35), now schematized as to axiality in (36):

90 Leonard Talmy
In other cases, though, the axiality of a grammatical form can conﬂict with that of a lexical item and, accordingly, can cause the latter to shift. Thus, sick in (37) – now associated with grammatical forms that refer to an end-point – shifts from its basic “directed shaft” type of axiality, and indeed from its reference to an axis of ‘health’; it now speciﬁes the end-point of an axis pertaining to ‘feeling physically bad’. (37) (After exposure to the virus, he felt worse and worse and)
he was almost sick at one point. / he ﬁnally got sick in 3 days.21
2.9. Perspectival mode As seen earlier, a particular event, whether static or changing, can have a pattern of distribution through time that is perhaps most basically associated with or intrinsic to it in its own right. But, in addition, language has the means for specifying an independent schema as to how one is to attend to the event. This schema includes the location and deployment of the perspective point one adopts from which to regard the event and the distribution of one’s attention over the event. This category of speciﬁcations, here called the “perspectival mode”, can either conform with or diverge from the event’s own basic pattern of distribution. Two principal members of the category are characterized in (38):

Chapter 2: Grammatical construal 91
(38) the assuming of: a. a steady-state long-range perspective point with global scope of attention b. a moving close-up perspective point with local scope of attention
For illustration, consider ﬁrst an example with a basically steady-state referent, viz., objects in location. The (38a) type of perspectival mode – the one more congruent with such a referent – is invoked in (39a), multiply speciﬁed there by the set of grammatical forms shown underlined, namely, plural forms, an adverbial expression of spatial dispersion, and the locative preposition in. But these can be replaced by grammatical forms coding for the (38b) perspectival mode – as in (39b) with singular forms, an adverbial expression of temporal dispersion, and the motion preposition through. Thereby, the evoked CR is converted to one where one’s perspective and attention or one’s own projected location shifts in turn from object to object. In effect, a steady-state multiplexity of objects has been converted to a sequential multiplexity of events consisting of conceptualized encounters with the objects.
(39) a. There are houses at various points in the valley. b. There is a house every now and then through the valley.
For representing certain static spatial conﬁgurations, the moving-perspective mode, though non-congruent in character, is greatly favored over the steady-state mode. Thus, the ready colloquial formulation of (40b) for moving-perspective is matched in the global steady-state mode of (40a) only by a stilted scientiﬁc style:
(40) a. The wells’ depths form a gradient that correlates with their locations on the road.
b. The wells get deeper the further down the road they are.
The reverse of the preceding circumstances also exists. That is, a sequential multiplexity of events, an example of which is represented in (41 a) with the more congruent moving-perspective mode, can also become the object of a ﬁxed global viewing, as represented in (41b). Metaphorically, the effect here is as if the vertical time line is tilted up into present-moment horizontality for integrated or summational assessment.
(41) a. I took an aspirin time after time during / in the course of the last hour.
b. I have taken a number of aspirins in the last hour.22

92 Leonard Talmy

2.10. Level of synthesis
The category to be considered now pertains to bounded quantities, like those schematized in the A/B row in (23). One form of locution already seen to specify such quantities is the particular type of “NP of NP” construction illustrated in (42a). Here the second NP speciﬁes the identity of the quantity involved, itself conceptualized as without intrinsic bounds, while the ﬁrst NP speciﬁes the bounding, or “portion-excerpting”, per se of the quantity. Moreover, in addition to such a pure operation of bounding, the ﬁrst NP can further specify the particular form or conﬁguration that the excerpted portion has, as in (42b):23

(42) a. a set of trees b. a cluster of trees

a body of water a puddle/drop of water

The two NPs here can be seen as coding for two different “levels of synthesis”. Describing this for the internally discrete case, e.g., a cluster of trees, we can say that the second NP speciﬁes an unsynthesized multiplexity of independent elements, while the ﬁrst NP speciﬁes a particular Gestalt synthesized out of that multiplexity.
Furthermore, language can mark an additional cognitive distinction here. Either level of synthesis can be placed in the foreground of attention while the other level is placed in the background. One grammatical device for marking this is the placement of the foregrounded NP at the head of the larger nominal construction (in English, placing it ﬁrst), as shown in (43a). With the use of this device, moreover, predications can be made that pertain solely to one level of synthesis or the other, as seen in (43b):

(43) a. the cluster of trees / the trees in the cluster b. That cluster of trees is small. The trees in that cluster are small.

There are certain forms, furthermore, whose referents are keyed to applying to only one or the other level of synthesis. Thus, together (toward each other) tends to correlate with multiple objects at large, while in upon -self tends to correlate with a composite formed therefrom, as seen in (44):

(44) The bricks in the pyramid came crashing together / *in upon themselves. The pyramid of bricks came crashing in upon itself / * together.

The preceding phenomena have involved the shift of attention from a multiplexity to a Gestalt that it can constitute, a process that can be called “Gestalt formation”. Also encountered in language are means for specifying the reverse: shift-

