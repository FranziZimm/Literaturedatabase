file:///C|/New%20Text%20Document.txt
Table of Contents Preface to Volume 2 Addresses of the PDP Research Group
IV PSYCHOLOGICAL PROCESSES 14 Schemata and Sequential Thought Processes in PDP Models
D.E. Rumelhart, P. Smolensky, J.L. McClelland, and G.E. Hinton
15 Interactive Processes in Speech Perception: The TRACE Model J.L. McClelland and J.L. Elman
16 The Programmable Blackboard Model of Reading J.L. McClelland
17 A Distributed Model of Human Learning and Memory J.L. McClelland and D.E. Rumelhart
18 On Learning the Past Tenses of English Verbs D.E. Rumelhart and J.L. McClelland
19 Mechanisms of Sentence Processing: Assigning Roles to Constituents J.L. McClelland and A.H. Kawamoto
V BIOLOGICAL MECHANISMS 20 Certain Aspects of the Anatomy and Physiology of the Cerbral Cortex
file:///C|/New%20Text%20Document.txt (1 of 2)9/25/2008 5:08:55 PM

file:///C|/New%20Text%20Document.txt
F.H.C. Crick and C. Asanuma
21 Open Questions About Computation in Cerebral Cortex T.J. Sejnowski
22 Neural and Conceptual Interpretation of PDP Models P. Smolensky
23 Biologically Plausible Models of Place Recognition and Goal Location D. Zipser
24 State-Dependent Factors Influencing Neural Plasticity: A Partial Account of the Critical Period P.W. Munro
25 Amnesia and Distributed Memory J.L. McClelland and D.E. Rumelhart
VI CONCLUSION 26 Reflections on Cognition and Parallel Distributed Processing
D.A. Norman
Future Directions References Index
file:///C|/New%20Text%20Document.txt (2 of 2)9/25/2008 5:08:55 PM

Preface
The chapters in this volume continue the explorations of parallel dis tributed processing that we began in Volume I . The accompanying table lays out the organization of both volumes . Part IV , which begins this volume , presents parallel distributed processing (POP ) models of psychological processes, and Part V explores the biological mechanisms of parallel distributed processing in the brain . Part VI provides a brief retrospective discussion of the whole book and our thoughts about
future directions .
The various parts of this book are interrelated , but they can generally be read in any order , and indeed most of the chapters can be under -
stood without reference to the rest of the book . However , readers may
find it useful to read some of the chapters in Part I before delving into the specific topics covered in the chapters of Parts IV and V . A discus sion of the contents of each chapter and the background that is relevant to, it may be found in the introductory section at the beginning of each part of the book .
Primary support for both volumes of the book came from the System Development Foundation and the Office of Naval Research . The System Development Foundation has provided direct support for the POP research group through a grant to Norman and Rumelhart , and has also supported several of the individual members of the group (Crick , Hin ton , Sejnowski , and Zipser ) . ONR contracts that have contributed support include NOOO14 - 79 - C - O323 , NR 667 -437 ~ NOOO14 - 85 - K -O450 , NR
667 - 548 ~ and NOOO14 - 82 - C - O374 , NR 667 - 483 . Several other sources have contributed to the support of individual
members of the group . These include the National Institute of Mental

x PREFACE

I. THEPOPPERSPECTIVIEI. BASICMECHANISMSIII. FORMAALNALYSES

1. The Appealof POP 2. A Frameworkfor POP
3. Distributed
Representations 4. GeneralIssues

5. CompetitiveLearning 6. HarmonyTheory 7. BoltzmannMachines
8. Learningby Error Propagation

9. Linear Algebra 10. Activation Functions
11. The Delta Rule
12. ResourceRequirements 13. ParallelNetwork
Simulator

VOLUMEII

IV. PSYCHOLOGICAL V. BIOLOGICAL

VI. CONCLUSION

PROCESSES

MECHANISMS

14. Schemata nd POP
15. SpeechPerception 16. Model of Reading 17. Learningand Memory 18. MorphologyAcquisition 19. SentenceProcessing

20. Anatomyand Physiology
21. Computationin the Brain
22. Neuraland
ConceptuaLl evels 23. PlaceRecognition 24. Neural Plasticity 25. Amnesia

26. Reflections Future Directions

Health , through a Career Development Award - PHS-MH -OO385- to McClelland and postdoctoral fellowships to Paul Smolensky and Paul Munro under Grant PHS-MH - 14268 to the Center for Human Informa -
tion Processingat UCSD. Smolensky received support in the form of a fellowship from the Alfred P. Sloan Foundation , and some of McClelland 's work was supported by a grant from the National Science Foundation (BNS-79-24062) . These and other sources of support for
specific individuals or projects are acknowledged in the appropriate chapters.
Once again we would like to acknowledge the support of the Institute for Cognitive Science at UCSD and of all of the people at UCSD and elsewhere who have helped us bring this work to completion . These people are mentioned individually in the acknowledgments section of Volume I , which applies to both volumes.

December 1985

David E. Rumelhart LAJOLLA, CALIFORNIA
JamesL. McClelland PITTSBUR,GPHENNSYLVANIA

Addresses of the PDP Research Group

Chisato Asanuma
FrancisH. C. Crick JeffreyL. Elman Geoffrey E. Hinton MichaelI. Jordan
Alan H . Kawamoto

Salk Institute P .O . Box 85800 San Diego , CA 92138
Salk Institute P .O . Box 85800 San Diego , CA 92138

Department

of Linguistics

University

of California

La Jolla , CA 92093

, San Diego

Department Carnegie Pittsburgh

of Computer

- Mellon

University

, P A 15213

Science

Department of Computer and Information Science
University of Massachusetts Amherst , MA 01003

Departmenotf Psychology Carnegi-eMellonUniversity Pittsburg,hPA 15213

X.I.I ADDRESSEOSFTHEPOPRESEARCGHROUP

JamesL. McClelland PaulW. Munro DonaldA. Norman Daniel E. Rabin David E. Rumelhart TerrenceJ. Sejnowski
Paul Smolensky Gregory O . Stone
RonaldJ. Williams David Zipser

Department of Psychology Carnegie-Mellon University Pittsburgh, PA 15213
Department of Information Science
Universityof Pittsburgh Pittsburg,hPA 15260
Institutefor CognitiveScience Universityof California, SanDiego La Jolla, CA 92093
Intellicorp 1975 EI Camino Real West Mountain View , CA 94040

Institute

for Cognitive

University

of California

La Jolla , CA 92093

Science , San Diego

Department

of Biophysics

Johns Hopkins

University

Baltimore

, MD 21218

Department University Boulder

of

Computer

of

Colorado

, CO

80309

Science

Center for Adaptive Systems
Department of Mathematics BostonUniversity Boston, MA 02215

Institutefor CognitiveScience
Universityof California, SanDiego La Jolla, CA 92093

lnsitute for CognitiveScience Universityof California, SanDiego La Jolla, CA 92093

PARIVT
PSYCHOLOGICALPROCESSES
The chapters in this section are designed to show how parallel distrib uted processing has changed the way we think about the mechanisms of cognition . Each chapter describes a model of some mental process. Each shows how the model captures some basic aspectsof the process. And each offers an alternative to other , earlier ways of thinking about aspectsof the process.
The models described in these chapters were motivated by a number of different considerations. Quite often , they were motivated by the feeling that parallel distributed processing mechanisms provide a very natural and appropriate set of mechanisms for dealing with some aspect of cognition that has not been dealt with successfully by other approaches. Quite often , they were motivated by an attempt to meet computational challenges posed by the processes they address. And quite often , they were motivated by attempts to extend the domain of POP models, to encompassprocessesand phenomena we did not know how to model at the outset.
The first chapter of the section, Chapter 14, explains how parallel distributed processing can take us beneath the surface of schemata, to a level of description that allows us to see how we can preserve the desirable characteristics of schemata and at the same time make them more flexible , more sensitive to context , more adaptable. This chapter also begins to show how POP mechanisms can be used as the building blocks from which we may construct sequential thought processes, such as problem solving .

2 PSYCHOLOGPIRCOALCESSES
The next two chapters consider issues in perception. Chapter 15 presents a model of speech perception and shows how it provides a uni fied framework for capturing a number of aspectsof speech. Here, the goal was to develop a model that accounts in detail for psychological data on the process of speech perception and, at the same time , to begin to deal with several computational problems that make the extension of POP models to speech a challenging and stimulating task. The model introduces a processing structure called the Trace, a dynamic working memory , in which units that stand for hypotheses about the contents of an utterance at different points in time can interact. The parallel distributed processing that occurs in the Trace allows the model to account for contextual influences on phoneme identification , and the simple competitive interactions among hypotheses representing competing interpretations of the same portion of an utterance allow the model to segment and identify the words in an utterance in a simple and integrated fashion. The model accounts for a wide range of data in a direct and coherent way, and shows how POP mechanisms offer new ways of interpreting several phenomena, such as categorical perception and the perception of phonologically regular nonwords.
The model described in Chapter 15 purchases its parallel processing capabilities by duplicating the same hardware to cover each time -slice of the Trace. This idea seems incorrect ~ in general, it seems more plausible to view the Trace not as a fixed processing structure , but as one that is dynamically configured in the course of processing, using knowledge of contingencies between hypotheses to construct the Trace on the fly . Chapter 16 develops a model called the Programmable Blackboard Model of Reading (PABLO for short) that does just this , though for printed , as opposed to spoken input . This model is based on the idea of connectioninformation distribution- roughly , the idea is to use information stored in one part of a processing system to set or program connections in another part of the same system. Two related simulation models based on this idea are applied to a number of aspects of reading that could not be addressed by the interactive activation model of word recognition , which was described in Chapter 1.
Neither TRACE nor PABLO really extend above the word level to deal with the larger syntactic and semantic structures that organize words into sentences~ these levels are considered in Chapter 19, which we will describe a bit more below.
Chapters 17 and 18 describe distributed models of different aspects of learning and memory . Chapter 3 (on Distributed Representations) provides useful background for these chapters, as well as for Chapter 19. Chapter 17 considers an existing dilemma for models of memory - whether to store summary representations in memory or whether to store an enumeration of specific experiences. The chapter

INTRODUCTTIOOPNARITV 3
points out that with distributed representations, you can have it both ways. In the model, the (long-term) memory trace of an event is the change or increment to the connections that results from the event. Functional equivalents of summary representations (e.g., prototypes) emerge naturally from the superimposition of memory traces of specific events. Traces of recent or often -repeated events can coexist with the summary representation. The chapter also illustrates that the same composite memory trace can learn several different prototypes from exemplars, without ever being informed - and indeed, without having to " figure out " - which exemplars belong to each category. The model uses the delta rule (examined in Chapters 2, 8, and 11) for adjusting connection strengths and has some advantages over some distributed memory models, but it contains no hidden units , and so is not capable of overcoming what we call the "linear predictability constraint " on the set of patterns it can learn. At the end of the chapter, we illustrate with a simple example simulation how the model can be extended with hidden units that are trained with the aid of the generalized delta rule discussedin Chapter 8.
Chapter 18 draws out some other implications of distributed models of learning and memory . It considers how knowledge underlying the lawful use of language might be represented in a PDP model and how that knowledge might be acquired. More generally, it shows how distributed representations provide an alternative to the conventional view that linguistic knowledge is represented in the form of explicit (though inaccessible) rules. The chapter considers a paradigm case of rule learning from the language acquisition literature - the acquisition of the past tense by children acquiring English as their first language. This case is often cited as an instance of rule acquisition par excellence because of the fact that children " regularize" irregular verbs at one stage, often saying "goed," for example. The model we describe in this chapter exhibits this and many other aspectsof the acquisition process, and it does this by using very simple learning mechanisms. Lawful behavior emerges from the superposition of changes to connection strengths. The representation of the rules of past-tense formation is implicit in the resulting connection strengths and is acquired without the aid of any device that relies on the formulation and testing of explicit but inaccessiblerules.
Many of the chapters we have been describing deal with aspects of language, but none of them get much beyond the processing of individ ual words. Does this indicate that PDP models are inappropriate for capturing higher levels of language structure and processing? We think not . Indeed, one of our goals has been to work toward the development of PDP models of sentence processing. As Chapter 19 indicates, much of the groundwork has now been laid. That chapter describes a

4 PSYCHOLOGPIRCOALCESSES

distributed

model

that

brings

the

benefits

of

parallel

distributed

pro -

cessing

to

the

processing

of

simple

sentences

, and

shows

how

a POP

network

can

be configured

to produce

a representation

that

can

capture

the

underlying

case

structure

of simple

sentences

. The

model

exhibits

a number

of very

nice

properties

. It can

assign

arguments

of sentences

to the

appropriate

case

roles

based

on word

- order

information

, based

on

the

mutual

selectional

constraints

imposed

by the

different

words

in the

sentence

, and

based

on

word

- order

and

mutual

constraints

working

together basis

~ it can

choose

of

the

content

the

appropriate

and

configuration

" case

frame

" for

of

the

arguments

a verb

on

the

in

the

sen -

tence ous

~ it can

choose

word

based

on

the

appropriate

constraints

imposed

reading by

of

a semantically

the

other

arguments

ambigu

-

in the

sentence

~ it can

fill

in default

values

for

missing

arguments

~ and

it can

generalize representation

its

case - role

of

some

assignments

of

the

to semantic

novel

verbs

if

it is given

a

features

of

the

verb

.

The

model

has

not

yet

reached

the

stage

where

it can

process

sentences

with

embedded

clauses

, but

we

suggest

three

ways

in

which

it might

be

extended

to do

tion

information

so , including distribution

one

that

mechanism

relies

on

the

described

use

of the

in

Chapter

connec

-

16 and

one

that

involves

" true

" recursion

.

These

suggestions

indicate

that

POP

mechanisms

are

capable

of

processing

recursively

defined

struc

-

tures

, contrary

to prevalent

belief

.

Similarities

and

Differences

Between

Models

Each

all

of

of the

the

models

others

.

described

One

model

in these

chapters

uses

continuous

differs - valued

in detail , asynchronous

from

units

~ several

stochastic

units

others

use

. In some

continuous models

, sychronous , activation

values

units

~ still

can

range

others from

use 1 to

- 1 ~ in others

, they

the

models

, however

can

only

, are

range examples

from

1 to 0 , or slightly

below

O . All

of

the

class

of

POP

models

, as

described incidental

in Chapter to their

2 , and

their

behavior

. Where

minor these

differences detailed

are

in

assumptions

most

cases

seem

to

make

a difference

, we

point

it out , but

in general

, we

do

not

think

that

much One

hinges

on

characteristic

these

differences

.

that

differentiates

some

of

the

models

from

the

others

requires

some

comment

: The

models

in Chapters

15 and

16 use

local

representations

, while

the

models

in the

other

chapters

use

distrib

-

uted

representations

. Even

this

does

not

reflect

a fundamental

differ

-

ence

in the

philosophy

of the

models

~ rather

, they

reflect

differences

in

the

points

we

wanted

to make

and

the

issues

we

wanted

to raise

in the

different

chapters

. In fact

, we

believe

that

both

the

TRACE

model

and

INTRODUCTIOTNOPARTIV 5
the models described in Chapter 16 could be made more efficient by the use of distributed rather than local representations, for reasons discussed in Chapters 3 and 12. It is also true that nearly all of the models can be seen as either local or distributed , depending on one's point of view. They are local, in the sense that each unit generally stands for a particular conceptual object or feature, or perhaps a (coarse coded) conjunction of features. They are distributed , in the sense that any given stimulus object- a phoneme, a word, a sentence, a sceneproduces a pattern of activation over a very large number of units . Whether we see the models as distributed or local is primarily a matter of whether we are looking at the forest or the trees.
Stepping Stones
Most of the models we present represent the result of a long series of explorations. In some cases, we learned a great deal from our earlier attempts, and the problems we had with them lead natually to better formulations . In other cases, our early attempts were failures we did not know at first how to overcome. For example, an early version of the model of past tense learning could be made to produce overgeneralization errors, but it could only processverbs consisting of a consonant, a vowel, and a consonant. It took us two years to formulate a better representation.
We think the models we describe in these chapters demonstrate progress in the development of POP models of psychological processes. But none of the models is the final word. Each model has its weaknesses, as well as its strengths. We have not solved all the problems~ rather, we have suggested an approach that shows promise of leading us closer to their solution . We offer these models in that spirit : as stepping stones along the way to a deeper understanding of the microstructure of cognition .

CHAP14TER
Schemataand SequentialThoughtProcesseisn PDP Models
D. E. RUMELHAR,TP. SMOLENSK, JY. L. McCLELLAND andG. E. HINTON
One of our goals for this book is to offer an alternative framework for viewing cognitive phenomena. We have argued that talk at the level of units and activations of units is the preferable way to describe human thought . There is, however, already an established language for discussing cognitive phenomena. In this chapter we wish to addressthe relationship between some of the key established concepts and our parallel distributed processing models. There are many important concepts from modern cognitive science which must be explicated in our framework . Perhaps the most important , however, is the concept of the schema or related concepts such as scripts, frames, and so on. These large scale data structures have been posited as playing critical roles in the interpretation of input data, the guiding of action, and the storage of knowledge in memory . Indeed, as we have argued elsewhere (cf. Rumelhart , 1980) , the schema has, for many theorists, become the basic building block of our understanding of cognition . Yet , the POP language we are proposing is devoid of terms such as schemata, scripts, frames, and so forth . Instead, we have proposed building blocks at a much more microlevel - at the level of units , activations, and similar "low-level " concepts. Interestingly , it was struggling with the concept of the schema and some of its difficulties that led one of us (OER) to an exploration of POP models to begin with . It was therefore with

8 PSYCHOLOPGRICOACLESSES
some priority that we began to develop an interpretation of the schema in the language of parallel distributed processing . 1
Perhaps the first thought that comes to mind is to map the notion of the schema onto the notion of the unit . This does , indeed , capture some of the important aspects of the schema . In particular , the unit is an element , like the schema , which monitors its inputs searching for a good fit and takes on a value which represents how well its inputs fits its own internal criteria . However , such an identification misses much of what makes the schema a powerful conceptual tool . In particular , there is no analog to the variable or default values . There is no notion of the internal structure of the schema nor many of the other important aspects of schemata . Moreover , the scale is wrong . Schema theorists talk of schemata for rooms , stories , restaurants , birthday parties , and many other high - level concepts . In our parallel distributed processing models , units do not tend to represent such complex concepts . Instead , units correspond to relatively simple features or as Hinton ( 1981a ) calls them microfeatures . If we are to do justice to the concept of the schema ~ we are going to have to look beyond the individual unit . We are going to have to look for schemata as properties of entire networks rather than single units or small circuits . In the following sections we show how features of networks can capture the important features of schemata . Since our interpretation is clearest in the subset of POP models that can be characterized as constraint satisfaction networks , it will be useful to first describe that class of models and provide a language for talking about their properties .

PARALLEL

DISTRIBUTED

PROCESSING

MODELS

AS

CONSTRAINT

SA TISF ACTION NETWORKS

It is often useful to conceptualize a parallel distributed processing network as a constraint network in which each unit represents a hypothesis of some sort ( e .g ., that a certain semanti .c feature , visual feature , or acoustic feature is present in the input ) and in which each connection represents constraints among the hypotheses . Thus , for example , if feature B is expected to be present whenever feature A is ,
1 All of the authors have contributed to the ideas expressed in this chapter. Smolensky's slightly different framework is sketched in Chapter 6. Hinton 's view of the microstructure of symbols is sketched in J. A . Anderson and Hinton ( 1981, pp. 29-32) , and McClelland ( 1981) shows how POP networks can be employed to fill default values (see the discussion in Chapter 1) . While we all agree with the flavor of the current discussion not all of us endorse the exact details.

14. SCHEMAATNADSEQUENTTIHALOUGHT9
there should be a positive connection from the unit corresponding to the hypothesis that A is present to the unit representing the hypothesis that B is present . Similarly , if there is a constraint that whenever A is present B is expected not to be present , there should be a negative con nection from A to B. If the constraints are weak , the weights should be small . If the constraints are strong , then the weights should be large . Similarly , the inputs to such a network can also be thought of as con straints . A positive input to a particular unit means that there is evi dence from the outside that the relevant feature is present . A negative input means that there is evidence from the outside that the feature is not present . The stronger the input , the greater the evidence . If such a network is allowed to run it will eventually settle into a locally optimal state in which as many as possible of the constraints are satisfied , with priority given to the strongest constraints . 2 The procedure whereby such a system settles into such a state is called relaxation . We speak of the system relaxing to a solution . Thus , a large class of POP models , including the interactive activation model of word perception , are con straint satisfaction models which settle on locally optimal solutions through the process of relaxation .
Figure 1 shows an example of a simple 16-unit constraint network . Each unit in the network represents a hypothesis concerning a vertex in a line drawing of a Necker cube .3 The network consists of two intercon nected subnetworks - one corresponding to each of the two global interpretations of the Necker cube . Each unit in each network is assumed to receive input from the region of the input figure - the cube - corresponding to its location in the network . Each unit in the Figure is labeled with a three letter sequence indicating whether its ver tex is hypothesized to be front or back (F or B) , upper or lower (U or L ) , and right or left ( R or L ) . Thus , for example , the lower left -hand unit of each subnetwork is assumed to receive input from the lower left -hand vertex of the input figure . The unit in the left -hand network represents the hypothesis that it is receiving input from a lower left hand vertex in the front surface of the cube (and is thus labeled FLL.) , whereas the one in the right subnetwork represents the hypothesis that it is receiving input from a lower left vertex in the back surface (BLL ) .
2 Actually, thesesystemswill in generalfind a locally bestsolution to this constraint satisfactionproblem. It is possibleunder someconditionsto insure that the "globally" bestsolution is found throughthe useof stochasticelementsand a processof annealing (cf. Chapters6 and 7 for a further discussio)n.
3 J. A. Feldman(1981) hasproposedan analysisof the Neckercube problemwith a somewhatdifferent network. Although the networksare rather different, the principles are the same. Our intention hereis not to providea seriousaccountof the Neckercube phenomen,abut ratherto illustrateconstraintnetworkswith a simpleexample.

10 PSYCHOLOPGRICOACLESSES
FIGURE 1. A simplenetwork representingsomeof the constraintsinvolved in perceiving the Necker cube.
Since there is a constraint that each vertex has a single interpretation , these two units are connected by a strong negative connection. Since the interpretation of any given vertex is constrained by the interpretations of its neighbors, each unit in a subnetwork is connected positively with each of its neighbors within the network . Finally , there is the constraint that there can only be one vertex of a single kind (e.g., there can only be one lower left vertex in the front plane FLL ) . There is a strong n~gative connection between units representing the same label in each subnetwork. Thus, each unit has three neighbors connected,positively , two competitors connected negatively, and one positive input from the stimulus . For purposes of this example, the strengths of connections have been arranged so that two negative inputs exactly balance three positive inputs . Further , it is assumed that each unit receives an excitatory input from the ambiguous stimulus pattern and that each of these excitatory influences is relatively small. Thus , if all three of a unit 's neighbors are on and both of its competitors are on, these effects would entirely cancel out one another~ and if there was a small input from the outside, the unit would have a tendency to come on. On the other hand, if fewer than three of its neighbors were on and both of its

1.4SCHEMAANTDSAEQUENTTHIAOLUGH1T1
competitorswere on, the unit would havea tendencyto turn off , even with an excitatoryinput from the stimuluspattern.
In the last paragraphwe focusedon the individual units of the networks. However, it is often useful to focus not on the units, but on entire statesof the network. In the caseof binary (on-off or 0-1) units, there is a total of 216possiblestatesin which this systemcould reside. That is, in principle, eachof the 16units could havethe value either 0 or 1. In the caseof continuousunits, in which eachunit can take on any value between0 and 1, the systemcan, in principle, take on any of an infinite number of states. Yet, becauseof the constraintsbuilt into the network, there are only a few of thosestatesin which the system will settle. To seethis, considerthe casein which the units are updated asynchronousl,yone at a time. During eachtime slice, one of the units is chosento update. If its net input exceeds0 its value will be pushed toward 1, otherwiseits value will be pushedtoward0, usingthe activation rule from the word perceptionmodel:
Q} (I + 1) = Q} (t) + I ne}ta(}1(-t ) a) (ot therwnies}te. > 0
Here, a) (t ) standsfor the activation of unit j at time t , and ne)t (t ) standsfor the net input to unit j at t . netj(t ) is simply the sum of the excitatoryandinhibitory influenceson unit j :
ej (t ) + r . Wjiai(t ) i~j
whereej (t ) is the externalinput to unit j at t and Wjiis the weight on the connectionto unit j from unit i .
Imagine that the system starts with all units off. A unit is then chosenat randomto be updated. Sinceit is receivinga slight positive input from the stimulus and no other inputs, it will be given a positive activationvalue. Then anotherunit is chosento update. Unlessit is in direct competitionwith the first unit, it too will be turned on. Eventually, a coalitionof neighboringunits will be turned on. Theseunits will tend to turn on more of their neighborsin the samesubnetworkand turn off their competitorsin the other subnetwork. The systemwill (almost always) end up in a situation in which all of the units in one subnetworkare fully activatedand none of the units in the other subnetwork are activated. That is, the systemwill end up interpretingthe Neckercubeas either facingleft or facingright. Wheneverthe system gets into a state and staysthere, the state is called a stablestateor a fIXedpointof the network.
Figure 2 showsthe output of three runs of a simulationbasedon this network. The sizeof the squareindicatesthe activationvaluesof each

12 PSYCHOLOGPIRCOALCESSES

Run 2 Left Right Subnet Subnet

Run 3
Left Right Subnet Subnet

FIGURE 2. Three runs of a simulationbasedon this network. The sizeof the square indicatesthe activationvalueof eachunit. The unitsarearrangedin the shapeof the subnetwork with eachsquareshownin its positioncorrespondingto the vertex of the cube from whichit is receivinginput. The statesareshownafter everysecondupdate.

1.4SCHEMAANSTDAEQUETNHTOIAULG1H3T

unit . The units are arranged in the shape of the subnetwork with each square shown in its position corresponding to the vertex of the cube from which it is receiving input . The system begins with a zero activa tion value on all units - represented by single dots . Then , once each time slice , at most one unit is changed . On each run the system winds up in a state in which each unit has a value of either 0 or 1 ( designated by a large square ) . The first two runs are most typical of the system . In this case , the inputs are low relative to the strength of the con straints among units . When low inputs are involved , the system virtu ally always winds up either in the state in which all of the units in the left - hand network are turned on and all of the units in the right - hand are off or vice versa . These final stable states correspond to the interpretations of a left -facing and right -facing cube as illustrated in the figure for the first and second run respectively . The third example of simulation results is much more aberrant and was generated with a high input value . With a high input value , the system can occasionally get a third interpretation of the Necker cube . This is the " impossible " cube with two front faces illustrated in the figure . Thus , of the 216 possible states of the system , only two are ever reached with low input values and only three are ever reached at all . The constraints implicit in the pattern of connections among the units determines the set of possible stable states of the system and therefore the set of possible interpreta tions of the inputs .
Hopfield ( 1982 ) has shown that it is possible to give a general account of the behavior of systems such as this one ( with symmetric weights and asynchronous updates ) . In particular , Hopfield has shown that such systems can be conceptualized as minimizing a global measure which he calls the energy of the system through a method of gradient descent or , equivalently , maximizing the constraints satisfied through a method of hill climbing . In particular , Hopfield has shown that the sys tem operates in such a way as to always move from a state that satisfies fewer constraints to a state that satisfies more constraints , where the measure of constraint satisfaction is given by 4

G ( t ) = LLW ;ja ; ( t ) aj ( t ) + Linputi ( t ) aj ( t ) .

i j

i

4 Note , the question of what to :call this constraint satisfaction function is difficult . Hopfield uses the negation of this function and, by analogy to thermodynamics , calls it energy. This system can thus be said to settle into states of minimum energy. Similarly , Hinton and Sejnowski (Chapter 7) use the same terminology . Smolensky (Chapter 6) has a similar function which he calls harmony to emphasize that increasing values correspond to more harmonious accounts of the inputs. In this chapter we have chosen to use the language of constraint satisfaction and call the function G for measure of the goodness-of-fit of the state to its constraints.

14 PSYCHOLOGPIRCOALCESSES
Essentially, the equation says that the overall goodness-of-fit is given by the sum of the degrees to which each pair of units contribute to the goodness plus the degree to which the units satisfy the input constraints. The contribution of a pair of units is given by the product of their activation values times the weights connecting them . Thus, if the weight is positive, each unit wants to be as active as possible- that is, the activation values for these two units should be pushed toward 1. If the weight is negative, then as least one of the units should be 0 to maximize the pairwise goodness. Similarly , if the input constraint for a given unit is positive, then its contribution to the total goodness-of-fit is maximized by being the activation of that unit toward its maximal value. If it is negative, the activation value should be decreasedtoward O. Of course, the constraints will generally not be totally consistent. Sometimes a given unit may have to be turned on to increase the function in some ways while decreasing it in other ways. The point is that it is the sum of all of these individual contributions that the system seeks to maximize . Thus, for every state of the system- every possible pattern of activation over the units - the pattern of inputs and the connectivity matrix W determines a value of the goodness-of -fit function . The system processesits input by moving upward from state to adjacent state until it reaches a state of maximum goodness. When it reaches such a stable state or fIXed point it will stay in that state and it can be said to have "settled" on a solution to the constraint satisfaction problem or alternatively , in our present case, "settled into an interpretation " of the input .
It is important to see, then , that entirely local computational operations , in which each unit adjusts its activation up or down on the basis of its net input , serve to allow the network to converge towards states that maximize a global measure of goodness or degree of constraint satisfaction. Hopfield 's main contribution to our present analysis was to point out this basic fact about the behavior of networks with symmetrical connections and asynchronous update of activations.
In general, since there are so many states, it is difficult to visualize the goodness-of -fit function over which the system is moving . In the present case, however, we can get a reasonably good image of this landscape. To begin, we can limit our consideration to those states in which a particular unit is either on or off since the system always ends up in such states. We can consider the states arrayed along two dimen sions. One dimension corresponds to the number of units turned on in the left subnetwork and the other dimension corresponds to the number of units turned on in the right subnetwork. Thus, at (0,0) we locate the state in which no units are turned on. Clearly, by the above

1.4SCHEMAANTDASEQUENTTHIAOLUGH1T5
equation such a state will have zero goodness of fit . 5 At (8,8) we have the state in which all of the units are turned on . At location (8,0) we have the state in which the units on the left network are all turned on and those on the right network are all off . At position (0,8) we have the state in which those in the left network are all off and those in the right network are all on . Each of those locations contain unique states . Now , consider the location ( 1,0) in which one unit from the left sub network and zero units in the right subnetwork are turned on . There are eight different states , corresponding to the eight different units in the left subnetwork that might have been turned on . In order to plot the goodness -of -fit landscape for this state space, we have plotted only the states at each location of the two -dimensional space with highest goodness -of -fit - i .e., the best state at each location . Figure 3 shows the landscape . In the figure , we are viewing the goodness landscape from about the (0 ,0) corner , the start state . Thus , the peak to the right corresponds to the goodness of the state in which all of the units in the left subnetwork are turned on and all in the right subnetwork are turned off . The peak at the upper left portion of the figure

;

goodness (0 ,8 )

'.

:.':
', : '

~'~:~.~,"'.."~~.:'~

',: .

;.

.; : . ' . "
. . ':.: . ' :

':~

(0 ,0 )

I
I
I
ifr'
(8 ,0)
::::::::::~__;~I'~~
.\ s of ' :\t 0\ uf ' \ "' A.IO{~
bf ' e \.'V' \f ' \ e\ \ su

FIGURE 3. The goodness -of -fit surface for the Necker -cube network . The low point at the (0 ,0) corner corresponds to the start state . The peaks on the right and left correspond to the standard interpretations of the Necker cube , and the peak in the center corresponds to the impossible Necker cube illustrated in the previous figure .

s Note , zero goodness -of -fit is not the minimum goodness -of -fit attainable . In general , goodness -of -fit can be negative as well as positive . When there is negative goodness -of fit , the system can always be made better by turning off all of the units ,

16 PSYCHOLOPGRICOACLESSES
corresponds to the state (0,8) . The two peaks in the graph at (8,0) and (0,8) correspond to the two primary interpretations of the Necker cube. It should be clear that if we start a system at (0,0) and allow it to " hill climb " it will almost always end up at one of these two peaks. It might be noted, that there are three smaller peaks right in the middle of the surface. These local peaks are very hard to get to becausethe system is almost always swept from the start state uphill to one of the two major peaks. It is possible, by having large input values, to reach location (4,4) . This peak corresponds to the impossible Necker cube illustrated in the previous figure .
The input to the system can be conceptualized as systematically modifying or sculptingthe goodness landscape. This effect is illustrated in Figure 4. In this case, the same landscapehas been plotted, except the units corresponding to the interpretation of the Necker cube as facing to the left receive more input than the corresponding units on the other subnetwork . (This could perhaps be done by slightly shading that face of the Necker cube.) What we see is a " sloping" goodnesssurface with the peak associatedwith the interpretation of the Necker cube as left facing.
To summarize, then , there is a large subset of parallel distributed processing models which can be considered constraint satisfaction models. These networks can be described as carrying out their infor mation processing by climbing into states of maximal satisfaction of the
FIGURE 4. The distortionsof the goodnesslandscapewhena largeinput is givento the units correspondingto the front face of a left-facingcube. The figure showsonly one majorpeakcorrespondingto the view of the left-facingcube.

1.4SCHEMAANTDASEQUENTTHIAOLUGH1T7
constraints implicit in the network . A very useful concept that arises from this way of viewing these networks is that we can describe the behavior of these networks, not only in terms of the behavior of indi vidual units , but in terms of properties of the network itself . A primary concept for understanding these network properties is the goodnes-sof-fit landscapeover which the system moves. Once we have correctly described this landscape we have described the operational properties of the system- it will process information by moving uphill toward goodness maxima. The particular maximum that the system will find is determined by where the system starts and by the distortions of the space induced by the input . One of the very important descriptors of a goodnesslandscapeis the set of maxima which the system can find , the size of the region that feeds into each maximum , and the height of the maximum itself . The states themselves correspond to possible interpretations , the peaks in the space correspond to the best interpretations , the extent of the foothills or skirts surrounding a particular peak determines the likelihood of finding the peak, and the height of the peak corresponds to the degree that the constraints of the network are actually met or, alternatively , to the goodness of the interpretation associatedwith the corresponding state.
CONSTRAINTSATISFACTIONAND SCHEMATA
In the previous section we recounted a perspective on parallel distrib uted processing systems. In this section we address, again, the nature of the schema and relate it to constraint satisfaction systems and POP models. We will proceed by first recounting some of the history of the concept of schemata, then by offering an interpretation of the schema in terms of POP models, by giving a simple example; and finally showing how the various properties attributed to schemata are, in fact, properties of the PDP networks of the kind we have been discussing.
The schema, throughout its history , has been a concept shrouded in mystery. Kant 's (1787/ 1963) use of the term has been provocative but difficult to understand. Bartlett 's ( 1932) usage has long been decried for its vagueness. Piaget ( 1952) used the term schema, but it was diffi cult to come up with a consistent interpretation of Piaget's own views on the matter. Throughout most of its history , the notion of the schema has been rejected by mainstream experimental psychologists as being too vague. As a result, the concept ot- the schema was largely shunned until the mid -1970s. The concept was then revived by an attempt to offer a more clearly specified interpretation of the schema in

18 PSYCHOLOGPIRCOALCESSES
terms of explicitly specified computer implementationsor, similarly, formally specified implementations of the concep.t Thus, Minsky (1975) postulated the concept of the frame, Schank and Abelson (1977) focusedon the conceptof the script, and Bobrowand Norman (1975) and Rumelhart (1975) developed an explicit notion of the schema. Although the detailsdiffered in eachcase, the ideawasessentially the same. PerhapsMinsky (1975) wasclearestin the motivation:
It seems to me that the ingredients of most theories both in artificial intelligence and in psychology have been on the whole too minute , local, and unstructured to account- either practically or phenomenologically- for the effectiveness of common sense thought . The "chunks " of reasoning, language, memory , and 'Iperception" ought to be larger and more structured , and their factual and procedural contents must be more intimately connected in order to explain the apparent power and speed of mental activities . (p. 211)
Minsky and the others argued that some higher-level " suprasentential " or, more simply , conceptual structure is needed to represent the complex relations implicit in our knowledge base. The basic idea is that schemata are data structures for representing the generic concepts stored in memory . There are schemata for generalized concepts underlying objects, situations, events, sequences of events, actions, and sequencesof actions. Roughly , schemataare like models of the outside world . To process information with the use of a schema is to determine which model best fits the incoming information . Ultimately , consistent configurations of schemata are discovered which , in concert, offer the best account for the input . This configuration of schemata together constitutes the interpretationof the input .
Different theorists have proposed more or less concrete specifications of the exact nature of these higher-level structures, but somehow none of them has ever really been adequate. None of them ever captured all of the qualitative characteristics that schemata were supposed to have. For example, a schema is supposed to be a kind of generative thing , which is flexible but which can produced highly structured interpretations of events and situations. Many representational formats have been proposed in an attempt to meet these criteria . For example, Rumelhart (1975) chose as a representation for the schema, a notation rich in generative capacity, namely, the rewrite rules from generative linguistics . Although the generativity of the rewrite rules and the idea that the structure is I'constructed" in the process of interpretation is well captured by the rewrite rules, the nonprocedural character of such a system seems wrong. Some more active representation seems

14. SCHEMATNADSEQUENTHIAOLUGH1T9
necessary. Moreover , the important notions of "default values," variables, and so forth are poorly represented by the rewrite notation . Min sky ( 1975) and Schank and Abelson ( 1977) employed passive data structures with slots and explicit default values. These representations are better but are not active and seem to lack the flexibility and generativity that the schema requires. Rumelhart (1977) proposed a representation in which schemata are special kinds of procedures. This view was most completely explicated in Rumelhart ( 1980) . Attempts to build explicit models employing this view, however, have proven unsuccessful. The representation is simply too unwieldy .
It should be clear from the foregoing that there are two distinct ways in which the term schema can be used. On the one hand, it is used to refer to an idea which is common to the work of Kant , Bartlett , Piaget, Minsky , Schank and Abelson , Norman and Bobrow, Rumelhart and Ortony , and many others. This is an idea that has evolved over the years and through the eyes of many different theorists. Many people have sought to clarify and further develop the idea. On the other hand, the term schema is used to refer to one of a large number of instantiations of the general idea of the schema. These explicit schema models are always only pale representations of the underlying intuitions . Whenever a new instantiation of the schema idea is developed, a new perspective is offered on the underlying idea. What we hope to do in this chapter is to propose an alternative to the conventional representation of the schema and at the same time , through the development of a new perspective on schemata, sharpen the idea and develop a system which better captures our intuitions of the nature of the human information -processingsystem.
One important feature of schemata proposed by Rumelhart and Ortony (1977) has never actually been included in any implementation of the idea. This involves the nature of variable constraints and the
filling of default values. The variable constraints associated with each variable serve two functions . On the one hand, they are important for determining whether a particular candidate is an allowable assignment for a variable and, if the variable remains unfilled , are used in the assignment of a default value. These constraints should not be considered absolute. Rather it was proposed that variable constraints should be considered as distributions of possible values. The nearer to the mode of the distribution , the better the variable filler . Moreover , the mode could itself be considered the default value. Importantly , however, there are interdependencies among the possible slot fillers . If one variable is filled with a particular value then it changes the default for the other variables. It was therefore proposed that the variable constraints (and the fillers of the default values) should be considered multivariate distributions in which the default value for a particular

20 PSYCHOLOGPIRCOALCESSES
variable is determined by the values filling the other slots. This idea was difficult to integrate with any of the conventional semantic networks or similar representational formats for schemata. As we shall see, this is a central feature of the POP analog to schemata.
If schemata are to work as a basis for models of cognitive processing, they must be very flexible objects- much more flexible than they really ever have been in any actual implementations . This is a sort of dilemma . On the one hand, schemata are the structure of the mind . On the other hand, schemata must be sufficiently malleable to fit around most everything . None of the versions of schemata proposed to date have really had these properties. How can we get a highly structured schema which is sufficiently rich to capture the regularities of a situation and to support the kinds of inferences that schemata are supposed to support and at the same time is sufficiently pliable to adapt to new situations and new configurations of events?
On our current view, the answer is simple. Schemata are not " things." There is no representational object which is a schema. Rather, schemata emerge at the moment they are needed from the interaction of large numbers of much simpler elements all working in concert with one another. Schemataare not explicit entities , but rather are implicit in our knowledge and are created by the very environment that they are trying to interpret - as it is interpreting them . 6 Roughly, the idea is this : Input comes into the system, activating a set of units . These units are interconnected with one another, forming a sort of constraint satisfaction network . The inputs determine the starting state of the system and the exact shape of the goodness-of -fit landscape. The system then moves toward one of the goodness maxima. When the system reaches one of these relatively stable states, there is little tendency for the system to migrate toward another state.
The states themselves are the product of the interaction among many groups of units . Certain groups, or subpatterns of units tend to act in concert. They tend to activate one another and, when activated, tend to inhibit the same units . It is these coalitions of tightly interconnected units that correspond most closely to what have been called schemata. The stable pattern as a whole can be considered as a particular configuration of a number of such overlapping patterns and is determined by
6 Hofstadter (1979) expressesessentially the same view in his book Gode,l Esche,r Bach when the Anteater says:
My "symbols" are ACTIVE SUBSYSTEMS of a complex system., and they are composed of lower-level active subsystems . . . They are therefore quite different from PASSIVE symbols., external to the system, such as letters of the alphabet of musical notes, which sit there immobile , waiting for an active system to process them . (p. 324)

1.4SCHEMAANTDASEQUENTTHIAOLUGH2T1
the dynamic equilibrium of all of these subpatterns interacting with one another and with the inputs. Thus, the maxima in the goodness-of-fit spacecorrespond to interpretations of the inputs or, in the language of schemata, configurations of instantiated schemata. In short, they are those states that maximize the particular set of constraints acting at the moment . Depending on the context and the inputs, the system will be closer to one or another of the peaks in the goodness-of -fit function at the outset and will usually find the closest one. This interpretation , we believe, captures almost all of the important aspectsof the schema with a view that is at once more flexible than the previous interpretations and yet highly structured. The degree of structure depends on the tightness of the coupling among the coalitions of units which correspond to the schemata in question. Thus, the language of schemata and schema theories should be considered an approximation to the language of POP. In those cases in which there are coalitions of units that tend to work together, we have a rather close correspondence to the more conventional notion of a schema. In those casesin which
the units are more loosely interconnected, the structures are more fluid and less schema-like . Often , knowledge is structured so that there are relatively tight connections among rather large subsets of units . In these cases, the schema provides a very useful description.
One important difference between our interpretation of schemata and the more conventional ones is that in the conventional story, schemata are stored in memory . Indeed, they are the major contento/ memory. In our case, nothing stored correspondsvery closely to a schema. What is stored is a set of connection strengths which , when activated, have implicitly in them the ability to generate states that correspond to instantiated schemata. This difference is important - especially with regard to learning. There is no point at which it must be decided to create this or that schema. Learning simply proceeds by connection strength adjustment, according to some simple scheme such as those we discuss in various placesin this book. As the network is reorganized as a function of the structure of its inputs , it may come to respond in a more or less schema-like way.
We now turn to an example to illustrate the various aspectsof these PDP networks and show that many of those features that prompted the invention of schemata in the first place are present in these networks. At the same time , we show that certain features that are problematic with conventional representations of schemata are better dealt with in the POP language.

22 PSYCHOLOPGRIOCCAELSSES
An Example

Consider our knowledge of different kinds of rooms. We all have a clear idea of what a typical kitchen or bathroom or living room or bedroom or office looks like . We know that living rooms have sofas and easy chairs, but they don't usually have ovens or bathtubs and that offices have desks and typewriters, but they don' t usually have beds. On the other hand, kitchens, living rooms, and offices might all very well have telephones, carpets, etc. Our default bathroom is very small, our default kitchen is somewhat larger but still probably small relative to our default living room . We chose our knowledge of rooms and types of rooms as the primary example to illustrate the POP representation of schem~ta. To begin, we need a constraint network that embodies the constraints implicit in our knowledge of rooms. We built our constraint network in the following way. We chose a set of 40 descriptors of rooms. These descriptors are listed (in Table 1. We asked two subjects to imagine an office and then, for each of the 40 descriptors asked if the descriptor was accurate of that office . We then asked subjects to imagine a living room and asked about the 40 descriptors again. We then asked about a kitchen , a bathroom , and a bedroom . After finishing these five types of rooms we asked subjects to imagine another office , etc. We collected a total of sixteen judgments of the 40 descriptors on each of the five room types. This data served as the basis for creating our network . 7 In principle , we could imagine presenting each!of these 80 room descriptions to the system and have it

ceiling large telephone books sofa
drapes cupboard toilet

TABLE! THEFORTYROOMDESCRIPTORS

door small typewriter clock coffee-cup coffeepot dresser oven

windows
\ 'ery-small bookshelf
picture ashtray ~efrigerator television computer

very-large desk
carpet floor -lamp fi replace toaster bathtub
clothes-hanger

7 This was not designed to be a formal experiment of any kind . Rather it was concep tualized as a method of Quickly getting a reasonable data base for building an example . Some slight modifications in the data base were made in order to emphasize certain points in our example .

1.4SCHEMAANTDSAEQUENTTHIAOLUGH2T3

learn according to one or another learning Rather than doing that , however , we simply to the following equation :

rule we have discussed . set the weights according

P (Xi = 0 & Xj = l )p (Xi = 1 & Xj = 0 )

Wi. = - In

.

J

P (Xi = 1 & Xj = l )p (Xi = 0 & ~ j = 0 )

This equation is derived from a Bayesian analysis of the probability that
unit Xi should be on given unit Xj is on and vice versa ( see Hinton & Sejnowski , 1983 ) . Four aspects of the weight equation should be noted :

. If the two units tend to be on and off together ( i .e ., the proba bility that Xi = Xi is much greater than the probability that Xi ~ Xi ) ' then the weight will be a large positive value .

. If , on the other hand , the probability that the two units take on
different values ( i .e ., Xi ~ Xi ) is much greater than the proba bility that they take on the same values ( i .e ., Xi = Xj ) , then the weight takes on a large negative value .

. If the two units come on and off independently

( i .e ., if

P (Xi = VI & Xj = V2) = P (Xi = VI )P (Xj - V2) ) , then the weight between the two units is zero .

. The weights are symmetric ( i .e ., W)i = W) i ) .

In addition , each unit has a bias ( constant input ) which is given by

.

P (Xi = 0 )

blGSi = - In P (Xi - 1) .

Note that if the unit is usually off , it has a negative bias ~ if it is usually on , it has a positive bias ~ and if it is equally often on or off , it has a zero bias . 8 The weight . matrix estimated by this means is shown in
Figure 5 . ~ he figure uses the method of Hinton and Sejnowski ( Chapter 7) to display the weights . Each unit is represented by a square . The name below the square names the descriptor represented by each square . Within each unit , the small black and white squares represent the weights from that unit to each of the other units in the

8 With a finite data base some of the probabilities mentioned in these two equations might be O. In this case the values of weights are either undefined or infinite . In estimating these probabilities we began by assuming that everything occurs with some very small probability (.00001) . In this way the equation led to finite values for all weights.

2ltfts.....40~"a",,e-Co'lDa.P...,.''S0YaCcmbssb..0....a'Hyle-0.O0,u0.-.L....O.O0.GPIRCwscetr.o0t.8....DOAa..L-CO0c......E...'uSOSEdvbctes.0Cor....S0'o.rp',0.o-a.eslcO-08....0c..",8Dmm[[,.]],owdadccc..ma."...o.'-o0e-0-D0t~.enhcnh,,'......gD0.,[a[.]]avtfccc.eo.o..'.".'0.."".-a-o,i0D.0pC,lOmie-.D,r....p.tu'.f0.U'pbddou.....D......eic...'0..l..,..fr....".sae....rlCtc....a....-aauhO...~.'...a..,0or.v.......p...d00r.k.ah,..'..'ree8eipseroloalerfapoo80lpw
FIGURE 5. The figure uses the method of Hinton and Sejnowski (Chapter 7) to display the weights. Each unit is represented by a square. The name below the square names the descriptor represented by each square. Within each unit , the small black and white squares represent the weights from that unit to each of the other units in the system. The relative position of the small squares within each unit indicates the unit with which that unit is connected.
system. The relative position of the small squares within each unit indicates the unit with which that unit is connected. For example, the white square on the lower right -hand portion of the refrigerator units represents the strength of the connection between refrigerator and oven. White squares represent positive connections and black squares represent negative connections. The size of the square represents the strength of the connection. Thus, the fact that the square representing the connection from the refrigerator unit to the stove unit is large and white represents the fact that there is a strong positive weight between the two.
It should be noted that each of the units in this example is a visible unit in the sense that each can directly receive inputs from outside the network . There are no hidden units receiving inputs only from other

1.4SCHEMAANTDASEQUENTTHIAOLUGH2T5
units in the network . We consider this example to be a simplified case. It is possible to imagine hidden units which respond to patterns among the input units. In the general case, we, of course, recognize that hidden units would be required to give different coalitions enough coherence. As we have pointed out elsewhere in the book (cf . Chapter 2 and Chapter 8) , multilayer systems containing hidden units are sometimes required to carry out certain computations. In the present instance, however, the existence of hidden units would not change the basic properties of the network which we wish to illustrate . Such higher-level units are not required for the basic schema-like behavior of these networks and, in no caseshould such a unit be confused with a schema.
It should also be noted that we have chosen a rather high level of abstraction for this example. We have taken such features as has television as a microjeature. In a more realistic example, we would expect televisionto itself be a particular pattern over a set of units that are used to represent many different varieties of television . There might be many variations on the television pattern corresponding to variations among televisions. Moreover , since televisions in bedrooms may be systematically different (perhaps smaller) than televisions in living rooms, we would expect that these correlations would be picked up and there would be a context dependency between the particular version of television and the remaining objects in the room . In such a case the units that participate in the representation of television would play the role of a slot in a schema, and the particular pattern of activation on these units would represent the characteristics of the slot filler .
Figure 6 shows several examples of the processing of this network . These runs started by "clamping" one of the descriptors on (that is, by setting the value to 1 and not letting it change) and then letting the system find a goodness-of-fit maximum . In the first example, the descriptor oven was clamped on. In such a case, we expect that the system will bring those units most tightly bound to the oven unit on and turn off those units negatively correlated to oven or other units that it turns on. On the assumption that oven is a central feature of the kitchen schema, the pattern the system eventually turns on is just that which might be said to correspond to the default kitchen schema. The strengths of each of the 40 units is shown along with the "goodness-of-fit " of the state after every 20 updates. The system begins with oven and ceiling on and then adds coffee-cup (weakly) , then sink and refrigerator, concludes that the room is small, adds toaster and coffeepotand finally ends up at a maximum with ceiling, walls, window, small, telephone, clock, coffee-cup, drapes, stove, sink, refrigerator, toaster, cupboard, coffeepo,t and oven. In other words, it finds the default or prototype kitchen . Similarly , runs of the system starting with desk, bathtub, sofa, or bed clamped lead to goodness maxima corresponding to the prototype or default office ,

26 PSYCHOLOPGRIOCCAELSSES

bathroom , living room , or bedroom , respectively . It is , as previously

noted , these maxima that we believe correspond roughly to instantia -

tions of schemata for kitchens , offices , bathrooms , living rooms , and

bedrooms . The system receives input in the form of having some of

the descriptors clamped from the outside . It then finds the best

interpretation of the input through this process of hill climbing . As it

climbs , the system " fills in " the relevant descriptors of the scene in

Question .

In the case of the network we created for this example , there are

essentially five maxima - one corresponding to each of the different

room types . There are 240 possible binary states in which the system

could potentially settle , but , in fact , when it is started by clamping

exactly one descriptor , it will only settle into one of five states . This

roughly corresponds to the view that this data base contains five sche-

mata defined over the set of 40 descriptors . There are , as we shall see,

numerous subschemata which involve subpatterns within the whole

pattern .

00000000000000000000

. ..................

. ....... . ........

. . . . . .

... ....

... ......... ....

. ....... . . . . . . . . . .

.. .... ... ...... ..

. ... ... .. .......

. . 000000000000000000 . . 0000000000000000 . 000000000000000000
. 0000000000000000000 0000000000000000000 . . . . . . . . . 000000000

. . . . 0 0 00000000000000

. ........ .........

.

. ..

....

,...

. c cOD 000000000000000

. ..................

. . . . . . .

. ........

. . . . . .

. .

. . . . . ..

. .

.. . ... ....

ooooooDDDDDDDD

.. .... ............

. . . . . .

.........

.. . . ,...

..,.. ..

. .

... .

,.... ........ .......... . . . . . . . ..

oven computer coat - hanger scale
toilet
bathtub television dresser
coff ee- pot cupboard toaster refrigerator sin k stove drapes fire - place ash - tray coffee - cup
easy - chair sofa
floor - lamp picture clock desk - chair
books
carpet bookshelf typewriter oed

: . . ~~ccoo00~0~0C?C?C? ~~~khone

.......... ......... . . . . ODD D D D D 000000000
....................

.. ... .. .........

. . . .

... .......

. . c c c c 0000000000000

. . .

.

. .

. .. ...

0000000000000000000

DDDDDDDDDDDD

0 0000000

very - small small medium
large very - large window
door
walls
ce i Ii n g

FIGURE 6 . Five runs of the network from five different starting places . In each case, the unit ceiling and one other is clamped on . The clamping of ceiling represents informa tion indicating that room is the domain of discussion . The other clamped units are oven, desk , bathtub , sQ(a , and bed in the five runs . In each case, the system settles on a proto type for the type of room most closely related to the clamped units .

28 PSYCHOLOGICPARLOCESSES
If it was difficult to visualize the landscapefor the caseof the Necker Cube model described above with 216states, it is even more difficult with the 240states of this example. It is, however, possible to get some idea of the landscapein the region of the maxima by plotting the goodness function over a small subset of the goodness landscape. It should be recalled that the states of a system with 40 units can be considered to be a vector in 40-dimensional space. If , as in the present case, the units have a minimum and maximum value, then each point in the 40dimensional hypercube is a possible state of the system. The states of the system in which all units are at their minimum or maximum values (the binary states of the system) correspond to the comers of the hypercube. Now , each maximum of our network falls at one comer of this 40-dimensional cube. The intersection of a plane and the hypercube will pick out a two-dimensional subset of all of the possible states of the system. Finally , since three points determine a plane, we chose subsets of three of the maxima and plotted the goodness-of-fit landscape for those states falling on the plane passing through those three points. Figure 7 shows the landscape for the plane passing through the maxima for bedroom, office, and kitchen. Note that there are three peaks on the graph, one corresponding to each of the maxima on the plane. Note also that there are "ridges" connecting the two maxima. These correspond to simple mixtures of pairs of concepts. The fact that the ridge connecting bedroom and office is higher than those connecting kitchen to either of the others indicates that kitchen is more

office
J' ,

, , .

kitchen goodness

.

~

I -' PO" ' : ,

,.

,

~

, ~. .

-

,

.' ,

*"1

". . . "' 1. 6. , "

., ., ~ \ . " . ~ . ,

:" . "

.

"

" '. .

"

,

~ " " ,' . ~

.-:. ' ' : " " "

~ '. . . ' . . . "

"~."'' '.~".:.:.'~!...-~"' .".<. 1.~...~...4.'.'

"" ~. ..~ -

' - . ',.

,

.,---: ,,

. "

,

.:~'~'

.

"

' ' . , ' "

"

.

.

......

.

.

,.' , '. . ',

,

"

.

" .'

,

,

,, ..

"

. ,. '

, , " ,

""

"

" "

'

,.. "

.

"

" ,.

'

"" "

"

'

:.

. . . " , " . ' . ."" " ' . ,,

" , " .- , " . " " " ' ,

,

.

'.

." " - '.

',. .

" " " " ~" " " ' "

"
,,
"
,

"

"

.

~ .

,

,

.

.

' . . " 1 . . . . . . ,. , . "

.

, ".

" " " ' . " J " " " ' . " ' ~" ~ ." "" ' "

" . " "" ' . " " " ' " " " , , "
, . .". ,"' :." ":":'.":""'"".';".0".-:''."......'.J~:""1''.~."~.(?""";,"-~"~'.:.;h.~.~."-;.~-;O.'::".ii""":'..":;:~.":'.":"."

" " ."'~" ~, .~.....~',.. . . " . . . ' " " '~ ' . ' r . . . .

.

'.''.I.~.,'~.' , ,."""'.~'. .,r._,. ":;:'.:-.....A,", . . "

, . " " ' : ,." ~' . ,

~" " ~."""

."~.~1~,:1~"~.i,i~~~:~'~.r:'t,..o:..";~':~.:...-~.:.

,..t,~ ' ~' ,' ." ,
.:;.,"""-:";-;" "r.'

",.' ,,""".":".;~: :"",:':.-"1"""~."!:''~;.".:".''~)~~-'i"~'

~L~i1
"

:-\..:.~A,.,-:.r...,..

0\;, L'.... " 0:' . : . 1' . ' "' ". \ :'' ~::~:!J~i1'i"\,,~I ;j.' ~. . ' .. ,

'

-.,

~

.

.

.

,

,

.

'

.

'

.

.

.

,

'

.

.

"

.

.

,

.

,

.

.

.

,

bedroom

FIGURE 7. The value of the goodness function for the states on the plane passing through the three goodness maxima corresponding to the prototypes for kitchen, bedroom, and Q/flce.

14. SCHEMAATNADSEQUENTHIAOLUGH2T9
distinctive from the other two than they are from each other . Figure 8 shows the plane containing office, bedroom, and bathroom. In this case we see that the goodness function sinks much lower between the office-bedroom axis and bathroom. This occurs because bathroom is much more different from the other two than is kitchen. In any of these cases, it should be recognized that given the starting configuration of the system it will simply find one of these maxima and thereby find one of these interpretations of the input . By contrast, Figure 9 shows the goodness-of-fit landscape on the plane passing through bedroom, office, and living-room. In order to get a clearer perspective on the surface, the angle of viewing was changed so we are looking at the figure from between bedroom and office. Clearly, the whole graph is greatly elevated. All points on the plane are relatively high. It is a sort of goodness plateau. These three points are essentially three peaks on a much larger mountain containing all three maxima. Finally , Figure 10 shows the goodness landscape on the plane containing the three most distinct prototypes- bedroom, kitchen, and bathroom. The goodness function dips well below zero in this plane. Mixtures of kitchens, living-rooms, and bathroomsare poor rooms indeed.

,I' office

..' .
. .
..

. . .. .

.

. ..

.

.. : . .

:=::.: .0..:.

.

.

.

.

. ', . .

. ..

. . ~ ~ .. .

...'."'. .~. . .. . . , '

.. . . . 0 . .

'

.

..

. .

. \ .~ . . .

.. .

.

.

.

.

.

. 0 .. . . . . . . A : # o. . "

.

. .

..
. .
..

. .~."!t1O .~...... .0.." . . . . ..' ~ .
. . . . .. . . . . . . ..." , . . z. )M ~ . . . . .' . . . ~

. ..,.' . . . . . .
. -' ". . . ' ~ . -.-z.. -. : .. . . ": . . .
.,-.. . ' " . .

. .
,..
,.~ . . { . ..

.

. ..

. ~ . . ~ . ., ' . .

...'.I.~l " 'i.\J.',:...,:.. .. . '.. .,'.~" .,..

. . ~.., .,."--~, .w, .., . .

. . . , . ,. ... . '

~ . . . . ~ . . ..

. . . . , . . .. . , u '

"

- . ,. . . '. . .\ . ' .

...,......\,.."..~.~'..:..',.J~:4.~".~; '~.~.~' :f.~~~- t~..........~.t.I.,~.,'~.{..\...:.....

~ 1~,.'#-:".I"~~.,:~.-'t~..
.,..~..: :.!~ . -. .. . .. .
.. . . . I)

... ...........'.,:........',..'...'.:..;.t.,..,..~".:.-.~~.<~,_..~-...;..."''~~'(~.cA~" .:.~...". . .

~..:.,.-.:.' '~.\~.;; . . . . , , ' . . . . .

~

. . .. . ' .~ . I " . .

" . .

. ,' .

.' ... .

:.\ .. ....:.:. .......,:."..,.,~I ".'."&r:'. .~.,.:.:.~..:.: .=".~.!.~.

.. ....;.":!~;~'~::".:~W~ :~.o:l.Ol ~",'~;!~m . ,i'!..,?'. ...

.: . . .

. . . . . . . . . ,..##,, ~ -. " " . . ._ w ~ . . .

..~..

.,\...:

.
"

.. .. ..

.

..

. ,

"' .

...

.
.

'... .-.

....,,.,.1\"..'~~ ...".,,,~".~"/..~'~~:~i..:!:";o"~.'..'

' "

~

....!.~...".. .. .'' .

...

.

.

,

,

..

.

.

.

.

'

r _r

.

.

: . . " . 0. . .

.

. " . , . .. .. . : -: -.\ " : . . " . . . " , . .. . ' .

. .. .

, . ,'

..

.

'

.T '

~

"

.

'. "

.

.: . . ' . ' . . . : . . .. . : . . .. . .... . ' . . . ' , ," ' . . ' . . . 0 . ' .

,

. . ~ .. ,

. ..

. .

.

, . . ..

,

..

.

. ."

..

'

...

'

.

.

..

.

.

..

. .' .

.

. ' ..

.

.

.

.

.

.

',

.

..

.

.

". . . 1 .

. .

.

.

.

. . . . . . .'

.

.

.

. . , . .. . .

"

,

.

'

. . . .. . . . ... . ' , :

..

.

.. . . . . .

k - - bedroom

FIGURE 8. The value of the goodness function for the states on the plane passing through the three goodness maxima corresponding to the prototypes for bathroom, bedroom, and office.

30 PSYCHOLOPGRICOACLESSES

living room

k - office

;

;.
. r.

'.. 1. .

J~
'I .'

.'" ,.::!, : .~ ~ . .: . , :\'

< , ' . ... .

.

.. '

.,~...."'~"'~I~~~l.!~:t"'~..1.l!1fii",'""",~,'"'. "." " '\'V~"" ' .

,

"

.~.

~.

.1 ,

' . " v,

b droom-.. 'i:.':o':. " ..:.~,~~,.:..~,,~~~:.~,.-;..f.~..'.i;"a~."o:.., . ..:'.I,.,..~.J j'..',-:;, e

': "'""."'r.~"~'..:",~" -'J")'!~ ' n'"\:'~'-~'~.llJ.i:~l:~""'""

"."','"..'::-;,'!I

' : .. . ' . . "" i....' :) ' :."I-' ,! , . U"" ."' I, i ; '---:" ~. -.J,"

" " : "" . "

.

. , . . . ~

" '...;, '.

~' . , 2.~ :t. . ' .' .".;I""' ~"""~ "-,,,~:,,,,-~ . "'."'~~-~k ~

:" ,

' A""I

. . ". , ,' , ~ ._ ~,

. ~ . " " " ' " w. . w;. : w"" . " , ". . " ' " ". . .. .. ,.~, . t . .~~". . " ' "

, .~.' , ~

. . 1, -

~ .: ..".',,"" '.".,",""""'~-'~'~' Y ; .
'~, ", . .-

.

. "" " "

..' , - .

.

w

.. .'" ;""" . ' :";"""I.'" :"I"" ."'"P".~~" " .'..,w~ .

~ ~' ~

t.

~ " .. , . "

.

'

,- '-" " " ' . ' .' ..' ,.",...".. '". ' '" ~

' .". : '". ' :' . ' , . , :" : : ", -"" "" ,""" " "' . .

.

"

I ' . . ' . . . ," . . ~

"

. ~iJ,("

"

"

"

.

, . . .A # ~

.~ .

.

". '."'.""';'"....'":',-.~:.'---:,'I.." .'. ;~J'~:\O

goodness

FIGURE 9. The value of the goodness function for the states on the plane passing through the three goodness maxima corresponding to the prototypes for living-room, bedroom, and office.
It should be mentioned that there are essentially two assumptions that can be made about the input . Under one assumption, inputs are clamped to either their minimum or maximum value and aren't allowed to move. That was the way inputs were treated in the present examples. Other times, it is convenient to imagine that inputs are merely biases feeding input into certain of the units . This is the way inputs were treated in the Necker cube example. These two ways of viewing inputs can be combined by assuming that the case of clamping corresponds to very, very strong biasing. So strong that internal constraints can never overcome the external evidence. The case of clamping is simpler , however. In this case there is no distortion of the goodness-of -fit landscape~ certain states are simply not available. The system is forced to move through a different part of the state space. In addition to its effects on the region of the state space that is accessible, the input (along with the context) determines where the system begins its processing and therefore , often , which of the maxima it will find . Figure 11 illustrates this point . The figure shows the goodnessfunction on the set of states on the plane passing through the start state, the bedroommaximum , and the kitchen maximum for two different inputs. In Figure llA we have clamped the bed unit to be on. In Figure lIB we have clamped the oven unit on. It should be noted that to move from the start state to the kitchen peak in the first case involves climb ing through a dip in goodness-of-fit . Since the system strictly goes

1.4SCHEMAANTDASEQUENTTHIAOLUGH3T1

goodness

~
' ..

:~':: ,

"

"

,

.,

.

'. "

' " "

" .'

,. '

'

,

, ..'.'

.'

'

,

"

'

'.

'.

'

.

" ,

, ., . '

"

. ,.

.

,

. .'

. , '. , '

,

" ." ' " .

"

.' .

. ."

"

kitchAn
' ~ - bedroom
' '
' .
I
. .
~ ' ' ' .

bathroom

. . ~ ~. .. , ,' ...,' .

':i : '." "

'

.

.

.

'

., '

.'"

, ...

. , .. '

~,

,

-, '

:: ; . . .

:.

.

.. .'

.

,. , ' .

.

' . ."

,

.

.'

.

"

,

. ,' . ' ,

'

'

. .,

., '

."

,

' .'

.

..

.

',

. .

.'

,," '

.

'

"

. , , ' . . , ' . ' ~, " , ' " . ' " .

.. "

"

' " ., " . ,

.

. ..

.

'.

,, "

"

,.

.

.

.

..

.'

"

"

"

, ,

"

,

' "

, ,"

"

.

..

"

"

.

..

, . ' .. . . " ,' , .

'

.

. .'

"

,

" . , . : : ', ', ' . .

"

,

':,::.::': : ',"

FIGURE 10. The value of the goodness function for the states on the plane passing through the three goodness maxima corresponding to the prototypes for kitchen, bedroom, and bathroom.

"uphill " it will be unable to reach the kitchen maximum and will move instead monotonically uphill toward the bedroom peak. Similarly , in Figure 11B with oven clamped there is a dip separating the start state from the bedroommaximum but a monotonically increasing slope flow ing into the kitchen peak. Figure llC shows, for comparison, the landscape from the start state when no units are clamped on . In this case, there is no dip separating the start state from either peaks, so the system can move to either maximum .
To summarize, we have argued that the maxima in the goodness-offit landscapesof our networks correspond to configurations of instantiated schemata. We have shown how these maxima are determined by coalitions among units and how the inputs determine which of the maxima the system will find . It should be clear that the multivariate distri butions proposed by Rumelhart and Ortony are readily captured in the PDP framework . The values of each variable determine what values
will be filled in for the other variables. We have yet to show that the kind of PDP system we have been describing really has all of the important properties of schemata. In the following section, we use the present example to illustrate these properties and discuss some of the advantages of our formulation over previous formulations of the schema idea.

kit c hen , ..........~"'~
goodness

1.4SCHEMAANTDASEQUENTTHIAOLUGH3T3

,
", "

~'

~ '"~ " .

'

~ I~

~, ~.~ - ~ , , . "

,

.~ ~ I, . ,

tI,'.~'",;'~.., ~ -~ l '\ .'.

;!r:o.~,.~' :.'"J'""'... -' .~ ' ~~':iI~~"'~~~ :

. .' . , . . ... . . . , .~

,',

""

"

""

.

.

,

"' S" ~1'~' "Yf'..~-/.'.:.".~"..~'_~T,~~~, : ,
. " " " " " ' . " " "" ~ ~ .

~ ..." , , , , ""' I~';e; " "

""

'.

'

"

.

.

. n .."

"

'. ,' .

I

'~ .' J)'":It~'. : : : "" " :/ :>II ~

' -" " "" ~" " ' , ...... . ..., ... r;

-"" " "

' - " "' ,

" , ."

" " " ' 0:

-

-

.

, r."

"'... ~"" , " " " ,
" "" """ , " " ,"
',' ,

bedroom + "oven"

'~

",

.\ : ~

"

..

, " " ',

"

"

" " .~

~'., ~ .

' . . ,. r "

'~'~

c

. '.,,' \-Y. ~ ~ - start + " ove nl '

FIGURE 11. The goodnessfunction over the set of stateson the planepassingthrough the startstate, the bedroommaximum, andthe kitchenmaximumfor two different inputs. In A we haveclampedthe bedunit to be on. In B we haveclampedthe ovenunit on. C showsthe landscapefrom the startstatewhenno unitsareclampedon.

Properties of Schemata and Maxima in Constraint Satisfaction Networks

Rumelhart and Ortony ( 1977~ Rumelhart , 1980) have outlined a set of properties which characterize schemata. In this section we consider each of these properties and show how they map onto features of the POP networks we are now outlining .
Schemata have variables. Essentially, the variables of a schema correspond to those parts of the pattern that are not completely determined by the remainder of the structure of the pattern itself . It is these parts that vary from one situation to another in which , nevertheless, the bulk of the units corresponding to the schema is active. On this account, the binding of a variable amounts to filling in a variable subpattern. Default values represent variable subpatterns that tend to get filled -in in the absenceof any specific input . Since patterns tend to complete themselves, default values tend to be automatically filled in by the process of settling into an interpretation . In some cases, there are sets of units that are mutually inhibitory so that only one can be active at a time but any of which could be combined with most other units . Such a set of units can be considered to constitute a slot which is

~

-

14. SCHEMAATNADSEQUENTTIHALOUGHT35
floor -lamp, and a fireplace. Similarly , the setting of the size variable modifies the default values for the other descriptors. In this case, if we set the size variable to large we get a bedroom with afireplace.
Schemata can embed. In structural interpretations of schemata, it is useful to think of a schema as a kind of tree structure in which subschemata correspond to subtrees that can fill variable slots. Under our interpretation , subschemata correspond to small configurations of units which cohere and which may be a part of many different stable patterns (and therefore constitute a schema on their own right ) . Each stable subset of cohering units can be considered a schema. Large schemata will often consist of patterns of coherence among these coherent subsets. There are several instances of this in our example. For example, the easy-chair and floor -lamp constitute a subschema, the desk and desk-chair, the window and drapes, and other similar combinations constitute small schemata that can be either present or absent in several different configurations . Consider, for example, the case of window and drapes. These two elements almost always appear together and either both appear or neither appear. We will refer to this pattern as the window schema. Figure 13 shows the effect of adding drapes and/ or window to the office schema. The default value for this schema involves no windows. The highest peak, at the origin of the graph, corresponds to the office maximum . One axis corresponds to the

~

office witho ut - - - . , .
window&drapes
goodness

tr~~i"'"

~i;-:'~,.\'i~~ ~ :::~ ~!.A., ~ "" "' "' - " '..- .. ~'.., . ~~.""f;:\~~ ..",:;.:;) 1.o

~ ' , . ' . . .-. ,

" ,; r .

~,.".~.II"'\'~"'L. .

\" "

'.' "-

."

II ' ~ " " 't ,

,

r , " "'

,,"

~ .':'II.! " .,:..." ...,.., ~ ' :f' .".:\, ~" ,.;0~' ~, "'":.:N.,.:~.,'... ' .

, . . , .. ,

"'

. ~.

r

" . II , . . " ~ .. . ' .

..

.--. ':;."; "" '"lu" =~"":-\':.'\" ."" -,:L-.,'~! ,-fl: .. ~. ~"' "."'" '!-'':k" !-I~ .( r . I

" '::I,/;.0";:).~:"~~~/!:.": . " .:. .~.'~ "- ' \ I. ~ ' ,." "" ~ ;,,,_~ -s"' .-'

;,"'i."i:l.f::"":~;"~:i"~~:('~~~\~'.~ ." \ . ' ~ .. \: i " " . .. '. . . . . "

",

.

r. l' ~. . " " .; ' . -',~" " ". " " ' . ' ~ : . . . . ~ . : ."

.""':,":'~"~"~~'f~f.~:~';:~:!'~~~~i:~:,~~,;~~.~;;:~:~~g~t:" ,''.":'.".. ~"~ t.r-.;"':..y""I .", ,..",.:..,.".,...".,::"...

drapes

.,.." ~~.,:," ,., . , ." ." ~.?o.~.,. ." . :'. ' '' ., ", .

" " " ' ." " ' . . ." " " ,. " . . . ".

" ,". " "

'"

, . ," ' "

. " " :;'.1(') . ' : ' :1" .: : ' . ' . ' .: .~~ l

',',.. ."" .. ' '. ''." .

' ., ' . ' " , ' ' . " ,

,.

' . . . ' , . < ." .. ~

.:::";~\ff:)l"'.':':~:'\.'.,..~,!,.~. .:.",",":.'..~:.,":.'.,<:',...~:~....,

"

, ... ,

,

:......:.-- ..~ :

office with
. / window&

..
. ..~.
. ...
" , ' ". "

'

."',-:"" .." , ..t'-,<',:~.,\

.

,"

."

..

~ ,\.'..;,:'"

"

drap eS

~

~

window

FIGURE 13. The goodness landscape for office as a function of the activation value of the drapesunit and the windowunit . The function shows that it is maximum when either both are 0 or both are 1. This pattern of interaction is consistent with the view that the combination window-drapesform a subschema.

36 PSYCHOLOGPIRCOACELSSES
amount of drapesadded to the schema (i.e., to the activation value for the drapesunit ) . The second axis corresponds to the amount of window added. The third axis, of course, corresponds to the goodness-of-fit for each of the states. It should be noted that the low points on the graph correspond to those casesin which one of the two units of the window subschema is on and the other is off . The high points on the graph, corresponding to goodness maxima, occur when either neither (at the origin ) or both of the units are on. The case where neither is on corresponds to a slightly higher peak than when both are on. Thus, the default office probably doesn' t have a window , but if the input indicates that either one of the units (window or drapes) is on, turning the other one on is best. To conclude, large schemata such as the office schema can be conceptualized as consisting, in part, of a configuration of subschematawhich mayor may not be present as wholes. Having parts of these subschemata is worse than having either the entire subschema or none of it .
Schemata represent knowledge at all levels. They should represent encyclopedic knowledge rather than definitional information . This amounts to the claim that all coherent subpatterns should be considered schemata as well as the whole stable pattern. It also suggests that knowledge of all sorts should be represented in the interconnections among the constituent units .
Schemata are active processes. This is obviously true of the the POP system we are describing. They are a kind of organic element which grows and fulfills itself within its environment .
Schemataare recognitiondeviceswhoseprocessingis aimed at the evaluation of their goodnes-sof-fit to the data beingprocesse.d This feature is obviously also a part of the idea outlined here. The goodnes-sof-fit is roughly determined by the height of the peak in goodnessspace. The processingof the systemis aimedtowardclimbing uphill alongthe goodnes-sof-fit gradien.t The stablepoints correspond to local maxima in this space. The height of the peakcorrespondsto the goodnes-sof-fit .
Some additional features of our interpretation . There are three major difficulties with the conventional representation of schemata that are naturally overcome in the POP approach. In the conventional approaches, decisions must be made about which aspects of a given

14. SCHEMATNADSEQUENTHIAOLUGH3T7
schema are constant and which are variable. The POP solution is
essentially that all aspects are variable~ some aspects are simply more tightly constrained than others. Secondly, in a conventional representation , one has to decide exactly which aspectsof the situation are part of the schema and which are not . In our PDP approach, units may cohere more or less strongly to their mates and in this sense be more or less a part of the schema. Finally , on the conventional view a decision must be made about whether a certain set of relationships should be put together to form a schema at all. Again , in the POP formulation no such decision needs to be made. One can have schemata of varying degrees of existence. The rigidity of the schema is determined by the tightness of bonding among the units that constitute the schema. The tighter the bond, the more strongly the constituent elements activate one another, and the more rigid the structure . The weaker the bonds, the more fluid the structure , and the more easily a system can flow among states. This degree of fluidity depends on the shape of the goodness-of-fit landscape. Tightly rigid schemata have sharp peaks in goodness space~ fluid schemata with many variable parts correspond to rounded hilltops . The goodness landscape, in turn , depends on the knowledge base that lies beneath it . If the knowledge is tightly inter constrained so that one part strongly predicts other parts, then we have a rigid schema. We can't easily get just part of it active. If part of it becomes active, the part will pull in the whole and suppressthe activity of aspectsthat are not part of it . On the other hand, if the knowledge is only loosely interrelated , the schema will be a relatively weak organizer of the information and will be a pressure for structuring the input , but it will flow easily from one pattern to another. Moreover , within a schema itself , some aspects will be tightly bound together while other aspectswill be only more loosely tied to the body of the schema. Input situations that demand an interpretation that breaks up the tightly bound clusters are going to be more difficult for the system to attain than those that require breaking up much more loosely interconnected elements.
Finally , we point out one way in which these ideas about schemata might be elaborated to overcome one apparent deficiency of the network we have thus far been considering. The network uses a fixed set of units to represent each type of object that might be present in a particular instantiation of a schema. This is clearly an oversimplification since it is often necessaryto be able to think about two different instantiations of the same subschema within a larger overall schema- for example, there is often more than one chair in a living room . To capture such situations, it is necessary to imagine that the network may contain several subsets of units , each capableof representing a different possible chair. The subsets would correspond to different roles the

38 PSYCHOLOPGRICOACLESSES
different chairs might play in the overall room schema. This would also allow the representation to capture the assignment of a particular object to a particular role.
PARALLEDL ISTRIBUTE~PDROCESSINMGODELSAND THINKING
In the previous section we offered an interpretation of the schema in terms of the emergent properties of simple POP networks. From there, we believe that we can make contact with much of the cognitive science literature . There are central issues, however, which remain difficult to describe within the PDP framework . We have particularly in mind here, the processof thinking , the contents of consciousness, the role of serial processes, the nature of mental models, the reason for mental simulations , and the important synergistic role of language in thinking and in shaping our thought . These issues are especially important because these are issues that PDP approaches do not , on first blush, seem to have much to say about. In this section we attack some of those problem areas. We don't claim to have solutions to them , rather we can outline a story that represents our current understanding of these processes. The story is overly simplistic but it does give an idea of where we are in our thinking on these critical issues.
It should be noted here that the account of mental processing we have been developing offers an interesting perspective on the relations between parallel and serial processing. The " parallel" in " parallel distributed processing" is intended to indicate that , as a basic architectural design principle , processing is carried out , in so far as possible, in parallel. Parallel algorithms are employed rather than serial ones. At the same time , however, the "distributed " in " parallel distributed processing" brings a serial component to POP systems. Since it is patterns of activations over a set of units that are the relevant representational format and since a set of units can only contain one pattern at a time , there is an enforced seriality in what can be represented. A given set of units can, however, be seen as representing a sequence of events. Since we assume that the system is moving toward a maximum goodness solution every time a new input comes into the system, the system operates in the following way. An input enters the system, the system relaxes to accommodate the new input . The system approachesa relatively stable state which represents the interpretation of the input by the system. The system then occupies this state until the stimulus conditions change. When a new input arrives, the system relaxes to a new state. Looking at the system over a short time frame , it is dominated

1.4SCHEMAANTDASEQUENTTHIAOLUGH3T9
by the relaxation process in which all units work cooperatively to "discover" an interpretation of a new input . Looking over a somewhat longer time frame , we see the system as sequentially occupying a series of relatively stable states- one for each change in input . Roughly , if we imagine that the relaxation process takes on the order of a few tenths of a second and that the time spent in essentially the same stable state is on the order of a half of a second or so, we could see events requiring less than about a half second to be essentially a parallel process, and those requiring several seconds to involve a series of such processesand therefore to have a serial component.
The Contentsof Consciousness
It isn't necessaryfor the arguments that follow , but for the sake of concreteness, we suppose that there is a relatively large subset of the total units in the system whose states of activity determine the contents of consciousness. We imagine that the time average of the activities of these units over time periods on the order of a few hundred mil liseconds correspond to the contents of consciousness. Since we imagine that our systems must be such that they reach equilibrium in about this amount of time , the contents of consciousnessare dominated by the relatively stable states of the system. Thus, since consciousnessis on the time scale of sequencesof stable states, consciousnessconsists of a sequence of interpretations - each represented by a stable state of the system. Typically , consciousness contains a single interpretation (i.e., a single pattern representing its inputs) and consists of a sequence of such interpretations . On occasionsin which the relaxation processis especially slow, consciousnesswill be the time average over a dynamically changing set of patterns and thus would be expected to lead to " fuzzy " or unclear phenomenal impressions.
The Problemof Control
One common critique of the kind of model we have sketched so far is that it can' t really change without external prodding. Suppose that we are in a fixed stimulus environment . In this case, the system will relax into ah interpretation for that environment and stay there. Our conscious experience will be of a fixed interpretation of a fixed stimulus . Until the world changesthere is no change to the system nor to the contents of our consciousness. Obviously this is an incorrect

40 PSYCHOLOGPIRCOALCESSES
conclusion. How can such a system do something? Perhaps the first thing that comes to mind is that the environment never really is fixed . It is always changing and therefore the contents of our consciousness must always be changing to interpret the current state of affairs. A good example of this might be the movies. We sit in the movies and watch. Our system reaches a sequence of interpretations of the events on the screen. But, since the movie is always continuing , we are driven to continue to interpret it . Surely, what is true of a movie is also true of life - to some extent . This may be part of the story, but it would appear to be rather more passive than we might want. We don't just sit passively by and let the world change and then passively monitor it . Rather we act on the world .
A second answer to the problem of a system fixated on a particular interpretation becomes apparent in realizing that our interpretation of an event often dictates an action which , in turn , changes the environ ment . The environmental change can then feed back into the system and lead to another interpretation and another action. Figure 14 illustrates how this feedback loop can continuously drive the system from state to state. A paradigm casefor this is playing a game. We can imagine that we are playing a game with someone~ our input consists of a board configuration , and we settle into a state which includes a specification of a response. It would be quite easy to build a relaxation network that would take as input a description of a current board situation and produce, as part of the state to which it relaxed, a specification of the response. It would simply require that, for each game situation , the system relaxes to a particular state. Certain units of the state represent the action (or class of actions) that should be taken. Upon taking these actions, the opponent makes a play which in turn leads to a new set of constraints to which the system relaxes. In this way, the system can make a sequence of moves. Indeed, as we describe below, we have built such a network that can play tic-tac-toe. Other more complex games, such as checkers or chess require rather more effort , of course, but can, in principle , be dealt with in the same way. Although this is a much more activist view, it is still a "data-driven" view. The system is entirely reactive- given I am in this state, what should I do?
Mental Models
Suppose, for arguments sake, that the system is broken into two pieces- two sets of units . One piece is the one that we have been discussing, in that it receives inputs and relaxes to an appropriate state that includes a specification of an appropriate action which will , in turn ,

14. SCHEMAATNADSEQUENTHIAOLUGH4T1
Interpretation Network

FIGURE

14 . The

inputs

to the

POP

system

should

be

considered

effects

that

the

output

of

the

system

has

had

on

the

environment

put

of the

system

can

drive

it from

state

to state

.

as partially

due

to the

. In this way, the out-

change the inputs to the system. The other piece of the system is simi lar in nature, except it is a ,tmodel ,t of the world on which we are act-
ing. This consists of a relaxation network which takes as input some specification of the actions we intend to carry out and produces an interpretation of ,twhat would happen if we did that ." Part of this specification would be expected to be a specification of what the new stimulus conditions would be like . Thus, one network takes inputs from the world and produces actions~ the other takes actions and predicts how the input would change in response. This second piece of the system could be considered a mental model of the world events.
This second portion , the mental model of the world , would be expected to be operating in any case, in as much as it is generating expectations

42 PSYCHOLOPGRICOACLESSES
about the state of the world and thereby " predicting " the outcomes of actions.
Now , supposethat the world events did not happen. It would be possible to take the output of the mental model and replace the stimulus inputs from the world with inputs from our model of the world . In this case, we could expect that we could " run a mental simulation" and imagine the events that would take place in the world when we performed a particular action. This mental model would allow us to perform actions entirely internally and to judge the consequencesof our actions, interpret them , and draw conclusions based on them . In other words, we can, it would seem, build an internal control system based on the interaction between these two modules of the system. Indeed, as we shall show, we have built a simple two-module model of tic-tac-toe which carries out exactly the processand can thereby "imagine" playing tic -tac-toe. Figure 15 shows the relationships between the interpretation networks, the inputs , the outputs, and the network representing a model of the world and the processof " mental simulations ."

Mental Simulationsand Mental Practice

One

nice

feature

of this model

is that

it ties into

the idea

of mental

simulations

task

involves

and learning

two

parts

through - a system

mental that

practice determines

. Performance

in the

what

to do in any

given action " world

situation

and a system

that predicts

what

will happen

if any given

is carried

out . If we have

a reasonably

good

model

of the

" we could

learn

from

our model

the various

consequences

of

our actions

- just

as if we were

carrying

them

out in the real world

. It

may

very

well

be that

such

a feature

accounts

for the improvement

that

occurs

in mentally

practicing

complex

motor

tasks .

Conversations

: Actual

and

Imagined

Imagine

a situation

in which

would

take

as input

a sentence

sentence

as well

as the specifications

we and

had

a relaxation

network

produce

an interpretation

for a response

to that input

which of that
. It is

possible carry

to imagine

how

out

a conversation

two individuals

each

. Perhaps

, under

with

such

appropriate

a network

could

circumstances

they

could

even

carry

out

don ' t actually

have

another

model

of the other

individual

a logical

argument

. Now

participant

, but

instead

. In that case , we could

, suppose have
imagine

that

we

a mental

carrying

From Environment

14. SCHEMATNADSEQUENTTHIAOLUGH4T3

Input

Inte rpretati on Network
Internal Units

Output

Model of World Internal Units
0t t u pu U nl "t s

Input U .
nits

To
Environment

FIGURE 15. The relationships among the model of the world ., the interpretation network ., the inputs., and the outputs for the purpose of mental simulations .
out a conversation with someone else. We could hold an imaginary argument with someone else and perhaps even be convinced by it ! Indeed, this brings up the last move that we wish to suggest. Suppose that we don't have a model of another person at all. Suppose that instead we simply use our one single model to both produce and react to imagined linguistic inputs. This description is, it would seem, consistent with Vygotsky's ( 1934/ 1962) view of thinking and is consistent with the introspections about a certain kind of thinking and "internal speech." Note , this does not suggest that thinking is simply internal speech. More generally, thinking , as we have argued, involves a sequence of states of consciousness. There are a number of ways of controlling that sequence. One way involves running " mental simulations ." Another way involves recycling linguistic inputs . Note , this gives languagean interesting , almost Whorfian , role however. Suppose that the interpretation that led to the production of the internal speech was much richer than the linguistic forms could possibly suggest. Thus,

44 PSYCHOLOGICPARL OCESSES
the linguistic forms pick out aspects of the entire interpretation to emphasize. Once this emphasis has taken place and the new input has been processed, the next state will be strongly affected by the new input and our new interpretation will be shaped, to some extent , by the words we chose to express our first idea. Thus, our thinking about a topic will be, sometimes strongly, affected by the language tools we have for expressing our ideas.
External Representations and Formal Reasoning
If the human information -processing system carries out its computations by "settling " into a solution rather than applying logical operations , why are humans so intelligent ? How can we do science, mathematics, logic, etc.? How can we do logic if our basic operations are not logical at all ? We suspect the answer comes from our ability to create artifacts- that is, our ability to create physical representations that we can manipulate in simple ways to get answers to very difficult and abstract problems.
The basic idea js that we succeed in solving logical problems not so much through the use of logic, but by making the problems we wish to solve conform to problems we are good at solving. People seem to have three essential abilities which together allow them to come to logical conclusions without being logical. It is these three abilities that have allowed us to accomplish those uniquely human achievements of formal reasoning. These abilities are:
. We are especially good at pattern matching. We seem to be able to quickly "settle" on an interpretation of an input pattern. This is an ability that is central to perceiving, remembering, and comprehending. Our ability to pattern match is probably not something which sets humans apart from other animals, but is probably the essential component to most cognitive behavior.
. We are good at modeling our world . That is, we are good at anticipating the new state of affairs resulting from our actions or from an event we might observe. This ability to build up expectations by " internalizing " our experiences is probably crucial to the survival of all organisms in which learning plays a key role.
. We are good at manipulating our environment . This is another version of man-the-tool -user, and we believe that this is perhaps the crucial skill which allows us to think logically, do mathematics and science, and in general build a culture .

14. SCHEMAATNADSEQUENTTIAHLOUGHT45

Especially

environment

what animals

sets .

important

here

so that

it comes

human

intellectual

is

our

ability

to represent

accomplishments

to

manipulate

the

something

. This

is

apart

from

other

Roughly speaking, the view is this : We are good at " perceiving" answers to problems. Unfortunately , this is not a universal mechanism for solving problems and thinking , but as we become more expert, we become better at reducing problem domains to pattern-matching tasks (of the kind best accomplished by PDP models) . 9 Thus, chess experts can look at a chess board and "see" the correct move. This , we assume, is a problem strictly analogous to the problem of perceiving anything. It is not an easy problem, but it is one that humans are especially good at. It has proven to be extraordinarily difficult to duplicate this ability with a conventional symbol-processing machine. However, not all problems can be solved by immediately "seeing" the answer. Thus, few (if any) of us can look at a three-digit multiplication problem (such as 343 times 822) and see the answer. Solving such problems cannot be done by our pattern-matching apparatus, parallel processing alone will not do the trick ~we need a kind of serial processing mechanism to solve such a problem. Here is where our ability to manipulate our environment becomes critical . We can, quite readily, learn to write down the two numbers in a certain format when given such a problem.
343
822
Moreove,r we canlearnto seethe first stepof sucha multiplication problem. (Namely, we canseethat we shouldentera 6 belowthe 3 and2.)
343 822
6

We can then use our ability

to pattern

match again to see what to do

next . Each cycle of this operation

involves

first creating

a representa

-

tion through

manipulation

of the environment

, then a processing

of

this ( actual physical ) representation

by means of our well - tuned percep -

tual apparatus

leading

to a further

modification

of this representation

.

9 As we have argued before , it is because experts have such a powerful pattern matching capability that expert systems that rely only on pattern matching ( albeit not nearly as powerful as the human system ) are as successful as they are .

46 PSYCHOLOGICPARL OCESSES
By doing this we reduce a very abstract conceptual problem to a series of operations that are very concrete and at which we can become very good. Now this applies not only to solving multiplication problems. It applies as well to solving problems in logic (e.g., syllogisms) , problems in science, engineering, etc. These dual skills of manipulating the environment and processing the environment we have created allow us to reduce very complex problems to a series of very simple ones. This ability allows us to deal with problems that are otherwise impossible. This is real symbol processing and, we are beginning to think , the primary symbol processing that we are able to do. Indeed, on this view, the external environment becomesa key extension to our mind .
There is one more piece to the story. This is the tricky part and, we think , the part that fools us. Not only can we manipulate the physical environment and then process it , we can also learn to internalize the representations we create, " imagine" them , and then processthese imagined representations- just as if they were external . As we said before, we believe that we are good at building models of our environment so that we can anticipate what the world would be like after some action or event takes place. As we gain experience with the world created by our (and others') actions we develop internal models of these external representations. We can thus imagine writing down a multiplication problem and imagine multiplying them together. If the problem is simple enough, we can actually solve the problem in our imagination and similarly for syllogisms. Consider, for example, a simple syllogism: All A are B and no Care B. We could solve this by drawing a circle for A , a larger circle including all of the A 's around the first circle to represent the B' s, and a third disjoint circle standing for the C' s. We could then "see" that no A 's are C. Alternatively , we need not actually draw the circles, we can merely imagine them. We believe that this ability to do the problem in our imagination is derivative from our ability to do it physically, just as our ability to do mental multiplication is derivative from our ability to do multiplication with pencil and paper. The argument that external representations playa crucial role in thought (or, say, in solving syllogisms) is sometimes challenged on the ground that we don't really have to draw Venn diagrams (or whatever) to solve them since we can solve them in our head. We argue that the major way we can do that is to imagine doing it externally . Since this imagination is, we argue, dependent on our experience with such representations externally , the argument that we can solve them mentally loses its force against the view that external symbols are important for thought processes. Indeed, we think that the idea that we reason with mental models is a powerful one precisely because it is about this process of imagining an external representation and operating on that .

14. SCHEMAATNADSEQUENTHIAOLUGH4T7
It is interesting that it is apparently difficult to invent new external representations for problems we might wish to solve. The invention of a new representation would seem to involve some basic insight into the nature of the problem to be solved. It may be that the process of inventing such representations is the highest human intellectual ability . Perhaps simply creating an external representation sufficient to support problem solving of a particular kind is evidence of a kind of abstract thinking outside of the simple-minded view sketched here. That may be, but it seems to us that such representational systems are not very easy to develop. Usually they are provided by our culture . Usually they have evolved out of other simpler such systems and over long periods of time . Newer ones, when they are developed, usually involve taking an older system and modifying it to suit new needs. One of the cri tical aspects of our school system would seem to be teaching such representational schemes. The insights into the nature of the problem become embedded in the representations we learn to use to solve the problems.
Language plays an especially tricky and interesting role in all of this . Perhaps the internal / external issue is not too important with language. The notion we have here is one of " self-instruction ." This follows
Vygotsky's (1934/ 1962) view, we believe. We can be instructed to behave in a particular way. Responding to instructions in this way can be viewed simply as responding to some environmental event. We can also remember such an instruction and " tell ourselves" what to do. We
have, in this way, internalized the instruction . We believe that the process of following instructions is essentially the same whether we have told ourselves or have been told what to do. Thus, even here, we have a kind of internalization of an external representational format (i.e., language) . We don't want to make too much of this point since we recognize that the distinction between external and internal when we ourselves produce the external representation is subtle at best, but we don't really think it differs too much from the case in which we write something down and therefore create a real, physical, viewable representation. Saying something out loud creates a hearable representation . There are interesting casesin which people talk to themselves (for example, solving difficult problems in noisy environments leads people to literally talk to themselves and instruct themselves on the problems they are solving) .
Before leaving this topic, one more important aspect of external representations (as opposed to internal representations) should be noted. External representations allow us to employ our considerable perceptual/ motor abilities in solving abstract problems. This allows us to break problems into a sequence of relatively simple problems. Importantly , once an external representation is created, it can be

48 PSYCHOLOGPIRCOALCESSES
reinterpreted without regard to its initial interpretation . This freedom allows us to discover solutions to problems without " seeing" our way to the end. We can inspect intermediate steps and find alternative solutions which might be better in some ways. In this way, we can discover new features of our representations and slowly extend them and make them more powerful .
Goal Direction in Thinking
Our discussion thus far has left one central issue undiscussed, namely, the role of goals in thought and problem solving . Clearly it is not the case that the same perceptual stimulus always drives the system to react in a consistent way. Rather, our goals or intentions interact with the stimuli (internal and external) that provide the inputs to the thinking process. Further , goals organize whole sequencesof thoughts into a coherent problem-solving activity , and the notion that there is a hierarchy of goals is certainly important for understanding these coherent sequences.
While we have not stressed the importance of goals, it is not difficult to see how they could be incorporated into our framework . Goals can be explicitly represented as patterns of activation and can thus provide one source of input to the thinking process. Nor is it difficult to imagine how a POP network could learn to establish specific subgoal patterns in responseto particular superordinate goals and inputs .
Summary
These ideas are highly speculative and detached from any particular POP model. They are useful , we believe, because they suggest how POP models can be made to come into contact with the class of phenomena for which they are, on the face of it , least well suited- that is, essentially sequential and conscious phenomena. Even in these cases, however, they lead us to view phenomena in new ways.
An Example
In these last few sections, we have been talking at a very general level . We often find it useful to be concrete about our ideas.

14. SCHEMAATNADSEQUENTTIAHLOUGHT49
Therefore , to illustrate the notion of thought as mental simulation more concretely, we created two relaxation networks that can be connected together to mentally simulate playing a game of tic-tac-toe. The two networks are very similar . The first is a system which , given a pattern representing the board of a tic-tac-toe game, will relax to a solution state that fills in an appropriate response. The second module is nearly identical to the first ~ it takes as input a board position and a move and settles to a prediction of the opponent's responding move. In short , it is a "mental model " of the opponent. When the output of the first is fed, as input , to the second and the output to the second is fed, as input , to the first , the two networks can simulate a game of tic-tac-toe.
Figure 16 illustrates the basic structure of the tic-tac-toe playing network . The network consists of a total of 67 units . There are nine units representing the nine possible responses. These are indicated by the nine dots at the top of the figure . There is one unit for each of the nine possible moves in tic-tac-toe. Since only one response is to be
Response Units

Line Detector
Units

Board Units

Player Pieces

Opponent Pieces

FIGURE16. Thebasisctructuroefthetic-tac-toeplayinngetwor.k

50 PSYCHOLOPGRIOCCAELSSES
made at a time , these units are mutually inhibitory . This is indicated by the heavy black line feeding back from the top plane in the figure to itself . There are a total of 18 units representing the board configuration . These are divided into two groups of nine : one group for the positions of the friendly or player pieces on the board and one group representing the positions of the opponent's pieces. Since if any square is occupied, it is not a possible move, each board unit strongly inhibits its corresponding output unit . This strong inhibition is indicated by the heavy black lines connecting the board units to the response units . In addition to these 9 output units and 18 input units , there is a total of 40 hidden units which detect patterns in the board units and activate the various response alternatives. These 40 units can be divided into eight classescorresponding to the eight possible ways of getting three x 's or o 's in a row. In the figure , one of each such category of units is illus trated. The receptive field of each unit is indicated by the line inside the circle representing that unit . Thus, there is one unit for each of the three horizontal lines, one for each of the three vertical lines, and one for each of the two possible diagonal lines. For each of the eight classesof hidden units , there are five different pattern types that dif ferent units are responsive to. For example, some units are responsive to empty regions. That is, they respond just in case none of the board units from which it receives inputs is turned on. This is implemented by making them be inhibited by any activity in their receptive field and by giving them a negative threshold . We call this an emptyline detector. All things being equal, it is better to move into an empty row, column , or diagonal~ therefore these units weakly activate their respective output units . At the start of the game these are the only units which are active and therefore the sole criterion for the first move is the number
of possible strings of three the square is a member of . Since the center square intersects the largest number , it will usually be chosen by the system for its first move. On later moves, there are other units feeding into the decision, but these units also contribute . Another unit type will respond whenever two or more units of the same kind occur in its regions. This is the kind of unit illustrated in the figure . It receives strong inhibitory input from one set of board units (in this case the opponent's pieces) and excitatory inputs from the other set. It has a rather high positive threshold so that it will not come on until at least two units are on in its row. We call this a friendly doublet detecto.r Whenever this unit comes on it means that the system can make a win ning move by playing in that row. Therefore , it is strongly positively connected to its respective output units . If such a move is possible, the system will make it . There are similar units which respond to two or more units from the representation of the opponent' s pieces are active in its receptive field . We call this an opponentdoubletdetector. If such a

1.4SCHEMAANTDASEQUENTTHIAOLUGH5T1
unit comes on, it means that the opponent could win by a move in this region, so it excites its response units very strongly as well . Unless there is a winning move somewhere else, the blocking response will become the most active. Finally , there are units which respond to one or more friendly pieces or one or more opponent pieces in an otherwise open line . We call these friendly singleton and opponentsingletondetectors. It is generally good to extend your own singleton or block an opponent's singleton if there is nothing more pressing, so these units also activate their respective output units , only rather more weakly than the units detecting doublets. Thus, the net input arriving at any given unit is the weighted sum of all of these urgencies detected by the hidden units . Becauseof the direct inhibition from the board units , only those response units corresponding to open squares receive positive input . The mutual inhibition insures that the strongest unit will usually win . In order that this system truly climb in overall goodness-of-fit , all weights are symmetric and the update is done asynchronously at random. This means that when there isn't much difference between the possible response alternatives, a weaker one will sometimes get the upper hand and win the competition . This never happens, however, when a unit is receiving very strong input , as with the case of an open double for a win or to be blocked.
The simplest case is when the system simply is given a board position , settles on a move, is given the next board position incorporating the opponent's response, settles on a move for that position , etc., until a game is finished . This involves only one network and presumably would be the basic modality for the system to run in . Figure 17 shows a sample run of such a situation . The activation levels of each of the 67 units is shown in each column . Successive activation states are shown from left to right . At the start, it should be noted that there is a friendly piece in the center square and two enemy pieces, one in each corner of the upper row. It is the system's move. The system starts with the units corresponding to the board position clamped on and all other units off . The figure shows the strengths for each of the units after every 50 asynchronous updates. By the second time slice, the system is beginning to extract the relevant features of the board position . The five groups of eight units shown in each column following the response units and board position display the line-detector units . Each group of eight is laid out with three units across the top corresponding to the top, middle , and bottom lines from left to right . The second row of the eight corresponds to the left and right diagonals, and the bottom row of each eight corresponds to the left , middle , and right columns. Thus, we see that the system has, by the second time slice, begun to discover that the bottom row is empty, that it has a singleton in the middle row, that the opponent has a singleton in the left column , and

1.4SCHEMAANTDASEQUENTTHIAOLUGH5T3
own responding to the environmental process of generating a sequence of stimuli . This is a very common form of control of sequential behavior and involves no special mechanism. The case of "mental simulations " involves a bit more machinery. We need a "model of the world " to predict the environment 's response to any action that might be taken. In the case of tic-tac-toe, this involves a network which models the opponent. In general, the model of the opponent may be arbitrarily different from that used by the system to make its own response. In our case, however, it is sufficient to build an identical network for the opponent. The only difference is that in the opponent' s network , the board is interpreted differently : The opponent' s board position of the original network setup drives the friendly board position in the model of the opponent, and the friendly board position in the original network drives the opponent board position in the model of the opponent. Figure 18 shows a run of the system " mentally simulating " the play of a game. The state of the units are shown after every 100 updates. First , the state of the original network is shown as it settles on its move, then the state of the model of the opponent is shown as it settles on its move. This continues until the game reaches a conclusion. In this instance, the "simulated player" makes a " mistake" in its response to the system's opening. Successivemoves show the system taking advantage of its own mistake and winning the game.
CONCLUSION
We have argued in this book that the analysis of psychological phenomena in terms of units , activations of units , connections among units , and the action of large coalitions of such units leads us to many insights that have not been possible in terms of the language that has recently been more popular in cognitive science. In that sense, we may be perceived as throwing out the insights gained from the more conventional language and concepts. We are not throwing out such insights. In this chapter, we attempt to show the relationship between two such insights and our models. At start, we argue that the concept of the schema has a correspondence in the PDP framework . In particular, we argue that a schema is best viewed as a coalition of units which cohere and that configurations of such coalitions determine the interpretations that the system can attain. These stable states correspond to instantiated configurations of schemata that can be characterized in terms of goodness-of-fit maxima that the system can move into . Such processing systems, we argue, have all of the features of schemata and more. Among the advantagesof this view is that the

56 PSYCHOLOPGRICOACLESSES
schema becomes much more fluid and flexible and able to accommodate itself to inputs . In more conventional representations there is a strong distinction between variables and slots and the bulk of the schema. Under our interpretation an aspect of the schema is more or less a variable. Even central aspectsof the schema can be missing and the system can still find a reasonably low energy stable state. If very rigid schemata are implicit in the knowledge base, this will show up as narrow peaks in the goodness landscape. If more fluid and variable schemata are required, the landscape will contain broad plateaus which allow for a good deal of movement in the region of the maximum .
We see the relationship between our models and schema theory as discussed by other researchers as largely a matter of levels of analysis. This is roughly analogous to the relationship between the level of discussion of fluid dynamics and an underlying level of description involv ing statistical mechanics. It is often useful to theorize at the level of turbulence and different kinds of turbulence , and such a description will do for many purposes. However, we can often run up against phenomena in which our high-level descriptions will not do, we must describe the system in terms of the underlying processes in order to understand its behavior. Another feature of this example is our understanding of the phenomena of emergent properties. Turbulence is not predicted by the knowledge of the elements of the system~it is inherent in the interactions among these elements. Similarly , we do not believe that single-unit activity is the appropriate level of analysis. Properties of networks .,emerge" from the interactions of the elements. Indeed, such properties as goodnessmaxima, etc., are emergent in just this way. In general, we see cognitive phenomena as emergent from the interactions of many units . Thus, we take the symbolic level of analysis to provide us with an approximation to the underlying system. In many casesthese approximations will prove useful~in some casesthey will be wrong and we will be forced to view the system from the level of units to understand them in detail.
We also discussed the relationship between POP models and the more conventional sequential processing systems. We believe that processesthat happen very quickly - say less than .25 to .5 secondsoccur essentially in parallel and should be described in terms of parallel models. Processes that take longer, we believe, have a serial component and can more readily be described in terms of sequential information -processing models. For these processes, a processdescription such as a production would , we imagine, provide a useful approximate description. We would caution, however, that when one chooses a formalism such as production systems and attempts to use it not only to describe the conscious sequential processes that occur at this slow time scale, it is important not to fall into the trap of assuming that the

14. SCHEMATNADSEQUENTHIAOLUGH5T7

microstructure

of these sequential processes should also be described in

the same terms . Production

systems have the power of Turing

machines and people often attempt to describe phenomena at this faster

time scale in terms of the same sequential

formalism

that seems

appropriate

for the slower time scale . We believe that it will turn out

that this approach is wrong , that the power of the formalism

has led us

astray . In these cases we suspect that the unit level of analysis will be

required .

Finally , we showed how the important notion of mental models and

the related notion of mental simulations

play important

roles in the

sequential

behavior of a POP system . We illustrated

this point with a

system which could use a " model of its opponent " to " mentally simu -

late " a tic - tac - toe game . We suspect that this process will turn out to

be important

when we begin to apply our models to temporally

extended reasoning and problem - solving tasks .

ACKNOWLEDGMENTS

This research was supported

by Contracts

NOOO14 - 79 - C - O323 , NR

667 - 437 and NOOO14 - 85 - K - O450 , NR 667 - 548 with the Personnel and

Training Research Programs of the Office of Naval Research , by grants

from the System Development

Foundation , and by a NIMH Career

Development

Award ( MHOO385 ) to the third author .

CHAP1T5ER
Interactive Processesin SpeechPerception: The TRACE Model
J. L. McCLELLANDandJ. L. ELMAN
Consider the perception of the phoneme / g / in the sentence She received a valuable gift . There are a large number of cues in this sen tence to the identity of this phoneme . First , there are the acoustic cues to the identity of the / g / itself . Second , the other phonemes in the same word provide another source of cues , for if we know the rest of the phonemes in this word , there are only a few phonemes that can form a word with them . Third , the semantic and syntactic context further constrain the possible words that might occur , and thus limit still further the possible interpretation of the first phoneme in gift .
There is ample evidence that all of these different sources of infor mation are used in recognizing words and the phonemes they contain . Indeed , as R . A . Cole and Rudnicky ( 1983 ) have recently noted , these basic facts were described in early experiments by Bagley ( 1900 ) over 80 years ago . Cole and Rudnicky point out that recent work ( which we consider in detail below ) has added clarity and detail to these basic findings but has not lead to a theoretical synthesis that provides a satis factory account of these and many other basic aspects of speech perception .
In this chapter , we describe a model that grew out of the view that the interactive activation processes that can be implemented in POP
This chapter is a condensed version of the article 'IThe TRACE Model of Speech Perception" by J. L . McClelland and J. L . Elman, which appeared in Cognitive Psychology, 1986, 18, 1-86. Copyright 1986 by Academic Press, Inc. Adapted with permission.

15. THETRACMEODEL 59

models sources the

earlier

provide

of

information

success

a

natural

way

in

speech

of

the

interactive

to

capture

perception

activation

the

integration

of

multiple

.

This

view

was

based

model

of

word

percep

on -

tion

( McClelland

&

Rumelhart

,

1981

~

Rumelhart

&

McClelland

,

1982

)

in

accounting

for

integration

of

multiple

sources

of

information

in

recognizing

letters

in

words

.

In

attempting

tion

model

to

of

word

apply perception

the

ideas

embodied

in

the

interactive

to

speech

,

it

soon

became

apparent

activa

-

that

speech the

provided TRACE

many

challenges

model

,

is

a

response

.

The

to

model many

we

have

of

these

come challenges

up

with

,

and

demonstrates

how

they

can

be

met

within

the

PDP

framework

.

After

we

developed

that

are

discover

consistent that

the the

model with
search

,

we

discovered

facts for

about

speech

a

mechanism

many

.

Thus

that

aspects

of

,

we

were

was

sufficient

its

behavior

gratified to

to meet

many accounts

of

the

challenges

of

a

number

also

of

basic

lead

to

aspects

a

model

of

the

that literature

provided

quite

on

speech

close

per

-

ception In
that TRACE

. what

follows

played

a

role

.

We

then

,

we

begin

in describe

shaping

by

reviewing

the

specific

the

structure

several

assumptions

of

the

TRACE

facts

about embodied
model

speech

in

and

the

salient

features

of

the

two

versions

we

have

developed

to

handle

dif

-

ferent

aspects

of

the

simulations

.

Following

this

,

we

model

accounts

for

a

considerable

body

of

psychological

some

of

the

computational

challenges

facing

mechanisms

ception

of

the

overcome

.

The

model these

discussion

,

explains

in

future

section

considers

its

limitations

work

.

some

reasons

,

and

indicates

describe

how

the

data

and

meets

of

speech

per

-

for

the

success

how

we

plan

to

SOME

IMPORTANT

FACTS

ABOUT

SPEECH

Our nature speech TRACE available

intention

here

is

not

to

provide

an

extensive

of

speech

,

but

rather

to

point

to

several

fundamental

that

have

played

important

model

.

A

very

useful

in

Klatt

( 1980

).

discussion

roles

in

the

of

several

development of

survey these

of aspects
of points

the of
the is

Temporal

Nature

of

the

Speech

Stimulus

It

does

characteristic

differentiates

not

,

of

course

,

take

a

scientist

to

observe

of

speech

:

It

is

a

signal

that

is

extended

speech

perception

from

most

other

perceptual

one

fundamental

in

time

applications

.

This

60 PSYCHOLOGICPARLOCESSES
of PDP models, which have generally been concerned with visual stimuli .
The sequential nature of speech poses problems for the modeling of contextual influences, in that to account for context effects, it is necessary to keep a record of the context . It would be a simple matter to process speech if each successiveportion of the speech input were processedindependently of all of the others, but , in fact, this is clearly not the case. The presence of context effects in speech perception requires a mechanism that keeps some record of that context , in a form that allows it to influence the interpretation of subsequent input .
Left and Right Context Effects
A further point , and one that has been much neglected in certain models, is that it is not only prior context , but also subsequent context , that influences perception. (This and related points have recently been made by Grosjean & Gee, 1984~ Salasoo& Pisoni, 1985~ and Thomp son, 1984) . For example, Ganong (1980) reported that the identifica tion of a syllable-initial speech sound that was constructed to be between Igl and 1kl was influenced by whether the rest of the syllable was 1Isl (as in kiss) or 11ft1 (as in gift) . Such right context effects (Thompson , 1984) indicate that the perception of what comes in now both influences and is influenced by the perception of what comes in later. This fact suggests that the record of what has already been presented cannot be a static representation but should remain in a malleable form , subject to alteration as a result of influences arising from subsequent input .
Lack of Boundaries and Temporal Overlap
A third fundamental point about speech is that the cues to successive units of speech frequently overlap in time . The problem is particularly severe at the phoneme level. A glance at a schematic speech spectrogram (Figure 1) clearly illustrates this problem. There are no separable packets of information in the spectrogram like the separatefeature bundles that make up letters in printed words.
Becauseof the overlap of successivephonemes~it is difficult ~and we believe counterproductive , to try to divide the speech stream up into separate phoneme units in advance of identifying the units . A number of other researchers (e.g., Fowler, 1984~ Klatt , 1980) have made much

15. THETRACMEODEL61
re
>u z w : =) a w ~ u-
TIME
FIGURE 1. A schematic spectrogram for the syllable bag, indicating the overlap of the information specifying the different phonemes. (From "The Grammars of Speech and Language" by A . M . Liberman , 1970, CognitivePsychology, 1, p. 309. Copyright 1970 by Academic Press, Inc. Reprinted by permission.)
the same point . A superior approach seems to be to allow the phoneme identification process to examine the speech stream for characteristic patterns , without first segmenting the steam into separate units .
The problem of overlap is less severe for words than for phonemes , but it does not go away completely . In rapid speech , words run into each other , and there are no pauses between words . To be sure , there are often cues that signal the locations of boundaries between words stop consonants are generally aspirated at the beginnings of stressed words in English , and word initial vowels are generally preceeded by glottal stops , for example . These cues have been studied by a number of investigators , particularly Lehiste ( e .g ., Lehiste , 1960 , 1964 ) and Nakatani and collaborators . Nakatani and Dukes ( 1977 ) demonstrated that perceivers exploit some of these cues , but found that certain utter ances do not provide sufficient cues to word boundaries to permit reli able perception of the intended utterance . Speech errors often involve errors of word segmentation ( Bond & Garnes , 1980 ) , and certain seg mentation decisions are easily influenced by contextual factors ( R . A . Cole & Jakimik , 1980 ) . Thus , it is clear that word recognition cannot count on an accurate segmentation of the phoneme stream into separate word units , and in many cases such a segmentation would perforce exclude from one of the words a shared segment that is doing double duty in each of two successive words .

62 PSYCHOLOPGRICOACLESSES
Context Sensitivity of Cues
A fourth major fact about speechis that the cues for a particular unit vary considerably with the context in which they occur. For example, the transition of the second formant carries a great deal of information about the identity of the stop consonant / b/ in Figure 1, but that for mant would look quite different had the syllable been big or bog instead of bag. Thus, the context in which a phoneme occurs restructures the cues to the identity of that phoneme (Liberman , 1970) .
Not only are the cues for each phoneme dramatically affected by preceding and following context , they are also altered by more global factors such as rate of speech (J. L . Miller , 1981) , by morphological and prosodic factors such as position in the word and in the stress contour of the utterance, and by characteristics of the speaker such as size and shape of the vocal tract, fundamental frequency of the speaking voice, and dialectical variations (see Klatt , 1980, and Repp & Liber man, 1984, for discussions) .
A number of different approachesto the problem have been tried by different investigators. One approach is to try to find relatively invariant - generally relational - features (e.g., Stevens & Blumstein , 1981) . Another approach has been to redefine the unit so that it encompasses the context , and therefore becomes more invariant (Fujimura & Lovins , 1982~ Klatt , 1980~ Wickelgren , 1969) . While these are both sensible and useful approaches, the first has not yet succeeded in establishing a sufficiently invariant set of cues, and the second may alleviate but does not eliminate the problem : Even units such as demisyllables (Fujimura & Lovins , 1982) , context -sensitive allophones (Wickelgren , 1969) , or even whole words (Klatt , 1980) are still influenced by context . We have chosen to focus instead on a third possibility: that the perceptual system uses information from the context in which an utterance occurs to alter connections dynamically, thereby effectively allowing the context to retune the perceptual mechanism in the course of processing.
Noiseand Indeterminacyin the SpeechSignal
To compound all the problems alluded to above, there is the additional fact that speech is often perceived under less than ideal circumstances. While a slow and careful speaker in a quiet room may produce sufficient cues to allow correct perception of all of the phonemes in an utterance without the aid of lexical or other higher-level

15. THETRACMEODEL 63
constraints , these conditions do not always obtain . People can correctly perceive speech under quite impoverished conditions if it is semanti cally coherent and syntactically well -formed (G . A . Miller , Heise , & Lichten , 1951) . This means that the speech mechanisms must be able to function , even with a highly degraded stimulus . In particular , as Grosjean and Gee ( 1984) , Norris ( 1982) , and Thompson ( 1984) have pointed out , the mechanisms of speech perception cannot count on accurate information about any part of a word . As we shall see , this fact poses a serious problem for one of the best current psychological models of the process of spoken word recognition , the COHORT model of Marslen -Wilson and Welsh ( 1978) .
Many of the characteristics that we have reviewed differentiate speech from print - at least , from very high quality print on white paper - but it would be a mistake to think that similar problems are not encountered in other domains . Certainly , the sequential nature of spoken input sets speech apart from vision , in which there can be some degree of simultaneity of input . However , the problems of ill -defined boundaries , context sensitivity of cues, and noise and indeterminacy are central problems in vision just as much as they are in speech (cf . Ballard , Hinton , & Sejnowski , 1983~ Barrow & Tenenbaum , 1978~ Marr , 1982) . Thus , though the model we present here is focused on speech perception , we would hope that the ways in which it deals with the challenges posed by the speech signal will be applicable in other
domains .

The Importance of the Right Architecture

All of the considerations listed above played an important role in the

formulation

of the TRACE model . The model is an instance of a POP

model , but it is by no means the only instance of such a model that we

have considered

or that could be considered . Other formulations

we

considered simply did not appear to offer a satisfactory framework for dealing with these central aspects of speech (see Elman & McClelland , 1984 , for discussion ) . Thus , the TRACE model hinges on the particu lar processing architecture it proposes for speech perception as well as on the POP mechanisms that implement the interactive activation

processes that occur within it .

Sources of TRACE 's architecture . The inspiration for the architecture of TRACE goes back to the HEARSAY speech understanding system (Erman & Lesser , 1980~ Reddy , Erman , Fennell , & Neely , 1973) .
HEARSAY introduced the notion of a Blackboard , a structure similar

64 PSYCHOLOGICPARL OCESSES
to the Trace in the TRACE model . The main difference is that the Trace is a dynamic processing structure that is self - updating , while the Blackboard in HEARSAY was a passive data structure through which autonomous processes shared information . The architecture of TRACE also bears a resemblance to the neural spectrogram proposed by Crowder ( 1978 ~ 1981 ) to account for interference effects between successive items in short -term memory .

THE TRACE MODEL

The TRACE model consists primarily of a very large number of units , organized into three levels , the feature , phoneme , and word levels .

Each unit stands for an hypothesis about a particular perceptual

object - feature , phoneme , or word - occurring at a particular point in time defined relative to the beginning of the utterance . Thus , the TRACE model uses local representation .

A small subset of the units in TRACE II , the version of the model

with which we will be mostly concerned , is illustrated in Figures 2 , 3 , and 4 . Each of the three figures replicates the same set of units , illus -

trating a different property of the model in each case . In the figures , each rectangle corresponds to a separate processing unit . The labels on

the units and along the side indicate the spoken object ( feature ,

phoneme , or word ) for which each unit stands . The left and right edges of each rectangle indicate the portion of the input the unit spans .

At the feature level , there are several banks of feature detectors , one

for each of several dimensions of speech sounds . Each bank is repli -

cated for each of several successive moments in time , or time slices .

At the phoneme level , there are detectors for each of the phonemes .

There is one copy of each phoneme detector centered over every three

time -slices . Each unit spans six time slices , so units with adjacent centers span overlapping ranges of slices . At the word level , there are

detectors for each word . There is one copy of each word detector cen -

tered over every three feature slices . Here , each detector spans a

stretch of feature slices corresponding to the entire length of the word .

Again , then , units with adjacent centers span overlapping slices .

ranges of

Input to the model , in the form of a pattern of activation to be

applied to the units at the feature level , is presented sequentially to the feature - level units in successive slices , as it would be if it were a real

stream of speech . Mock - speech inputs on the three illustrated dimen -

sions for the phrase tea cup ( / tik " p / ) are shown in Figure 2 . At any instant , input is arriving only at the units in one slice at the feature

68 PSYCHOLOPGRICOACLESSES
system. These continuing interactions permit the model to incorporate right context effects and allow the model to account directly for certain aspects of short-term memory, such as the fact that more information can be retained for short periods of time if it hangs together to form a coherent whole.
Processing takes place through the excitatory and inhibitory interactions of the units in the Trace. Units on different levels that are mutu ally consistent have mutually excitatory connections, while units on the same level that are inconsistent have mutually inhibitory connections. All connections are bidirectional . Thus, the unit for the phoneme Ikl centered over Feature-Slice 24 (shown in Figure 3) has bidirectional excitatory connections to feature units that would be activated if the input contained that phoneme centered on Time -Slice 24. It also has bidirectional excitatory connections to all the units at the word level for words containing Ikl at Time -Slice 24. The connections of illustrative feature- and word-level units are shown in Figure 4. Units on the same level are mutually incompatible , and hence mutually inhibitory , to the extent that the input patterns they stand for would overlap with each other in time . That is to say, units on the same level inhibit each other in proportion to the extent of the overlap of their temporal spans, or windows. At the feature level , units stand for the content of only a single time slice, so they only compete with units standing for other values on the same dimension (see Figure 4) . At the phoneme and word level, however, there can be different degrees of overlap, and hence of mutual inhibition . The extent of the mutual inhibition between the I kl in Slice 24 and other phoneme-level units is indicated in Figure 3 by the amount of shading that falls over the rectangle for the other unit . Similarly , the extent of mutual inhibition between the unit for I kApi starting in Slice 24 and other word-level units is indi cated in Figure 4.
Context -Sensitive Tuning of Phoneme Units
The connections between the feature and phoneme levels determine what pattern of activations over the feature units will most strongly activate the detector for each phoneme. To cope with the fact that the features representing each phoneme vary according to the phonemes surrounding them , the model uses multiplicative connections of the kind proposed by Hinton ( 1981b) and discussed in Chapters 4 and 16. These multiplicative connections essentially adjust the connections from units at the feature level to units at the phoneme level as a function of activations at the phoneme level in preceding and following time slices.

15. THETRACMEODEL69
For example, when the phoneme I tl is preceded or followed by the vowel Iii , the feature pattern corresponding to the It I is very different than it is when the It I is preceded or followed by another vowel, such asla / . Accordingly , when the unit for Iii in a particular slice is active, it changes the pattern of connections for units for It / in preceding and following slices .
TRACE I and TRACE II
In developing TRACE and in trying to test its computational and psychological adequacy , we found that we were sometimes led in rather different directions . We wanted to show that TRACE could process real speech , but to build a model that did so, it was necessary to worry about exactly what features must be extracted from the speech signal , about differences in duration of different features of different phonemes , and about how to cope with the ways in which features and feature durations vary as a function of context . Obviously , these are important problems , worthy of considerable attention . However , con cern with these issues tended to ohscure attention to the fundamental properties of the model and the model ' s ability to account for basic aspects of the psychological data obtained in many experiments .
To cope with these conflicting goals , we have developed two dif ferent versions of the model , called TRACE I and TRACE II . Both models spring from the same basic assumptions , but focused on dif ferent aspects of speech perception . TRACE I was designed to address some of the challenges posed by the task of recognizing phonemes from real speech . This version of the model is described in detail in Elman and McClelland (in press) . With this version of the model , we have been able to show that the TRACE framework could indeed be used to process real speech - albeit from a single speaker uttering isolated monosyllables at this point . We have also demonstrated the effi cacy of the idea of using multiplicative connections to adjust feature to -phoneme connections on the basis of activations produced by sur rounding context .
The second version of the model , TRACE II , will be the main focus of this chapter . We developed this version of the model to account for lexical influences on phoneme perception and for what is known about on -line recognition of words , though we will use it to illustrate how certain other aspects of phoneme perception fallout of the TRACE frame work . This version of the model is actually a simplified version of TRACE I . Most importantly , we eliminated the connection -strength adjustment facility , and we replaced the real speech inputs to TRACE I

70 PSYCHOLOPGRICOACLESSES
with mock speech. This mock-speech input consisted of overlapping but contextually invariant specifications of the features of successive phonemes. Thus, TRACE II sidesteps many of the issues addressedby TRACE I , but it makes it much easier to see how the mechanism can account for a number of aspectsof phoneme and word recognition . A number of further simplifying assumptions were made to facilitate examination of basic properties of the interactive activation processes taking place within the model.
Implementation Details
The material in this section is included for completeness, but the basic line of development may be followed without reading it . Readers uninterested in these details may wish to skip to the section on factors influencing phoneme identification .
Units and their dynamics. The dynamic properties of the units in TRACE are the same as those used in the interactive activation model of visual word perception~these are described in detail in Chapter 2. In brief , the model is a synchronous model, in that all the units update their activation at the same time , based on the activations computed in the previous update cycle. Each unit takes a sum of the excitatory and inhibitory influences impinging on it . Each influence is essentially the product of the output of the influencing unit and the weight on the connection between it and the receiver. If this net input is positive~it drives the activation of the unit upward in proportion to the distance left to the fixed maximum activation level ; if the net input is negative, it drives the activation of the unit down in proportion to the distance left to the fixed minimum . Activations also tend to decay back to their resting activation level , which was fixed at 0 for all units . The output of a unit is 0 if the activation is less than or equal to O~ otherwise it is equal to its activation .
TRACE I . The inputs to TRACE I are sets of 15 parameter values extracted at 5 msec intervals from syllables spoken by a male native speaker of English. The bulk of the TRACE I simulations have been done with a set of CV syllables consisting of an unvoiced stop consonant (I pi , I t / , or I k/ ) followed by one of the vowels I ai , I ii , and I ul , as in the words shah, tea, and who. At the feature level, TRACE I consists of detectors for each of eight different value ranges on each of the 15 input parameters. There is a complete set of detectors for each 5 msec time slice of the input . Since there are 100 slices, the model is capable of processing 500 msec samples of speech.

15. THETRACMEODEL71

There phoneme

are no word

- level

units

- level

units

in TRACE

for

each

successive

15

I . However

msec

time

, there

are

slice

of the

speech

. The

connections

from

the feature

to the phoneme

units

were

determined

by

using

the

perceptron

convergence

procedure

( see

Chapter

2 ) under

two different

conditions

. First , in the invariant

con -

nections

condition

, a single

set of connection

strengths

was found

for

each

phoneme

, using

tokens

of the phoneme

spoken

in all different

contexts

. In the context

- sensitive

connections

condition

, separate

sets

of connection text of each

strengths

were

of the vowels

.

found

for each stop consonant

in the con -

TRACE

using

the

I can be multiplicative

tested

either

using

context

- sensitive

the

invariant

connections

connections described

or

above

.

In the latter

case , the weights

coming

into

a particular

phoneme

are

weighted

according

to the relative

activation

of other

phonemes

in the

surrounding

context

. Consider

an arbitrary

phoneme

unit

which

we

will designate

, for now , the target

unit . The

strengths

of the connec

-

tions

coming

into

this

unit

can be designated

by the vector

w , where

the elements

of the vector

are just

the individual

weights

from

each

feature

unit

to the phoneme

unit . This

vector

is the average

over

all

context

phonemes

k of the context

- specific

weight

vectors

appropriate

for the target

phoneme

in the context

of k , where

the contribution

of

each

of

exponential

these of

context

- specific

the activation

weight

vectors

of phoneme

k

is proportional

summed

over

to the

the

time

slices

adjacent

to the target

phoneme

unit

( see Elman

& McClelland

,

1986 , in press , for further

details

).

TRACE

II . Inputs

to TRACE

II are not

real

speech

, but

mock

speech

of the kind

illustrated

in Figure

2 . The

mock

speech

is a series

of specifications

for inputs

to units

at the feature

level , one for each 25

msec erated

time by

slice

of

a simple

the mock computer

utterance program

. These from

specifications a sequence

are gen of to - be -

presented

segments

provided

by the human

user of the simulation

pro -

gram . The

allowed

segments

consist

of the stop

consonants

/ b/ , / p/ ,

Id / , It / , / g / , and / k / ~ the fricatives

/ s / and / S / ( sh as in ship ) ~ the

liquids

/ II and / r / ~ and the vowels

/ a / ( as inpot

) , / i / ( as in beet ) , / u /

( as in boot ) , and / A / ( as in but ) . / A / is also used

to represent

reduced

vowels

such

as the second

vowel

in target . There

is also

a I' silence

I'

segment

represented

way between

/ b / and

by 1 - / . Special

segments

/ p / , can be constructed

, such as well

as a segment .

half -

A feature

set of - level

seven inputs

dimensions . Of course

is used , these

in TRACE dimensions

II to represent are intentional

the sim -

plifications

way

that

of the the font

real acoustic

structure

used

by McClelland

of speech

, in much

the same

and

Rumelhart

( 1981 ) in the

interactive

activation

model

of

visual

word

recognition

was

an

72 PSYCHOLOPGRICOACLESSES

intentional simplification of the real structure of print . Each dimension is divided into eight value ranges . Each phoneme has a value on each dimension ~ the values on the vocalic , diffuseness , and acuteness dimensions for the phonemes in the utterance ItikA pi are shown in
Figure 2. The dimensions and the values assigned to each phoneme on each dimension are indicated in Table 1. Numbers in the cells of the table indicate which value on the indicated dimension is most strongly
activated by the feature pattern for the indicated phoneme . Values range from 1 (very low ) to 8 (very high ) . The last two dimensions were altered for the categorical perception and trading relations simula tions , as described below .
Values are assigned to approximate the values real phonemes would have on these dimensions and to make phonemes that fall into the same phonetic category have identical values on many of the dimen sions . Thus , for example , all stop consonants are assigned the same values on the power , vocalic , and consonantal dimensions . We do not claim to have captured the details of phoneme similarity exactly . Indeed , one cannot do so in a fixed feature set because the similarities vary as a function of context . However , the feature sets do have the property that the feature pattern for one phoneme is more similar to the feature pattern for other phonemes in the same phonetic category (stop , fricative , liquid , or vowel ) than it is to the patterns for phonemes

TABLE 1 PHONEMEFEATUREVALUES USEDIN TRACE II PHONEME POW VOC DIF ACU CON VOl

BUR

POW = power, VOC = vocalicness, DIF = diffuseness, ACU = acuteness, CON = consonantal, val = voicing, BUR = burst amplitude . Only the stops have values on this last dimension .

1.5THTERACMEODEL73

in other categories. Among the stops, those phonemes sharing place of
articulation or voicing are more similar than those sharing neither attribute .

The feature specification of each phoneme in the input stream

extends over 11 time slices of the input . The strength of the pattern grows to a peak at the sixth slice and falls off again , as illustrated in

Figure 2. Peaks of successive phonemes are separated by six slices .

Thus , specifications of successive phonemes overlap , as they do in real speech (Fowler , 1984~ Liberman , 1970) .

Generally , there are no cues in the speech stream to word

boundaries - the feature specification for the last phoneme of one word

overlap with the first phoneme of the next in just the same way feature

specifications of adjacent phonemes overlap within words . However ,

entire utterances presented to the model for processing - be they indi vidual syllables , words , or strings of words - are preceded and followed

by silence . Silence is not simply the absence of any input ~rather , it is a pattern of feature values , just like the phonemes . Thus , a ninth value

on each of the seven dimensions

is associated with silence . These

values are actually outside the range of values that occurred in the

phonemes themselves so that the features of silence are completely uncorrelated with the features of any of the phonemes .

TRACE II contains a unit for each of the nine values on each of the

seven dimensions , in each time slice of the Trace . At the phoneme level , each Trace contains a detector for each of the 15 phonemes and a

detector for the presence of silence . The silence detectors are treated like all other phoneme detectors . Each member of the set of detectors

for a particular phoneme is centered over a different time - slice at the

feature level , and the centers are spaced three time - slices apart . The unit centered over a particular slice receives excitatory input from feature units in a range of 11 slices , extending both forward and back ward from the slice in which the phoneme unit is located . It also sends

excitatory feedback down to the same feature units in the same range
of slices .

The connection strengths between the feature -level units and a particular phoneme -level unit exactly match the feature pattern the phoneme is given in its input specification . Thus , as illustrated in Figure 3, the strengths of the connections between the unit for / k/ centered over Time -Slice 24 and the units at the feature level are
exactly proportional to the pattern of input to the feature level pro duced by an input specification containing the features of / k / centered
in the same time slice .

TRACE II also contains detectors for the 211 words found in a com -
puterized phonetic word list that met all of following criteria : (a) The word consisted only of phonemes in the list above ~ (b) it was not an

74 PSYCHOLOGPIRCOALCESSES

inflection

of some other word that could be made by adding ed , s , or

ing ~ and ( c ) the word together with its ed , s , and ing inflections

occurred with a frequency of 20 or more per million in the Kucera and

Francis ( 1967 ) word count . It is not claimed that the model ' s lexicon is

an exhaustive

list of words meeting these criteria since the computer -

ized phonetic lexicon this . To make specific tors for the following

was not complete , but it is reasonably close to points about the behavior of the model , detec three words not in the main list were added :

blush , regal , and sleet . The model also has detectors for silence ( I - I ) , which is treated like a one - phoneme

at the word level word .

Presentation

and processing

of an utterance . Before processing of

an utterance begins , the activations

of all of the units are set at their

resting values . At the start of processing , the input to the initial slice

of feature units is applied . Activations

are then updated , ending the

initial time cycle . On the next time cycle , the input to the next slice of

feature units is applied , and excitatory

and inhibitory

inputs to each

unit resulting from the pattern of activation left at the end of the previ -

ous time slice are computed .

It is important

to remember

that the input is applied , one slice at a

time , proceeding from left to right as though it were an ongoing stream

of speech " writing on " the successive time slices of the Trace . The

interactive

activation process is occurring throughout

the Trace on each

time slice , even though the external input is only coming in to the

feature units one slice at a time . Processing interactions

can continue

even after the left to right sweep through the input reaches the end of

the Trace . Once this happens , there are simply no new input specifica -

tions applied to the Trace ~ the continuing

interactions

are based on

what has already been presented . This interaction

process is assumed

to continue indefinitely , though for practical purposes it is always ter -

minated after some predetermined

number of time cycles has elapsed .

Activations

and overt responses . Activations

of units in the Trace

rise and fall as the input sweeps across the feature level . At any time , a

decision can be made based on the pattern of activation as it stands at

that moment . The decision mechanism

can , we assume , be directed to

consider the set of units located within a small window of adjacent

slices within any level . The units in this set then constitute the set of

response alternatives , designated by the identity of the item for which the unit stands ( note that with several adjacent slices included in the

set , several units in the alternative

set may correspond

to the same

overt response ) . Word - identification

responses are assumed to be

based on readout from the word level , and phoneme - identification

responses are assumed to be based on readout from the phoneme level .

15, THETRACMEODEL 75

As far as phoneme identification is concerned, then , a homogeneous mechanism is assumed to be used with both word and nonword stimuli .
The decision mechanism can be asked to make a response either (a) at a critical time during processing, or (b) when a unit in the alternative set reaches a critical strength relative to the activation of other alternative units . Once a decision has been made to make a response, one of the alternatives is chosen from the members of the set. The probability of choosing a particular alternative i is then given by the Luce ( 1959) choice rule :
Si P(R)i=-:J:r;s;

where j indexes the members of the alternative set , and Si = ekai . The

exponential transformation ensures that all activations are positive and

gives great weight to stronger activations ~ the Luce rule ensures that

the sum of all of the response probabilities adds up to 1.0 . Substan -

tially the same assumptions ( 1981 ) .

were used by McClelland

and Rumelhart

Parameters. At the expense of considerable realism, we have tried to keep both TRACE I and TRACE II simple by using homogeneous parameters wherever possible. The strength of the total excitation coming into a particular phoneme unit from the feature units is normalized
to the same value for all phonemes, thus making each phoneme equally excitable by its own canonical pattern. Other simplifying assumptions should be noted as well. For example, there are no differences in connections or resting levels for words of different frequency. It would have been a simple matter to incorporate frequency as McClelland and Rumelhart ( 1981) did , and a complete model would , of course, include some account for the ubiquitous effects of word frequency. We left it out here to facilitate an examination of the many other factors that appear to influence the process of word recognition in speech perception.
Even with all the simplifications described above, TRACE II still has 10 free parameters~ these are listed in Table 2. There was some trial and error in finding the set of parameters used in the reported simulations, but, in general, the qualitative behavior of the model is remarkably robust under parameter variations, and no systematic search of the spaceof parameters is necessary.
In all the reported simulations using TRACE II , the parameters were held at the values given in Table 2. The only exception to this occurred in the simulations of categorical perception and trading relations. Since we were not explicitly concerned with the effects of feedback to the feature level in any of the other simulations , we set the

76 PSYCHOLOPGRIOCCAELSSES

TABLE2

PARAMETERS

OF TRACE

II

Parameter

Value

Feature - Phoneme

Excitation

.02

Phoneme - Word Excitation

.05

Word - Phoneme

Excitation

.03

Phoneme - Feature Excitation

.00

Feature - Level Inhibition

.04

Phoneme - Level Inhibition

*

.04

Word - Level Inhibition

*

.03

Feature - Level Decay

.01

Phoneme - Level Decay

.03

Word - Level Decay

.05

* Per 3 time slices of overlap .

feedback from the phoneme level to the feature level to zero to speed
up the simulations in all other cases. In the categorical perception and trading relations simulations this parameter was set at 0.05. Phonemeto-feature feedback tended to slow the effective rate of decay at the feature level and to increase the effective distinctiveness of different
feature patterns. Rate of decay of feature level activations and strength of phoneme-to-phoneme competition were set to 0.03 and 0.05 to compensate for these effects. No lexicon was used in the categorical perception and trading relations simulations , which is equivalent to setting the phoneme-to-word excitation parameter to zero. In TRACE I , the parameters were tuned separately to compensate for the finer time scale of that version of the model.

FACTORISNFLUENCINPGHONEMIEDENTIFICATION

We are ready to examine the performance of TRACE , to see how well it can account for psychological data on the process of speech perception and, to determine how well it can cope with the computational challenges posed by speech. In this section we consider the process of phoneme identification . In the next section we examine several aspects of word recognition . The sections may be read independently, in either order .
In the introduction , we motivated the approach taken in the TRACE model in general terms. In this section, we will see that the simple concepts that lead to TRACE provide the basis for a coherent and synthetic account of a large number of different kinds of findings on the

15. THETRACMEODEL 77
perception of phonemes . Previous models have been able to provide fairly accurate accounts of a number of these phenomena . For exam ple , Massaro and aden ' s feature integration model (Massaro , 1981~ Massaro & aden , 1980a, 1980b ~ aden & Massaro , 1978) accounts in detail for a large body of data on the influences of multiple cues to phoneme identity , and the Pisoni / Fujisaki -Kawashima model of categorical perception (Fujisaki & Kawashima , 1968~ Pisoni , 1973, 1975) accounts for a large body of data on the conditions under which subjects can discriminate sounds within the same phonetic category . Marslen -Wilson ' s COHORT model (Marslen -Wilson & Welsh , 1978) can account for the time course of certain aspects of lexical influences on phoneme identification . Recently Fowler ( 1984) has proposed an interesting account of the way listeners cope with coarticulatory influ ences on the acoustic parameters of speech sounds . Here we will show that TRACE brings these phenomena , and several others not con sidered by any of these other models , together into a coherent picture of the process of phoneme perception as it unfolds in time .
This section consists of four main parts . The first focuses on lexical effects on phoneme identification and the conditions under which these effects are obtained . The second part of this section focuses on the question of the role of phonotactic rules - that is, rules specifying which phonemes can occur together in English - in phoneme identification . Here , we see how TRACE mimics the apparently rule -governed behavior of human subjects , in terms of a " conspiracy " of the lexical items that instantiate the rule . The third part focuses on two aspects of phoneme identification often considered quite separately from lexical effects - namely , the contrasting phenomena of cue tradeoffs in phoneme perception and categorical perception . The simulations in the first three parts were all done using TRACE II . The fourth part describes our simulations with TRACE I , illustrating how the connection - modulation mechanisms embedded in that version of the model account for the fact that listeners appear to alter the cues they use to identify phonemes in different contexts .
Lexical Effects
You can tell a phoneme by the company that it keeps. 1 In this section , we describe a simple simulation of the basic lexical effect on
1 This title is adapted from the title of a talk by David E . Rumelhart on related phenomena in letter perception . These findings are described in Rumelhart and McC ]el land ( 1982) .

78 PSYCHOLOPGRICOACLESSES
phoneme identification reported by Ganong (1980) . We start with this phenomenon because it , and the related phonemic restoration effect , were among the primary reasons why we felt that the interactive activation mechanisms provided by POP models would be appropriate for speech perception, as well as visual word recognition and reading.
For the first simulation , the input to the model consisted of a feature specification which activated Ibl and Ipl equally, followed by (and partially overlapping with ) the feature specifications for I 11, then I AI , then I gl . Figure 5 shows phoneme- and word-level activations at several points in the unfolding of this input specification. Each panel of the figure represents a different point in time during the presentation and concomitant processing of the input . The upper portion of each panel is used to display activations at the word level~the lower panel is used for activations at the phoneme level. Each unit is represented by a rectangle labeled with the identity of the item the unit stands for . The horizontal extension of the rectangle indicates the portion of the input spanned by the unit . The vertical position of the rectangle indicates the degree of activation of the unit . In this and subsequent figures, activations of the phoneme units located between the peaks of the input specifications of the phonemes (at Slices 3, 9, 15, etc.) have been deleted from the display for clarity . The input itself is indicated below each panel, with the successive phonemes positioned at the temporal positions of the centers of their input specifications. The " A" along the x-axis represents the point in the presentation of the input stream at which the snapshot was taken.
The figure illustrates the gradual build -up of activation of the two interpretations of the first phoneme, followed by gradual build -ups in activation for subsequent phonemes. As these processesunfold , they begin to produce word-level activations. It is difficult to resolve any word-level activations in the first few frames, however, since in these frames, the information at the phoneme level simply has not evolved to the point where it provides enough constraint to select anyone particular word. It is only after the Igl has come in that the model has infor mation telling it whether the input is closer to plug, plus, blush, or blood (TRACE 's lexicon contains no other words beginning with / pIAI or IblA I ) . After that point , as illustrated in the fourth panel, plug wins the competition at the word level , and through feedback support to Ip / , causes/ p/ to dominate Ib / at the phoneme level . The model, then , provides an explicit account for the way in which lexical information can influence phoneme identification .
Factors influencing the lexical effect. There is now a reasonable body of literature on lexical effects on phoneme identification . One important property of this literature is the fact that the lexical effect is

15. THETRACMEODEL79

12 1 -- g ~

B

B

B

12 l "" g~

-B
~!1!1!I!Ii~~:i:J~)- ~ :1!;t~IJ:~J}

0 .6 -
0 .5

1 ....

.. ..

-

1 g

0 .4

gl

g g

p

r

r

-

b

0 .3

0 .2

P

....

k

r k

0 .1

- ~

0 .0

-

?

r

-

-

a

d

-

a

-

b
- I "" g P

b
- ) "" g P

b
- l "" g P

_ bl "" g P

FIGURE 5. Phoneme - and word -level activations at sev ~ral points in the unfolding of a segment ambiguous between / b/ and / p/ , followed by / 1/ , / A/ , and / g/ . See text for a full explanation .

_ laD _ . . "'_11:='1 :8" . .

often somewhat difficult to obtain . For example , Fox ( 1982, 1984) found that the lexical effect can be eliminated by time pressure . Ganong reported that the lexical effect only shows up with segments that are ambiguous ~ we know that in running speech , people often per ceived as co: rectly pronounced words with deliberate errors (Marslen Wilson & Welsh , 1978) , but at the beginnings of isolated words lexical influences appear to lead to misperceptions of unambiguous tokens of phonemes . In reaction time studies , it has been observed by Foss and Blank ( 1980) that there is no lexical effect on the reaction time to detect word -initial phonemes .
Many of these findings have been taken as evidence against the view that top -down influences really playa role in normal perceptual processing (Foss & Gernsbacher , 1983) , and only come into play in a post perceptual stage of processing (Fox , 1982) . However , we observe the same results in simulations with TRACE , where top -down influences are always at work . The reason why lexical effects do not emerge until late in processing for word -initial targets is simply that the contextual information is not available until then . The reason why lexical effects do not emerge with word -initial targets that are not ambiguous is simply that the bottom -up information is there to identify the target , long before the contextual information would be available . Simulations
demonstrating the absence of lexical effects for word -initial segments

41~UdJ1S dsuodsdH

80 PSYCHOLOPGRICOACLESSES
under speeded conditions or when the segment is unambiguous are described in McClelland and Elman (in press) .
The crucial observations concern what happens with lexical effects on word -final segments . It is well known that lexical effects are larger later in words than they are at the beginnings of words (Marslen Wilson & Welsh , 1978) and can be obtained in reaction time studies even with unambiguous segments ( Marslen -Wilson , 1980) .
TRACE produces stronger lexical effects when the target comes late in the word , simply because the context is already providing top -down support for the target when it starts to come in under these cir cumstances . We illustrate by comparing response strength for the phoneme It I in Isikrtl (the word secre)t and in the nonword IgAldAtl ( guldut) in Figure 6. The figure shows the strength of the It I response as a function of processing cycles , relative to all other responses based on activations of phoneme units centered at Cycle 42 , the peak of the input specification for the I t / . Clearly , response strength grows faster for the I tl in I sikr tl than for the I tl in IgAIdAtl ~ picking an arbitrary threshold of 0.9 for response initiation , we find that the It I in Isikr tl reaches criterion about 3 cycles or 75 msec sooner than the It I in I gAIdAt/ . The size of the effect Marslen-Wilson ( 1980) obtains is quite comparable to the effect observed in Figure 6.

t
1 . 00

0 .80 0 .60

S kr - t g - ld - t

0 .40

0 . 20

0 . 00 0

6

12

18

24

30

36

42

48

54

60

66

72

Processing Cycles

FIGURE 6. Probabilityof the It I responseas a function of processingcycles, basedon activationof phonemeunits at Cycle42, for the streamI sikr"tl (secre)tandI g"ld"tl (gu-l dut) . Verticallines indicatethe peaksof the input patternscorrespondingto the succe-s sivephonemesin eitherstream.

15. THETRACMEODEL81
Are Phonotactic Rule Effects the Result of a Conspiracy ?
Recently , Massaro and M . M . Cohen ( 1983) have reported evidence they take as support for the use of phonotactic rules in phoneme iden tification . In one experiment , Massaro and Cohen ' s stimuli consisted of phonological segments ambiguous between Irl and III in different con texts . In one context (/ t_ i/ ) , Irl is. permissible in English , but III is not . In another context ( / s_ i / ) , III is permissible in English but Irl is not . In a third context (/ f_ i / ) , both are permissible , and in a fourth (I v_ i I ) , neither is permissible . Massaro and Cohen found a bias to perceive ambiguous segments as I r I when I r I was permissible , or as III when III was permissible . No bias appeared in either of the other two conditions .
With most of these stimuli , phonotactic acceptability is confounded with the actual lexical status of the item ~ thus Iflil and Ifril (flee and free ) are both words , as is Itril but not Itli / . In the Is _ if context , however , neither / slil or / sri / are words , yet Massaro and Cohen found a bias to hear the ambiguous segment as Ill , in accordance with phonotactic rules .
It turns out that TRACE produces the same effect , even though it lacks phonotactic rules . The reason is that the ambiguous stimulus pro duces partial activations of a number of words (sleep and sleet in the model ' s lexicon ~ it would also activate sleeve , sleek , and others in a model with a fuller lexicon ) . None of these word units gets as active as it would if the entire word had been presented . However , all of them (in the simulation , there are only two , but the principle still applies ) are partially activated , and all conspire together and contribute to the activation of I II . This feedback support for the I II allows it to dom inate the I r I , just as it would if I sli I were an actual word , as shown in Figure 7.
The hypothesis that phonotactic rule effects are really based on word activations leads to a prediction : We should be able to reverse these effects if we present items that are supported strongly by one or more lexical items even if they violate phonotactic rules . A recent experi ment by Elman ( 1983) confirms this prediction . In this experiment , ambiguous phonemes (for example , halfway between Ihl and Id / ) were presented in three different types of contexts . In all three types , one of the two (in this case, the I d / ) was phonotactically acceptable , while the other (the Ib / ) was not . However , the contexts differed in their relation to words . In one case, the legal item actually occurred in a word (bwindleldwindle ) . In a second case, neither item made a word , but the illegal item was very close to a word (bwacelefIdwacelet ) . In a third case, neither item was particularly close to a word (bwif/le Idwif /le) .

82 PSYCHOLOPGRICOACLESSES

B-

G- .

As 1 i P1

ls 1 i lj

B-

rs 1 ~ pL

IS 1 i II

~

~~

~=r-1

~~II ~j~}
-
S

S t
-

1

-- S

1-

r

-{:~j:;i!:I!i!~~!~!f
-s

1
1 -
r

-

ua

I

- S

1-

r

i--::-{s!:-:l] : I }
-s i-

1
r -

I .

- S

1-

r

{:::2

-s

1

1

-

r

-

' ""

1

- S

1-

r

FIGURE

between

are

boxed

7.

State

of

the

Trace

/ 1/

and

together

/ r/

in

the

context

since

they

take

at

several

points

in

processing

/ s_ i / .

The

units

on

identical

activation

for

sleep

values

a

segment

( / slip .

/)

and

ambiguous

sleet

( / slit

/)

Results word

of identical

the

alternatives

influenced

in

the

case

the

experiment

to

one

are

shown

in

Table

of

the

two

alternatives

by

the

subjects

where

a

single

phonetic

'

choices

the

phonotactically

between

feature the
irregular

3.

The

or

differing

existence from

of

a

one

of

of

one

phoneme

two

alternatives

alternative

strongly

.

Indeed

,

( bwacelet

)

was tended item

one

feature

to

hear

away the

from ambiguous

( that

is

,

as

a

I hi

)

even

a

particular

item

though

lexical

in

accord

item with

it

was

phonotactically

( bracelet

),

subjects

the

similar

lexical

incorrect

.

TABLE 3

PERCENTCHOICEOF PHONOTACTICALLY IRREGULARCONSONANT

StimulusType

Example

Percentagoef Identifications as'fIllega,l. Phoneme(/ b/ )*

Legalword/ illegalnonword

dwindle/ bwindle

Legalnonword/ illegalnonword dwiffle/ bwiffle

Legalnonword/ illegalnear-word dwacele/tbwacelet

*F(2,34) = 26.414, p < .001

37/r)

46%

55%

-

15. THETRACMEODEL83
To determine whether the model would also produce such a reversal of the phonotactic rule effects with the appropriate kinds of stimuli , we ran a simulation using a simulated input ambiguous between Ipl and I tl in the context I _1uli I . I pi is phonotactically acceptablein this context , but I tl in this context makes an item that is very close to the word truly. The results of this run , at two different points during processing, are shown in Figure 8. Early on in processing, there is a slight bias in favor of the Ipl over the It I becauseat first a large number of I pll words are slightly more activated than any words beginning with It / . Later, though , the It I gets the upper hand as the word truly comes to dominate at the word level . Thus, by the end of the word or shortly thereafter, the closest word has begun to playa dominating role, causing the model to prefer the phonotactically inappropriate interpretation of the ambiguous initial segment.
Of course, at the same time the word truly tends to support I r I rather than III for the second segment. Thus, even though this segment is not ambiguous and the I II would suppress the I rI interpretation in a more neutral context , the I rI stays Quite active.

-B G-
{I : Lm 1 i ~

$ i :. f
1~ ~fi t-t~ -

pi
r

u a

-

t

- Ptluli -

.
-

1

PUt

r

1

riP
a

-

t

-

Iul

P

8
...... .... .
i-

it r u 1 i ~ -B

1t r u 1 i ~ G-

{! =~

~I-J:{I~I ~ +~1 {!=:t} -

uI . -

1

1

p r

r a

-

B

-

{1L: g}
i ~ :ftIIiJ-

-

-

1

ul

1
t r

r

-

a

-

- tluli -
P

lluli -
P

FIGURE 8. Stateof the Traceat severalpointsin processingan ambiguous/ p/ -/ t/ segment followedby/ luli/ .

84 PSYCHOLOPGRICOACLESSES
Trading Relationsand CategoricaPl erception
In the simulations considered thus far , phoneme identification is influenced by two different kinds of factors: featural and lexical. When one sort of information is lacking, the other can compensate for it . The image that emerges from these kinds of findings is of a system that exhibits great flexibility by being able to base identification decisions on different sources of information . It is, of course, well established that within the featural domain each phoneme is generally signaled by a number of different cues and that human subjects can trade these cues off against each other . The TRACE model exhibits this same flexibil ity , as we shall detail shortly .
But there is something of a paradox. While the perceptual mechanisms exhibit great flexibility in the cues that they rely on for phoneme identification , they also appear to be quite "categorical" in nature. That is, they produce much sharper boundaries between phonetic categories than we might expect based on their sensitivity to multiple cues~ and they appear to treat acoustically distinct feature patterns as perceptually equivalent , as long as they are identified as instances of the same phoneme.
In this section, we illustrate that in TRACE , just as in human speech perception, flexibility in feature interpretation coexists with a strong tendency toward categorical perception.
For these simulations , the model was stripped down to the essential minimum necessaryso that the basic mechanisms producing cue tradeoffs and categorical perception could be brought to the fore . The word level was eliminated altogether, and at the phoneme level there were only three phonemes, I ai , I g/ , and I k/ , plus silence (I -I ) . From these four items, inputs and percepts of the form I -ga-1 and I -ka-1 could be constructed. The following additional constraints were imposed on the feature specifications of each of the phonemes: (a) the lal and I -I had no featural overlap with either Igl or Ikl so that neither lal nor I -I would bias the activations of the Igl and / kl phoneme units where they overlapped with the consonant in time ~ (b) Igl and I kl were identical on five of the seven dimensions and differed only on the remaining two dimensions.
The two dimensions which differentiated Igl and I k/ were voice onset time (VOT ) and the onset frequency of the first formant (FIOF ) . These dimensions replaced the voicing and burst amplitude dimensions used in all of the other simulations . Figure 9 illustrates how FIOF tends to increase as voice onset time is delayed.
Trading relations . TRACE quite naturally tends to produce trading relations between features since it relies on the weighted sum of the

1.5THETRACMEODEL85

2000

1500

1000

500

/

0

0

50

100

150 300

TIME

FIGURE 9. Schematic diagram of a syllable that will be heard as / ga/ or / ka/ , depending on the point is the syllable at which voicing begins. Before the start of voicing, F2 (top curve) and F3 are energized by aperiodic noise sources, and FI is "cut back" (the noise source has little or no energy in this range) . Becauseof the fact that Fl rises over time after syllable onset (as the vocal tract moves from a shape consistent with the consonant into a shape consistent with the vowel) , its frequency at the onset of voicing is higher for later values of VaT . Parameters used in constructing this schematic syllable are derived from Kewley-Port ( 1982) .

. .. ]~~r.I.~tZ~.

excitatory inputs to determine how strongly the input will activate a particular phoneme unit . All else being equal, the phoneme unit receiving the largest sum bottom -up excitation will be more strongly activated than any other and will therefore be the most likely response when a choice must be made between one phoneme and another. Since the net bottom -up input is just the sum of all of the inputs , no one input is necessarily decisive in this regard.
Generally, experiments demonstrating trading relations between two or more cues manipulate each of the cues over a number of values ranging between a value more typical of one of two phonemes and a value more typical of the other . Summerfield and Haggard ( 1977) did this for VaT and F1OF and found the typical result, namely, that the value of one cue that gives rise to 50% choices of / k/ was affected by the value of the other cue: The higher the value of F1OF, the shorter the value of VaT needed for 50% choices of / k/ . Unfortunately , they did not present full curves relating phoneme identification to the values used on each of the two dimensions. In lieu of this , we present curves
in Figure 10 from a classic trading relations experiment by Denes ( 1955) . Similar patterns of results have been reported in other studies, using other cues (e.g., Massaro, 1981) , though the transitions are often somewhat steeper.

86 PSYCHOLOPGRICOACLESSES

100 '
(/)
~
U. J
~ 19 80 0 :)
J
<n (/)
w 60 ~
w U
0 >
L.J.. 4 0
0
W
19
~ 20
Z
~
rr
UJ 0 a..

0
.
. ...

VOWEL
DURATION
. 50 MSEC
0 100MSEC
. 150 MSEC
.6. 200MSEC

100

150

200

250

FRICATION

DURATION

( MSEC )

FIGURE 10. Resultsof an experimentdemonstratingthe trade-off betweentwo cuesto the identityof I sl andI z/ . Datafrom Denes, 1955, reprintedandfitted by the modelof Massaroand Cohen. (From "The Contribution of Voice-OnsetTime and Fundamental
Frequencyas Cuesto the Izi / -/ sil Distinction" by D. W. Massaroand M. M. Cohen, 1977, Perceptio&n Psychop)'shics, 22, p. 374. Copyright1977by the PsychonomicSociety. Reprintedby permission.)

To demonstrate that TRACE would simulate the basic tradeoff
effect , we generated a set of 25 intermediate phonetic segments made up by pairing each of five different intermediate patterns on the VaT dimension with each of five different intermediate patterns on the FI0F dimension . The different feature patterns used on each dimension are shown in Figure 11, along with the canonical feature patterns for Igl and Ikl on each of the two dimensions. On the remaining five dimensions, the intermediate segments all had the common canonical feature values for I gl and I kl .
The model was tested with each of the 25 stimuli , preceded by silence (I -I ) and followed by la -I . The peak on the intermediate phonetic segment occurred at Slice 12, the peak of the following vowel occurred at Slice 18, and the peak of the final silence occurred at Slice 24. For each input presented, the interactive activation process was allowed to continue through a total of 60 time .slices, well past the end of the input . At the end of the 60th time slice, we recorded the activation of the units for I g/ and / k/ in Time -Slice 12 and the probability of choosing Igl based on these activations. It makes no difference to the general pattern of the results if a different decision time is used.

88 PSYCHOLOGPIRCOALCESSES
FIGURE 12. Simulated probability of choosing / k/ at Time -Slice 60, for each of the 25 stimuli used in the trading relations simulation experiment . Numbers next to each curve refer to the intermediate pattern on the F10F continuum used in the 5 stimuli contribut ing to each curve. Higher numbers correspond to higher values of F10F .
/ k/ , we can seethat the VaT neededincreasesasthe FIOF decrease,s
just as these investigators found .
Categorical perception. In spite of the fact that TRACE is quite flexible in the way it combines information from different features to determine the identity of a phoneme, the model is Quite categorical in its overt responses. This is illustrated in two ways: First , the model shows a much sharper transition in its choices of responsesas we move from / g/ to / k/ along the VaT and FIOF dimensions than we would expect from the slight changes in the relative excitation of the / g/ and / k/ units . Second, the model tends to obliterate differences between different inputs which it identifies as the same phoneme, while sharpening differences between inputs assigned to different categories. We will consider each of these two points in turn , after we describe the stimuli used in the simulations .
Eleven different consonant feature patterns were used, embedded in the same simulated / -_a-/ context as in the trading relations simulation . The stimuli varied from very low values of both VaT and FIOF , more extreme than the canonical / g/ , through very high values on both dimensions, more extreme than the canonical / k/ . All the stimuli were spaced equal distances apart on the VaT and FIOF dimensions. The locations of the peak activation values on each of these two continua are shown in Figure 13.

j ')f/ .'au~soo4JJoAl I~~qeq .o1d

15. THETRACMEODEL89

/ g/

/ k/

1 2 3 4 5 678 91011

-

0

2

3

4

5

6

7

89

Voice Onset Time

/ g/

/ k/

1 2 3 4 5 6 7 8 91011

-

0

2

3

4

567

Fl Onset Frequency

FIGURE 13. Locationsof peakactivationsalong the VaT and FI0F dimensions, for eachof the 11stimuli usedin the categoricapl erceptionsimulation.

Figure 14 indicates the relative initial bottom -up activation of the / g/ and / k/ phoneme units for each of the 11 stimuli used in the simulation . The first thing to note is that the relative bottom -up excitations of the two phoneme units differ only slightly . For example, the canonical feature pattern for / g/ sends 75% as much excitation to / g/ .as it sends to / k/ . The feature pattern two steps toward / g/ from / k/ (stimulus number 5) , sends 88% as much activation to / g/ as to / k/ .
The figure also indicates, in the second panel, the resulting activations of the units for / g/ and / k/ at the end of 60 cycles of processing. The slight differences in net input have been greatly amplified , and the activation curves exhibit a much steeper transition than the relative
bottom -up excitation curves. There are two reasons why the activation curves are so much sharper
than the initial bottom -up excitation functions . The primary reason is competitive inhibition. The effect of the competitive inhibition at the phoneme level is to greatly magnify the slight difference in the excitatory inputs to the two phonemes. It is easy to see why this happens.

90 PSYCHOLOGPIRCOALCESSES

1.a 0

/ g/
- - - ......- - -..- - .- " - ."- ..." .'- .'.' .

/ k/

0 .7 5

-_.._ .._ - _ ._ - ; "....~~~.......--

- -~~...............~

0 . 50

025

0 .00
a

1

2

3

4

5

Stimulus

! I I

6

7

8

9

10

11

12

NumbeJ '

8ImllVal . m ,. dPON dwduolld

FIGURE 14. Effects of competition on phoneme activations . The first panel shows rela tive amounts of bottom - up excitatory input to / g/ and / k / produced by each of the 11 stimuli used in the categorical perception simulation . The second panel shows the activa -
tions of units for / g/ and / k / at Time -Cycle 60 . Stimuli 3 and 9 corr ~spond to the canonical / g/ and / k / 'I respectively .

111
. WIW.8lat.a111111 :111111

Once one phoneme is slightly more active than the other , it exerts a stronger inhibitory influence on the other than the other can exert on

it . The net result is that ffthe rich get richer ." This general property of competitive inhibition mechanisms has been noted many times (Grossberg , 1976; Levin , 1976; McClelland & Rumelhart , 1981) . A second cause of the sharpening of the activation curves is the phoneme -to -feature feedback , which we will consider in detail in a

moment

.

The identification functions that result from applying the Luce choice rule to the activation values shown in the second panel of Figure 14 are shown in Figure 15 along with the ABX discrimination function , which

15. THETRACMEODEL 91

FIGURE 15. Simulatedidentificationfunctionsand forced-choiceaccuracyin the ABX task.

will be discussed later . The identification

functions

are even sharper

than the activation

curves ~ there is only a 4 % chance that the model

will choose / k / instead of / g / for Stimulus 5 , for which / k / receives

88 % as much bottom - up support as / g / . The increased sharpness is

due to the properties

of the response strength assumptions . These

assumptions

essentially implement

the notion that the sensitivity

of the

decision mechanism , in terms of d ' for choosing the most strongly

activated of two units , is a linear function of the difference in activation

of the two units . When the activations are far enough apart , d ' will be

sufficient

to ensure near - IOO % correct performance

, even though both

units have greater than zero activation . 2

In TRACE , the categorical

output of the model comes about only

after an interactive competition

process that greatly sharpens the differ -

ences in the activation

of the detectors for the relevant units . This

interactive

process takes time . In the simulation

results reported here ,

we assumed that subjects waited a fixed time before responding . But , if

we assume that subjects are able to respond as soon as the response

strength ratio reaches some critical level , we would find that subjects

2 Many readers will note that the apparent sharpness of the identification functions shown in Figure 15 contrasts with the much shallower functions shown previously in the trading relations simulations . The reason for this is simply that the stimuli are spaced more closely together in the trading relations simulation than in the categorical perception case. This follows the standard experimental practice of emphasizing gradualness in trade -off experiments and sharpness in categorical perception experiments ( Lane , 1965) .

92 PSYCHOLOPGRIOCCAELSSES

would be able to respond more quickly to stimuli near the prototype of

each category than they can to stimuli near the boundary . This is

exactly what was found by Pisoni and Tash ( 1974 ) .

There is another aspect to categorical

perception

as exhibited

by

TRACE feature

. This is the fact that feedback

from the phoneme

to the

level tends to cause the model to obliterate

the differences

between input feature patterns that result in the identification

of the

same phoneme . This allows the model to account for poor within -

category discrimination

and good between - category discrimination

- the

second hallmark of categorical perception . 3 The way it works is this .

When a feature pattern comes in , it sends more excitation

to some

phoneme units than others ~ as they become active , they begin to com -

pete , and one gradually comes to dominate the others . This much we

have already observed . But as this competition

process is going on ,

there is also feedback from the phoneme level to the feature level .

Thus , as a particular phoneme becomes active , it tends to impose its

canonical pattern of activation on the feature level . The effect of the

feedback becomes particularly

strong as time goes on since the feature

input only excites the feature units very briefly ~ the original pattern of

activation

produced

by the phoneme

units is , therefore , gradually

replaced by the canonical pattern imposed by the feedback from the

phoneme level . The result is that the pattern of activation remaining at

the feature level after 60 cycles of processing has become assimilated to

the prototype . In this way , feature patterns for different

inputs

assigned to the same category are rendered nearly indistinguishable

.

This effect is illustrated

in Figure 16 , which shows how different

pairs of patterns of activation at the feature level are at the end of 60

cycles of processing . The measure of difference

is simply 1 - r ab ,

where r ab stands for the correlation

of the patterns produced by stimuli

a and b . Only the two dimensions

which actually differ between the

canonical / g / and / k / are considered in the difference measure .

3 Strictly speaking , at least as defined by Liberman , Cooper , Shankweiler , and Studdert - Kennedy ( 1967) , true categorical perception is only exhibited when the ability to discriminate different sounds is no better than could be expected based on the assump tion that the only basis a listener has for discrimination is the categorical assignment of the stimulus to a particular phonetic category . However , it is conceded that " true " categorical perception in this sense is never in fact observed (Studdert - Kennedy , Liber man , Harris , & Cooper , 1970) . While it is true that the discrimination of sounds is much better for sounds that perceivers assign to different categories than for sounds they assign to the same category , there is also at least a tendency for discrimination to be somewhat better ' than predicted by the identification function , even between stimuli that are always assigned to the same category . TRACE II produces this kind of approximate categorical perception .

0 . 40
-~

~ "-"

0 . 30

0 . 20

15. THETRACMEODEL 93

0 . 10

0 . 00 0

2

3

4

5

6

7

8

9

10

11

12

Stimulus

Number

FIGURE 16. Differences between patterns of activation at the feature level at Cycle 60, for pairs of stimuli one step apart along the / g/ -/ k/ continuum used for producing the identification functions shown previously in Figure 15.

III . .

To relate the difference between two stimuli to probability correct choice performance in the ABX task generally used in categorical perception experiments, we once again use the Luce ( 1959) choice model. The probability of identifying stimulus x with alternative a is given by
p(R=ax)=SSa+Sxaxb' x
where Sax is the " strength " of the similarity between a and x . This is
given simply by the exponential of the correlation of a and x ,
Sax= ek'rax,
and similarly for Sbx. Here, k, is the parameter that scalesthe relation between correlations and strengths. The resulting response probabilities are shown in Figure 15.
Basically, the figures show that the effect of feedback is to make the feature patterns for inputs well within each category more similar than those for inputs near the boundary between categories. Differences between stimuli near the prototype of the same phoneme are almost obliterated . When two stimuli straddle the boundary, the feature level patterns are much more distinct . As a result, the probability of correctly discriminating stimuli within a phoneme category is much lower than the probability of discriminating stimuli in different categories.

---

94 PSYCHOLOGPIRCOALCESSES
Like the completion process considered earlier , the process of " canonicalization " of the representation of a speech sound via the feed back mechanism takes time . During this time , two things are happen ing : One is that the activations initially produced by the speech input are decaying ~ another is that the feedback , which drives the representa tion toward the prototype , is building up . In the simulations , we allowed a considerable amount of time for these processes before com puting similarities of different activation patterns to each other . Obvi ously , if we had left less time , there would not have been as much of an opportunity for these forces to operate . Thus , TRACE is in agreement with the finding that there tends to be an increase in within category discrimination when a task is used that allows subjects to base their responses on judgments of the similarity of stimuli spaced closely together in time (Pisoni & Lazarus , 1974) .
It should be noted that it would be possible to account for categorical perception in TRACE without invoking feedback from the phoneme level to the feature level . All we would need to do is assume that the feature information that gives rise to phoneme identification is inacces sible , as proposed by the motor theory of speech perception (Liberman , Cooper , Shankweiler , & Studdert -Kennedy , 1967) , or is rapidly lost as proposed by the dual code model (Fujisaki & Kawashima , 1968~ Mas saro , 1975 , 1981~ Pisoni , 1973, 1975) . The dual code model has had considerable success accounting for categorical perception data and accounts for all the aspects of categorical perception discussed thus far .
Both feedback models and dual code models can also accommodate
the fact that vowels show less of a tendency toward categorical percep tion than consonants (Fry , Abramson , Eimas , & Liberman , 1962 ~ Pisoni , 1973) . It is simply necessary to assume that vowel features are more persistent than consonant features (Crowder , 1978 , 1981~ Fujisaki & Kawashima , 1968~ Pisoni , 1973, 1975) . However , the two classes of interpretations do differ in their predictions of performance in discrim inating two stimuli , both away from the center of a category , but still within it . Here , TRACE tends to show greater discrimination than it shows between stimuli squarely in the middle of a category . Standard interpretations of categorical perception can account for increases in discriminability near the boundary between two categories (where iden tification may in fact be somewhat variable ) by assuming that marginal stimuli are more likely to give rise to different category labels . But TRACE can account for increases in discriminability at extreme values of feature continua which would not give rise to different category labels . In TRACE , the reason for this increase in discriminability is that the activation of the appropriate item at the phoneme level is weaker , and therefore the feedback signal is weaker than it is when the input occurs near the center of the category . This results in less

