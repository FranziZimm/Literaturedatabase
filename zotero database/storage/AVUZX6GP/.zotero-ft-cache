  DOI 10.1515/langcog-2013-0021   Language and Cognition 2013; 5(4): 313 – 343
Helen Earis and Kearsy Cormier
Point of view in British Sign Language and spoken English narrative discourse: the example of “The Tortoise and the Hare”
Abstract: This paper discusses how point of view (POV) is expressed in British Sign Language (BSL) and spoken English narrative discourse. Spoken languages can mark changes in POV using strategies such as direct/indirect discourse, whereas signed languages can mark changes in POV in a unique way using “role shift”. Role shift is where the signer “becomes” a referent by taking on attributes of that referent, e.g. facial expression. In this study, two native BSL users and two native British English speakers were asked to tell the story “The Tortoise and the Hare”. The data were then compared to see how point of view is expressed and maintained in both languages. The results indicated that the spoken English users preferred the narrator’s perspective, whereas the BSL users preferred a character’s perspective. This suggests that spoken and signed language users may structure stories in different ways. However, some co-speech gestures and facial expressions used in the spoken English stories to denote characters’ thoughts and feelings bear resemblance to the hand movements and facial expressions used by the BSL storytellers. This suggests that while approaches to storytelling may differ, both languages share some gestural resources which manifest themselves in different ways across different modalities.
Keywords: point of view, narrative discourse, British Sign Language, English, role shift, gesture
Helen Earis: Deafness, Cognition & Language Research Centre, University College London. E-mail: helen.earis@mac.com Kearsy Cormier: Deafness, Cognition & Language Research Centre, University College London
1 Introduction
Expressing the point of view from which a story is being told and marking changes in point of view are key elements of narrative discourse in both spoken and signed languages. Spoken languages can mark changes in point of view using strategies such as direct and indirect reported speech (Coulmas 1986), cou-
Downloaded from http:/www.cambridge.org/core. Lehrst F Alte Geschichte Hist Inst, on 27 Oct 2016 at 12:36:50, subject to the Cambridge Core terms of use, available at http:/www.cambridge.org/core/terms. http://dx.doi.org/10.1515/langcog-2013-0021

  314   Helen Earis and Kearsy Cormier
pled with optional non-verbal and paralinguistic cues, such as co-speech gesture (McNeill 1992) and particular intonation patterns (Schleef 2003; Wennerstrom 2001). In direct discourse, the speaker gives a (presumably) verbatim account of what another speaker has said, whereas in indirect discourse, the speaker adapts what another speaker has said and relates it from his own point of view, as shown in Example 1.
(1) Direct discourse: You know, John told Lucy, “I don’t think the weather will be good today.” Indirect discourse: John told Lucy that the weather won’t be good today.
It is also suggested that spoken languages have a third type of reported speech used primarily in literary narratives and known variously as verschleierte Rede [veiled speech], free indirect style or represented speech. Utterances of this type are phrased from the point of view of the narrator, but the content reflects the character’s speech, thought or perception (Coulmas 1986). Banfield (1982) cites an example from Virginia Woolf’s Mrs. Dalloway to illustrate this phenomenon more clearly:
Mrs Dalloway said she would buy the flowers herself. For Lucy had her work cut out for her. The doors would be taken off their hinges; Rumpelmayer’s men were coming. And then, thought Clarissa Dalloway, what a morning – fresh as if issued to children on a beach. What a lark! What a plunge! For so it had always seemed to her when, with a little squeak of the hinges, which she could hear now, she had burst open the French windows and plunged at Bourton into the open air.
(Woolf 1925/2000: 1)
Banfield (1982) suggests that despite technically being told from the narrator’s point of view, this passage clearly allows the reader to experience Mrs Dalloway’s feelings. The utterances thought Clarissa Dalloway and so it had always seemed to her place the reader in Mrs Dalloway’s shoes.
In signed languages, it is claimed that changes in point of view can be marked using role shift, also known as referential shift, role shift, role play, shifting reference, constructed action and surrogate blends (e.g. Dudis 2004; Emmorey and Reilly 1995; Liddell 2003; Lillo-Martin 1995; Loew 1984; Metzger 1995). Role shift is a common device in sign language narrative discourse, where the signer imitates typically a human or animate referent by taking on one or more attributes of that referent, such as facial expression and/or body position (Loew 1984). Within role shift, verbs and pronouns which are marked for first person refer to the referent being portrayed rather than the signer. Role shift is most commonly marked
Downloaded from http:/www.cambridge.org/core. Lehrst F Alte Geschichte Hist Inst, on 27 Oct 2016 at 12:36:50, subject to the Cambridge Core terms of use, available at http:/www.cambridge.org/core/terms. http://dx.doi.org/10.1515/langcog-2013-0021

  Point of view in sign language and spoken narrative   315
by changes in non-manual features such as eye gaze or body position (EngbergPedersen 1993). Of all the linguistic devices that convey a change in point of view in spoken languages, direct discourse appears to be the most similar to role shift (Poulin and Miller 1995). However, some suggest that different types of role shift can be used in different linguistic situations. Engberg-Pedersen (1993), for example, suggests that role shift can be used not only to represent the dialogue of a referent other than the speaker, but also to achieve an effect similar to that of represented speech and thought in spoken languages, e.g. using a combination of a shift in body position and facial expressions. Furthermore, role shift need not refer to just a single referent; various articulators on the body may be partitioned such that different articulators may represent different referents (Dudis 2004).
There has been much discussion about the use of role shift in signed languages, particularly in terms of the syntactic role of pronouns and other indexic signs used within role shift (e.g. Kegl 1985; Lillo-Martin 1995; Quer 2005; Sandler and Lillo-Martin 2006). Indexing is a device commonly used in signed languages, whereby the signer points to a location in the signing space to refer to a person or object; this location then becomes associated with that person or object and remains so until the end of the discourse or until the signer explicitly changes that association. Noun signs can be accompanied by indexic pointing signs functioning as determiners, either simultaneously or sequentially. For example, in British Sign Language (BSL), a signer could be talking about her sister and then point to an area of the signing space to her right, as shown in Figure 1.1
Fig. 1: Use of a pointing sign functioning as a determiner to establish a location for a referent
1 The decision about where to establish the location of a referent may be motivated by the actual or a perceived location of the referent, or it may be arbitrary.
Downloaded from http:/www.cambridge.org/core. Lehrst F Alte Geschichte Hist Inst, on 27 Oct 2016 at 12:36:50, subject to the Cambridge Core terms of use, available at http:/www.cambridge.org/core/terms. http://dx.doi.org/10.1515/langcog-2013-0021

  316   Helen Earis and Kearsy Cormier
Fig. 2: Use of pointing sign functioning as a pronoun
This area of space, or locus, is now associated with the signer’s sister for the remainder of the discourse, or until it is actively changed. If the signer later referred back to her sister, she could use an indexic pointing sign functioning as a pronoun, as in Figure 2.
If the signer in Figure 2 were using role shift to take on the point of view of her sister, she would use a first person pronoun to refer to her sister, pointed at her own chest, instead of the third person pronoun shown in Figure 2. The role shift could take the form of a change in eye gaze or a particular facial expression or body position associated with the sister.
Some have suggested that the shift in body position that can denote the onset of role shift is a shift towards a previously established locus: that of the referent whose actions are being imitated (e.g. Lillo-Martin 1995). This lateral body shift is used in what Padden (1986) refers to as contrastive role shift in ASL – specifically, role shift used to contrast dialogue between two (and only two) referents. Padden also notes that there is another type of role shift: non-contrastive role shift, which may be used to depict the dialogue, thoughts or actions of any number of referents in a discourse, and involves changes in facial expression and eye gaze but not body position. This non-contrastive use of role shift is consistent with the ASL data analysed by Janzen (2004), in which a shift in body position was not necessarily a shift towards a locus. Instead, body shift reflected the body positions of the referents whose actions were being imitated. Janzen suggests that signers mentally rotate the scene in the discourse so that the signer’s perspective aligns with the perspective of the referent in the narrative. An example of this kind of rotation is shown in Figure 3; this is a scene where a car driver has tried to overtake a lorry but did not see the oncoming cyclist until the last minute. Figure 3a shows the scene from the cyclist’s point of view (with the car coming towards him), whereas Figure 3b shows the scene from the car driver’s point of view (with
Downloaded from http:/www.cambridge.org/core. Lehrst F Alte Geschichte Hist Inst, on 27 Oct 2016 at 12:36:50, subject to the Cambridge Core terms of use, available at http:/www.cambridge.org/core/terms. http://dx.doi.org/10.1515/langcog-2013-0021

  Point of view in sign language and spoken narrative   317
Fig. 3: Mental rotation: a cyclist versus car driver’s point of view
the cyclist coming towards him); the narrator mentally rotates his perspective to align with that of the referent. Within either of these points of view, a signer may use verbs of location and motion (also known as classifier constructions) to indicate the locations of the various referents in space relative to each other, and/or lexical signs and/or eye gaze directed toward particular locations in space.
Role shift is a technique often used in signed language narrative discourse. Research on narratives in signed languages has tended to focus only on sign (e.g. Bahan and Supalla 1995; Morgan 2002, 2006; Perniss 2007; Wilson 1996) rather than comparisons between sign and speech. While little comparative research between signed and spoken language has been undertaken in narrative discourse, particularly between BSL and spoken English, there are some crossmodal studies of narrative discourse between other signed languages and spoken English. Rayman (1999), for example, looked in detail at “The Tortoise and the Hare” fable in ASL and spoken English. She recruited five native ASL users and five native English speakers, matching them for age and educational background. After recruiting ASL participants, Rayman (1999) found that one had an extensive theatrical background. In order to match participants as equally as possi-
Downloaded from http:/www.cambridge.org/core. Lehrst F Alte Geschichte Hist Inst, on 27 Oct 2016 at 12:36:50, subject to the Cambridge Core terms of use, available at http:/www.cambridge.org/core/terms. http://dx.doi.org/10.1515/langcog-2013-0021

  318   Helen Earis and Kearsy Cormier
ble, she also recruited a hearing, non-signing actress as one of the native English speakers. All participants were asked to watch a silent cartoon and then tell the story in their own way.
Rayman (1999) found that the main difference between the ASL and spoken English narratives was the perspectives used by each storyteller. The ASL story­ tellers favoured a character’s (first person) perspective, whereas the spoken English users preferred the narrator’s (third person) perspective. Moreover, in contrast to the ASL users, the spoken English users rarely used facial expressions to depict character’s thoughts and feelings. Interestingly, only the hearing, non-signing actress used facial expression in a remotely similar way, but her facial expressions were still considerably less marked than those used by the ASL storytellers. In addition, the ASL storytellers depicted events in the story in a much more detailed manner than the spoken English storytellers, e.g. by indicating the manner of characters’ movements.
The less frequent use of expressive elements in spoken language storytelling has been mentioned in other comparative studies. Marentette, Tuck, Nicoladis and Pika (2004) and Marentette and Nicoladis (2008) suggest that ASL storytellers use more “embodied gestures” (role shift) in comparison to spoken English users. In addition, ASL storytellers tend to tell stories from a first person perspective and also tell longer stories, which is consistent with Rayman’s (1999) findings.
In their study, Marentette et al. (2004) suggest that cultural differences and/ or lack of experience in storytelling may account for some of the differences they noted in stories told in both English and ASL by participants from different backgrounds. Three groups were asked to watch a Pink Panther cartoon and tell it in ASL: deaf native signers from a deaf signing family, deaf late learners of ASL, and hearing native signers of ASL from deaf families. Two groups were also asked to tell the story in English: hearing native signers and sign-naïve native mono­ lingual English speakers.
Marentette et al. (2004) found that there was a marked difference in the length and number of “direct action” components (i.e. sections that denoted characters’ actions, thoughts or feelings) used by the different groups. The deaf native signers typically produced longer stories and more direct action components than those who were deaf late learners of ASL or native hearing ASL users. The native monolingual English speakers produced shorter stories than any of the ASL groups. Marentette et al. (2004) suggest ASL storytellers are able to recall and produce longer stories with more direct action components because deaf culture is one in which face-to-face storytelling highly valued, something which has also been suggested by other researchers (e.g. Ladd 2003; Peters 2000).
There have also been a number of other studies focusing on the use of gestures by spoken language users in narrative discourse that illustrate that speakers
Downloaded from http:/www.cambridge.org/core. Lehrst F Alte Geschichte Hist Inst, on 27 Oct 2016 at 12:36:50, subject to the Cambridge Core terms of use, available at http:/www.cambridge.org/core/terms. http://dx.doi.org/10.1515/langcog-2013-0021

  Point of view in sign language and spoken narrative   319
can draw on gestural resources in similar ways to signed language users. It is clear that speakers frequently gesture when they talk, whether in narrative or everyday discourse. Gestures are generally movements of the hands and arms and are closely linked to the speech itself (Cassell and McNeill 1991). Gestures can be conventionalised or non-conventionalised: for example, the thumbs-up gesture is a widespread gesture meaning “good” in the English-speaking world, but other gestures, such as those which naturally accompany the rhythm of speech, do not contain meaning in this way. A number of different ways of classifying gestures have been proposed (e.g. Ekman and Friesen 1969; Kendon 1980); the most widely used of which is presented in McNeill (1992), who recognises four major types of gesture: iconic, metaphoric, beat and deictics. Beats are meaningless gestures that accompany the rhythm of speech and deictics are pointing gestures. Iconic gestures depict an action or aspects of a character, e.g. a character running, and metaphoric gestures help explain an abstract concept.
Iconic gestures can be further broken down into character viewpoint gestures and observer viewpoint gestures (Cassell and McNeill 1991; McNeill 1992). Observer viewpoint gestures are gestures which depict the actions of a character from an outsider’s viewpoint, e.g. the use of a pointed index finger to trace the path of a character running across a room. Character viewpoint gestures, on the other hand, are gestures where the speaker uses his or her own body to represent some aspect of the character, e.g. by adopting the hand/body movements of a character running across a room. It is unclear what causes a speaker to select one type of gesture over another when telling a story, although Parrill (2009, 2010) has suggested that the event structure has a major influence on which type of viewpoint gesture is selected.
1.1 Aims and hypotheses
The aim of the current study is to examine and compare the strategies used in BSL and spoken English to mark point of view in narrative discourse in signers and speakers with similar storytelling skills.
Two main hypotheses will be tested in this study: firstly, as previous studies comparing narrative discourse in signed and spoken languages have found that signers prefer character (first person) perspectives and speakers prefer narrator (third person) perspectives when telling stories, it is hypothesised this will also occur in the BSL and spoken English data examined here.
The use of expressive elements such as co-speech gestures in spoken lan­ gu­age narrative has been widely documented (e.g. Holler and Wilkin 2009; McNeill 1992; Parrill 2009, 2010; So, Kita and Goldin-Meadow 2009; Sweetser 2007),
Downloaded from http:/www.cambridge.org/core. Lehrst F Alte Geschichte Hist Inst, on 27 Oct 2016 at 12:36:50, subject to the Cambridge Core terms of use, available at http:/www.cambridge.org/core/terms. http://dx.doi.org/10.1515/langcog-2013-0021

  320   Helen Earis and Kearsy Cormier
particularly in cartoon retellings. However, comparative studies of spoken and signed language users more generally suggest that although spoken language users can draw on gestural resources and facial expressions to achieve similar effects, they rarely do so. Therefore, the second hypothesis for this study is that the spoken English users will use little (if any) gesture or facial expressions to depict characters.
2 Methodology
The BSL data for this study were taken from the ECHO (European Cultural Heritage Online) corpus for signed languages (http://echo.mpiwg-berlin.mpg.de/home). This corpus is part of a larger European Union initiative to create a network of research institutes, archives and libraries, and provide a space on the internet for these institutes to publish corpora and knowledge. The corpus provides a variety of video data from four European signed languages, including recordings of stories and poems, as well as conversational data. Part of this project involved asking users of Swedish Sign Language (SSL), Sign Language of the Netherlands (NGT) and BSL to tell their own versions of five well-known fables: “The Boy Who Cried Wolf”, “The Dog and the Bone”, “The Lion and the Mouse”, “The Tortoise and the Hare” and “The Two Friends and the Bear”.
The video data for the BSL section of the ECHO corpus were collected by a team of researchers at City University London and the University of Bristol (Woll, Sutton-Spence and Waters 2004). The two participants in this corpus, B1 and B2, are both deaf and native signers of BSL. They were chosen to take part in the ECHO project because of their storytelling abilities; both are well-known in the British deaf community as experienced BSL storytellers. They were each provided with a short summary of each story in written English one week prior to being filmed, and were asked to use this time to read the summaries through and prepare their own versions of the fables based on these. Both participants were requested not to translate the stories verbatim but rather to tell the stories in their own way. The stories were recorded using a digital video camera directed at the upper body (Waters, personal communication).
For the spoken English data, experienced storytellers were recruited for the current study in order to match the level of storytelling experience across the two languages. Two participants, E1 and E2, were recruited from the Scottish Storytelling Centre in Edinburgh. As with the BSL users, both were given the same short written summaries of each story and asked to tell the stories in their own way to camera.
Downloaded from http:/www.cambridge.org/core. Lehrst F Alte Geschichte Hist Inst, on 27 Oct 2016 at 12:36:50, subject to the Cambridge Core terms of use, available at http:/www.cambridge.org/core/terms. http://dx.doi.org/10.1515/langcog-2013-0021

  Point of view in sign language and spoken narrative   321
2.1 Data coding
The data were annotated using ELAN (Eudico Linguistic Annotator), an annotation programme developed for the analysis of speech, sign language and gesture. ELAN allows the playback of video and/or audio data simultaneously with timealigned annotations, and users can create and edit annotations for these data on so-called ‘tiers’. Figure 4 shows a screenshot of ELAN with the video data in the top left-hand corner and the annotation tiers directly below.
Fig. 4: Screenshot of annotated BSL narrative within ELAN
The BSL data were coded by Woll et al. (2004) with fourteen different tiers in accordance with Nonhebel, Crasborn and van der Kooij’s (2004) sign language transcription conventions for the ECHO project. These tiers included gloss (a rough word-for-sign English translation), sign repetition, hand direction, spatial location, eyebrow movements, eye aperture, eye gaze, mouth movements, cheeks, role (i.e. which point of view the story is being told from, e.g. narrator, character, etc.) and full English translation. Not all of these tiers are relevant to the study of how point of view is marked, thus only the relevant tiers were ana­ lysed, namely the gloss, eye gaze, role and English translation tiers.
In order to be able to compare data across the two languages, the spoken English data were annotated for the same elements, i.e. role and eye gaze. A transcription of the spoken English data was made, and the data were also annotated for elements specific to spoken language, namely co-speech gestures and vocal prosodic elements. Table 1 below shows the tiers coded and analysed in both sets of data.
Downloaded from http:/www.cambridge.org/core. Lehrst F Alte Geschichte Hist Inst, on 27 Oct 2016 at 12:36:50, subject to the Cambridge Core terms of use, available at http:/www.cambridge.org/core/terms. http://dx.doi.org/10.1515/langcog-2013-0021

  322   Helen Earis and Kearsy Cormier

Table 1: List of tiers in both sets of data
BSL tiers
Eye gaze Eye aperture Role English translation Gloss RH Gloss LH

English tiers
Eye gaze Eye aperture Role English transcription Gesture RH Gesture LH Pitch Loudness Duration

Both sets of data also contain annotations within the gloss tiers (BSL) and transcription tiers (English) that were potentially useful for this study; these were nouns, pronouns and lexical items denoting mental state.
2.2 Tier values used for coding data
Each tier was coded using a different set of values. The BSL gloss and English transcription tiers involved word-for-word (or word-for-sign) transcription/translation of the data. Where the same tiers were coded in both the BSL and spoken English data, the same set of annotation values was used for each language. Table 2 shows the values used for coding the eye gaze, eye aperture and role tiers in both the BSL and spoken English data. Eye gaze, the direction in which a signer or speaker is looking, was annotated using values including left, right, upwards and downwards, and blinking for eye aperture. The “role” tier depicts the point of view from which the story is being told, i.e. when the participant took on the role of narrator or a particular character during the narrative. Data were annotated for three types of role: narrator, character, and a narrator/character mix. In spoken English, role was determined primarily by the type of pronouns used in a given section. If the participant used third person pronouns referring to the characters in the story and/or first person pronouns referring to him/herself, the role was coded as narrator. If the participant used first person pronouns referring to a character in the story within a direct quotation, role was coded as the respective character. There were also some sections where the participants used third person pronouns to refer to the characters in the story but other elements such as the participant’s facial expression, intonation or gestures indicated that the participant was at least partially viewing the scene from the perspective of a

Downloaded from http:/www.cambridge.org/core. Lehrst F Alte Geschichte Hist Inst, on 27 Oct 2016 at 12:36:50, subject to the Cambridge Core terms of use, available at http:/www.cambridge.org/core/terms. http://dx.doi.org/10.1515/langcog-2013-0021

  Point of view in sign language and spoken narrative   323

Table 2: Values used in coding the same tiers in both the BSL and spoken English data

Eye gaze
Eye aperture Role

l-90 l r-90 r u d lh rh bh p c
b
Narrator Character Narrator/Character

left, close to 90 degrees (of midsaggital plane) left, close to 45 degrees (of midsaggital plane) right, close to 90 degrees (of midsaggital plane) right, close to 45 degrees (of midsaggital plane) upwards downwards to the left hand to the right hand to both hands towards a person present towards the camera
(eye aperture) blink
section told from the perspective of the participant section told from the perspective of a character section told from the perspective of both narrator (participant) and character

character by displaying, e.g. a character’s thoughts or feelings. In these cases, role was coded as narrator/ character.2
In BSL, role was defined using pronouns, as well as whether or not role shift was being used. When no role shift was used, the role was coded using the default value of narrator. The role was coded as character when the participant used role shift, i.e. the participant’s facial expressions and body position made it clear that he/she had taken on the role of a character. Finally, narrator/character role was coded when the participant was telling the story from the perspective of the narrator but some elements of role shift were also present, e.g. facial expression denoting a particular character.
The spoken English data were additionally coded for co-speech gesture and vocal prosodic elements. Table 3 shows the values used to code these tiers. Gestures were classified according to McNeill (1992): i.e. iconic, metaphoric, beat and deictics. As noted previously, beats are meaningless gestures that accompany the rhythm of speech and deictics are pointing gestures. Iconic gestures were coded whenever a speaker depicted an action or aspects of a character, e.g. a character running, and metaphoric gestures were coded whenever a speaker used gestures to help explain an abstract concept.

2 Cf. also Dudis’s (2004) concept of “body partitioning”, whereby a signer can use different parts of the body to represent different characters.

Downloaded from http:/www.cambridge.org/core. Lehrst F Alte Geschichte Hist Inst, on 27 Oct 2016 at 12:36:50, subject to the Cambridge Core terms of use, available at http:/www.cambridge.org/core/terms. http://dx.doi.org/10.1515/langcog-2013-0021

  324   Helen Earis and Kearsy Cormier

Table 3: Values used in coding tiers for co-speech gesture and vocal prosodic elements

Gesture RH/LH
Pitch
Loudness Duration

b

beat gesture (co-speech gesture that coincides with the rhythmic

action of speech)

d

deictic gestures (pointing at someone/an object)

m

metaphoric gesture (depicts an image but of an abstract concept)

i

iconic gesture (depicts the scene being described in speech)

hp high pitch (where pitch differs noticeably from speaker’s normal

pitch)

lp

low pitch

rp

rising pitch

fp

falling pitch

l

a word or syllable sounds louder than what is typical for that

speaker e.g. if emphasis is being placed on a particular word

d

the duration of a word is longer than what is typical for that

speaker e.g. it took a loooong time

The main prosodic features of spoken language are tone, stress and duration, the phonetic correlates of which are pitch, loudness and duration. Loudness and duration were coded using the values l and d respectively. These elements were coded whenever the speaker’s voice differed from what was typical for that speaker, e.g. loudness when a word was spoken noticeably louder than was typical for that speaker, and duration when a word or phrase was noticeably longer or shorter length than normal. Pitch was again coded whenever the pitch of the speaker’s voice differed noticeably from what was typical for that speaker. Changes in pitch were coded for high or low pitch (hp, lp), rising pitch (rp) or falling pitch (fp).

2.3 Intercoder reliability
A second coder was instructed in how to use ELAN and the values being used for each of the tiers. This coder was asked to code two minutes of one story (i.e. approximately 20% of the English data) in order to see whether the coding done for the English data accurately and consistently followed the system outlined above. Coding done by the second coder resulted in the same coding at the same points in the story for each tier, except for a few slight differences in overall duration of some annotations; some annotations were a few milliseconds longer or shorter than the annotations. However, given the categories coded were the same, this provided some validation of the coding undertaken for the English data.

Downloaded from http:/www.cambridge.org/core. Lehrst F Alte Geschichte Hist Inst, on 27 Oct 2016 at 12:36:50, subject to the Cambridge Core terms of use, available at http:/www.cambridge.org/core/terms. http://dx.doi.org/10.1515/langcog-2013-0021

  Point of view in sign language and spoken narrative   325
3 Results
In order to compare how point of view is marked in BSL and spoken English in “The Tortoise and the Hare”, role will be examined first, as this forms the basis for analysing other elements that may help to mark point of view, such as eye gaze.
3.1 Role
As described in section 2.1.3, three types of role were coded: narrator, narrator/ character and character. Figure 5 shows the percentage of time each storyteller spent telling the story from each perspective.
This graph shows that the English storytellers spend a greater percentage of time telling the story from the narrator’s perspective (44.48% for E1 and 64.78% for E2 compared to 22.69% and 18.53% for B1 and B2), whereas the BSL storytellers, particularly B2, spend a greater percentage of time telling the story from a character’s perspective (42.35% for B1 and 76.91% for B2 compared to 38.04% for E1 and 23.4% for E2). This suggests that the BSL storytellers prefer telling this story from a different perspective compared to the spoken English storytellers.
The following section compares and contrasts the various elements that may be used in individual roles to help express point of view in both languages, namely (pro)nominal elements, eye gaze, lexical items denoting mental state and – for spoken English – co-speech gestures and vocal prosodic elements. The first and most important of these are (pro)nominal elements.
Fig. 5: Percentage of time spent telling story from each perspective
Downloaded from http:/www.cambridge.org/core. Lehrst F Alte Geschichte Hist Inst, on 27 Oct 2016 at 12:36:50, subject to the Cambridge Core terms of use, available at http:/www.cambridge.org/core/terms. http://dx.doi.org/10.1515/langcog-2013-0021

  326   Helen Earis and Kearsy Cormier
3.2 (Pro)nominal
Both the BSL and spoken English stories were analysed for the number of pronouns used in each story and whether these referred to speaker/signer, addressee or non-addressed participants. Figure 6 shows the percentage of pronouns used by each participant. It can be seen that there are individual differences across narratives in each language; E1 and B1, for example, use more pronouns in character roles than E2 and B2 respectively: E1 uses 31 pronouns in character roles compared to E2’s 25, and B1 uses 25 pronouns in character roles compared to B2’s 8. Figure 7 shows the breakdown of these pronouns into first, second and third person.3
Figure 7 shows that the most striking difference between the two languages is the extensive use of third person pronouns in spoken English; this suggests that third person pronouns are a device which spoken English storytellers rely on heavily to refer and maintain reference to characters throughout the course of a narrative. In the BSL data, the situation appears to be different. B2 does not use any third person pronouns in his narrative, whereas B1 uses some in narrator and narrator/character roles. Thus, like E1 and E2, B1 also uses third person pronouns to maintain reference to characters, though not to the same degree.
Fig. 6: Percentage of pronouns used in each role type
3 There is some debate in the signed language literature as to whether the labels first, second and third person are used appropriately for signed languages (see Cormier 2012 for a review). However, these labels are used here in order to facilitate comparison between the two languages.
Downloaded from http:/www.cambridge.org/core. Lehrst F Alte Geschichte Hist Inst, on 27 Oct 2016 at 12:36:50, subject to the Cambridge Core terms of use, available at http:/www.cambridge.org/core/terms. http://dx.doi.org/10.1515/langcog-2013-0021

  Point of view in sign language and spoken narrative   327
Fig. 7: Distribution of first, second and third person pronouns
In spoken English, third person pronouns are normally used in addition to full noun phrases to maintain reference, as third person pronouns refer back to noun phrases previously mentioned in the discourse. In these data, the spoken English storytellers used a greater number of nouns to refer to characters and maintain a particular perspective than the BSL storytellers. Figure 8 shows the overall number of nouns used to refer to characters by both the spoken English and BSL storytellers: E1 uses 16 nouns, E2 uses 22 nouns, B1 uses 10 nouns and B2 uses 13 nouns.
Fig. 8: Use of nouns in narratives
Downloaded from http:/www.cambridge.org/core. Lehrst F Alte Geschichte Hist Inst, on 27 Oct 2016 at 12:36:50, subject to the Cambridge Core terms of use, available at http:/www.cambridge.org/core/terms. http://dx.doi.org/10.1515/langcog-2013-0021

  328   Helen Earis and Kearsy Cormier
In BSL, the situation is rather different. The BSL pronouns in these data consist of indexic pointing signs. As mentioned in section 1, signers can direct an indexic sign – either a pronoun or determiner – towards the location associated with that referent to establish and maintain reference to a referent. In these data, indexic signs functioning as either determiners or third person pronouns occurred only in B1’s narrative.
In this narrative, maintenance of reference is closely linked to the deter­ miners B1 uses with the noun signs HARE and TORTOISE in the first (narrator) role. With the noun sign HARE, she directs the accompanying determiners to her left as shown in Figure 9. Likewise, with TORTOISE, she directs the accompanying determiners to her right. Subsequent reference to either of these characters is then made using these locations, e.g. by directing a third person pronoun to her left to indicate the hare.
Fig. 9: Establishment of reference for the hare in B1’s narrative
The use of indexic signs appears to be an individual choice of the storyteller, given that no determiners are used in B2’s narrative. It may be that B2 uses other devices to maintain reference to characters and convey point of view, such as eye gaze. In signed languages, maintenance of reference using indexic signs is often closely linked to the use of eye gaze (e.g. Zimmer and Patschke 1990; Metzger 1998; Engberg-Pedersen 2003). The use of eye gaze to signal a change in point of view has been widely reported in the literature (e.g. Loew 1984; Padden 1986; Bahan and Supalla 1995; Kegl 1995) and is discussed in the following section.
3.3 Observations on the use of eye gaze
In B1’s narrative, the use of eye gaze is closely linked to the storyteller’s use of indexic signs; the location for the hare is to the signer’s left and upwards, and the
Downloaded from http:/www.cambridge.org/core. Lehrst F Alte Geschichte Hist Inst, on 27 Oct 2016 at 12:36:50, subject to the Cambridge Core terms of use, available at http:/www.cambridge.org/core/terms. http://dx.doi.org/10.1515/langcog-2013-0021

  Point of view in sign language and spoken narrative   329
location for the tortoise is to the signer’s right and downwards (see also Figure 9). In roles containing direct discourse between the hare and the tortoise, eye gaze is directed towards these locations to show that the hare is addressing the tortoise or vice versa. The same occurs in B2’s narrative. Although B2 does not set up locations for the tortoise and the hare using indexic signs, he also directs his eye gaze towards the right and downwards when portraying the hare addressing the tortoise, and to the left and upwards when portraying the tortoise addressing the hare. An example of this is shown in Figure 10.
Figure 10 highlights that it is not just eye gaze that is important in differentiating characters, but also the use of non-manual features such as facial expression and body position. Here, B1 has adopted the facial expression, head position and body position of the hare. In sequences told from the point of view of a character that do not involve dialogue, facial expression (including eye gaze and eye aperture) can be used as part of the overall portrayal of a character, as seen in Figure 11.
Fig. 10: B2’s use of eye gaze in role of hare addressing tortoise
Fig. 11: Use of eye gaze as part of role shift in B2’s narrative
Downloaded from http:/www.cambridge.org/core. Lehrst F Alte Geschichte Hist Inst, on 27 Oct 2016 at 12:36:50, subject to the Cambridge Core terms of use, available at http:/www.cambridge.org/core/terms. http://dx.doi.org/10.1515/langcog-2013-0021

  330   Helen Earis and Kearsy Cormier
In contrast, neither spoken English storyteller consistently uses a particular eye gaze direction in direct discourse to show, e.g. the hare addressing the tortoise. However, like BSL, eye gaze is used in the spoken English narratives as part of the overall portrayal of a character in role shift. In E1’s narrative, for example, eye gaze is used when the storyteller is portraying the hare speaking to the tortoise about the small size of the tortoise’s feet in comparison to the hare’s large feet (see Figure 12). She directs her eye gaze downwards as if looking at the tortoise’s feet.
Fig. 12: Use of eye gaze as part of role shift in E1’s narrative
However, usage of eye gaze and space in the way shown above is not consistent; the speaker in Figure 12, for example, does not consistently use this particular location/eye gaze combination to refer to the tortoise throughout the discourse.
3.4 U sage of other elements to denote point of view in both languages
Eye gaze in both BSL narratives is consistently accompanied by a change in body position and/or head position towards the location associated with the respective character (e.g. Figure 9 above). Rather than imitating specific body postures of referents, head and body position in the BSL narratives appear to be closely related to the use of space and also to eye gaze; the head and body are consistently directed towards the locations associated with specific characters. This use of lateral body shift depicting the dialogue, thoughts and actions of two referents is consistent with Padden’s (1986) notion of contrastive role shift as described above in Section 1.
Downloaded from http:/www.cambridge.org/core. Lehrst F Alte Geschichte Hist Inst, on 27 Oct 2016 at 12:36:50, subject to the Cambridge Core terms of use, available at http:/www.cambridge.org/core/terms. http://dx.doi.org/10.1515/langcog-2013-0021

  Point of view in sign language and spoken narrative   331
Head and body movements also occur in the spoken English narratives, but because particular locations within the speaker’s physical space have not been set up for individual characters, neither speaker orients him/herself consistently towards a particular location to denote a particular character.
Other elements which may also help to mark a change in point of view include facial expression. Facial expression in both signers and non-signers can be used to denote a character’s thoughts or feelings, as seen in Figure 13, where the storyteller is portraying the hare ridiculing the tortoise’s claim that he can beat the hare in a race.
Facial expressions in BSL can be used either grammatically (e.g. a questioning facial expression with raised eyebrows signalling that the signer is asking a polar question) or for affect to denote a character’s (or the signer’s own) thoughts or feelings, as shown in Figure 14. Observation of the data shows remarkable similarities between the affective facial expressions used by the spoken English
Fig. 13: Example of the use of affective facial expression depicting the hare in E1’s narrative
Fig. 14: Affective facial expression depicting the hare in B1’s narrative
Downloaded from http:/www.cambridge.org/core. Lehrst F Alte Geschichte Hist Inst, on 27 Oct 2016 at 12:36:50, subject to the Cambridge Core terms of use, available at http:/www.cambridge.org/core/terms. http://dx.doi.org/10.1515/langcog-2013-0021

  332   Helen Earis and Kearsy Cormier
storytellers with those used for the same purpose by the BSL storytellers. Contrast Figure 14 from B1’s narrative with Figure 13: like E1, B1’s facial expression is portraying the hare ridiculing the tortoise’s claim that he can beat the hare in a race.
3.5 E lements that occur only in the spoken English narratives
Co-speech gestures and vocal prosodic elements were only coded in the spoken English data. The issue of whether and to what extent signers gesture is an issue under much debate within the field of sign linguistics (e.g. Emmorey 1999; Liddell 2003). For sake of simplicity, only gestures used by the non-signers will be reported here, although any parallels between spoken and signed data in this respect will be discussed.
3.5.1 Co-speech gestures Figures 15 and 16 below show the number of tokens of each type of gesture that occur in each role type. Figure 15 shows the data from E1’s narrative and Figure 16 the data from E2’s narrative.
Beat and iconic gestures are the most frequent type of gesture in the spoken English narratives: E1 uses 26 beat gestures and 11 iconic gestures overall, whereas E2 uses 21 beat gestures and 15 iconic gestures in total. Deictic gestures also occur in both narratives, but the number of instances of these gestures is much lower (E1 uses 4 and E2 uses 3), and no metaphoric gestures are used in either narrative.
Fig. 15: Percentage of gestures used in each role type in E1’s narrative
Downloaded from http:/www.cambridge.org/core. Lehrst F Alte Geschichte Hist Inst, on 27 Oct 2016 at 12:36:50, subject to the Cambridge Core terms of use, available at http:/www.cambridge.org/core/terms. http://dx.doi.org/10.1515/langcog-2013-0021

  Point of view in sign language and spoken narrative   333
Fig. 16: Percentage of gestures used in each role type in E2’s narrative
Beat gestures, the most frequent type of gesture in both narratives, are described by Cassell and McNeill (1991) as the most insignificant looking but also the most revealing gestures. Although the gesture itself is intrinsically meaningless, consisting of a flick or a wave of the hands upwards or sideways, beat gestures, as their name implies, follow the rhythm of speech. One example of this is shown in Figure 17.4 E1 is introducing the story he is about to tell; the beat gesture starts from a clasped hand position on “my second story”, moves outwards on “tortoise” and back inwards on “and a hare”.
Beat gestures are not continuously used throughout the narrative in these data; they appear to be used to signify that a particular word or section is particularly important. Cassell and McNeill (1991) describe this usage of beat gestures as “momentary indexing”, in that they are used to link to or focus on some part of the narrative structure, such as the introduction of new characters. The beat gestures in these data are used in this way, and also sometimes coincide with the use of vocal prosodic elements such as loudness, as is the case with Figure 17. In this case, the storyteller amplifies his voice on the word “tortoise”.
Deictic gestures can also be used by speakers to focus attention on a part of the narrative. Moreover, there is an interesting parallel with the use of deic-
4 It is possible that some of the gestures coded as “beats” (such as in Figure 17) may be better considered as “conduit” metaphoric gestures, which have been described as helping to frame narratives. A common conduit metaphoric gesture is the use of a cupped hand which seems to “contain” a topic, a character, etc. (or even the narrative itself) and offer it to the listener (Cassell and McNeill 1991, McNeill 1992). As Kendon (2004) notes, it can be difficult to identify gestures as belonging to unique categories. The important point for the current study is that these gestures, whether beats or metaphoric conduit gestures, did not occur in the sign language data.
Downloaded from http:/www.cambridge.org/core. Lehrst F Alte Geschichte Hist Inst, on 27 Oct 2016 at 12:36:50, subject to the Cambridge Core terms of use, available at http:/www.cambridge.org/core/terms. http://dx.doi.org/10.1515/langcog-2013-0021

  334   Helen Earis and Kearsy Cormier
Fig. 17: The use of a beat gesture for emphasis in E2’s narrative
tic gestures to point to fictional characters in the English narratives and indexic signs in the BSL narratives. In E1’s narrative, Figure 12 shows an example of the use of a deictic gesture. Although the spoken English storytellers do not make associations between referents and specific locations in space, they still appear on occasion to use the space in front of them using remarkably similar forms for similar functions. The deictic gesture in Figure 12 above occurs with the second person pronoun “you” (singular) and is analogous to the indexic signs used for pronominal reference in the BSL narratives (e.g. Figure 10). However, the fundamental difference between the two is that the deictic gestures are not required in the spoken English narratives as the information is also conveyed using the pronoun and not the deictic gesture alone, whereas in BSL the indexic sign in such cases is the pronoun.
Another interesting similarity between the spoken English and BSL story­ tellers is in the use of iconic gestures; some of the iconic gestures used in the English narratives bear remarkable similarities to the production of role shift in the BSL narratives. In E2’s narrative, for example, the storyteller uses iconic gestures to depict the tortoise moving slowly (see Figure 18).
These gestures are similar to the role shift used in one of the BSL narratives (see Figure 19). This is an interesting parallel as it highlights the way in which gestural resources are used across the two languages. Meir, Padden, Aronoff and Sandler (2007) suggest that in such cases in sign languages, the signer’s body acts as the subject of the action. However, under their argumentation, this would also mean that spoken language users’ bodies could also act as the subject argument in similar situations, e.g. in Figure 18 shown above. This poses an interesting
Downloaded from http:/www.cambridge.org/core. Lehrst F Alte Geschichte Hist Inst, on 27 Oct 2016 at 12:36:50, subject to the Cambridge Core terms of use, available at http:/www.cambridge.org/core/terms. http://dx.doi.org/10.1515/langcog-2013-0021

  Point of view in sign language and spoken narrative   335
Fig. 18: The use of iconic gestures in E2’s narrative to depict the tortoise
question: is the body acting as subject in Fig. 19 because it is embedded within sign language use, but not in Fig. 18 because it is a gestural component used alongside speech? We would argue that the body is not acting as subject in either case. With the spoken example, there would likely be a subject expressed in the speech as English is not an argument drop language and generally subjects are expected to occur. With the signed example, the signer may indeed express the subject with a lexical NP before the role shift, in the same way as in English. This might not necessarily occur, but if it does not, it is more likely to be due to the fact that BSL, like many signed and spoken languages, is a language that allows the subject to be dropped (Cormier, Smith and Zwets 2013).
Fig. 19: Depiction of the tortoise in B2’s narrative
Downloaded from http:/www.cambridge.org/core. Lehrst F Alte Geschichte Hist Inst, on 27 Oct 2016 at 12:36:50, subject to the Cambridge Core terms of use, available at http:/www.cambridge.org/core/terms. http://dx.doi.org/10.1515/langcog-2013-0021

  336   Helen Earis and Kearsy Cormier
3.5.2 Vocal prosodic elements Figures 20 and 21 show the percentage of change in pitch, duration and loudness used in each role type. It can be seen that a change in pitch, duration or loudness does not occur consistently in a particular role type. This, coupled with the differences between the two participants, suggests that changes in vocal prosodic elements are, like co-speech gestures, more closely related to the content or the structure of the discourse than any particular point of view type.
Fig. 20: Vocal prosodic elements in E1’s narrative
Fig. 21: Vocal prosodic elements in E2’s narrative
Downloaded from http:/www.cambridge.org/core. Lehrst F Alte Geschichte Hist Inst, on 27 Oct 2016 at 12:36:50, subject to the Cambridge Core terms of use, available at http:/www.cambridge.org/core/terms. http://dx.doi.org/10.1515/langcog-2013-0021

  Point of view in sign language and spoken narrative   337
Changes in loudness seem to be used for placing emphasis on important points in the story. In Example 2, the words in bold signify where an increase in loudness occurs:
(2) E1 (Narrator role): “And my next story is the tortoise and the hare.”
Changes in duration of words or phrases more closely reflect the content of the discourse than any other prosodic element. In both narratives, the storytellers alter the duration of words or phrases when describing the movement of characters. E1, for example, slows her speech down when describing the tortoise moving down the course, causing an overall decrease in duration. Example 3 below shows changes in duration marked in bold. She starts by speaking slowly to emphasise how slowly the tortoise moves, but speeds up the closer the tortoise gets to the finish line. This is an example of what Okrent (2002) refers to as a “vocal gesture”, i.e. the use of vocal characteristics to evoke imagery. In this case, the increasing speed of E1’s speech depicts the increasing speed with which the tortoise moves toward the finish line. Both the vocal gestures and the lexical items they occur with display iconicity.
(3)
Changes in duration of individual words or phrases can also be used to mark the beginning of utterances, particularly in E1’s narrative. E1 sometimes uses a longer duration for a word at the beginning of a sentence to emphasise that this is a new section. In Example 4, the point at which the storyteller uses a change in duration to mark a new sentence is marked in bold:
(4) And the hare was always admiring his big feet and how fast he could run. And he would be always saying to the tortoise . . .
Changes in pitch are particularly interesting from a referential point of view. In storytelling, storytellers sometimes adopt different voices for different characters, e.g. a higher pitched voice for a younger character contrasting with a lower pitched voice for an older character, particularly in stories told to children (e.g. Wennerstrom 2001). A storyteller can therefore use a change in pitch to mark a change in point of view. In these data, both storytellers used a change in pitch to signify the use of constructed dialogue by characters, as in Example 5 below:
Downloaded from http:/www.cambridge.org/core. Lehrst F Alte Geschichte Hist Inst, on 27 Oct 2016 at 12:36:50, subject to the Cambridge Core terms of use, available at http:/www.cambridge.org/core/terms. http://dx.doi.org/10.1515/langcog-2013-0021

  338   Helen Earis and Kearsy Cormier
(5)
However, a change in pitch was not consistently used in this way each time there was a section containing direct discourse. While the “default” pitch used for imitation of characters was a high pitch in both narratives, both storytellers sometimes used a lower pitch for the tortoise and a contrasting higher pitch for the hare, although the lower pitch was never used for the hare. Thus, while the use of a change in pitch was used in character roles in these narratives to mark characters’ speech, it was not used consistently in all character roles, nor was it consistently used to mark a change between different characters.
In E2’s narrative, a change in pitch was also used when describing certain actions such as “to leap”. Example 6 shows how the storyteller uses a rise in pitch on the word “leap” and a higher pitch on the word “huge”. The rise in pitch on “leap” could be another example of a vocal gesture (Okrent 2002) as it evokes imagery of upward movement consistent with the concept of leaping. (6)
4 Discussion and conclusions
This analysis of one narrative produced by four storytellers has given useful insights into the differences and similarities between BSL and spoken English narrative discourse. Although the narratives exhibit individual differences, these data suggest that the fundamental markers of point of view in spoken English are nouns and pronouns, whereas the main marker of point of view in BSL is eye gaze.
Downloaded from http:/www.cambridge.org/core. Lehrst F Alte Geschichte Hist Inst, on 27 Oct 2016 at 12:36:50, subject to the Cambridge Core terms of use, available at http:/www.cambridge.org/core/terms. http://dx.doi.org/10.1515/langcog-2013-0021

  Point of view in sign language and spoken narrative   339
As hypothesised, the spoken English storytellers preferred telling this story from the narrator’s point of view, whereas the BSL storytellers preferred the character’s perspective. This is commensurate with what has been found in previous literature for other signed languages, e.g. Marentette and Nicoladis (2008) for ASL. The current study takes these previous findings one step further by showing that the structural differences between the BSL and English narratives occur even when participants are matched for storytelling ability However, more research would be needed to determine whether these differences occur with other storytellers or different types of stories (e.g. those with more or fewer characters) and indeed whether the structure of a story has any influence on the choice of character vs. observer viewpoint gestures as suggested by Parrill (2009, 2010).
The hypothesis that the spoken English participants would use few cospeech gestures and facial expressions to depict characters was not confirmed. Both spoken English storytellers used vocal prosodic elements and co-speech gestures in a creative way to enrich the narrative discourse. Some co-speech gestures, particularly iconic and deictic gestures, bear remarkable similarities to the use of role shift and pronouns (respectively) in the BSL data.
The considerable use of co-speech gestures and vocal prosodic elements in these spoken English data may be due to the fact that both participants were experienced storytellers. Although McNeill (1992) and Cassell and McNeill (1991) have found that speakers frequently use co-speech gesture in cartoon retellings, previous studies comparing signed and spoken languages suggest that spoken English storytellers typically do not use many co-speech gestures or facial expressions to depict characters, even when they have some experience of performing to an audience (e.g. Rayman 1999; Marentette et al. 2004). Although there are many other factors that may influence whether or not individuals use co-speech gestures or facial expressions in stories, it appears that experience of storytelling, or immersion in a community or group where storytelling is valued (in this case, the Scottish Storytelling Centre), may have an effect on the way in which characters are depicted in spoken language stories.
This is also an important point to make here with respect to signed languages. Previous studies have illustrated that if participants are not matched for storytelling ability, there are clear differences in the extent to which character depictions are used in each of the two modalities. Spoken language users tend to use fewer expressive elements relative to signed language users. This would suggest that signed language users are more skilled storytellers at the outset. There are a number of reasons why this may be the case. Some researchers have noted that signers are exposed to a rich storytelling culture (e.g. Ladd 2003), which may mean that they are more likely to become skilled in telling stories full of expressive detail in a way that spoken language users do not unless they are exposed
Downloaded from http:/www.cambridge.org/core. Lehrst F Alte Geschichte Hist Inst, on 27 Oct 2016 at 12:36:50, subject to the Cambridge Core terms of use, available at http:/www.cambridge.org/core/terms. http://dx.doi.org/10.1515/langcog-2013-0021

  340   Helen Earis and Kearsy Cormier
to a similar culture of storytelling, as evidenced by the two participants in this study. Another aspect suggested by Slobin (1996) is that the spatial nature of signed languages may make it easier for signers to depict characters in a rich and expressive way.
There is, however, an importance difference between the two languages in this respect: although both languages have a pool of resources they can draw on for storytelling, some of the elements used by the BSL storytellers to depict characters’ actions are clearly more conventionalised than those used by the spoken English storytellers. Depicting characters using expressive elements such as cospeech gesture does not always occur in spoken English, but depicting characters through the use of role shift appears to be a very important element of storytelling in signed narratives. Quinto-Pozos (2007a, 2007b) raises the question of whether role shift can be considered obligatory in signed languages, what elicits role shift in certain contexts, and whether or not role shift is linguistic or gestural. He suggests that the use of role shift may be obligatory in some contexts and that signed language users appear to prefer the use of role shift over other resources that could be used to depict the same actions, e.g. classifier constructions. This is a relatively unexplored area in signed language research, but one that requires further investigation, particularly in terms of determining precisely which elements are more conventionalised and which are less conventionalised.
Given that there are some remarkable similarities in the depiction of characters in both languages, our main conclusion therefore is that signers and speakers have a pool of resources to draw upon in the construction of narratives, but signers would appear to have a richer range of resources to draw upon when presenting visual events or action. Our data provide some evidence to support these claims, in that the BSL storytellers have a range of resources at their disposal and there appears to be some degree of flexibility in which resources they can use. This is not the case in spoken English, where storytellers prefer the narrator viewpoint and consistently use third person pronouns for reference. However, our study indicates that there are some resources, such as co-speech gestures and vocal prosodic elements, that speakers can draw on and use creatively, and which can be used in a similar way to BSL. These similarities highlight the importance of the multimodal nature of face-to-face interaction. Comparisons between signed and spoken language must take into consideration gesture and vocal prosodic elements, rather than just the classic linguistic characteristics which are the exclusive focus of much work in mainstream approaches to the study of language.
Acknowledgments: We thank Sandra Smith for acting as the model in Figures 1 and 2. We also thank Dafydd Waters for information about the methodology used
Downloaded from http:/www.cambridge.org/core. Lehrst F Alte Geschichte Hist Inst, on 27 Oct 2016 at 12:36:50, subject to the Cambridge Core terms of use, available at http:/www.cambridge.org/core/terms. http://dx.doi.org/10.1515/langcog-2013-0021

  Point of view in sign language and spoken narrative   341
in collecting the BSL data for the ECHO project as described in §2 and Jordan Fenlon for helping with coding.
This research was supported by an Arts and Humanities Research Council doctoral award to Helen Earis (award no. 104505) and by the Economic and Social Research Council of Great Britain (Grant RES-620-28-6001), Deafness, Cognition and Language Research Centre (DCAL).
References
Bahan, B. & S. Supalla. 1995. Line Segmentation and Narrative Structure: A Study of Eyegaze Behavior in American Sign Language. In K. Emmorey & J. Reilly (eds.), Language, Gesture and Space, 171–191. Mahwah, NJ: Lawrence Erlbaum.
Banfield, A. 1982. Unspeakable Sentences: Narration and representation in the language of fiction. Boston, MA: Routledge & Kegan Paul Ltd.
Cassell, J. & D. McNeill. 1991. Gesture and the Poetics of Prose. Poetics Today 12(3). 375–404. Cormier, K. 2012. Pronouns. In R. Pfau, M. Steinbach & B. Woll (eds.), Sign language: An
international handbook, 227–244. Berlin: Mouton de Gruyter. Cormier, K., S. Smith & M. Zwets. 2013. Framing constructed action in British Sign Language
narratives. Journal of Pragmatics 55. 119–136. Coulmas, F. 1986. Direct and Indirect Speech. Berlin: Mouton de Gruyter. Dudis, P. G. 2004. Body partitioning and real-space blends. Cognitive Linguistics 15(2).
223–238. Ekman, P. & W. V. Friesen. 1969. The repertoire of nonverbal behavior: categories, origins,
usage and coding. Semiotica 1. 49–98. Emmorey, K. 1999. Do signers gesture? In R. Campbell & L. Messing (eds.), Gesture, Speech,
and Sign, 133–159. Oxford: Oxford University Press. Emmorey, K. & J. S. Reilly. 1995. Theoretical Issues Relating Language, Gesture and Space:
An Overview. In K. Emmorey and J. Reilly (eds.), Language, Gesture and Space, 1–16. Hillsdale, New Jersey: Lawrence Erlbaum Associates. Engberg-Pedersen, E. 1993. Space in Danish Sign Language: The Semantics and Morphosyntax of the Use of Space in a Visual Language (Vol. 19). Hamburg: Signum Verlag. Engberg-Pedersen, E. 2003. From pointing to reference and predication: pointing signs, eyegaze, and head and body orientation in Danish Sign Language. In S. Kita (ed.), Pointing: where language, culture, and cognition meet, 269–292. Mahwah, NJ: Lawrence Erlbaum. Holler, J. & K. Wilkin. 2009. Communicating common ground: How mutually shared knowledge influences speech and gesture in a narrative task. Language and Cognitive Processes 24(2). 267–289. Janzen, T. 2004. Space rotation, perspective shift and verb morphology in ASL. Cognitive Linguistics 15(2). 149–174. Kegl, J. 1985. Locative Relations in American Sign Language Word Formation, Syntax, and Discourse. Cambridge, MA: MIT doctoral dissertation. Kegl, J. 1995. The Manifestation and Grammatical Analysis of Clitics in American Sign Language. Chicago Linguistic Society 31(2). 140–167.
Downloaded from http:/www.cambridge.org/core. Lehrst F Alte Geschichte Hist Inst, on 27 Oct 2016 at 12:36:50, subject to the Cambridge Core terms of use, available at http:/www.cambridge.org/core/terms. http://dx.doi.org/10.1515/langcog-2013-0021

  342   Helen Earis and Kearsy Cormier
Kendon, A. 1980. Gesticulation and speech: two aspects of the process of utterance. In M. R. Key (ed.), The Relationship of Verbal and Nonverbal Communication, 207–227. The Hague: Mouton.
Kendon, A. 2004. Gesture: Visible Action as Utterance. Cambridge: Cambridge University Press. Ladd, P. 2003. Understanding deaf culture: in search of deafhood. Clevedon: Multilingual
Matters. Liddell, S. 2003. Grammar, Gesture and Meaning in American Sign Language. Cambridge:
Cambridge University Press. Lillo-Martin, D. 1995. The Point of View Predicate in American Sign Language. In K. Emmorey & J.
Reilly (eds.), Language, Gesture and Space, 155–170. Hillsdale, NJ: Lawrence Erlbaum. Loew, R. C. 1984. Roles and Reference in American Sign Language: A Developmental
Perspective. Minnesota: University of Minnesota doctoral dissertation. Meir, I., C. Padden, M. Aronoff & W. Sandler. 2007. Body as subject. Journal of Linguistics 43.
531–563. Marentette, P. & E. Nicoladis. 2008. Iconicity and simultaneity in the gesture-language link: A
comparison of ASL signers and English speakers. Paper presented at the 30. Jahrestagung der deutschen Gesellschaft für Sprachwissenschaft, University of Bamberg, 26–29 February. Marentette, P., N. Tuck, E. Nicoladis & S. Pika. 2004. The Effects of Language, Culture and Embodiment on Signed Stories. Paper presented at Theoretical Issues in Sign Language Research 8, University of Barcelona, 30 September – 2 October. McNeill, D. 1992. Hand and Mind. Chicago: University of Chicago Press. Metzger, M. 1995. Constructed dialogue and constructed action in American Sign Language. In C. Lucas (ed.), Sociolinguistics in Deaf Communities, 255–271. Washington, DC: Gallaudet University Press. Metzger, M. 1998. Eye gaze and pronominal reference in American Sign Language. In C. Lucas (ed.), Pinky Extension and Eye Gaze: Language Use in Deaf Communities, 170–182. Washington DC: Gallaudet University Press. Morgan, G. 2002. Children’s Encoding of Simultaneity in British Sign Language Narratives. Sign Language & Linguistics 5(2). 131–165. Morgan, G. 2006. The development of narrative skills in British Sign Language. In B. S. Schick, M. Marschark & P. Spencer (eds.), Advances in the Development of Sign language by Deaf Children, 314–343. Oxford: Oxford University Press. Nonhebel, A., O. Crasborn & E. van der Kooij. 2004. Sign language transcription conventions for the ECHO Project. Version 9, 20 January 2004. Nijmegen: Radboud University Nijmegen. Okrent, A. 2002. A modality-free notion of gesture and how it can help us with the morpheme vs. gesture question in sign language linguistics. In R. P. Meier, K. Cormier & D. Quinto-Pozos (eds.), Modality and Structure in Signed and Spoken Language, 175–198. Cambridge: Cambridge University Press. Padden, C. A. 1986. Verbs and role shifting in American Sign Language. In C. Padden (ed.), Proceedings of the Fourth National Symposium on Sign Language Research and Teaching, 44–57. Silver Spring, MD: NAD. Parrill, F. 2009. Dual viewpoint gestures. Gesture 9(3). 271–289. Parrill, F. 2010. Viewpoint in speech-gesture integration: Linguistic structure, discourse structure, and event structure. Language and Cognitive Processes 25(5). 650–668. Perniss, P. 2007. Achieving spatial coherence in German Sign Language narratives: The use of classifiers and perspective. Lingua 117. 1315–1338.
Downloaded from http:/www.cambridge.org/core. Lehrst F Alte Geschichte Hist Inst, on 27 Oct 2016 at 12:36:50, subject to the Cambridge Core terms of use, available at http:/www.cambridge.org/core/terms. http://dx.doi.org/10.1515/langcog-2013-0021

  Point of view in sign language and spoken narrative   343
Peters, C. 2000. Deaf American Literature: From Carnival to the Canon. Washington DC: Gallaudet University Press.
Poulin, C. & C. Miller. 1995. On narrative discourse and point of view in Quebec Sign Language. In K. Emmorey & J. Reilly (eds.), Language, Gesture and Space, 117–131. Hillsdale, NJ: Lawrence Erlbaum.
Quer, J. 2005. Context shift and indexical variables in sign languages. In E. Georgala & J. Howell (eds.), Proceedings from Semantics and Linguistic Theory 15, 152–168. Ithaca, NY: CLC.
Quinto-Pozos, D. 2007a. Can constructed action be considered obligatory? Lingua 117(7). 1285–1314.
Quinto-Pozos, D. 2007b. Why does Constructed Action Seem Obligatory? An Analysis of Classifiers and the Lack of Articulator-Referent Correspondence. Sign Language Studies 7(4). 458–506.
Rayman, J. 1999. Storytelling in the Visual Mode: A Comparison of ASL and English. In E. A. Winston (ed.), Storytelling and Conversation: Discourse in Deaf Communities, 59–82. Washington DC: Gallaudet University Press.
Reilly, J. 2000. Bringing affective expression into the service of language: Acquiring perspective marking in narratives. In K. Emmorey & H. Lane (eds.), The signs of language revisited: An anthology to honor Ursula Bellugi and Edward Klima, 415–433. Mahwah, NJ: Lawrence Erlbaum Associates.
Sandler, W. & D. Lillo-Martin. 2006. Sign Language and Linguistic Universals. Cambridge: Cambridge University Press.
Schleef, E. 2003. Prosody and Narrative Structure in Varieties of Low German and Alemannic. Journal of Germanic Linguistics 15. 325–257.
Slobin, D. 1996. From “thought to language” to “thinking for speaking”. In J. Gumperz & S. Levinson (eds.), Studies in the social and cultural foundations of language: Vol. 17. Rethinking linguistic relativity, 70–86. Cambridge: Cambridge University Press.
So, W. C., S. Kita & S. Goldin-Meadow. 2009. Using the Hands to Identify Who Does What to Whom: Gesture and Speech Go Hand-in-Hand. Cognitive Science 33(1). 115–125.
Sweetser, E. 2007. Looking at space to study mental spaces: Co-speech gesture as a crucial data source in cognitive linguistics. In M. Gonzalez-Marquez, I. Mittelberg, S. Coulson & M. J. Spivey (eds.), Methods in Cognitive Linguistics, 201–224. Amsterdam: John Benjamins.
Wennerstrom, A. 2001. The Music of Everyday Speech: Prosody and Discourse Analysis. Oxford: Oxford University Press.
Wilson, J. 1996. The tobacco story: Narrative structure in an American Sign Language story. In C. Lucas (ed.), Multicultural aspects of sociolinguistics in deaf communities, 152–180. Washington, DC: Gallaudet University Press.
Woll, B., R. Sutton-Spence, R. & D. Waters. 2004. ECHO data set for British Sign Language (BSL). London: Department of Language and Communication Science, City University.
Woolf, V. 2000. Mrs. Dalloway. Oxford: Oxford University Press. (Original work published 1925). Zimmer, J. & C. Patschke. 1990. A Class of Determiners in ASL. In C. Lucas (ed.), Sign Language
Research: Theoretical Issues, 201–210. Washington, D.C.: Gallaudet University Press.
Downloaded from http:/www.cambridge.org/core. Lehrst F Alte Geschichte Hist Inst, on 27 Oct 2016 at 12:36:50, subject to the Cambridge Core terms of use, available at http:/www.cambridge.org/core/terms. http://dx.doi.org/10.1515/langcog-2013-0021

