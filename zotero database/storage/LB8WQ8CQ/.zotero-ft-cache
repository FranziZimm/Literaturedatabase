Handbuch Sprache  im multimodalen Kontext
Herausgegeben von Nina-Maria Klug und Hartmut Stöckl

print_cont_9783110295740_NinaMariaKlug.indb 3

26.07.16 12:07

ISBN 978-3-11-029574-0 e-ISBN [PDF] 978-3-11-029609-9 e-ISBN [EPUB] 978-3-11-039387-3 
Library of Congress Cataloging-in-Publication Data A CIP catalog record for this book has been applied for at the Library of Congress.
Bibliografische Information der Deutschen Nationalbibliothek Die Deutsche Nationalbibliothek verzeichnet diese Publikation in der Deutschen Nationalbibliografie; detaillierte bibliografische Daten sind im Internet über http://dnb.dnb.de abrufbar.
© 2016 Walter de Gruyter GmbH, Berlin/Boston Typesetting: fidus Publikations-Service GmbH, Nördlingen Printing and binding: CPI books GmbH, Leck ♾ Printed on acid-free paper Printed in Germany
www.degruyter.com

print_cont_9783110295740_NinaMariaKlug.indb 4

26.07.16 12:07

Inhaltsverzeichnis

Nina-Maria Klug/Hartmut Stöckl Einleitung   VII

I

Sprache im Feld multimodaler Kommunikation

Hartmut Stöckl

1.

Multimodalität – Semiotische und textlinguistische Grundlagen   3

John A. Bateman

2.

Methodological and Theoretical Issues in Multimodality   36

Constanze Spieß

3.

Metapher als multimodales kognitives Funktionsprinzip   75

Jürgen Spitzmüller

4.

Typographie – Sprache als Schriftbild   99

Sigrid Norris

5.

Multimodal Interaction – Language and Modal Configurations   121

II Zugriffe auf multimodale Verknüpfungen

Carey Jewitt/Berit Henriksen

6.

Social Semiotic Multimodality   145

Nina-Maria Klug

7.

Multimodale Text- und Diskurssemantik   165

Winfried Nöth

8.

Verbal-visuelle Semiotik   190

Nadia Koch/Thomas Schirren 

9.

Verbal-visuelle Rhetorik   217

Charles Forceville 10. Pictorial and Multimodal Metaphor   241

print_cont_9783110295740_NinaMariaKlug.indb 5

26.07.16 12:07

VI   Inhaltsverzeichnis
Andrea Mayr 11. Multimodal Critical Discourse Analysis (MCDA)   261
Michael Klemm/Daniel Perrin/Sascha Michel 12. Produktionsforschung   277
Michael Klemm 13. Kulturvergleich   300
III Aspekte multimodaler Textsorten
Ulrich Schmitz 14. Multimodale Texttypologie   327
Terry D. Royce 15. Intersemiotic Complementarity in Print Advertisements   348
Helen Andersson/David Machin 16. A Multimodal Approach to Song   372
Werner Holly 17. Nachrichtenfilme als multimodale audiovisuelle Texte   392
Stefan Meier 18. Websites als multimodale digitale Texte   410
Volker Eisenlauer 19. Facebook als multimodaler digitaler Gesamttext   437
Christina Margrit Siever 20. Foto-Communitys als multimodale digitale Kommunikationsform   455
Jeff Bezemer/Gunther Kress 21. The Textbook in a Changing Multimodal Landscape   476
Sachregister   499

print_cont_9783110295740_NinaMariaKlug.indb 6

26.07.16 12:07

Hartmut Stöckl
1. Multimodalität – Semiotische und textlinguistische Grundlagen
Abstract: Dieses Kapitel skizziert einen theoretischen Rahmen für die Betrachtung und empirische Analyse multimodaler Texte. Dabei werden erstens die elementaren Unterschiede in der Funktionsweise der zentralen Zeichenmodalitäten Sprache, Bild und Ton (Musik, Geräusch) erläutert – hier kommen grundlegende semiotische Parameter und Modelle zum Tragen. Zweitens wird der multimodale Text als kohäsives und kohärentes Ganzes beschrieben, das die unterschiedlichen Modalitäten strukturell und funktional integriert. Hier übertrage ich zentrale textlinguistische Kategorien, wie Textsorte, Themen- und Handlungsstruktur oder Kohäsion/Kohärenz etc., und prüfe deren Beschreibungspotenzial für multimodale Artefakte anhand ausgewählter Beispiele. Die Grundthese ist, dass uns Multimodalität immer in Gestalt konkreter multimodaler Genres begegnet, die wir nur produzieren und verstehen können, wenn wir um die Ausdruckspotenziale der Zeichenmodalitäten wissen und die genrespezifische multimodale Textur kennen.
1 Anknüpfungspunkte – Desiderate – Thesen 2 Ein Konzept von ‚Zeichenmodalität‘ 3 Zentrale Zeichenmodalitäten im semiotischen Vergleich 4 Beschreibungsdimensionen des multimodalen Texts 5 Fazit und Ausblick 6 Literatur
1 Anknüpfungspunkte – Desiderate – Thesen
Es ist dem rasanten Aufschwung der Multimodalitätsforschung zu verdanken, dass Linguisten heute weder „blind für Bilder“ (Schmitz 2003) noch „besinnungslos“ gegenüber den Zeichenmodalitäten anderer Sinneskanäle, wie z. B. Musik und Geräusch sind. Im Zuge einer konsequenten Orientierung auf den Sprachgebrauch und dank der Hinwendung zu den semiotischen Oberflächen und Körper der Texte (z. B. Kesselheim 2011) sieht man heute alle die Sprache begleitenden Zeichenmodalitäten als ihren notwendigen Ko- und Kontext. Der Stand der Forschung zu multimodaler Kommunikation (s. dieses Handbuch, Jewitt 2014; Björkvall 2012; Norris/Maier 2014) zeigt sich festigende, v. a. sozialsemiotische terminologische Grundlagen, eine zunehmende Inventarisierung der „grammatischen“ Ressourcen einzelner ‚modes‘ und, im Ansatz, die empirische Untersuchung ausgewählter multimodaler Gesamttexte. Trotz aller Fortschritte ist Björkvall (2012, 18) zuzustimmen, wenn er meint,

print_cont_9783110295740_NinaMariaKlug.indb 3

26.07.16 12:07

4   Hartmut Stöckl
dass die Multimodalitätsforschung „[is] still very much an emerging field and there is both room and need for methodological development“. Vor allem die Integration von Zeichenmodalitäten in multimodalen Gesamttexten ist m. E. noch unzureichend beschrieben, so dass die Verknüpfungsmuster von ‚modes‘ und die Prinzipien der intersemiotischen Sinnstiftung einen weitestgehend blinden Fleck markieren.
Das Wesen multimodaler Texte besteht darin, dass zumindest zwei Zeichenmodalitäten strukturell und funktional integriert werden bzw. sich ein und dieselbe Modalität in verschiedenen Medien manifestiert (Fricke 2012, 49 f.). So kombiniert ein Film bewegte Bilder und gesprochene Sprache mit Musik und Geräusch; Sprache manifestiert sich zugleich im der Rede und der Gestik. Ist das Phänomen Multimodalität als textuelles und rhetorisches Prinzip der Vielgestaltigkeit von Zeichentypen und ihrer Verknüpfung recht klar umrissen, so ist der Begriff des ‚mode‘ noch ungenügend geklärt. Forceville bringt die Folgen dieses Defizits treffend zur Sprache:
if there was no agreement on what constitutes a mode, any dimension of discursive meaning could qualify for modal status, and that would make the concept useless. (Forceville 2014, 51 f., Hervorhebung im Original)
Zwei Herangehensweisen lassen sich diesbezüglich unterscheiden. Die eine vermeidet dezidiert eine klare Unterscheidung von Zeichenmodalitäten, indem sie argumentiert, dass „a mode is what a community takes to be a mode and demonstrates that in its practices“ (Kress 2014, 65). Die andere unterscheidet prototypische Modalitäten (wie Rede, Schrift, Bild, Ton, Gestik, Mimik etc.), die uns als Alltagskategorien vertraut sind, konzediert deren potentielle Überlappungen und mangelnde Trennschärfe, bietet aber auch keine kategoriale Definition. Diese Lücke nehme ich als ersten Anknüpfungspunkt und werde zeigen, wie sich ‚Zeichenmodalität‘ „im Kraftfeld der Konzepte Medium, Kode und Sinneswahrnehmung“ (Klug/Stöckl 2015, 244) klären lässt.
Ein zweiter Anknüpfungspunkt ergibt sich aus der Diskussion um die Gemeinsamkeiten und Unterschiede zwischen den Zeichenmodalitäten. Die grundlegende Frage, welche ‚modal affordance‘ (Jewitt/Kress 2003, 14 ff.), d. h. welches distinkte Ausdruckspotenzial die verschiedenen ‚modes‘ haben, welcher Logik (vgl. ‚modal logic‘ – ibid.) sie folgen und über welche semantisch-pragmatische Reichweite (vgl. ‚reach of mode‘ – Kress 2014, 63 f.) sie verfügen, ist bisher ungenügend beantwortet worden. Forceville (2014, 51) sieht deren Klärung aber als wesentlich, wenn er schreibt:
If the study of multimodal discourse is to develop into a respectable scholarly humanities discipline, each of the modes/modalities partaking in multimodal discourse must also be theorized separately. The question is thus first of all what, and how, a mode can communicate on its own.
Van Leeuwen (2005a, 73) erkennt daher folgendes Desiderat:

print_cont_9783110295740_NinaMariaKlug.indb 4

26.07.16 12:07

Multimodalität – Semiotische und textlinguistische Grundlagen   5
Comparisons between various ‘grammars’ are especially needed. We need to know more about the extent to which different modes can do the same kind of communicative work and about the extent to which they differ in their semiotic potential […].
Ich will in diesem Beitrag einen solchen direkten Vergleich der Zeichenmodalitäten Sprache, Bild, Musik und Geräusch anstellen und aufzeigen, welche semiotischen Basiskategorien und -modelle dazu nützlich sind.
Der dritte Anknüpfungspunkt betrifft die oft aber nie systematisch angestellten Projektionen textlinguistischer Konzepte (wie z. B. Genre – vgl. van Leeuwen 2005a/b; Bateman 2008 oder Kohäsion – vgl. Royce 1998 und Kohärenz – vgl. Stöckl 2012a, 251 ff.) auf multimodale Kommunikate. Die Texthaftigkeit multimodaler Artefakte steht außer Frage (wie auch die von Bildern und Musik für sich genommen), jedoch muss es darauf ankommen, multimodale Textualität zu fassen, indem man ein systematisches Mehr-Ebenen-Modell des multimodalen Text entwickelt, das wichtige Konzepte zueinander in Beziehung setzt. Ein solches Modell will ich in diesem Beitrag auch grob skizzieren, wobei das Augenmerk auf der inhärenten Typen- und Sortenzugehörigkeit multimodaler Texte liegt.
Die dargelegten Anknüpfungspunkte und Desiderate lassen sich in zwei Thesen bündeln, die diesen Beitrag leiten sollen: 1. Grundlegende semiotische Konzepte und Modelle sind hilfreich, um die prototy-
pischen Merkmale der verschiedenen Zeichenmodalitäten aufzuzeigen. Ein systematischer ‚mode‘-Vergleich stellt ihre kategorialen Unterschiede in der Funktionsweise und im Ausdruckspotenzial heraus und verdeutlicht die wesenseigene Spezifik jeder einzelnen Zeichenmodalität. Die semiotische Gegenüberstellung basaler Modalitäten führt zwangsläufig auch zu einer Bestimmung des Begriffs der Zeichenmodalität. Solche konzeptuellen Überlegungen begründen unser Wissen über die tatsächlichen Funktionsweisen von Modalitäten im multimodalen Text; insbesondere leiten sie unser Verständnis der zahlreichen ‚mode‘-Überlappungen und -integrationen. 2. Die Kombination mehrerer Zeichenmodalitäten ist ein text-konstitutives Handeln, bei dem die einzelnen ‚modes‘ formal-strukturell und semantisch-funktional in den Gesamttext eingebunden werden. Jeder multimodale Text realisiert eine Textsorte (z. B. Infografik, Zeitungsnachricht, Werbeanzeige), die sich in einem Mehr-Ebenen-Modell beschreiben lässt. Dabei sind textlinguistische Basiskonzepte wie Kohäsion, Kohärenz oder Textstruktur (thematisch, Handlungsstruktur) etc. hilfreich, um multimodale Integration im Gesamttext zu erklären. Von zentraler Bedeutung ist die Frage, wie stark typisiert die einzelnen Modalitäten verwendet werden und wodurch sich die multimodalen Texturen der einzelnen Textsorten unterscheiden. In anderen Worten: Gibt es z. B. ein typisches Werbe-, Zeitungs- oder infographisches Bild? Und inwiefern ist die multimodale Kohärenz einer Infografik distinkt?

print_cont_9783110295740_NinaMariaKlug.indb 5

26.07.16 12:07

6   Hartmut Stöckl
2 Ein Konzept von ‚Zeichenmodalität‘
Prinzipiell ruft die Idee einer Synthese mehrerer Zeichenmodalitäten im kommunikativen Gebrauch die typologisierende Frage auf den Plan: Welche Modalitäten gibt es und wie kann man sie voneinander abgrenzen? Dass für die Beschreibung multimodaler Texte generell eine semiotische Perspektive zielführend ist, habe ich a. a. O. (Stöckl 2014) bereits gezeigt. Hier möchte ich einen direkten und systematischen Vergleich zentraler Zeichenmodalitäten anstellen. Dabei beschränke ich mich auf Sprache, Bild, Musik und Geräusch, weil sie im Alltagsverständnis der Zeichenverwender zweifelsfrei als basale Modalitäten gelten können und weil deren Kombination eine einfache aber weithin gültige Typologie multimodaler Texte (Print-Text, Audio-Text, Audiovisueller Text) etabliert (s. dazu Schmitz i. d. B; Stöckl 2012b, 20). Eine solche Engführung schließt zum einen bestimmte für mediatisierte textuelle Artefakte eher randständige Modalitäten der Sinneswahrnehmung wie Geruch, Geschmack oder Taktiles aus. Zum anderen lässt sie solche Zeichenmodalitäten wie Gestik und Mimik, aber auch Typographie oder Intonation/Stimmgestaltung unberücksichtigt, weil diese in dem Sinne peripher und kaum autonom sind, dass sie in andere Modalitäten integriert werden und nur bei der gleichzeitigen Realisierung von Rede, Schrift oder Bild ins Spiel kommen. Für alle typologischen Fragen gilt, dass „many categories allow for subdivisions and, second, that they tend to have fuzzy borders“ (Forceville 2014, 52); Schmitz (i. d. B.) warnt zudem vor „pedantischem Positivismus“.
Bevor die Funktionsweisen zentraler Zeichenmodalitäten miteinander verglichen werden, entwickle ich hier zunächst kurz ein Konzept von Zeichenmodalität (s. Abb. 1). In erster Linie wird der Begriff in seinem psychologischen Sinn als Zeichentyp verstanden, der durch die jeweilige Sinnesmodalität oder den Wahrnehmungskanal begründet ist, in denen die Zeichen prozessiert werden. Auf diesem Verständnis fußt auch die ursprüngliche Prägung des Begriffs ‚Multimodalität‘ (van Leeuwen 2011, 549). Koch (1971, 219 ff.) schlägt diesbezüglich fünf große Zeichentypen vor: visuell, auditiv, taktil, olfaktorisch und gustativ (s. auch die Überlegungen von Eco 1977, 174 ff.). Obgleich diese Einteilung valide ist, reduziert sie das Konzept der Zeichenmodalität, vergröbert stark und erweist sich als nicht trennscharf: So ist gesprochene Sprache auditiv, geschriebene hingegen visuell – soll man Sprache deshalb als zwei Modalitäten (Rede und Schrift) auffassen, obwohl ihnen beiden die gleiche Lexik und Grammatik zugrunde liegt? Oder: Bild und Schrift sind klar getrennte Modalitäten, rangieren aber beide als visuelle Zeichentypen. Diese Probleme deuten darauf hin, dass ‚Zeichenmodalität‘ ein breiter gefasstes Konzept ist, das Aspekte der Kodiertheit und der Medialität von Zeichen einschließt.

print_cont_9783110295740_NinaMariaKlug.indb 6

26.07.16 12:07

print_cont_9783110295740_NinaMariaKlug.indb 7

Multimodalität – Semiotische und textlinguistische Grundlagen   7

Abb. 1: Ein Konzept von Zeichenmodalität. Eine Synthese mehrerer Zeichenmodalitäten im kommunikativen Gebrauch wirft die Frage nach ihrer Abgrenzbarkeit und Typologisierung auf. Dieses mehrdimensionale Modell des Konzepts Zeichenmodalität unterscheidet Aspekte der sinnlichen Wahrnehmbarkeit von Zeichen (psychologisch), ihrer strukturierten Kodiertheit (semiotisch) und ihrer materiell-technischen Realisierung (medial).

26.07.16 12:07

8   Hartmut Stöckl
Aus semiotischer Sicht scheint vor allem die Zugehörigkeit von Zeichen zu einem Kode oder Zeichensystem der zentrale Aspekt bei der Abgrenzung von Zeichenmodalitäten. Kodiertheit setzt voraus, dass es ein kulturell etabliertes und konventionalisiertes Zeicheninventar gibt, das den Benutzern als Werkzeug für absichtsvolle Kommunikation und praktisches Handeln dient. Die Zeichenrepertoires sind intern strukturiert, d. h. sie verfügen über „Zuordnungsvorschriften“ für Zeichenform und -inhalt sowie über Regeln der Kombinierbarkeit der Zeichen zu größeren Aussageeinheiten. Interne Strukturiertheit lässt sich mit Blick auf Sprache kurz als ‚LexikoGrammatik‘ etikettieren. Morris (1971, 28 ff.) hat die Idee stark gemacht, dass jedes semiotische System, jede Zeichenmodalität, in den Dimensionen Syntax („relations of signs to one another“ – Morris 1971, 28), Semantik („relations of signs to their designata“ – Morris 1971, 35), Pragmatik („relation of signs to their interpreters“ – Morris 1971, 43) funktionieren muss. Die Sozialsemiotik betont, dass Zeichenmodalitäten jeweils über ihnen eigene semiotische Ressourcen verfügen. Unterschiede zwischen Sprache, Bild, Musik, Geräusch etwa sind also demnach daran festzumachen, wie sie sich syntaktisch, semantisch und pragmatisch verhalten und welches ihre spezifischen Ressourcen sind (z. B. Sprache: Zeitformensystem der Verben, Satztypen, Sprechakte vs. Musik: Melodie, Harmonie, Rhythmus, Dynamik etc.).
Es ist eine bekannte Tatsache, dass zentrale Zeichenmodalitäten medial unterschiedlich realisiert werden können: Sprache wird gesprochen und geschrieben; Bilder lassen sich z. B. fotografieren, malen oder collagieren etc.; Musik wird gespielt oder notiert. Ganz gleich, wie weit oder eng man Mediales fassen will, ob physikalisch – als materielle Voraussetzung oder technologisch – als technische Hilfsmittel zur Kommunikation bzw. auch handlungsbezogen – als „sozial konstituierte Verfahrensformen“ (Schneider 2008, 246 f.) der Zeichenverarbeitung, mediale Aspekte haben einen konstitutiven Einfluss auf Struktur und Gebrauch der Zeichenmodalitäten. Medien ermöglichen überhaupt erst die Wahrnehmung und Kodierung von Zeichen, und sie hinterlassen Spuren in den Textsorten und kommunikativen Darstellungsformen. Es verwundert daher nicht, dass der Begriff ‚Zeichenmodalität‘ auch über Mediales definiert worden ist – etwa, wenn Jewitt/Kress (2003, 1 f.) die „work of culture in shaping material“ hervorheben, die ‚modes‘ erst erschaffen. Allerdings plädiert die Sozialsemiotik für eine Trennung von ‚modes‘ und ‚media‘ (s. z. B. Kress/ van Leeuwen 2001, 21 f.). Die germanistische Medien(text)linguistik schlägt mit ‚Kommunikationsform‘ (z. B. Gespräch, Zeitung, TV, Radio, Ansichtskarte, Plakat, Warenverpackung) ein Konzept vor, in dem alle medial-materiellen, zeitlich-räumlichen und situativen Aspekte von Kommunikation gefasst und typisiert werden können. Diese medialen Rahmen der Zeichenverwendung bedingen auch jeweils verfügbare Zeichenmodalitäten und typische Verknüpfungsmuster (z. B. kombiniert das Radio Rede, Musik und Geräusch). Holly bezeichnet Kommunikationsformen als „medial bedingte kulturelle Praktiken“ (Holly 2011, 155) oder auch als „kommunikative Dispositive, die sich auf der Basis verfügbarer technischer Möglichkeiten und sozialer Bedürfnisse allmählich herausbilden“ (Holly 2011, 155). A. a. O. (Klug/Stöckl 2015,

print_cont_9783110295740_NinaMariaKlug.indb 8

26.07.16 12:07

Multimodalität – Semiotische und textlinguistische Grundlagen   9
245) habe ich dafür plädiert, die Begrifflichkeiten wie folgt zu ordnen: Materialien und Technologien ermöglichen Kommunikationsformen, diese setzen die größeren medialen und situativen Konfigurationen für die Produktion von multimodalen Texten, die wiederum – je nach Sorte – verschiedene Zeichenmodalitäten in unterschiedlichen Verknüpfungen verwenden.
Zusammenfassend lässt sich die mehrdimensionale Natur des Konzepts Zeichenmodalität erkennen: Jede Zeichenmodalität ist an einen Kanal der Sinneswahrnehmung gebunden. Sie muss materiell-medial realisiert werden und in einer raumzeitlichen und sozialen Situation verwendet werden. Semiotische Modalitäten verfügen über eine interne Strukturierung, die Bedeutungen, Kombinationsmöglichkeiten und Gebrauchsfunktionen ihrer Zeicheninventare regelt. Aus dieser Auffassung lässt sich der Schluss ziehen, dass bei der Zuordnung von Phänomenen zu modes Vorsicht geboten ist. Farbe z. B. scheint eher Bestandteil, d. h. Ressource von Bild oder Typographie; Film, Comics, Oper, Tanz etc. sind medial bestimmte Kommunikationsformen bzw. ihre multimodalen Textsorten, nicht aber Zeichenmodalitäten. Die Einteilung in übergeordnete Klassen wie etwa verbale, non-verbale und paraverbale Zeichen macht Sinn, wirft aber vor allem die alte logozentrische Frage nach der Rolle der Sprache und nach der Nähe/Ferne anderer Modalitäten zu ihr innerhalb der multimodalen Semiosphäre auf (s. dazu Sebeok 1994, 105 ff.; Eco 1977, 172 ff.)
3 Zentrale Zeichenmodalitäten im semiotischen Vergleich
Sinn und Zweck des nun anzustellenden Vergleichs ist es, Gemeinsamkeiten und Unterschiede zwischen zentralen Zeichenmodalitäten aufzuzeigen, indem einzelne semiotische Parameter – wie z. B. Semiotisierungsgrad, Zeichenkomplexion, Referenzherstellung, Kommunikationsfunktionen – herangezogen und überprüft werden. Der Einfachheit halber werden diese Kriterien in den drei großen Dimensionen Syntax (Form), Semantik (Inhalt), Pragmatik (Funktion) (s. o.) geordnet (s. Tab. 1). Dabei gehören Beobachtungen über die Beschaffenheit der Kodes und zeichentypologische Fragen zu den syntaktischen Aspekten, Aussagen über die Wahrnehmung und die kognitive Verarbeitung der Zeichenmodalitäten zu ihrer pragmatischen Dimension. Im Ergebnis steht ein kontrastives Portrait der jeweils modespezifischen Logik, ihrer Ausdruckspotenziale (und -beschränkungen) sowie der zugrunde liegenden Funktionsweisen.

print_cont_9783110295740_NinaMariaKlug.indb 9

26.07.16 12:07

10   Hartmut Stöckl
3.1 Syntax – Beschaffenheit und interne Struktur
Zuallererst stellt sich die Frage, über welchen Sinneskanal die Zeichen verarbeitet werden. Während Geräusche rein auditive und Bilder rein visuelle Zeichenphänomene sind, erlauben Sprache und Musik eine duale mediale Realisierung und bedienen daher entweder den auditiven oder visuellen Sinneskanal. Ursprünglich und wesenseigen sind Sprache und Musik phonischer Natur. Mit Schrift und Notation stehen Aufschreibsysteme zur Verfügung, die akustische Phänomene visuell kodieren und erfahrbar machen. Diese Phonographien entreißen Sprache und Musik ihrer zeitlichen Flüchtigkeit; sie ermöglichen und erleichtern das systematische Studium der Zeichenstrukturen. Obwohl Sprache und Musik sehr verschiedene Modalitäten sind, weisen sie also in dieser Hinsicht Parallelen auf. Die gemeinsame Motivation von Schrift und Notation liegt vermutlich in der linearen Syntax der Zeichen von Sprache und Musik, die eine flexible Rekonstruktion und Weitergabe von Textteilen bedingt haben mag. Für Bilder und Geräusche gibt es derartige sekundäre mediale Realisierungen nicht.
Semiotisierung bezeichnet den Prozess, in dem ein Rezipient ein beliebiges materielles Phänomen als Zeichenkörper anerkennt und ihm einen bestimmten Inhalt oder Sinn zuschreibt. Damit ist verbunden, dass einzelne Zeichen zu Systemen oder Ressourcen zugeordnet werden und dementsprechend semiotisches Wissen über die jeweilige Zeichenmodalität abgerufen wird. Wir sprechen von Graden der Semiotisierung, um auszudrücken, dass die Sinnstiftung mit Zeichen kein entweder oder, sondern ein mehr oder weniger ist. Manche Modalitäten generieren Sinn fast axiomatisch, automatisiert; bei anderen schreiben wir Sinn erst nach gründlicher Reflexion der Zeichen und ihrer Strukturen zu. Geräusche weisen eine niedrige Semiotisierung auf; wir nutzen sie primär, um unser praktisches Verhalten in den uns umgebenden Situationen auszurichten. Die massenmediale Semiotisierung von Geräuschen, etwa im Film oder Radiotext orientiert sich in starkem Maße an unseren auditiven Umwelterfahrungen. Musik ist in einem höheren Maße semiotisiert, als kulturelles Artefakt deuten wir ihre Zeichen im Rahmen eines komplexeren ‚Texts‘, nicht in Analogie zur Wahrnehmung der uns umgebenden Welt, sondern nach system- und genreimmanenten ‚Regeln‘. Ähnliches lässt sich für Bilder behaupten, wenngleich die Semiotisierung hier in gewissem Maße auf Analogien zwischen Umweltsehen und Bildbetrachten zurückgreifen kann. Die Sprache schließlich weist eine hohe Stufe der Semiotisierung auf. Eigens als Mittel zur effizienten Verständigung geschaffen, verstehen wir Sprache immer nur in einer klaren Kommunikationssituation und einem Ko- und Kontext. Im Unterschied zu Musik, Geräusch und Bild ist die Beschäftigung mit sprachlich kodierten Informationen total – ihr Sinn kann nur aufgrund der weitgehenden Kenntnis des Kodes erschlossen werden. Bei Bildern, Musik und Geräusch scheint eine nur periphere Zuwendung von Aufmerksamkeit möglich – das Lesen der Botschaften nach festen Koderegeln stellt eher eine Ausnahme dar und diese Regeln sind inhärent genre-, situations- und kontextabhängig. Bezüglich des Semiotisie-

print_cont_9783110295740_NinaMariaKlug.indb 10

26.07.16 12:07

Multimodalität – Semiotische und textlinguistische Grundlagen   11
rungsgrads ergibt sich also ein Kontinuum vom niedrig semiotisierten Geräusch über die im mittleren Maße semiotisierten Modalitäten Bild und Musik bis hin zur hoch semiotisierten Sprache. Der niedrige Semiotisierungsgrad von Geräuschen erklärt sich auch aus der Tatsache, dass es sich bei ihnen im Sinne von Eco (1977, 177 f.) um natürliche und sekundäre Zeichen handelt. Geräusche werden von den Gegenständen unserer Umwelt und im praktischen Alltagshandeln erzeugt ohne kommunikative Absichten zu verfolgen. Erst in sekundärer Weise können sie Funktionen in der Kommunikation übernehmen; dabei ergeben sich ihre einfachen Bedeutungen erst aus dem Gesamttext. Musik, Bild (außer natürlichen und Spiegelbildern) und Sprache hingegen sind vom Menschen geschaffene zeichenhafte Ausdrucksmittel und dienen primär kommunikativen Zwecken.
Betrachten wir nun die interne Struktur der Modalitäten. Sprache gilt als Zeichensystem par excellence, weil sie eine große Menge distinkter Einzelzeichen hat (Lexik), die vielfältige und systematische Sinnbezüge (Paradigmatik) zueinander herstellen und nach syntaktischen Regeln (Grammatik) zu größeren Aussageeinheiten verknüpft werden (Syntagmatik). Diese Kombination aus geordnetem Lexikon und expliziter Grammatik macht ganz wesentlich die semantisch-kommunikative Stärke von Sprache aus. Hinzu kommt, dass Sprache ein doppelt gegliedertes Zeichensystem ist: lediglich bedeutungsunterscheidende Sprachlaute kombiniert sie auf der ersten Gliederungsebene zu Morphemen (lexikalisch oder grammatisch) und fügt sie auf der zweiten Gliederungsebene zu Wörtern unterschiedlicher Komplexität. Dieses semiotische Abstraktionsprinzip sorgt dafür, dass man aus einer begrenzten Zahl von Phonemen unendlich viele (lexikalische) Morpheme und Wörter bilden kann.
Über eine solche doppelte Artikulation verfügt das Bild nicht. An die Stelle der linearen Verkettung von Einzelzeichen tritt in Bildern die quasi simultan verlaufende Integration visueller Gestalten zu größeren flächig-räumlichen Konfigurationen. Von distinkten Zeichen kann dabei an sich nicht die Rede sein; Eco (1977, 176) spricht von „gradated continua“, d. h. Zeichenangebote, bei denen verschiedene materiell wahrnehmbare Parameter bedeutungsrelevant werden können. Nöth (2011, 307) meint daher, Bilder als „wahrnehmungsnahe Zeichen“ (Sachs-Hombach 2003, 73 ff.) haben eine „iconic syntax“, d. h. die Konfiguration der Bildelemente entspricht der Ordnung der Dinge in den uns bekannten realen oder fiktiven Welten. Zwei syntaktische Prinzipien im Bild sind die meronymische, d. h. auf Teil-Ganzes-Bezügen beruhende Ordnung von Einzelzeichen und die Konvertierung flächiger Zeichen-Arrangements in räumliche Vorstellungen. In Anbetracht dieser syntaktischen ‚Schwächen‘ des Bildkodes spielen Vorwissen, Kontext, Seherfahrungen und inferierende Prozesse beim Bildverstehen eine vergleichsweise große Rolle.
Musik verfügt über eine ausgeprägte und komplexe Syntax. Zum einen werden einzelne Töne zu größeren Einheiten, wie Melodien, Themen/Motiven, Sätzen etc. verknüpft (syntagmatisch), zum anderen verbinden sich paradigmatisch ‚passende‘ Töne zu Akkorden oder Harmonien. Hinzu kommt, dass die so entstehenden Zeichenkomplexe z. B. in Rhythmus, Tempo, Dynamik und Instrumentierung ‚flektiert‘,

print_cont_9783110295740_NinaMariaKlug.indb 11

26.07.16 12:07

12   Hartmut Stöckl
d. h. modifiziert werden können. Diese multiplen syntaktischen Dimensionen sind so zentral für die Funktionsweise der Zeichenmodalität Musik, dass man sie in vielleicht zu radikaler Sicht als „ein genuin syntaktisches Gebilde“ sieht, „dessen Bedeutung seine wahrgenommene Syntax ist“ (Faltin 1985, 187). Auch wenn das konstruierende Spiel mit den Strukturen des Klangmaterials wesentlich für die Funktionsweise von Musik ist, kann sich ihre Semantisierung nicht auf das rein Syntaktische beschränken (s. u.). Geräusche schließlich sind einzelne nicht-verbale und nicht-musikalische Schallereignisse (Wolff 1996, 5 f.). Man kann sie zwar paradigmatisch, d. h. nach thematischen Gruppen ordnen (Wolff 1996, 189 ff.), aber – außer rein kumulativ-additiv in „Geräuschatmosphären“ (Wolff 1996, 206) haben sie ein geringes syntaktisches Potenzial. Bedenkt man zudem ihre einfache indexikalische Semantik als raum-zeitliche Verweise auf Dinge, Zustände oder Handlungen, so scheinen Geräusche syntaktisch und semantisch schwach kodiert.
Wir haben gesehen: Die vier Zeichenmodalitäten unterscheiden sich bezüglich der internen Struktur ihrer Zeicheninventare und deren ‚grammatischen‘ Funktionsprinzipien deutlich. Diese Unterschiede interpretieren wir als Spezifik, die Auswirkungen auf ihre Verwendung in multimodalen Texten hat. Dass man geneigt ist, die ‚modes‘ als stärker oder schwächer einzustufen, hängt primär mit Urteilen über den Grad ihrer Konventionalität oder Motiviertheit zusammen. Sind die Form-InhaltsZuordnungen der Zeichen willkürlich (arbiträr) und erklärt sich die Funktionsweise des Kodes nicht aus Umwelterfahrung oder Analogien, so ist die jeweilige Zeichenmodalität stark konventionell und nicht motiviert. Die vier Modalitäten ordnen sich auf einer Skala von ‚stark konventionell/kaum motiviert‘ zu ‚schwach konventionell/ stark motiviert‘ wie folgt: Sprache, Musik, Bild, Geräusch. D. h. Sprache und Musik sind konventionell, weil man ihre komplexe und arbiträre Syntax erlernen muss. Bilder und Geräusch hingegen verstehen wir in Analogie zum Umweltsehen bzw. als Anzeichen für die raumzeitliche Präsenz von Objekten und Prozessen; sie sind schwach konventionell.
3.2 Semantik – Bedeutungsgenerierung
Peirce hat Bedeutung pragmatisch als „Wirkung (effect) des Zeichens im Bewusstsein eines Interpreten“ (Nöth 1985, 38) verstanden und drei generelle Wirkungsweisen unterschieden. Sie eignen sich, um den prinzipiellen Wirkungsmechanismus jeder Zeichenmodalität zu beschreiben. Emotionale Bedeutungen wecken unmittelbar Gefühle, energetische Bedeutungen bewirken eine Handlung im Sinne einer „körperlichen oder geistigen Anstrengung des Interpreten“ (Nöth 1985, 38) und logische Bedeutungen führen zu einer axiomatischen Korrelation von Zeichenform und -inhalt und zu Veränderungen im Denken und Verhalten. Demnach generiert Musik vorwiegend emotionale Bedeutungen, weil sie Gefühle des Rezipienten evoziert. Juslin/Sloboda (2001, 3) meinen dazu: „emotional experience is probably the main

print_cont_9783110295740_NinaMariaKlug.indb 12

26.07.16 12:07

Multimodalität – Semiotische und textlinguistische Grundlagen   13
reason behind most people’s engagement with music“. Sprache neigt insofern zur logischen Wirkungsweise, als ihre Zeichen automatisch Verknüpfungen von mentalen Konzepten und Referenzobjekten herstellen. Geräusche wirken hauptsächlich energetisch; der Rezipient orientiert an ihnen sein praktisches Handeln und bindet sie über assoziative und kausale Schlüsse an sekundäre Bedeutungen. Bilder werden sowohl logisch als auch energetisch gedeutet. Der Betrachter erkennt in ihnen dank kognitiver Invarianten (visuelles Wissen), Seherfahrung und Darstellungskonvention bestimmte Objekte und Sachverhalte (logisch). Bilder erlauben aber auch assoziative und inferierende gedankliche Operationen, die zu weiteren Deutungen führen (energetisch). Auch wenn Peirce meint, jedes Zeichen könne im Gebrauch alle drei Zeichenwirkungen entfalten, gibt es m. E. für jede Zeichenmodalität jeweils einen dominanten prototypischen Wirkungsmechanismus.
In der Semiotik ist die Idee verbreitet, dass man Zeichenarten auch danach differenzieren kann, welche materiell-medialen Eigenschaften des Zeichenkörpers in welchem Maße für Deutung und Verstehen relevant werden. Goodman (1976) spricht in diesem Zusammenhang von syntaktischer Fülle und Peirce unterscheidet Quali-, Sin- und Legizeichen (Nöth 1985, 39). Für Sprache scheint die konkrete Formausprägung (graphisch oder phonetisch) der ‚token‘nebensächlich (abgesehen von paraverbaler Typographie oder Stimmgestaltung). Wesentlich für die Bedeutungsgenerierung ist lediglich das Erkennen des ‚types‘, d. h. das Verstehen der gesetzmäßigen Verbindung von Form und Inhalt. In diesem Sinne ist Sprache abstrakt, die Verwender sind auf wenige, die Bedeutung unterscheidende Formmerkmale fixiert – Sprache gilt als Set von Legizeichen. Im Falle von Bildern, Musik und Geräuschen kann prinzipiell die ganze Fülle der individuellen Formeigenschaften und die Materialität der Zeichen in die Deutung eingehen. Einfach gesagt, spielt für die Sinnstiftung bei diesen Zeichenmodalitäten nicht allein eine Rolle, was gezeigt wird oder zu hören ist, sondern eben auch wesentlich und vordergründig, wie die Objekte visuell (z. B. Farbe) und auditiv (z. B. Instrumentierung) genau beschaffen sind. Im Unterschied zu Sprache kann man daher Bilder, Musik und Geräusch auch als Zeichenmodalitäten bezeichnen, deren Singularität (Sinzeichen) und Qualität (Qualizeichen) semantisch relevant ist – sie sind syntaktisch dicht(er) und voll(er).
Am grundlegendsten für die semantische Funktionsweise von Zeichentypen ist sicherlich ihr „Objektbezug“ (Nöth 1985, 39 f.), d. h. die Art und Weise der Bezugnahme von Zeichen auf die zu bezeichnenden Konzepte und Sachverhalte. Danach hat Peirce Ikone, Indices und Symbole unterschieden (Chandler 2007, 36–38). Auch wenn es Mischformen gibt, lässt sich jede Zeichenmodalität einem dominanten Objektbezug zuordnen. So gilt Sprache als überwiegend symbolisch, denn hier besteht eine willkürliche Zuordnung von Zeichen zu Referenzobjekten. Nur ein kleiner Teil des sprachlichen Repertoires funktioniert ikonisch (Lautmalerei) oder indexikalisch (deiktische Ausdrücke). Bilder sind typische Ikone: ihre Zeichen ähneln den Objekten, die sie abbilden, im Sinne einer Analogie von Umweltsehen und Bildbetrachtung. Manche Bilder erlangen durch häufigen Gebrauch sekundäre symbolische

print_cont_9783110295740_NinaMariaKlug.indb 13

26.07.16 12:07

14   Hartmut Stöckl
Bedeutungen in bestimmten Kontexten. Musik und Geräusch eint ihr indexikalischer Charakter. Ihre Zeichen sind relativ unbestimmte Symptome für emotionale Befindlichkeiten und Stimmungen (Musik) oder Hinweise auf Objekte, Zustände und Handlungen (Geräusch), die durch Kontiguität oder Kausalität motiviert sind. Musik kann aber auch ikonisch funktionieren, wenn sie Naturphänomene nachahmt; Geräusche können symbolische Bedeutungen erwerben (z. B. Glocken für Tod).
Schließlich gilt es, die spezifischen Ausdruckspotenziale der Zeichenmodalitäten zu vergleichen, d. h. jeweils zu fragen, welche Bedeutungen oder Aussagen sich gut, schwer oder gar nicht kommunizieren lassen. Die Semantik der Sprache wird dabei zumeist als beinahe unbeschränkt gesehen. Dies lässt sich einerseits mit der internen Struktur und den Ressourcen des linguistischen Systems begründen. Hier ist insbesondere an die doppelte Gliederung, an klare grammatische Kategorien (wie Tempus, Kasus oder Modus) und an das große Inventar distinkter autosemantischer Zeichen, aber auch an das eindeutige Anzeigen von Sprechakten und deren illokutiver Kraft zu denken. Andererseits sieht man sprachliche Ausdrucksgewalt darin, dass „not only every human experience but also every content expressed by means of other semiotic devices can be translated into the terms of verbal language“ (Eco 1977, 172). Die große effability (Eco 1977, 172) von Sprache ist aber dennoch nicht total: Obwohl prinzipiell mit willkürlichen Zeichen die ganze Vielfalt realer wie fiktiver Wahrnehmungen und Denkwelten darstellbar wird, tut sich Sprache z. B. schwerer mit der Schilderung räumlicher Objektanordnungen und physischer Details wie auch mit der Beschreibung komplexer Sinneswahrnehmungen (Geschmack, Geruch und Klang).
Das Ausdruckspotenzial von Bildern ist zunächst insofern eingeschränkt, als sie prinzipiell nur Visuelles/Sichtbares darstellen können. Der Merkmalsreichtum der dargestellten Objekte führt andererseits zu einem Bedeutungsüberschuss; zudem sorgt die „syntactic indeterminacy“ (Messaris 1997, xff.) für eine Vagheit der Aussagen in Bildern. Im Vergleich mit Sprache (Stöckl 2004, 94 ff. u. 245 ff.; Nöth 2011, 307 ff.) treten einige bildliche ‚Schwächen‘ zutage; diese beziehen sich meist auf das Fehlen entsprechender grammatischer Kategorien. So können Bilder Verneinungen, logische Verknüpfungen von Sachverhalten, Modalität (Wirklichkeitsbezug und Sprechereinstellung), deiktische Verweise oder direkte und explizite Sprechakte (vgl. hierzu die gegenteiligen Meinungen in Nöth 2011, 309 f. vs. Schmitz 2007) nicht (klar) ausdrücken. Die semantische ‚Stärke‘ von Bildern liegt in ihrem graphischen Darstellungsreichtum, der informatives Explorieren wie auch konnotative Bedeutungen und emotionale Anmutungen ermöglicht.
Von einer Semantik der Musik zu reden, ist problematisch, weil ihr die Fähigkeit zur Darstellung fehlt – man bescheinigt ihr bestenfalls eine „ephemere denotative Kraft“ (Karbusicky 1990, 11). „Musik als Zeichensystem in spé“ (Karbusicky 1987, 241) wird individuell verschieden und in starker Abhängigkeit von Erfahrungen, Einstellungen, Stimmungen wie auch von Wissen über Musikgenres und -kulturen semantisiert. Wenn Musik auch nicht – wie Sprache und Bild – denotieren kann, so schreiben Hörer ihr Sinn zu, indem sie musikalische Strukturen, Themen oder Genres als asso-

print_cont_9783110295740_NinaMariaKlug.indb 14

26.07.16 12:07

Multimodalität – Semiotische und textlinguistische Grundlagen   15
ziative Verweise auf Bewusstseinsinhalte, Orte oder Ereignisse deuten. Als expressive Zeichenmodalität macht Musik Gefühlszustände und seelische Befindlichkeiten erlebbar. Insgesamt scheint das adäquate Einpassen von Musik in soziale Kontexte oder Gesamttexte eine der wesentlichen Umgangsweisen mit Musik.
Das semantische Potenzial von Geräuschen ist stark eingeschränkt, weil sie ‚nur‘ auf Objekte, Handlungen oder Zustände verweisen können und weil sie keiner Syntax unterworfen sind. Geräusche zu ‚verstehen‘, bedeutet den raum-zeitlichen Bezug zum jeweiligen Referenzobjekt herzustellen und dessen Präsenz zur Kenntnis zu nehmen. Daher haben Geräusche meist die Funktion, Sachverhalte und Handlungen zu authentifizieren und sie situativ zu verorten. Ein erweitertes Bedeutungspotenzial ergibt sich, wenn Geräusche nicht nur indexikalisch-assoziativ (z. B. Ticken für Uhr), sondern übertragen-symbolisch (z. B. Ticken für Zeit, Schicksal) oder intertextuellgattungsspezifisch (z. B. Action-Film-Atmo) verwendet werden. Eine Semantik der Geräusche lässt sich modellieren, wenn man sie in eine enzyklopädische Ordnung von Geräuschfamilien bringt, die auf den klanglich-materiellen Eigenschaften oder den thematischen Verwendungsbereichen der Geräusche basieren. Im Unterschied zu Sprache, Bild und Musik hat das Geräusch keine kommunikative Autonomie. Da Geräusche nur in Verbindung mit anderen Zeichenmodalitäten funktionieren können, hängen deren Gebrauchs- und Wirkungsweisen immer von den Strukturen des Gesamttexts ab.
Zusammenfassend zeigen sich auf der semantischen Ebene erneut deutliche modalitätsspezifische Unterschiede. Sie betreffen die Zeichenwirkungen, die Art und Weise, wie die materiell-medialen Zeichenkörper zur Bedeutungsgenerierung verwendet werden, die Objektbezüge sowie generelle Potenziale und Defizite der Modalitäten beim Herstellen von Sinn. Die Unterschiede in der Semantik von Zeichentypen sind mit den vergröbernden Begriffsdichotomien vage vs. präzise, eindeutig vs. mehrdeutig und zuverlässig vs. unzuverlässig beschrieben worden (Nöth 1985, 96 u. 54). Diese stellt man sich jedoch vielleicht besser als gradierte Skalen vor. Musik z. B. kann als vergleichsweise unzuverlässige Modalität gelten, weil sie zur Denotation nicht fähig ist. Alle Zeichenmodalitäten können eindeutig oder mehrdeutig sein, allerdings scheint z. B. das Bild inhärent mehrdeutig(er) als z. B. Sprache. Mehrdeutigkeit ist gegeben, wenn Zeichen zugleich mehrere Denotate bezeichnen. Vagheit schließlich – hier ist die Bestimmung des Umfangs der Denotatklasse von Zeichen schwierig – ist ein generelles und graduierbares Phänomen für alle Modalitäten.
3.3 Pragmatik – Zeichenverarbeitung und kommunikative Funktion
Die pragmatische Dimension umfasst die Art und Weise der Wahrnehmung und mentalen Verarbeitung sowie die Gebrauchsfunktionen einer Zeichenmodalität. Hier zeigen sich wiederum klare Unterschiede auf verschiedenen Ebenen.

print_cont_9783110295740_NinaMariaKlug.indb 15

26.07.16 12:07

16   Hartmut Stöckl
Betrachten wir zunächst die Perzeption und Kognition, so erscheint Sprache aufgrund ihrer bindenden Linearität als vergleichsweise zeitaufwändige Modalität. Die abstrakte, willkürliche und wahrnehmungsferne Natur ihrer Zeichen hat zudem zur Folge, dass weniger Sinneseindrücke für die mentale Verarbeitung und das Behalten zur Verfügung stehen. Damit Laut- oder Buchstabenkombinationen Sinn bekommen, bedarf es seitens der Rezipienten einer Umkodierung. Er muss die Zeichen, die den Objekten seiner Umwelt nicht ähneln, in Anschauung und sensorisches Erleben transponieren, um ihnen Sinn zu geben. Bilder hingegen verfügen über wahrnehmungsnahe Zeichen, die im Unterschied zu Sprache ganzheitlich-simultan wahrgenommen werden. Außerdem verfügen Bilder über einen großen visuell-graphischen Merkmalsreichtum, der die Wahrnehmung befördert und Erinnern begünstigt. Diese Eigenschaften führen zu einer Überlegenheit von Bildern gegenüber Sprache, die Schnelligkeit und Effektivität von Verarbeitung und Behalten aber auch die Unmittelbarkeit der Wahrnehmungseindrücke betrifft. Für die Perzeption von Musik ist sowohl die lineare (z. B. Melodien, Motive) als auch die ganzheitliche Dimension (Akkorde) relevant; dies potenziert das Wahrnehmungserlebnis. Unsere auditive Wahrnehmung lässt sich im Unterschied zur visuellen nicht ‚ausschalten‘. Daraus kann man schließen, dass akustische Mittel „noch unterschwelliger und emotionaler wirken“ und „für die Aufmerksamkeitssteuerung eine stärkere Wirkung als Bilder“ (Holly 2004, 47) haben. Im Vergleich mit den anderen Zeichenmodalitäten scheint die Wirkungskraft von Musik besonders rasch, intensiv und unmittelbar. Die Zielorientierung der Musik auf Bewegung und Gefühl hebt Engel (1990, 55 f.) hervor, wenn er die perzeptiv-kognitiven Wirkungen von Musik als „rein emotionell sensitiv-physiologisch-motorisch erregte Affekte“ bezeichnet. Geräusche schließlich haben eine vergleichsweise geringere Chance überhaupt wahrgenommen zu werden, weil der Mensch meist in komplexen Geräuschkulissen agiert und darauf aus ist, Geräusche bewusst auszublenden. Dieser unterbewussten Wahrnehmung muss ein hypertrophes Sound-Design in Film oder Radio z. B. entgegenwirken. Während die Perzeption von Geräuschen darin besteht, eine auditive Gestalt aus dem Klangfluss zu isolieren, erschöpft sich ihr Verstehen auf das Erkennen der jeweiligen Verweisfunktion.
Für die Beschreibung von Kommunikationsfunktionen stehen v. a. Hallidays Metafunktionen (Halliday 1978) sowie Bühlers und Jakobsons Sprachfunktionen (Bühler 1934/1990; Jakobson 1960) zur Verfügung. Nach Hallidays metafunctional principle muss jede Zeichenmodalität drei Grundfunktionen erfüllen: Weltausschnitte und konzeptuelle Logik repräsentieren (ideational), soziale Bezüge zwischen den Kommunizierenden gestalten (interpersonal) und die Botschaft intern strukturieren (textual). Bei einem Vergleich ergeben sich aber deutliche Unterschiede: So sind Sprache und Bild in allen drei Dimensionen pragmatisch funktionsfähig, Musik und Geräusch hingegen nicht. Musik hat zwar ein großes textbildendes Potenzial, taugt aber nicht zur Darstellung und ist kaum zur Beziehungsgestaltung fähig. Geräusche sind in ihrer Darstellung auf den raumzeitlichen Verweis zu einem Objekt etc. eingeschränkt; in der interpersonellen und textuellen Funktion versagen sie fast gänzlich.

print_cont_9783110295740_NinaMariaKlug.indb 16

26.07.16 12:07

Multimodalität – Semiotische und textlinguistische Grundlagen   17
Bei der Anwendung von Bühlers Kommunikationsfunktionen (Darstellung, Ausdruck, Appell) zeigen sich modalitätstypische Dominanzverhältnisse. Obwohl generell appell- und ausdrucksfähig liegt die pragmatische Domäne von Sprache und Bild in der Darstellung (s. o.). Musik hingegen dient primär der expressiven Entäußerung des Senders (Ausdrucksfunktion) und Geräusche werden im weitesten Sinne als Appell gedeutet, so sie nicht allein die Präsenz eines Objekts anzeigen (s. o.).
Jakobson fügt den Funktionen Bühlers zwei wichtige hinzu, die metakommunikative und die poetische. Erstere bezeichnet die Fähigkeit von Zeichen, den verwendeten Kode zu thematisieren und zu kommentieren. Zur Metakommunikation ist nur die Sprache fähig. Bilder, Musik und Geräusche können ihre interne Strukturiertheit nicht reflektieren. Die poetische Kommunikationsfunktion bezieht sich auf die Möglichkeit, die Form einer Botschaft im Verstehen vordergründig zur Geltung kommen zu lassen. Dieses auch als Ästhetisierung von Kommunikation bekannte Phänomen (Stöckl 2013, 99 ff.) schließt vor allem das Spiel mit Formen und Strukturen einer Botschaft ein. Wir hatten bereits argumentiert, dass der visuelle und auditive Formenreichtum der Gestaltung bei Bild und Musik (bei Geräuschen weniger) eine tragende Rolle für die Sinnstiftung spielt. Daher lässt sich die poetische Funktion als ein Wesensmerkmal piktorialer und musikalisch-tonbildender Botschaften verstehen. Natürlich ist Sprache zur poetischen Kommunikation grundsätzlich in der Lage, neigt aber zumindest im Gros der informativen Gebrauchstextsorten des Alltags weniger dazu.
Abschließend will ich fragen, zu welchen typischen Kommunikationsaufgaben sich die vier Zeichenmodalitäten in Gesamttexten eignen und diese nach Möglichkeit syntaktisch oder semantisch begründen. Sprache dient aufgrund ihrer „great articulatory and combinational flexibility“ (Eco 1977, 172) vor allem dazu, Geschehnisse und Prozesse in ihrer zeitlichen Abfolge zu schildern (Narration). Ebenso hat Sprachliches einen großen Vorteil bei der Erklärung logischer Zusammenhänge (Explikation) und der Konstruktion von Argumentationen. Zum Vorteil gereichen der Sprache bei all diesen Aufgaben eine flexible und klare Referenz auf Sachverhalte (der/ein Wein, dieser Wein dort, Rot-/Weißwein, Chardonnay, 2006er Bordeaux etc.), Aussagen verknüpfende Wortarten (deshalb, weil, aufgrund) sowie die Fähigkeit, die Intention einer Aussage (erlauben, bitten, versprechen etc.) zu erkennen zu geben.
Bilder als wahrnehmungsnahe visuelle Zeichenkonfigurationen haben ihre Stärken beim Vor-Augen-Führen von Objekten und ihrer Lage im Raum. Ihr semantischer Überschuss, ihre Mehrdeutigkeit und Offenheit eignen sich zudem für konnotationsreiche Botschaften, die, besonders wenn visuelle Schlüsselreize bedient werden, ein hohes emotionales Aktivierungspotenzial haben. Aufgrund ihrer Eigenschaft, visuelle Realität zu simulieren, können manche Bildtypen auch zur Handlungsanleitung verwendet werden.
Musik wird einerseits als eigenständiger Text, andererseits in „dienender Funktion“ (Holly 2004, 49) verwendet. Für sich allein kann sie eine Reihe spezifischer Funktionen übernehmen, wie z. B. eine sozial-kommunikative – d. h. Gebrauch in

print_cont_9783110295740_NinaMariaKlug.indb 17

26.07.16 12:07

18   Hartmut Stöckl

bestimmten gesellschaftlichen Gruppen und zu definierten Anlässen (rituell-magisch, Feiern, Tanz, Sport etc.) und eine individualpsychologische – d. h. die persönliche Befindlichkeit zu regulieren (entspannen, unterhalten, aktivieren etc.) (vgl. dazu Bullerjahn 2001, 56). Gerade weil Musik semantisch defizitär ist und nichts darstellt, entlastet sie vom Faktisch-Informativen anderer Zeichenmodalitäten. Musik erbaut uns, „weil unser Gehör nicht dazu verpflichtet ist, in jeder Tonformel ein ‚Zeichen‘ zu dechiffrieren“ (Karbusicky 1987, 229). In multimodalen Gesamttexten kann Musik verschiedene Funktionen übernehmen: z. B. den Text strukturieren, eine Grundstimmung erzeugen, Personen oder Handlungen charakterisieren u. a. (vgl. Holly 2004, 49 ff.; Stöckl 2007, 195 f.).
Aufgrund ihrer syntaktischen und semantischen Eigenschaften scheinen Geräusche funktional relativ eingeschränkt und sind allein kaum textbildend. Allerdings verweisen sie effektiv auf Orte, Situationen und Handlungen – auch und gerade bei Abwesenheit einer bildlichen oder sprachlichen Darstellung. Historisch gesehen ist die Bedeutung des sound design (Flückiger 2007) gestiegen; der Variationsreichtum der klanglich-materiellen Gestalt von Geräuschen hat medientechnisch bedingt zugenommen und sie haben sich vom Rand in das Zentrum der Semiosphäre bewegt. Trotz ihrer semiotischen Defizite reichern Geräusche multimodale Gesamttexte (Film, Radio) mit „Ausdrucks- und Informationswert“ (Flückiger 2007, 142) an, der u. a. darin besteht, dass sie den Realitätseindruck verstärken, Vorstellungen evozieren, Teil bzw. Auslöser von Handlungen sind oder Aufmerksamkeit lenken und die Darstellung dramatisieren (s. Wolff 1996, 258 ff.; Stöckl 2007, 196 f.).

Tab. 1: Dimensionen und Kriterien zur Differenzierung von Zeichenmodalitäten

SYNTAX
Sinneskanal Semiotisierung Interne Struktur

SEMANTIK
Zeichenwirkung Qualität/Singularität Objektbezug Ausdruckspotenzial

PRAGMATIK
Wahrnehmung Kognition Kommunikative Funktion Potenziale/Defizite

3.4 Der Wert semiotischer Vergleiche und Typologien
Mit Hilfe einzelner Vergleichskriterien der Dimensionen Syntax, Semantik und Pragmatik haben wir Unterschiede der Zeichenmodalitäten Sprache, Bild, Musik und Geräusch herausgearbeitet (s. Tab. 1). Dabei zeigt sich: Sie folgen einer unterschiedlichen internen Logik, haben verschiedene semantische Reichweiten und erlauben je spezifische kommunikative Funktionen.
Zunächst scheinen die gewählten Kriterien gut zum Vergleich geeignet. Ihre Anwendung auf andere Zeichenmodalitäten sollte daher problemlos möglich sein.

print_cont_9783110295740_NinaMariaKlug.indb 18

26.07.16 12:07

Multimodalität – Semiotische und textlinguistische Grundlagen   19
Insofern ist mit dem vorgeschlagenen Raster ein systematisches Fundament für die Beurteilung der semiotischen Potenziale und ‚Grammatiken‘ von modes gelegt. Eine gewisse Schwäche mag man in der strukturalistischen Vorgehensweise sehen, die suggeriert, die Kategorien wären trennscharf und distinkt. Wir haben aber gesehen, dass dies nicht immer der Fall ist: z. B. können Bilder, Musik und Geräusch symbolisch, indexikalisch und ikonisch verwendet werden. Solche Unschärfen deuten auf die interne Heterogenität der Zeichenmodalitäten, vor allem was ihren Gebrauch angeht. Diesem Problem bin ich begegnet, indem Redundanzen eingebaut sind (Kriterien und Ebenen überlappen teilweise) und die Abstufung von Merkmalen nach typischen Gebrauchsformen vorgenommen wird.
Eine zweite Schwierigkeit besteht darin, dass viele der verwendeten Kriterien primär an der Funktionsweise von Sprache ausgerichtet sind. Sie dient (zwangsläufig) als semiotisches „modelling system“ (Sebeok 1994, 117 ff.), so dass man den hier angestellten Vergleich als ‚logozentrisch‘ bezeichnen könnte. Ich habe es vermieden, von Stärken oder Schwächen im Sinne der sprachähnlichen Leistungsfähigkeit einer Zeichenmodalität zu sprechen und stattdessen jeweils mode-Spezifisches und -Typisches hervorgehoben. Ob und inwiefern es richtig ist, Sprache als semiotisch starkes „Gravitationszentrum“ (Krämer 2005, 153) oder „Archimedium“ (Jäger 2002, 34) zu sehen, das kann letztlich nur ein Blick auf die tatsächliche multimodale Praxis in Gebrauchsdomänen und Textsorten zeigen.
Diesem Beitrag fehlt nun noch die textlinguistische Perspektive. Nach der Erörterung der Spezifik einzelner Zeichenmodalitäten bleibt jetzt zu fragen, wie sie multimodale Texte bilden und wie man diese beschreiben kann.
4 Beschreibungsdimensionen des multimodalen Texts
4.1 Multimodale Textualität
Obwohl es mit Blick auf das Alltagskonzept von Text (d. h. sprachlich und schriftlich verfasst) kontraintuitiv scheinen mag, Infografiken, TV-/Radiowerbespots, Webseiten oder Opern als Texte zu bezeichnen, kann die Betrachtung von Multimodalität m. E. theoretisch sinnvoll nur im Rahmen eines semiotisch erweiterten Textbegriffs erfolgen, wie ihn Fix (2001) fordert. Sie schreibt: „Texte müssen als Komplexe von Zeichen verschiedener Zeichenvorräte betrachtet werden“ (Fix 2001, 118). Dafür spricht eine Reihe von Gründen: Erstens reklamieren Sprache, Bild und Musik für sich bereits Textstatus, da sie zentrale Kriterien der Textualität erfüllen; sie sind also zugleich eigenständige Texte und Textteile in multimodalen Gesamttexten. Zweitens macht gerade die Verknüpfung der Zeichenmodalitäten das Spezifikum von Multimodalität

print_cont_9783110295740_NinaMariaKlug.indb 19

26.07.16 12:07

20   Hartmut Stöckl
aus – diese Verbundenheit von semiotisch unterschiedlich konstituierten Textteilen lässt sich nur als kohäsive und kohärente Bezüge zwischen Textelementen deuten. Drittens schließlich argumentiert Posner (1991, 46), dass Gegenständen dann Textstatus zukommt, wenn sie als Artefakte absichtsvollem kommunikativem Handeln entspringen und ihnen als kodierten Instrumenten eine kulturell abgesicherte Funktion und Bedeutung zukommt. Ein multimodaler Text ließe sich also als Zusammenschluss mehrerer unterschiedlicher Zeichenmodalitäten zu einem kohäsiven und kohärenten Ganzen definieren, dessen musterhafte Inhalts- und Handlungsstruktur sowie Verwendungsweisen der Modalitäten typisierten Gebrauchssituationen entspringen und bestimmte kommunikative Funktionen erlauben.
Einen textlinguistischen Rahmen zur Behandlung von Multimodalität legt die noch wichtigere Tatsache nahe, dass Produzenten wie Rezipienten ein klares Bewusstsein davon benötigen, welchen Typ oder welche Sorte Text sie gestalten bzw. verstehen. Textbenutzer fällen nämlich vordergründig keine pauschalen Textualitätsurteile; vielmehr müssen sie sicher gehen, dass ein multimodaler Text so beschaffen ist, dass er als Exemplar eines Typs oder einer Sorte erkannt und gedeutet wird. Diese Idee der Typisiertheit und Musterhaftigkeit von Texten in Abhängigkeit von Situation/Kontext, Inhalt, Medium oder Funktion liegt neben Texttyp und -sorte (Schubert 2012, 96 ff.) auch den Begriffen Genre, Register und Stil (Biber/Conrad 2009) zugrunde (s. u.). Dass das Textherstellen wie auch das Textverstehen in essentieller Weise Typisierungsleistungen voraussetzt und diese ein Grundbedürfnis im Umgang mit Kommunikationsangeboten darstellen, zeigt sich u. a. auch in den Namen, die wir (multimodalen) Texten geben – z. B. Live-Ticker (Situation), Expertenrunde (Kontext), Kochshow (Inhalt), Radio-Interview (Medium), Infografik (Funktion/Modalität). Zuletzt stellt Kesselheim (2011) die Frage, wie wir die Textsortenzugehörigkeit in der Rezeption bestimmen und behauptet,
sie wird beim Lesen konstruiert, und zwar dadurch, dass wir bei der Lektüre eine große Bandbreite von Hinweisen auf Textsortenzugehörigkeit auswerten“ (Kesselheim 2011, 362 f.); und weiter: „Textsorten ergeben sich also aus expliziten Textsortenhinweisen und der musterhaften Ausprägung anderer Textualitätshinweise (Kesselheim 2011, 364).
Solche Hinweise auf (multimodale) Textsorten beziehen wir prinzipiell aus drei miteinander in Beziehung zu setzenden Quellen: den Strukturen und Verwendungsweisen der einzelnen Zeichenmodalitäten, der wahrnehmbaren Textoberfläche inklusive Aspekten der Situation und Materialität sowie dem Erfahrungswissen über Textmuster und -verwendungen (vgl. Kesselheim 2011, 339 f.). Ich plädiere hier dafür, Multimodalität nicht als kategoriales, sondern als ein typisiertes Textphänomen zu sehen; Multimodalität zu verstehen bedeutet multimodale Textsorten/Genres differenzierend wahrzunehmen.

print_cont_9783110295740_NinaMariaKlug.indb 20

26.07.16 12:07

Multimodalität – Semiotische und textlinguistische Grundlagen   21
4.2 Textklassifikation und multimodaler Text
Auffassungen über Kommunikationstypen oder Arten von Texten machen zwei Grundannahmen. Erstens: Textsorten beruhen auf Wissen über typische Korrelationen zwischen externen Situationen/Funktionen und internen Texteigenschaften. In diesem Sinne sind Genres soziokognitive Größen, die uns Orientierung bieten; einerseits als Erwartungen in der Rezeption, andererseits als Muster in der Produktion und Gestaltung. Beides gibt unserem Umgang mit Texten einen organisierenden Rahmen. Zweitens: Textsorten sind komplexe Phänomene, die auf mehreren Ebenen und mit Hilfe diverser Kriterien zu beschreiben sind. Diese Poly-Dimensionalität erlaubt auch eine Gewichtung der verschiedenen Merkmale und hilft, Textsorten als prototypisch organisierte Kategorien zu charakterisieren (Sandig 2000) – d. h. mit jeweils typischen und weniger typischen Exemplaren.
Lomborg (2014, 45) sieht Genres (= Textsorten) als „socio-cognitive devices for sense-making in everyday life“ und streicht drei grundsätzliche Ebenen ihres Funktionierens heraus (Lomborg 2014, 45–48). Aus pragmatischer Sicht bestehen Textsorten erstens aus musterhaften Abfolgen von kommunikativen Handlungen. In kognitiver Perspektive erscheinen Textsorten zweitens als musterhafte Konfigurationen von Wissensbeständen. Drittens sind Textsorten in sozialer Hinsicht semiotische Instrumente, die stets in Abhängigkeit von Situation bzw. Kontext gestaltet werden. Hinzu kommt der wichtige Gedanke, dass es trotz aller „normative orientations within a social situation“ (Lomborg 2014, 46) neben einer prototypischen Umsetzung des Musters auch starke Variationsgrade, Individualisierungen und Hybridisierungen von Textsorten gibt. Die drei Komponenten Handlungsstruktur, Themenstruktur und Kontextsensitivität liegen allen Ansätzen zur Textklassifizierung zugrunde, sie werden aber in den Modellen jeweils verschieden gewichtet.
In der systemisch-funktionalen Linguistik werden unter dem Begriff Genre vor allem die stages, d. h. die einzelnen kommunikativen Handlungen hervorgehoben, die in einer Textsorte in je typischer Weise strukturiert sind. Sie dienen einer übergeordneten sozialen Aktivität, wie z. B. dem Erklären oder dem Überzeugen, und zeichnen sich jeweils durch markante sprachliche Muster aus (vgl. Muntigl 2011, 317). Die funktionale Linguistik hat auch den Gedanken stark gemacht, dass Kulturen letztlich durch die miteinander in vielfältigen Bezügen stehenden Textsorten, also durch in Familien, Netzen oder Gruppen organisierte Textsortenrepertoires konstituiert werden (Martin/Rose 2008, 235 ff.). Ohne einen Einbezug multimodaler Texte sind diese Repertoires und Kulturen nicht denkbar.
Das Konzept Register betont in neueren Ansätzen (Biber/Conrad 2009, 6–11) den systematischen Zusammenhang zwischen Aspekten der Situation und den sprachlichen Mitteln. Die Gestaltung einer Textsorte resultiert hier funktional aus situativen Faktoren und diese Sicht muss für multimodale Textsorten auf typische Ressourcen aller beteiligten Zeichenmodalitäten ausgeweitet werden. Der Register-Perspektive

print_cont_9783110295740_NinaMariaKlug.indb 21

26.07.16 12:07

22   Hartmut Stöckl
auf Textsorten kommt zugute, dass sie über ein komplexes Bild aller situativen Faktoren verfügt (s. Martin/Rose 2008, 36–47).
An dem Stil-Begriff scheiden sich die Ansichten; klar ist nur, dass Stilmerkmale auf allen Textbeschreibungsebenen relevant werden können und somit Teil eines Konzepts von Textsorte sind. Während die anglistische Linguistik dazu neigt, Stil als Resultat individueller oder sozialer ästhetischer Vorlieben zu sehen und nicht als direkte Funktion des situativen Kontexts (Biber/Conrad 2009, 72), tendiert die germanistische Linguistik eher zu der Auffassung, es gibt Textsortenstile, die dann – im Sinne von Register (s. o.) – typische Gestaltungsmittel beinhalten. Es spricht m. E. viel dafür, Stile als Bezeichnungen für Sub-Textsorten (sub-registers/sub-genres) zu reservieren, die dadurch zustande kommen, dass Textsortenmuster variierend durchgeführt werden. Anzahl und Art der Stile einer Textsorte bestimmen dann, wie sie intern strukturiert ist; d. h. ob die betreffende Textsorte über einen klaren Prototyp verfügt und welche peripheren Typen sie hat. Multimodale Stile, etwa für Zeitungsartikel, Werbeanzeigen oder Infografiken (s. u.) sind u. a. von medialen und sozialen Faktoren bedingt – wie z. B. Material, Technologien oder Trends, Einstellungen und Präferenzen von Agenturen.
4.3 Multimodale Textsortenanalyse – Ein Modell
Ganz gleich wie man Textsorte fasst, wichtig scheint ein Modell, das konkrete (multimodale) Textsorten auf möglichst vielen Beschreibungsebenen zu charakterisieren vermag. Das hat sich bewährt und entspricht den oben erläuterten Vorstellungen zur Textklassifikation. Traditionell (z. B. Heinemann/Heinemann 2002, 144 ff.) kommen dabei vergröbernd die folgenden Grunddimensionen zum Einsatz: Situation/Kontext, Inhalt, Handlung (Funktion), Form (Struktur, Gestaltung, Formulierung etc.); diese können flexibel spezifiziert werden. Für multimodale Textsorten stellt sich nun die Frage, ob und wie die Parameter adaptiert oder erweitert werden müssen. Muntigl (2011, 333) argumentiert, dass wir aufgrund der multimodalen Konstruktion von Genres ein Modell benötigen, das „zeigen kann, wie Genres als multi-modaler Prozess entstehen“. Van Leeuwen (2005a, 80) meint, „the generic structure of the text is […] multimodally realised“ und unterscheidet diesbezüglich zwei Grundkonstellationen. Entweder werden für verschiedene funktionale Handlungsabschnitte (stages) unterschiedliche Zeichenmodalitäten gewählt – z. B. kann ein Online-Nachrichtentext das Authentifizieren einer berichteten Tatsache mit einem Bild oder Videoclip bewerkstelligen (statt mittels eines sprachlichen Zitats). Hier entsteht eine Textstruktur, in der sich die modes abwechseln. Oder: ein funktionaler Abschnitt kann durch eine gezielte Kombination von modes realisiert werden – z. B. konstruieren moderne Werbeanzeigen ihre Argumentation nicht rein sprachlich, sondern verbal-visuell. Hier besteht die Textstruktur aus einer Abfolge semiotisch gemischter stages. Insgesamt kann man m. E. eher von einer integrativen Mischung der Zeichenmodalitäten in multimodalen Textstrukturen ausgehen, so dass „these different modes fuse (Hervorhebung im Original)

print_cont_9783110295740_NinaMariaKlug.indb 22

26.07.16 12:07

Multimodalität – Semiotische und textlinguistische Grundlagen   23
in the realisation, rather than that they have distinct functional roles to play“ (van Leeuwen 2005a, 80). In jedem Falle muss es darauf ankommen, das Zusammenspiel aller beteiligten Zeichenmodalitäten in der Struktur und Gestaltung des multimodalen Texts als Funktion von typischen Kontext- und Situationsfaktoren beschreiben und so zur Charakterisierung einer spezifischen multimodalen Textsorte gelangen zu können.
Auf diesen Grundüberlegungen aufbauend, will ich im Folgenden ein kompaktes heuristisches Modell zur Analyse multimodaler Textsorten vorschlagen und illustrieren (s. Abb. 2). Dabei nutze ich allgemein akzeptierte Kriterien bzw. Ebenen der Beschreibung (Kesselheim 2011) und adaptiere sie für die Bedingungen multimodaler Textualität. 1. Gliederung/Abgrenzung: Texte signalisieren durch diverse Mittel ihre interne
Gliederung in größere oder kleinere Textteile. So lassen textgraphische oder -rhythmische Ressourcen eine Binnenstruktur entstehen, die dem Rezipienten in der Wahrnehmung als sortentypische multimodale Gestalt oder Konfiguration bewusst wird und die Grundlage für die Ordnung von Handlungen und Themen schafft. Aber auch nach außen markieren Texte ihre Grenzen gegenüber benachbarten Kommunikationsangeboten in Textsortennetzen, Sendungsstrukturen oder Programmflüssen – etwa durch Linien, Rahmen, Texturwechsel, akustische Signale oder Pausen etc. 2. Handlungsstruktur: Wenn es stimmt, dass Textsorten vor allem durch bestimmte Abfolgen oder Anordnungen von funktionalen Handlungsabschnitten gekennzeichnet sind, so muss eine multimodale Analyse bestimmen, wie sich die Zeichenmodalitäten auf diese ‚stages‘ verteilen. Oder anders: Die pragmatischen Leistungen der einzelnen ‚modes‘ und deren Gewicht und Status für das übergeordnete Handlungsziel (z. B. Erklären, Instruieren) sind zu ermitteln. Dabei stellt sich die theoretisch noch ungeklärte Frage, ob alle Zeichenmodalitäten überhaupt kommunikative Handlungen im Sinne von Sprechakten ausführen können (s. dazu z. B. van Leeuwen 2005b, 122). 3. Themenstruktur: Unter dem Aspekt ihrer Repräsentationsfunktion sind Texte Konfigurationen von Teilthemen, die in einer größeren Struktur entfaltet und geordnet werden. Für multimodale Texte soll untersucht werden, welche Teilthemen die einzelnen Zeichenmodalitäten zum Gesamttext beitragen und wie sie in der Kombination der Zeichentypen strukturiert werden. Hier ist nach den Koreferenzen von Textelementen über die Grenzen von ‚modes‘ und deren Organisation in Wissensrahmen zu fragen. 4. Multimodale Verknüpfung: Im Kern einer multimodalen Textsortenanalyse muss die Frage stehen, wie die beteiligten Zeichenmodalitäten verknüpft sind. Darauf geben Themen- und Handlungsstruktur nur zum Teil eine Antwort. Der genaue Blick auf die Bezüge zwischen den Modalitäten erhellt, welche Elemente sich in welcher Weise kohäsiv oder kohärent zueinander verhalten und welche pragmatischen oder rhetorischen Funktionen die Modalitäten in wechselseitiger Bezogenheit füreinander übernehmen.

print_cont_9783110295740_NinaMariaKlug.indb 23

26.07.16 12:07

24   Hartmut Stöckl

Abb. 2: Multimodale Textsortenanalyse. Dieses Modell der multimodalen Textanalyse nutzt tradierte linguistische Beschreibungskriterien wie z. B. Kontext/Situation, Inhalt, Funktion, Form/Struktur und adaptiert sie für die Untersuchung multimodaler Textualität. Die Infografik demonstriert die Analyseebenen bzw. -schritte des Modells (s. 1–5) anhand der Werbeanzeige Volkswagen Front Assist. It knows what’s ahead (s. Abb. 4) und illustriert deren Ergebnisse.

print_cont_9783110295740_NinaMariaKlug.indb 24

26.07.16 12:07

Multimodalität – Semiotische und textlinguistische Grundlagen   25
5. Intertextualität: Wie ein Text intern strukturiert und multimodal verfasst ist, hängt auch von seinen Bezügen zu benachbarten Zeichenangeboten ab. Hier ist darauf zu schauen, welche expliziten Verweise auf Nachbartexte vorkommen und welche gestalterischen Ähnlichkeiten zwischen dem aktuellen und verwandten Texten es gibt.
Man mag die Kriterien anders einteilen oder weitere hinzunehmen – aber mit diesem Grundraster haben wir m. E. die wesentlichen Elemente eines multimodalen Textsortenmodells beschrieben. Zu bedenken bleibt dabei, dass die einzelnen Beschreibungsebenen nur in der Analyse zu trennen, in den Prozessen des Textherstellens und -verstehens aber ineinander verwoben sind. Wichtig ist auch, dass diese textinternen Charakteristika sortenbildend gestaltet werden, indem sie jeweils auf die situativen Faktoren zugeschnitten werden. Unter diesen text-externen Charakteristika kommt der Textfunktion, d. h. dem kommunikativen Zweck der Sorte das größte Gewicht zu. Alle Situationsfaktoren sind in dem übergeordneten Begriff der Kommunikationsform aufgehoben (s. Kap. 2).
4.4 Empirische textsortenkontrastierende Multimodalitätsanalyse
Im Folgenden sollen drei multimodale Textsorten der Kommunikationsform Zeitung/Zeitschrift (Print) – Nachricht (Abb. 3), Werbeanzeige (Abb. 4) und Infografik (Abb. 5) – mit Hilfe des vorgestellten Modells analysiert werden. Das Ziel besteht darin, die Eignung der Kriterien zu überprüfen und zu zeigen, wo genau die Unterschiede zwischen den multimodalen Textsorten liegen und wie sie in der Konstitution der Texte zustande kommen. Insbesondere ist es interessant, die durch die einheitliche Kommunikationsform bedingten Gemeinsamkeiten gegen die sortenbedingten Unterschiede abzuwägen.
Die drei Textsorten zeigen eine je eigene multimodale Gliederung: Die Nachricht (s. Abb. 3) besteht aus Überschrift, Textkörper, Bild und Bildunterschrift. Die Anzeige (s. Abb. 4) gliedert sich in die (vier) Bilder, die Schriftzeile und das Logo. Die Infografik (s. Abb. 5) ist in Textkörper, Bild, Namen-/Zahlen-Etiketten und weißes Schriftband geteilt. Die Textteile der multimodalen Gestalt werden durch verschiedene textgraphische Mittel signalisiert, wie z. B. Schriftstil und -größe, Linien/Rahmen sowie Form und Farbe, und durch Positionierung konfiguriert. Diese Ressourcen gibt die Kommunikationsform vor, sie werden aber so verwendet, dass (wieder)erkennbare Textformen entstehen. Die Abgrenzung der Texte gegenüber benachbarten Kommunikationsangeboten ist durch Texturunterschiede der Flächen bzw. durch Abstände und Rahmen gegeben. Für die Nachricht scheint typisch, dass trotz Abgrenzung auch Bezüge zu angrenzenden Texten ermöglicht werden; die bebilderte Hauptnachricht

print_cont_9783110295740_NinaMariaKlug.indb 25

26.07.16 12:07

26   Hartmut Stöckl
stellt einen graphischen Konnex mit dem thematisch verwandten, rechts stehenden Kommentar her.

Abb. 3: Hollande und Sarkozy in der Stichwahl (Frankfurter Allgemeine Zeitung FAZ 23.04.2012, Titelseite/Ausschnitt)
Die textgraphische Konturierung einer sortentypischen Gestalt bildet die Basis für die Etablierung von Handlungs- und Themenstruktur. In der Nachricht (s. Abb. 3) kündigt die Überschrift den Inhalt an (Wahl in FR), der Textkörper berichtet die Details, das Bild führt einen Akteur vor Augen und die Bildunterschrift nimmt eine Bewertung vor und ergänzt Details. Die Anzeige (s. Abb. 4) beinhaltet drei funktionale Abschnitte: die vier Bilder präsentieren Tarot-Karten, die Schriftzeile beschreibt und bewertet ein Merkmal des Autos und der Slogan fasst verallgemeinernd zusammen und schließt den Text ab. Für die Infografik (s. Abb. 5) ergeben sich die folgenden Teilhandlungen: der Textkörper stellt Fragen (Mordrisiko, Mordraten), das Bild zeigt einen Mord, die Namen-/Zahlen-Etiketten beantworten die Fragen, indem sie nennen und quantifizieren, das weiße Schriftband gibt Quellen und Autoren an. Gemeinsam ist den multimodalen Textsorten also, dass sie die einzelnen Handlungen (stages) klar auf die Modalitäten verteilen und dass Sprache dabei eine zentrale Stellung einnimmt, wenn ihr Status auch anteilsmäßig verschieden ist (am geringsten in der Anzeige). Unterschiedlich fällt aber die Beziehung der modes zueinander aus (s. u.). Dies lässt den Schluss zu, dass multimodale Textsorten eine jeweils spezifische Matrix funktionaler Abschnitte haben und diese in je eigener, sorten-typischer Weise auf die Modalitäten verteilen.
Gleiches lässt sich für die Themenstruktur sagen. Eine narrative Matrix in der Nachricht (s. Abb. 3) beinhaltet das Hauptereignis (Überschrift) und seine Details

print_cont_9783110295740_NinaMariaKlug.indb 26

26.07.16 12:07

Multimodalität – Semiotische und textlinguistische Grundlagen   27
(Textkörper, Bild, Bildunterschrift); dabei wählt das Bild den Hauptakteur und bewertet ihn in der Bildunterschrift. So folgt die multimodale Themenentfaltung einer Ganzes-Teil-Struktur. Die Themenstruktur der Anzeige (s. Abb. 4) beruht auf einer argumentativen Matrix, indem sie zwei scheinbar inkompatible Themen (Tarot-Spiel und Kfz-Sicherheitssystem) verbindet und durch das Logo auf die Marke VW bezieht. Hier muss Multimodalität für den Vergleich der Themen sorgen und ihren logischen Konnex herstellen. Die Infografik (s. Abb. 5) gehorcht einer explikativen Matrix; in ihr erklären Bild und Namen-/Zahlen-Etiketten das Thema Gewaltverbrechen, indem sie Quantitäten lokalisieren. Multimodalität gewährleistet hier Übersichtlichkeit und das selektive Explorieren der Daten.

Abb. 4: Volkswagen Front Assist. It knows what’s ahead. VW, DDB London UK, (Lürzer’s Archiv 4/2012, 26, 4.1235)
Die Verknüpfung der Zeichenmodalitäten lässt sich als eine spezifische Form von Kohäsion und Kohärenz verstehen, bei der Form- und Bedeutungszusammenhänge sowie Sinnkontinuitäten zwischen semiotisch unterschiedlich konstituierten Textteilen hergestellt werden. Die Konnektivität und Vernetzung von Sprache, Bild, Textgraphischem und Musik/Geräusch folgt dem generellen Prinzip der intersemiotischen Komplementarität (Royce 1998), nach dem sich die einzelnen modes gegenseitig ergänzen und zur Sinnstiftung wechselseitig aufeinander angewiesen sind. Auch bedeutet die Annahme einer multimodalen oder intersemiotischen Kohäsion (Stöckl

print_cont_9783110295740_NinaMariaKlug.indb 27

26.07.16 12:07

28   Hartmut Stöckl
2012a, 251 ff.), dass es in der Struktur der Texte „Kontaktstellen“ (Stöckl 1997, 143) oder „edit points“ (van Leeuwen 2005b, 184) gibt, an denen sich Zeichen unterschiedlicher Modalitäten (z. B. Wörter oder Bildelemente etc.) explizit oder implizit aufeinander beziehen und so eine Junktion (Wetzchewald 2012, 233–238) oder ein cohesive tie (Halliday/Hasan 1976) entsteht. Folgt man der textlinguistischen Theorie, so lassen sich zumindest drei große Typen multimodaler Textkonnektivität unterscheiden und als analytische Instrumente verwenden.
Lexikalische Kohäsion (s. Schubert 2012, 46 ff.) stellt Beziehungen zwischen eigenständig bedeutungstragenden Zeichen her, d. h. z. B. zwischen Lexemen, darstellenden Bildelementen, verweisenden Geräuschen und symbolischer Musik. Hier können Elemente wiederholt bzw. paraphrasiert werden, zueinander in intersemiotic sense-relations stehen (wie z. B. Antonymie, Hyperonymie oder Meronymie) und als Kollokationen (im Sinne von Halliday/Hasan 1976) oder „lexical sets“ (Schubert 2012, 54) in assoziativen Feldern oder Sachgruppen verknüpft sein. Grammatische Kohäsion (s. Schubert 2012, 32 ff.) ist stärker in der spezifischen Funktionsweise von Sprache verankert, lässt sich aber auch auf intermodale Konnektivität projizieren. Hierzu gehören alle Zeichen, die auf andere Textelemente verweisen können, wie z. B. Demonstrativ- und Personalpronomina, elliptische Strukturen, Parallelismen und Konjunktionen. ‚Grammatisch‘ kohäsiv wirken aber auch solche textgraphischbildlichen Mittel wie Pfeile, Linien, Balken, Rahmen, Farben und alles, was für einen formalen Zusammenhalt der Modalitäten sorgt.
Kohärenz schließlich wird vom Rezipienten als Sinnkontinuität eines Textes durch aktives Interpretieren und Inferieren unter bestimmten Wissensvoraussetzungen und Kontextannahmen hergestellt (Schubert 2012, 65). Insofern ist sie formal nicht direkt repräsentiert, wird aber insbesondere durch Mittel der lexikalischen Kohäsion signalisiert. Kohärenz kann im multimodalen Text zum einen als logisch-semantische Relationen zwischen Propositionen, d. h. sogenannte relational propositions (Mann/ Thompson 1986) oder discourse relations (Renkema 2004, 108 ff.) modelliert werden. So z. B. kann ein Bild die logische Folge einer sprachlich ausgedrückten Ursache sein. In ähnlicher Weise hat man versucht, rhetorische Figuren (z. B. Metapher) als mentale Operationen zwischen Aussagen in verschiedenen Zeichenmodalitäten zu beschreiben (s. Gaede 1981; Bonsiepe 1965/1996). Zum anderen lässt sich Kohärenzaufbau dadurch zeigen, dass einzelne Elemente verschiedener Zeichenmodalitäten in bestehende Wissensrahmen und mentale Skripte (frames/scripts) passen, die so multimodal präsentierte Inhalte integrieren. Im Folgenden will ich – aufbauend auf den erörterten Theorien von Kohäsion/Kohärenz – illustrieren, wie multimodale Verknüpfungen in den drei Textsortenbeispielen funktionieren.

print_cont_9783110295740_NinaMariaKlug.indb 28

26.07.16 12:07

Multimodalität – Semiotische und textlinguistische Grundlagen   29

Abb. 5: Murder International!, GOOD Worldwide Inc. & Chris Korbey, USA 2009 (www.good.is/infographics, s. Korpus in Stöckl 2012c)
In der Nachricht (s. Abb. 3) entsteht grammatische Kohäsion in erster Linie durch das Personalpronomen ihn in der Bildunterschrift, das zugleich auf das zentrale Bildelement wie auch auf den Namen Hollande in Über- und Unterschrift rekurriert. Die Linie unterhalb von Nachricht und Bild ‚unterstreicht‘ die formale Zusammengehörigkeit. Ein lexikalischer Konnex kommt in zweifacher Weise zustande: Die bewertende Formulierung Alle Blicke sind auf ihn gerichtet wird im Foto bildlich paraphrasiert; dabei stehen ‚Blick‘ und ‚Kameras‘ in metonymischem Sinnbezug. Zudem liefert die Bildunterschrift Lexeme, die im Bild nicht erfahrbare Informationen geben (Sonntag, nach der Stimmabgabe = Zeit, in Tulle in Zentralfrankreich = Ort) und in das vom Thema vorgegebene und im Text elaborierte Begriffs-Set Wahl passen. Schließlich legen diese inhaltlichen Bezüge eine relationale Proposition des ‚Background‘ nahe, d. h. die Bildunterschrift enthält Hintergrundinformationen zum im Bild Dargestellten und kontextualisiert es so. Rhetorisch fällt die bedeutungsspielerische Literalisierung des metaphorischen Ausdrucks Alle Blicke sind auf ihn gerichtet im Bild auf. Vielleicht am stärksten für multimodale Kohärenz sorgt das Bildmotiv, das einen Hauptakteur im dem Text zugrunde liegenden Skript Präsidentenwahl zeigt. Rezipienten verfügen diesbezüglich über stereotypes Wissen und deuten die Stimmabgabe des Favoriten als herausgehobenes Ereignis in der Narration der Nachricht.
Die Werbeanzeige (s. Abb. 4) erhält grammatische Kohäsion mittels des Relativpronomens what, das auf die Bildinhalte hinweist. Formal werden Schrift und Bild

print_cont_9783110295740_NinaMariaKlug.indb 29

26.07.16 12:07

30   Hartmut Stöckl
nur dadurch in Beziehung gebracht, dass sie auf dem gleichen texturierten Untergrund montiert sind. Lexikalische Kohäsion ist signalisiert, indem die vier Kartenbeschriftungen (learner driver, old lady, courier, van man) Kohyponyme zum Oberbegriff ‚Personen (im Straßenverkehr)‘ bilden und damit die vier Einzelbilder konzeptuell zu einer Sachgruppe bündeln und auf what rekurrieren lassen. Das Verstehen der Anzeige beruht auf zwei Inferenzen: Erstens, die dargestellten Personen sind die Objekte, die das Front Assist beispielsweise erkennt. Zweitens, der Text öffnet mit Bild(ern) und Sprache zwei an sich zusammenhangslose Wissensrahmen (Tarot-Karten = Wahrsagen, Front Assist = Sicherheitssystem), die bei näherer Überlegung in einen antonymischen Sinnbezug (Ungewissheit vs. Gewissheit) zu setzen sind. Diese Frame-Antithese legt den argumentativen Schluss nahe, dass man sich auf Front Assist verlassen kann, weil es Gefahren nicht wahrsagt, sondern erkennt. Die relationale Proposition, die hier zustande kommt, ist die der Elaboration; die Bilder geben illustrative Beispiele.
In der Infografik (s. Abb. 5) sorgen die Interrogativpronomina where (in the world) und which (countries) für grammatische Kohäsion, da die im Bild ‚aufgestellten‘ Schilder Ländernamen und Zahlen beinhalten und somit die Fragen beantworten. Der Bildbegleittext und die Etiketten haben die gleiche graphische Form, zudem korrelieren lowest und highest mit den Farben hellblau und rot sowie Zahlen mit Schildergrößen – auch dadurch entsteht formale Kohäsion. In lexikalischer Hinsicht zeigt der Text multimodale Kohäsion durch ausgedehnte hyponymische Sinnbezüge und lexikalische Felder (countries – USA, Malta, Ireland etc.; homicide rates/murders per 100.000 people – 0.7, 45.7 etc.). Intermodale Kohärenz ergibt sich hier dadurch leicht, dass ein Wissensrahmen (Mordratenverteilung) sprachlich wie bildlich aktiviert und dann konsequent durch Daten (Orte und Zahlen) gefüllt wird. Der Text folgt dem rhetorischen Grundmuster der Frage-Antwort, das sich auf die Modalitäten verteilt. Das Hintergrundbild kann mit Blick auf den Begleittext als Restatement (being stabbed by a murderer), die Schilder als lokalisierende und quantifizierende Elaboration verstanden werden.
Die drei multimodalen Textsorten unterscheiden sich auch in ihrer Intertextualität. Die Nachricht verweist explizit (Fortsetzung Seite 2, Vorteil Hollande) auf die benachbarten Texte Bericht und Kommentar, mit denen sie ein thematisches Textsortennetz bildet. Die Werbeanzeige beinhaltet keine expliziten Intertextualitätshinweise. Das Markenlogo VW und der Begriff Front Assist können aber als implizite Verweise auf andere Textwelten (Markenkommunikation, technische Dokumentation, Technikjournalismus) gedeutet werden. Die Infografik zeichnet wiederum ein expliziter Intertextualitätsverweis aus, in diesem Falle auf die verwendeten Quellen (Sources), die für ihre Qualität und Aussagekraft wichtig sind.

print_cont_9783110295740_NinaMariaKlug.indb 30

26.07.16 12:07

Multimodalität – Semiotische und textlinguistische Grundlagen   31
5 Fazit und Ausblick
Abschließend will ich zusammenfassen, welche Haupterkenntnisse über Multimodalität die dargelegten theoretischen Reflexionen und praktischen Analysen bringen. Dabei ist zunächst zu fragen, was sich aus den exemplarischen Textsortenanalysen lernen lässt. Der Vergleich der drei Beispiele liefert sowohl typische Merkmale multimodaler Texte allgemein als auch Hinweise auf Spezifika der Sorten. Zuallererst bedingt die Kommunikationsform Zeitung/Zeitschrift eine textgraphische Binnengliederung, die den Raum einer Seite in textsortentypischer Weise zu wiedererkennbaren Gestalten konfiguriert. Texte audiovisueller Kommunikationsformen z. B. müssen hingegen den linear-zeitlichen Fluss der Zeichen rhythmisch konturieren und nutzen dazu Charakter und Tempo der Musik, Sprechgeschwindigkeit und -rhythmus oder den Schnitt der bewegten Bilder. Die Handlungs- und Themenstruktur der Sorte und des konkreten Exemplars bestimmt dabei – wie die Beispiele zeigen – die graphische Gliederung der multimodalen Texte. Für die Strukturierung von Handlungen und Themen wiederum ist die Textfunktion, d. h. der Texttyp maßgebend. Hier scheint es jeweils eine entsprechende funktionale Matrix zu geben (d. h. z. B. zugrunde liegende narrative, argumentative oder explikative Muster), die einen größeren organisierenden Rahmen für semantische und pragmatische Strukturierungsentscheidungen vorgibt.
Bezüglich der Verknüpfung der Zeichenmodalitäten zur Herstellung von intermodaler Kohäsion/Kohärenz gibt es die markantesten Unterschiede zwischen den Textsorten. So kann v. a. lexikalische Kohäsion unterschiedlich dicht (d. h. mit wenigen oder vielen Elementen) und mit verschiedenen Mitteln (Paraphrase vs. Sachgruppe vs. Hyponymie) hergestellt werden. Außerdem resultieren aus den inhaltlichen Bezügen der Modalitäten unterschiedliche relationale Propositionen (z. B. Background) und verschiedene rhetorische Muster (z. B. Metapher), die textsortenprägend sein können. Schließlich scheint die Art und Weise, wie Frames oder Skripts signalisiert und aufgebaut werden, ein klares differenzierendes Kriterium für multimodale Textsorten. Während für Nachricht und Infografik Frame- bzw. Skriptkontinuität typisch sind, zeigt die Werbeanzeige Divergenz bzw. kalkulierte semantische Gegensätze. Die drei Beispielanalysen legen aber auch sortenübergreifende Gemeinsamkeiten in der multimodalen Verknüpfung nahe; diese betreffen die grammatische bzw. formale Kohäsion. In den sprachlichen Begleittexten gibt es jeweils Ausdrücke (Pronomina), die auf die Bilder verweisen und so explizite intermodale Bezüge herstellen. Außerdem verhelfen verschiedene graphisch-bildliche Mittel (Farbe, Form, Größe, Linien, Textur) den Modalitäten zu einem formalen Zusammenhang, so dass eine einheitliche textgraphische Gestalt entsteht.
Das Konzept der multimodalen Textsorte folgt dem Grundgedanken, dass die Strukturierung und semiotische Gestaltung einer Sorte durch die jeweils relevanten Aspekte der Situation – vornehmlich durch die Funktion – geprägt und typisiert werden. Diese typisierende Prägung erfolgt auf zwei großen Ebenen: Erstens bezieht

print_cont_9783110295740_NinaMariaKlug.indb 31

26.07.16 12:07

32   Hartmut Stöckl
sie sich, wie oben gezeigt, auf die Verknüpfung der Modalitäten bzw. die Herstellung von intermodaler Kohäsion/Kohärenz, zweitens aber auch auf den Gebrauch der einzelnen Modalitäten für sich. So muss man fragen, wie Sprache in den verschiedenen Textteilen einer Nachricht, Werbeanzeige oder Infografik typischer Weise gebraucht wird. Genauso ist zu fragen ist, welche Gestaltungsmerkmale ein Nachrichten-, Werbe- oder infographisches Bild auszeichnen. Dabei ist prinzipiell von einer Vielfalt der Muster auszugehen, die um einen Prototypen herum organisiert sind. Für diese Variabilität der Gestaltung multimodaler Textsorten und ihrer einzelnen Zeichenmodalitäten kann m. E. der Begriff des Stils (d. h. multimodale Textsortenstile) sinnvolle Anwendung finden.
Blicken wir schließlich auf die Prozesse des Verstehens und der Produktion von multimodalen Texten, so legen die Ausführungen in den Kapiteln 3 und 4 die Notwendigkeit einer Dreifachkompetenz nahe. Rezipienten müssen – um multimodale Zeichenangebote sinnvoll interpretieren zu können – 1) einzelne Zeichenmodalitäten in ihren syntaktischen, semantischen und pragmatischen Dimensionen different verstehen (semiotische Kompetenz), 2) formale, inhaltliche und funktionale Zusammenhänge zwischen den Zeichenmodalitäten erkennen (integrative Kompetenz) und 3) die typisierte, musterhafte Verwendung der Modalitäten als einer Textsorte und einem Stil zugehörig deuten (Textsortenkompetenz).
Für die weitere Entwicklung der Multimodalitätsforschung machen die hier dargelegten Konzepte, Modelle und Reflexionen zwei Paradigmen stark: Einerseits ist die kontrastive Erforschung multimodaler Textsortenrepertoires geboten, um der situativ-funktionalen Wandelbarkeit multimodaler Gestaltung und historischen Veränderungen multimodaler Textsortenstile nachgehen zu können. Andererseits benötigen wir mehr Produkt-, Produktions- und -rezeptionsforschung zum multimodalen Text, damit wir die inhaltlich-funktionalen Besonderheiten der Modalitäten und ihre daraus resultierenden Gebrauchsweisen noch besser verstehen lernen.
6 Literatur
Bateman, John (2008): Multimodality and Genre. A Foundation for the Systematic Analysis of Multimodal Documents. Basingstoke.
Biber, Douglas/Susan Conrad (2009): Register, Genre, and Style. Cambridge. Björkvall, Anders (2012): Multimodality. In: Jan-Ola Östmann/Jeff Verschueren (eds.): Handbook of
Pragmatics. Amsterdam, 1–20. Bonsiepe, Gui (1965/1996): Visuell-verbale Rhetorik. Über einige Techniken der persuasiven
Kommunikation. In: Gui Bonsiepe (Hg.): Interface – Design neu begreifen. Mannheim, 85–103. Bühler, Karl (1934/1990): Theory of Language. The Representational Function of Language.
Amsterdam. Bullerjahn, Claudia (2001): Grundlagen der Wirkung von Filmmusik. Augsburg. Chandler, Daniel (2007): Semiotics. The Basics. London. Eco, Umberto (1977): A Theory of Semiotics. London/Basingstoke.

print_cont_9783110295740_NinaMariaKlug.indb 32

26.07.16 12:07

Multimodalität – Semiotische und textlinguistische Grundlagen   33
Engel, Hans (1990): Sinn und Wesen der Musik. In: Karbusicky 1990, 50–60. Faltin, Peter (1985): Bedeutung ästhetischer Zeichen, Musik und Sprache. Aachen. Fix, Ulla (2001): Zugänge zu Stil als semiotisch komplexer Einheit. In: Eva-Maria Jakobs/Annely
Rothkegel (Hg.): Perspektiven auf Stil. Tübingen, 113–126. Flückiger, Barbara (2007): Sound Design. Die virtuelle Klangwelt des Films. Marburg. Forceville, Charles (2014): Relevance theory as model for analysing visual and multimodal
communication. In: David Machin (ed.): Visual Communication. Berlin/Boston, 51–70. Fricke, Ellen (2012): Grammatik multimodal. Wie Wörter und Gesten zusammenwirken. Berlin/
Boston. Gaede, Werner (1981): Vom Wort zum Bild. Kreativ-Methoden der Visualisierung. München. Goodman, Nelson (1976): Languages of Art. An Approach to a Theory of Symbols. Indianapolis. Habscheid, Stephan (Hg.) (2011): Textsorten, Handlungsmuster, Oberflächen. Linguistische
Typologien der Kommunikation. Berlin/New York. Halliday Michael A. K. (1978): Language as Social Semiotic. The Social Interpretation of Language
and Meaning. London. Halliday, Michael A. K./Ruqayia Hasan (1976): Cohesion in English. London. Heinemann, Margot/Wolfgang Heinemann (2002): Grundlagen der Textlinguistik. Interaktion –
Text – Diskurs. Tübingen. Holly, Werner (2004): Fernsehen. Tübingen (Grundlagen der Medienkommunikation, 15). Holly, Werner (2011): Medien, Kommunikationsformen, Textsortenfamilien. In: Habscheid, 144–163. Jäger, Ludwig (2002): Transkriptivität. Zur medialen Logik der kulturellen Semantik. In: Ludwig
Jäger/Georg Stanitzek (Hg.): Transkribieren Medien/Lektüre. München, 19–41. Jakobson, Roman (1960): Closing statement. Linguistics and poetics. In: Thomas A. Sebeok (ed.):
Style in Language. Cambridge, 350–377. Jewitt, Carey (2014): The Routledge Handbook of Multimodal Analysis. 2nd edition. London/New York. Jewitt, Carey/Gunther Kress (eds.) (2003): Multimodal Literacy. New York. Juslin, Patrik N./John A. Sloboda (2001): Music and Emotion. Theory and Research. Oxford. Karbusicky, Vladimir (1987): Zeichen und Musik. In: Zeitschrift für Semiotik 9 (3–4), 227–249. Karbusicky, Vladimir (Hg.) (1990): Sinn und Bedeutung in der Musik. Texte zur Entwicklung des
musiksemiotischen Denkens. Darmstadt. Kesselheim, Wolfgang (2011): Sprachliche Oberflächen. Musterhinweise. In: Habscheid, 337–366. Klug, Nina-Maria/Hartmut Stöckl (2015): Sprache im multimodalen Kontext. In: Ekkehard Felder/
Andreas Gardt (Hg.): Handbuch Sprache und Wissen. (Handbücher Sprachwissen – HSW, Bd. 1). Berlin/Boston, 242–264. Koch, Walter A. (1971): Varia Semiotica. Hildesheim (Studia Semiotica Series Practica, 3). Krämer, Sybille (2005): Das Medium zwischen Zeichen und Spur. In: Gisela Fehrmann/Erika Linz/ Cornelia Epping-Jäger (Hg.): Spuren Lektüren. Praktiken des Symbolischen. München, 153–166. Kress, Gunther (2014): What is mode? In: Jewitt, 60–75. Kress, Gunther/Theo van Leeuwen (2001): Multimodal Discourse. The Modes and Media of Contemporary Communication. London. Leeuwen, Theo van (2005a): Multimodality, genre and design. In: Sigrid Norris/Rodney H. Jones (eds.): Discourse in Action. Introducing Mediated Discourse Analysis. London/New York, 73–94. Leeuwen, Theo van (2005b): Introducing Social Semiotics. London/New York. Leeuwen, Theo van (2011): Multimodality and multimodal research. In: Margolis/Pauwels, 549–569. Lomborg, Stine (2014): Social Media, Social Genres. Making Sense of the Ordinary. New York. Lürzer’s Archiv. Werbung aus aller Welt. Nr. 4/2012. Mann, William C./Sandra A. Thompson (1986): Relational propositions in discourse. In: Discourse Processes 9, 57–90.

print_cont_9783110295740_NinaMariaKlug.indb 33

26.07.16 12:07

34   Hartmut Stöckl
Margolis, Eric/Luc Pauwels (eds.) (2011): The Sage Handbook of Visual Research Methods. Los Angeles etc.
Martin, J. R./David Rose (2008): Genre Relations. Mapping Culture. London. Messaris, Paul (1997): Visual Persuasion. The Role of Images in Advertising. London. Morris, Charles (1971): Writings on the General Theory of Signs. Edited by Thomas A. Sebeok. The
Hague/Paris. Muntigl, Peter (2011): Genre. In: Habscheid, 314–336. Nöth, Winfried (1985): Handbuch der Semiotik. Stuttgart. Nöth, Winfried (2011): Visual semiotics. Key features and an application to picture ads. In: Margolis/
Pauwels, 298–316. Norris, Sigrid/Carmen Daniela Maier (2014): Interactions, Images and Texts. A Reader in
Multimodality. Berlin/Boston. Posner, Roland (1991): Kultur als Zeichensystem. Zur semiotischen Explikation
kulturwissenschaftlicher Grundbegriffe. In: Aleida Assmann/Dietrich Harth (Hg.): Kultur als Lebenswelt und Monument. Frankfurt a. M., 37–74. Renkema, Jan (2004): Introduction to Discourse Studies. Amsterdam. Royce, Terry (1998): Synergy on the page. Exploring intersemiotic complementarity in page-based multimodal text. In: JASFL Occasional Papers 1, 25–48. Sachs-Hombach, Klaus (2003): Das Bild als kommunikatives Medium. Elemente einer allgemeinen Bildwissenschaft. Köln. Sandig, Barbara (2000): Text als prototypisches Konzept. In: Martina Mangasser-Wahl (Hg.): Prototypentheorie in der Linguistik. Anwendungsbeispiele – Methodenreflexion – Perspektiven. Tübingen, 93–112. Schmitz, Ulrich (2003): Blind für Bilder. Warum sogar Sprachwissenschaftler auch Bilder betrachten müssen. LAUD Papers Series A: General & Theoretical Papers 581. Duisburg/Essen. Schmitz, Ulrich (2007): Bildakte? How to do things with pictures. In: Zeitschrift für Germanistische Linguistik 35, 397–418. Schneider, Jan Georg (2008): Spielräume der Medialität. Linguistische Gegenstandskonstitution aus medientheoretischer und pragmatischer Perspektive. Berlin. Schubert, Christoph (2012): Englische Textlinguistik. Eine Einführung. 2. Aufl. Berlin. Sebeok, Thomas A. (1994): Signs. An Introduction to Semiotics. Toronto/Buffalo. Stöckl, Hartmut (1997): Werbung in Wort und Bild. Textstil und Semiotik englischsprachiger Anzeigenwerbung. Frankfurt a. M. Stöckl, Hartmut (2004): Die Sprache im Bild. Das Bild in der Sprache. Zur Verknüpfung von Sprache und Bild im massenmedialen Text. Berlin/New York. Stöckl, Hartmut (2007): Hörfunkwerbung – „Kino für das Ohr“. Medienspezifika, Kodeverknüpfungen und Textmuster einer vernachlässigten Werbeform. In: Kersten Sven Roth/Jürgen Spitzmüller (Hg.): Textdesign und Textwirkung in der massenmedialen Kommunikation. Konstanz, 177–202. Stöckl, Hartmut (2012a): Werbekommunikation semiotisch. In: Nina Janich (Hg.): Handbuch Werbekommunikation. Sprachwissenschaftliche und interdisziplinäre Zugänge. Tübingen, 243–262. Stöckl, Hartmut (2012b): Medienlinguistik. Zu Status und Methodik eines (noch) emergenten Forschungsfeldes. In: Christian Grösslinger/Gudrun Held/Hartmut Stöckl (Hg.): Pressetextsorten jenseits des ‚News‘. Medienlinguistische Perspektiven auf journalistische Kreativität. Frankfurt a. M., 13–34. Stöckl, Hartmut (2012c): Finanzen visualisieren – Die Text-Bild-Sorte Infografik. In: OBST Osnabrücker Beiträge zur Sprachtheorie 81, 177–199. Stöckl, Hartmut (2013): Ästhetik und Ästhetisierung von Werbung. Begriffliche, forschungsmethodische und medientheoretische Überlegungen. In: Hartmut Stöckl

print_cont_9783110295740_NinaMariaKlug.indb 34

26.07.16 12:07

Multimodalität – Semiotische und textlinguistische Grundlagen   35
(Hg.): Werbung – Keine Kunst!? Phänomen und Prozesse der Ästhetisierung von Werbekommunikation. Heidelberg, 89–116. Stöckl, Hartmut (2014): Semiotic paradigms and multimodality. In: Jewitt, 274– 286. Wetzchewald, Marcus (2012): Junktoren zwischen Text und Bild – dargestellt anhand der Unternehmenskommunikation im Internet. Duisburg. Wolff, Harald (1996): Geräusche und Film. Materialbezogene und darstellerische Aspekte eines Gestaltungsmittels. Frankfurt a. M.

print_cont_9783110295740_NinaMariaKlug.indb 35

26.07.16 12:07

