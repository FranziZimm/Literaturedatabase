file:///C|/New%20Text%20Document%20(2).txt
Table of Contents Preface Acknowledgments Addresses of the PDP Research Group
I THE PDP PERSPECTIVE 1 The Appeal of Parallel Distributed Processing
J.L. McClelland, D.E. Rumelhart, and G.E. Hinton
2 A General Framework for Parallel Distributed Processing D.E. Rumelhart, G.E. Hinton, and J.L. McClelland
3 Distributed Representations G.E. Hinton, J.L. McClelland, and D.E. Rumelhart
4 PDP Models and General Issues in Cognitive Science D.E. Rumelhart and J.L. McClelland
II BASIC MECHANISMS 5 Feature Discovery by Competitive Learning
D.E. Rumelhart and D. Zipser
6 Information Processing in Dynamical Systems: Foundations of Harmony Theory P. Smolensky
file:///C|/New%20Text%20Document%20(2).txt (1 of 2)9/25/2008 5:03:17 PM

file:///C|/New%20Text%20Document%20(2).txt
7 Learning and Relearning in Holtzmann Machines G.E. Hinton and T.J. Sejnowski
8 Learning Internal Representations by Error Propagation D.E. Rumelhart, G.E. Hinton, and R.J. Williams
III FORMAL ANALYSIS 9 An Introduction to Linear Algebra in Parallel Distributed Processing
M.I. Jordan
10 The Logic of Activation Functions R.J. Williams
11 An Analysis of the Delta Rule and the Learning of Statistical Associations G.O. Stone
12 Resource Requirements of Standard and Programmable Nets J.L. McClelland
13 P3: A Parallel Network Simulating System D. Zipser and D.E. Rabin
References Index
file:///C|/New%20Text%20Document%20(2).txt (2 of 2)9/25/2008 5:03:17 PM

Preface
One of the great joys of science lies in the moment of shared discovery. One person's half -baked suggestion resonates in the mind of another and suddenly takes on a definite shape. An insightful critique of one way of thinking about a problem leads to another, better understanding. An incomprehensible simulation result suddenly makes sense as two people try to understand it together.
This book grew out of many such moments. The seeds of the book were sown in our joint work on the interactive activation model of word perception. Since then , each of us has worked with the other and with other collaborators. The results of these collaborations are reported in several of the chapters of this book. The book also contains many chapters by other colleagues whose explorations have become intertwined with ours. Each chapter has its own by-line , but each also reflects the influences of other members of the group. We hope the result reflects some of the benefits of parallel distributed processing!
The idea of parallel distributed processing- the notion that intelli gence emerges from the interactions of large numbers of simple processing units - has come and gone before. The idea began to seem more and more attractive to us as the contrast between our convictions about basic characteristics of human perception, memory , language, and thought and the accepted formal tools for capturing mental processes became more apparent. Symbol-processing machines, for all their Tur ing equivalence, had failed to provide useful frameworks for capturing

x PREFACE
the simple insights about the interactive nature of processing that had lead to such models as the HEARSAY model of speech understanding.
More generally, they had failed to provide a framework for representing knowledge in a way that allowed it to be accessedby content and effectively combined with other knowledge to produce useful automatic syntheses that would allow intelligence to be productive . And they made no contact with the real strengths and weaknesses of the hardware in the brain. A Cray computer can perform on the order of 100 million double-precision multiplications in a second, but it does not exhibit natural intelligence. How then are we to understand the capabilities of human thought , given the time constants and noisiness inherent in neural systems? It seemed obvious that to get any processing done in real time , the slow, noisy hardware in the brain would have to do massively parallel processing.
As our interest in parallel mechanisms developed, we began to study the work of others who shared our convictions and to build on their
work . Particularly important in this regard was Hinton and J. A . Anderson's ( 1981) Parallel Models of AssociativeMemory. Indeed, we see our book as a descendant of their book on two accounts. First , the material presented here represents further developments on the work presented in Hinton and Anderson 's book. Second, we owe a particular intellectual debt to both Hinton and Anderson. Our interest in distrib -
uted, associative memories goes back to interactions with Jim Ander son, beginning as early as 1968. Our interest in these topics began in earnest, however, during the period when we were developing the interactive activation model of word perception, in 1979, shortly after Geoffrey Hinton began a postdoctoral fellowship at UCSD. Geoffrey 's crisp explanations showed us the potential power and generality of models created from connections among simple processing units , and fit together nicely with our own developing conviction that various aspectsof perception, language processing, and motor control were best thought of in terms of massively parallel processing (see McClelland , 1979, and Rumelhart , 1977, for our earliest steps in this direction ) .
The project culminating in this book formally began in December, 1981 when the two of us and Geoffrey Hinton decided to work together exploring the implications of network models and to write a book outlining our conclusions. We expected the project to take about six months . We began in January 1982 by bringing a number of our colleagues together to form a discussion group on these topics. During the first six months we met twice weekly and laid the foundation for most of the work presented in these volumes. Our first order of business was to develop a name for the class of models we were investigating. It seemed to us that the phrase parallel distributedprocessing(POP

PREFACE X.I

for short ) best captured what we had in mind . It emphasized the paral lel nature of the processing , the use of distributed representations and

distributed control , and the fact that these were general processing systems , not merely memories we were studying , as the phrase associative memory suggests . Thus the POP research group was born . Hinton and McClelland left after the first six months - Hinton to CMU and

McClelland to MIT and later to CMU . The POP research group , how ever , has continued regular meetings at UCSO up to the present time .

The group has varied from five or six of us at times to as many as 15 or more at other times , and there is now a parallel group of about 15 or so psychologists and computer scientists at CMU .
Shortly after leaving UCSO in 1982, Hinton began working with Terrence Sejnowski on the Boltzmann machine (Chapter 7) and decided to dl"'JP from the role of organizer of the project to a contributor , so he could spend more time working on the implications of the Boltzmann machine . Thus , the primary responsibility for putting the book together fell to the two of us. At first we expected to complete the book within a year after we began our work . Soon , however , it became

clear that there was much work to be done and many directions

to

explore . Thus , our work continued and expanded as we and our col -

leagues followed the implications of the POP approach in many dif ferent ways .

A good deal has happened since we began this project . Though much of the initial groundwork was laid in early 1982, most of the material described in these volumes did not take its present form until much
later .

The work has been interdisciplinary and represents what we consider a true cognitive science approach . Although the two of us have been trained as cognitive psychologists , the POP group as a whole includes people from a wide range of backgrounds . It includes people trained in physics , mathematics , neuroscience , molecular biology , and computer sciences , as well as in psychology . We also envision an interdisciplinary audience for our book . We are cognitive psychologists and we hope , primarily , to present POP models to the community of cognitive psychologists as alternatives to the models that have dominated cogni tive psychology for the past decade or so. We also , however , see our selves as studying architectures for computation and methods for artifi cial intelligence . Therefore , we hope that this book will be seen as relevant to researchers in computer science and artificial intelligence . Also , the POP approach provides a set of tools for developing models of the neurophysiological basis of human information processing , and so we hope portions of these books will seem relevant to neuroscien tists as well .

X.I.I PREFACE
ORGANIZATIONOFTHE BOOK

Our book consists of six parts , three in each of the two volumes . The overall structure is indicated in the accompanying table . Part I pro vides an overview . Chapter 1 presents the motivation for the approach and describes much of the early work that lead to the developments
reported in later sections . Chapter 2 describes the POP framework in more formal terms . Chapter 3 focuses on the idea of distributed representation , and Chapter 4 provides a detailed discussion of several general issues that the POP approach has raised and explains how these issues are addressed in the various later chapters of the book .
The remaining parts of the book present different facets of our explorations in parallel distributed processing . The chapters in Part II address central theoretical problems in the development of models of
parallel distributed processing , focusing for the most part on fundamen tal problems in learning . The chapters in Part III describe various mathematical and computational tools that have been important in the development and analysis of POP models . Part IV considers

A CONDENSED

TABLE OF CONTENTS

VOLUME I

I . THE POP PERSPECTIVE

II . BASIC MECHANISMS

III . FORMAL ANALYSES

1. The Appeal of POP 2. A Framework for PDP 3 . Distributed
Representations 4. General Issues

5. Competitive Learning 6 . Harmony Theory 7 . Boltzmann Machines
8. Learning by Error Propagation

9 . Linear Algebra 10. Activation Functions
11 . The Delta Rule
12. Resource Requirements 13. Parallel Network
Simulator

IV . PSYCHOLOGICAL PROCESSES

VOLUME II
V . BIOLOGICAL MECHANISMS

--
VI . CONCLUSION

14 . Schemata and POP
15. Speech Perception 16. Model of Reading 17. Learning and Memory 18. Morphology Acquisition 19. Sentence Processing

20 . Anatomy and
Physiology 21. Computation in
the Brain 22 . Neural and
Conceptual Levels 23. Place Recognition 24. Neural Plasticity
25 . Amnesia

26 . Reflections Future Directions

PREFACEX.I.I.I

applications and implications of PDP models to various aspects of human cognition , including perception , memory , language , and higher level thought processes . Part V considers the relation between parallel distributed processing models and the brain , reviews relevant aspects of the anatomy and physiology , and describes several models that apply POP models to aspects of the neurophysiology and neuropsychology of information processing , learning , and memory . Part VI contains two short pieces : a reflection on PDP models by Don Norman and a brief discussion of our thoughts about promising future directions .
How to read this book? It i~ too long to read straight through . Nor is it designed to be read this way . Chapter 1 is a good entry point for readers unfamiliar with the POP approach , but beyond that the various parts of the book may be approached in various orders , as one might explore the different parts of a complex object or machine . The vari ous facets of the POP approach are interrelated , and each part informs the others ~ but there are few strict sequential dependencies . Though we have tried to cross -reference ideas that come up in several places , we hope that most chapters can be understood without reference to the rest of the book . Where dependencies exist they are noted in the intro ductory sections at the beginning of each part of the book .
This book charts the explorations we and our colleagues have made in the microstructure of cognition . There is a lot of terrain left to be explored . We hope this book serves as a guide that helps others join us in these ongoing explorations .

December1985

JamesL. McClelland PI1TSBURG, PHENNSYLVANIA
David E. Rumelhart LAJOLLA, CALIFORNIA

Acknowledgments
As we have already said, nearly all the ideas in this book were born out of interactions, and one of our most important acknowledgments is to the environment that made these interactions possible. The Institute for Cognitive Science at UCSD and the members of the Institute have made up the core of this environment .
Don Norman , our colleague and friend , the Founder and Director of the Institute , deserves special credit for making ICS an exciting and stimulating place, for encouraging our explorations in parallel distrib uted processing, and for his central role in arranging much of the finan cial support this book has benefited from (of which more below) . The atmosphere depends as well on the faculty , visiting scholars, and graduate students in and around ICS. The members of the PDP Research Group itself , of course, have played the most central role in helping to shape the ideas found in this book. All those who contributed to the actual contents of the book are listed on the cover page; they have all contributed , as well, in many other ways. Several other participants in the group who do not have actual contributions to the book also deserve mention . Most prominent among these are Mike Mozer and Yves Chauvin , two graduate students in the Cognitive ScienceLab, and Gary Cottrell , a recent addition to the group from the University of Rochester.
Several other members of the intellectual community in and around ICS have played very important roles in helping us to shape our thoughts. These include Liz Bates, Michael Cole, Steve Draper, Don

XV.I ACKNOWLEDGMENTS
Gentner , Ed Hutchins , Jim Hollan , Jean Mandler , George Mandler , Jeff Miller , Guy van Orden , and many others , including the participants in Cognitive Science 200 .
There are also several colleagues at other universities who have helped us in our explorations . Indeed , the annual connectionist workshops (the first of which resulted in the Hinton and Anderson book ) have been important opportunities to share our ideas and get feedback on them from others in the field , and to learn from the con tributions of others . Jim Anderson , Dana Ballard , Jerry Feldman , Geoff Hinton and Terry Sejnowski all had a hand in organizing dif ferent ones of these meetings ; and we have learned a great deal from discussions with them and other participants , particularly Andy Barto , Scott Fahlman , Christof von der Malsburg , John Hopfield , Dave Touretzky , and more recently Mark Fanty and Gene Charniak . McClelland ' s discussions at MIT (particularly with Jerry Fodor and Molly Potter ) helped in the clarification of several aspects of our think ing , and various colleagues at and around CMU - particularly John Anderson , Mark Derthick , Dave Klahr , Brian MacWhinney , and Jeff Sokolov - have contributed a great deal through discussions over the last year and a half or so, as we have worked toward the completion of the book . Others one or both of us have interacted with a great deal include Bill Brewer , Neal Cohen , Al Collins , Billy Salter , Ed Smith , and Walter Schneider . All of these people have contributed more or less directly to the development of the ideas presented in this book .
An overlapping group of colleagues deserves credit for helping us improve the book itself . Jim Anderson , Andy Barto , Larry Barsalou , Chris Reisbeck , Walter Schneider , and Mark Seidenberg all read several chapters of the book and sent useful comments and suggestions . Many other people read and commented on individual chapters , and we are sincerely grateful for their careful contributions , which we acknowledge in the appropriate chapters .
This project owes a tremendous amount to the help of the excellent staff of the Institute for Cognitive Science . Kathy Farrelly , in particu lar , has played an enormous role in all aspects of the production of the book; her cheerful , thoughtful , and very careful assistance made the production of the book run much more smoothly than we have had any right to hope and allowed us to keep working on the content of some of the chapters even as the final production was rolling forward on other sections. Eileen Conway's assistancewith graphics and formatting has also been invaluable and we are very grateful to her as well . Mark Wal len kept the computers running , served as chief programming consul tant and debugger par excellence , and tamed troff , the phototypesetter . Without him we would never have gotten all the formatting to come out right . Karol Lightner worked very hard toward the end of the

. . ACKNOWLEDGMENTSXVII

project on final proofing and indexing , and Sondra Buffett , as the Administrative Director of ICS , held everything together and kept

everything running throughout the entire four years of the project . Our project has been supported by a number of different agencies

and foundations . Primary support came from the System Development Foundation and the Office of Naval Research . The System Develop -

ment Foundation has provided direct support for the PDP research

group through a grant to Norman and Rumelhart , and has also sup ported several of the individual members of the group (Crick , Hinton ,

Sejnowski , and Zipser ) . ONR contracts that have contributed support

include NOOO14 - 79 - C -O323 , NR 667 - 437 ~ NOOO14 - 85 - K -0450 , NR 667 -

548 ~ and NOOO14 - 82 -C - O374 , NR 667 -483 .

The people behind both SDF and ONR deserve acknowledgment too . The entire PDP enterprise owes a particular debt of gratitude to Charlie

Smith , formerly of SDF , who appreciated the appeal of parallel distrib -

uted processing very early on , understood our need for computing

resources , and helped provide the entire POP research group with the

funds and encouragement needed to complete such project . Henry Halff , formerly of ONR , was also an early source of support ,

encouragement , and direction . Charlie Smith has been succeeded by Carl York , and Henry Halff has been succeeded by Susan Chipman ,

Michael Si:tafto , and Harold Hawkins . We are grateful to all of these

people for their commitment to the completion of this book and to the

ongoing development of the ideas . Several other sources have contributed

to the support of individual

members of the group . These include the National Institute of Mental

Health , through a Career Development Award - PHS-MH -00385 - to McClelland and post -doctoral fellowships to Paul Smolensky and Paul Munro under Grant PHS - MH - 14268 to the Center for Human Informa -

tion Processing at UCSD . Smolensky received support in the form of a

fellowship from the Alfred P. Sloan Foundation , and some of McClelland ' s work was supported by a grant from the National Science Foundation (BNS -79-24062 ) . These and other sources of support for

specific individuals or projects are acknowledged in the appropriate chapters .

Finally , we would like to thank our wives , Heidi and Marilyn . Their

understanding , encouragement , and support throughout the four years

of this project helped to make the process of bringing this book to life I
much more rewarding than it might have been .

JLM/ DER

Addresses of the PDP Research Group

ChisatoAsanuma FrancisH. C. Crick Jeffrey L. Elman GeoffreyE. Hinton MichaelI. Jordan
Alan H. Kawamoto

SalkInstitute P.O. Box85800 SanDiego, CA 92138
SalkInstitute P.o . Box85800 SanDiego, CA 92138
Departmenotf Linguistics Universityof California, SanDiego La Jolla, CA 92093

Department Carnegie Pittsburgh

of Computer

- Mellon

University

, PA

15213

Science

Department

of Computer

and

Information

Science

University Amherst

of , MA

Massachusetts 01003

Department Carnegie Pittsburgh

of Psychology

- Mellon

University

, PA

15213

xx ADDRESOSEFTSHEPDPRESE)LRCGHROUP

JamesL. McClelland PaulW. Munro
Donald A . Norman
DanielE. Rabin David E. Rumelhart TerrenceJ. Sejnowski Paul Smolensky GregoryO. Stone RonaldJ. Williams David Zipser

Departmentof Psychology Carnegie-Mellon University Pittsburgh, PA 15213
Departmentof InformationScience University of Pittsburgh Pittsburgh, PA 15260
Institute for CognitiveScience
Universitoyf Californ,iaSanDiego LaJolla, CA92093
Intellicorp 1975El CaminoRealWest Mountain View, CA 94040
Institute for CognitiveScience University of California, SanDiego La Jolla, CA 92093
Departmentof Biophysics Johns Hopkins University Baltimore, MD 21218

Department University Boulder

of

Computer

of

Colorado

,

CO

80309

Science

Center Department Boston Boston

for

Adaptive

of

Mathematics

University

,

MA

02215

Systems

Institute

UniverSi

La

Jolla

for

Cognitive

~y

of

California

,

CA

92093

Science

,

San

Diego

Insitutefor CognitiveScience
Universityof California, SanDiego La Jolla, CA 92093

CHAPTE1R
The Appeal of Parallel Distributed Processing
J. L. McCLELLAN,DD. E. RUMELHAR,TandG. E. HINTON
What makes people smarter than machines? They certainly are not quicker or more precise. Yet people are far better at perceiving objects in natural scenes and noting their relations, at understanding language and retrieving contextually appropriate information from memory, at making plans and carrying out contextually appropriate actions, and at a wide range of other natural cognitive tasks. People are also far better at learn. ing to do. these things more accurately and fluently through processlng experIence.
What is the basis for these differences? One answer, perhaps the classic one we might expect from artificial intelligence , is "software." If we only had the right computer program, the argument goes, we might be able. to capture the fluidity and adaptability of human information processnl g.
Certainly this answer is partially correct. There have been great breakthroughs in our understanding of cognition as a result of the development of expressive high-level computer languagesand powerful algorithms . No doubt there will be more such breakthroughs in the future . However, we do not think that software is the whole story.
In our view, people are smarter than today's computers becausethe brain employs a basic computational architecture that is more suited to deal with a central aspect of the natural information processing tasks that people are so good at. In this chapter, we will show through examples that these tasks generally require the simultaneous consideration of many pieces of information or constraints. Each constraint may be imperfectly specified and ambiguous, yet each can playa potentially

4 THEPDPPERSPECTIVE
decisive role in determining the outcome of processing. After examining these points, we will introduce a computational framework for modeling cognitive processesthat seems well suited to exploiting these constaints and that seems closer than other frameworks to the style of computation as it might be done by the brain. We will review several early examples of models developed in this framework , and we will show that the mechanisms these models employ can give rise to powerful emergent properties that begin to suggest attractive alternatives to traditional accounts of various aspectsof cognition . We will also show that models of this class provide a basis for understanding how learning can occur spontaneously, as a by-product of processing activity .
Multiple Simultaneous Constraints
Reaching and grasping. Hundreds of times each day we reach for things. We nearly never think about these acts of reaching. And yet, each time , a large number of different considerations appear to jointly determine exactly how we will reach for the object. The position of the object, our .posture at the time , what else we may also be holding , the size, shape, and anticipated weight of the object, any obstaclesthat may be in the way- all of these factors jointly determine the exact method we will use for reaching and grasping.
Consider the situation shown in Fi,gure 1. Figure 1A shows Jay McClelland 's hand, in typing position at his terminal . Figure 18 indi cates the position his hand assumed in reaching for a small knob on the desk beside the terminal . We will let him describe what happened in the first person:
On the desk next to my terminal are several objects- a chipped coffee mug, the end of a computer cable, a knob from a clock radio. I decide to pick the knob up. At first I hesitate, because it doesn't seem possible. Then I just reach for it , and find myself grasping the knob in what would normally be considered a very awkward position - but it solves all of the constraints. I ' m not sure what all the details of the movement were, so I let myself try it a few times more. I observe that my right hand is carried up off the keyboard, bent at the elbow, until my forearm is at about a 300 angle to the desk top and parallel to the side of the terminal . The palm is facing downward through most of this . Then , my arm extends and lowers down more or less parallel to the edge of the desk and parallel to the side of the terminal and, as it drops, it turns about 900 so that the

1. TIlE APPEAL OF PDP 5
A
FIGURE 1. A: An everyday situation in which it is necessary to take into account a large number of constraints to grasp a desired object. In this case the target object is the small knob to the left of the cup. B: The posture the arm arrives at in meeting these
constraints.

6 THEPOPERSPECTIVE
palm is facing the cup and the thumb and index finger are below. The turning motion occurs just in time , as my hand drops, to avoid hitting the coffee cup. My index finger and thumb close in on the knob and grasp it , with my hand completely upside down.
Though the details of what happened here might be quibbled with , the broad outlines are apparent. The shape of the knob and its position on the table~ the starting position of the hand on the keyboard; the positions of the terminal , the cup, and the knob~ and the constraints imposed by the structure of the arm and the musculature used to control it - all these things conspired to lead to a solution which exactly suits the problem . If any of these constraints had not been included, the movement would have failed. The hand would have hit the cup or the terminal - or it would have missed the knob .
The mutual influence of syntax and semantics. Multiple constraints operate just as strongly in language processing as they do in reaching and grasping. Rumelhart ( 1977) has documented many of these multi ple constraints. Rather than catalog them here, we will use a few examples from language to illustrate the fact that the constraints tend to be reciprocal: The example shows that they do not run only from syntax to semantics- they also run the other way.
It is clear, of course, that syntax constrains the assignment of meaning. Without the syntactic rules of English to guide us, we cannot correctly understand who has done what to whom in the following sentence:
The boy the man chased kissed the girl .
But consider these examples (Rumelhart , 1977; Schank, 1973) :
I saw the grand canyon flying- to New York . I sawthe sheepgrazingin the field.
Our knowledge of syntactic rules alone does not tell us what grammatical role is played by the prepositional phrases in these two cases. In the first , IIflying to New York " is taken as describing the context in which the speaker saw the Grand Canyon- while he was flying to New York . In the second, "grazing in the field II could syntactically describe an analogous situation , in which the speaker is grazing in the field , but this possibility does not typically become available on first reading. Instead we assign IIgrazing in the field II as a modifier of the sheep (roughly , 'Iwho were grazing in the field II) . The syntactic structure of each of

1. THEAPPEALOFPDP 7
thesesentence,sthen, is determinedin part by the semanticrelations that the constituents of the sentence might plausibly bear to one another. Thus, the influencesappearto run both ways, from the syntax to the semanticsandfrom the semanticsto the syntax.
In these examples, we see how syntactic considerationsinfluence semanticones and how semanticones influence syntacticones. We cannotsaythat one kind of constraintis primary.
Mutual constraintsoperate, not only betweensyntacticand semantic processin,g but also within each of these domains as well. Here we consideran examplefrom syntacticprocessin,gnamely, the assignment of wordsto syntacticcategorie.s Considerthe sentence:s
like the joke. like the drive. like to joke. like to drive.
In this case it looks as though the words the and to serve to determine whether the following word will be read as a noun or a verb. This , of course, is a very strong constraint in English and can serve to force a verb interpretation of a word that is not ordinarily used this way:
I like to mud.
On the other hand, if the information specifyingwhetherthe function word precedingthe final word is to or theis ambiguous, then the typical readingof the word that follows it will determinewhich way the function word is heard. This was shown in an experiment by Isenberg, Walker, Ryder, andSchweikert(1980) . They presentedsoundshalfway betweento (actuallyItAI ) and the (actuallyIdAI ) and found that words like joke, which we tend to think of first as nouns, madesubjectshear the marginal stimuli as the, while words like drive, which we tend to think of first as verbs, madesubjectshear the marginalstimuli as to. Generally, then, it would appearthat eachword can help constrainthe syntacticrole, andeventhe identity, of everyother word.
Simultaneous mutual constraints in word recognition . Just as the syntactic role of one word can influence the role assigned to another in analyzing sentences, so the identity of one letter can influence the identity assigned to another in reading. A famous example of this , from Selfridge, is shown in Figure 2. Along with this is a second example in which none of the letters, considered separately, can be identified unambiguously, but in which the possibilities that the visual

~~~~

8 THEPDPERSPECTIVE
I
FIGURE 2. Some ambiguousdisplays. The first one is from Selfridge, 1955. The secondline showsthat three ambiguouscharacterscaneachconstrainthe identity of the others. The third, fourth, and fifth lines showthat thesecharactersare indeedambiguous in that they assumeother identitiesin other contexts. (The ink-blot techniqueof makinglettersambiguousis due to LindsayandNorman, 1972). information leaves open for each so constrain the possible identities of the others that we are capableof identifying all of them .
At first glance, the situation here must seem paradoxical: The identity of each letter is constrained by the identities of each of the others. But since in general we cannot know the identities of any of the letters

1. THEAPPEALOFPOP 9
until we have established the identities of the others , how can we get
the process started ? The resolution of the paradox , of course , is simple . One of the dif -
ferent possible letters in each position fits together with the others . It appears then that our perceptual system is capable of exploring all these possibilities without committing itself to one until all of the constraints are taken into account .
Understanding through the interplay of multiple sources of knowledge. It is clear that we know a good deal about a large number of different standard situations . Several theorists have suggested that we store this knowledge in terms of structures called variously : scripts (Schank , 1976) , frames (Minsky , 1975) , or schemata (Norman & Bobrow , 1976 ; Rumelhart , 1975) . Such knowledge structures are assumed to be the basis of comprehension . A great deal of progress
has been made within the context of this view . However , it is important to bear in mind that most everyday situa -
tions cannot be rigidly assigned to just a single script . They generally involve an interplay between a number of different sources of informa tion . Consider , for example , a child ' s birthday party at a restaurant . We know things about birthday parties , and we know things about restaurants , but we would not want to assume that we have explicit knowledge (at least , not in advance of our first restaurant birthday party ) about the conjunction of the two . Yet we can imagine what such a party might be like . The fact that the party was being held in a restaurant would modify certain aspects of our expectations for birthday parties (we would not expect a game of Pin -the -Tail -on -the -Donkey , for example ) , while the fact that the event was a birthday party would inform our expectations for what would be ordered and who would pay the bill .
Representations like scripts , frames , and schemata are useful struc tures for encoding knowledge , although we believe they only approxi mate the underlying structure of knowledge representation that emerges from the class of models we consider in this book , as explained in Chapter 14. Our main point here is that any theory that tries to account for human knowledge using script -like knowledge structures will have to allow them to interact with each other to capture the gen erative capacity of human understanding in novel situations . Achieving such interactions has been one of the greatest difficulties associated with implementing models that really think generatively using script - or frame -like representations .

10 THEPOPPERSPECTIVE
PARALLEL DISTRIBUTEDPROCESSING
In the examples we have considered, a number of different pieces of information must be kept in mind at once. Each plays a part, constraining others and being constrained by them . What kinds of mechanisms seem well suited to these task demands? Intuitively , these tasks seem to require mechanisms in which each aspect of the informa tion in the situation can act on other aspects, simultaneously influenc ing other aspects and being influenced by them . To articulate these intuitions , we and others have turned to a class of models we call Parallel Distributed Processing (POP) models. These models assume that information processing takes place through the interactions of a large number of simple processingelements called units , each sending excitatory and inhibitory signals to other units . In some cases, the units stand for possible hypotheses about such things as the letters in a particular display or the syntactic roles of the words in a particular sentence. In these cases, the activations stand roughly for the strengths associated with the different possible hypotheses, and the interconnections among the units stand for the constraints the system knows to exist between the hypotheses. In other cases, the units stand for possible goals and actions, such as the goal of typing a particular letter , or the action of moving the left index finger , and the connections relate goals to subgoals, subgoals to actions, and actions to muscle movements. In still other cases, units stand not for particular hypotheses or goals, but for aspects of these things. Thus a hypothesis about the identity of a word, for example, is itself distributed in the activations of a large number of units.
POPModels: CognitiveScienceor Neuroscienc?e
One reason for the appeal of POP models is their obvious "physiological" flavor : They seem so much more closely tied to the physiology of the brain than are other kinds of information -processing models. The brain consists of a large number of highly interconnected elements (Figure 3) which apparently send very simple excitatory and inhibitory messages to each other and update their excitations on the basis of these simple messages. The properties of the units in many of the POP models we will be exploring were inspired by basic properties of the neural hardware. In a later section of this book, we will examine in some detail the relation between POP models and the brain.

12 THEPOPPERSPECTIVE
The Microstructureof Cognition
The process of human cognition , examined on a time scale of seconds and minutes , has a distinctly sequential character to it . Ideas come, seem promising , and then are rejected; leads in the solution to a problem are taken up, then abandoned and replaced with new ideas. Though the process may not be discrete, it has a decidedly sequential character, with transitions from state-to-state occurring, say, two or three times a second. Clearly, any useful description of the overall organization of this sequential flow of thought will necessarily describe a sequenceof states.
But what is the internal structure of each of the states in the sequence, and how do they come about? Serious attempts to model even the simplest macrosteps of cognition - say, recognition of single words- require vast numbers of microsteps if they are implemented sequentially. As Feldman and Ballard ( 1982) have pointed out , the biological hardware is just too sluggish for sequential models of the microstructure to provide a plausible account, at least of the microstructure of human thought . And the time limitation only gets worse, not better, when sequential mechanisms try to take large numbers of constraints into account. Each additional constraint requires more time in a sequential machine, and, if the constraints are imprecise, the constraints can lead to a computational explosion. Yet people get faster, not slower, when they are able to exploit additional constraints.
Parallel distributed processing models offer alternatives to serial models of the microstructure of cognition . They do not deny that there is a macrostructure, just as the study of subatomic particles does not deny the existence of interactions between atoms. What PDP models do is describe the internal structure of the larger units , just as subatomic physics describes the internal structure of the atoms that form the constituents of larger units of chemical structure .
We shall show as we proceed through this book that the analysis of the microstructure of cognition has important implications for most of the central issues in cognitive science. In general, from the PDP point of view, the objects referred to in macrostructural models of cognitive processing are seen as approximate descriptions of emergent properties of the microstructure . Sometimes these approximate descriptions may be sufficiently accurate to capture a process or mechanism well enough~ but many times, we will argue, they fail to provide sufficiently elegant or tractable accounts that capture the very flexibility and openendedness of cognition that their inventors had originally intended to capture. We hope that our analysis of PDP models will show how an

1. THEAPPEOAFLPDP 13
examination of the microstructure of cognition can lead us closer to an a. dequate.d.escription of the real extent of human processing and learnIng capacities.
The development of POP models is still in its infancy . Thus far the models which have been proposed capture simplified versions of the kinds of phenomena we have been describing rather than the full elaboration that these phenomena display in real settings. But we think there have been enough steps forward in recent years to warrant a concerted effort at describing where the approach has gotten and where it is going now, and to point out some directions for the future .
The first section of the book represents an introductory course in parallel distributed processing. The rest of this chapter attempts to describe in informal terms a number of the models which have been proposed in previous work and to show that the approach is indeed a fruitful one. It also contains a brief description of the major sources of the inspiration we have obtained from the work of other researchers. This chapter is followed , in Chapter 2, by a description of the quantitative framework within which these models can be described and examined. Chapter 3 explicates one of the central concepts of the book: distributed representation. The final chapter in this section, Chapter 4, returns to the question of demonstrating the appeal of parallel distributed processing models and gives an overview of our explorations in the microstructure of cognition as they are laid out in the remainder of this book.
EXAMPLEOSFPDPMODELS
In what follows , we review a number of recent applications of POP models to problems in motor control , perception, memory, and language. In many cases, as we shall see, parallel distributed processing mechanisms are used to provide natural accounts of the exploitation of multiple , simultaneous, and often mutual constraints. We will also see that these same mechanisms exhibit emergent properties which lead to novel interpretations of phenomena which have traditionally been inter preted in other ways.
Motor Control
Having. started with an exa.mple . of how multiple .constraints ap. pear to operate In motor programming , It seems appropriate to mention two

14 THEPOPERSPECTIVE
models in this domain . These models have not developed far enough to capture the full details of obstacle avoidance and multiple constraints on reaching and grasping , but there have been applications to two prob lems with some of these characteristics .
Finger movements in skilled typing. One might imagine, at first glance , that typists carry out keystrokes successively , first programming one stroke and then , when it is completed, programming the next . However , this is not the case. For skilled typists, the fingers are continually anticipating upcoming keystrokes . Consider the word vacuum. In this word , the v, a, and c are all typed with the left hand , leaving the right hand nothing to do until it is time to type the first u. However , a high speed film of a good typist shows that the right hand moves up to anticipate the typing of the u , even as the left hand is just beginning to type the v. By the time the c is typed the right index finger is in posi tion over the u and ready to strike it .
When two successive key strokes are to be typed with the fingers of the same hand , concurrent preparation to type both can result in similar or conflicting instructions to the fingers and / or the hand . Consider , in this light , the difference between the sequence ev and the sequence ere The first sequence requires the typist to move up from home row to type the e and to move down from the home row to type the v, while in the second sequence , both the e and the f are above the home row .
The hands take very different positions in these two cases. In the first case, the hand as a whole stays fairly stationary over the home row . The middle finger moves up to type the e, and the index finger moves down to type the v. In the second case , the hand as a whole moves up , bringing the middle finger over the e and the index finger over the f . Thus , we can see that several letters can simultaneously influence the positioning of the fingers and the hands .
From the point of view of optimizing the efficiency of the typing motion , these different patterns seem very sensible . In the first case , the hand as a whole is maintained in a good compromise position to allow the typist to strike both letters reasonably efficiently by extending the fingers up or down . In the second case, the need to extend the fingers is reduced by moving the whole hand up , putting it in a near optimal position to strike either key .
Rumelhart and Norman ( 1982) have simulated these effects using POP mechanisms . Figure 4 illustrates aspects of the model as they are illustrated in typing the word very. In brief , Rumelhart and Norman assumed that the decision to type a word caused activation of a unit for that word . That unit , in turn , activated units corresponding to each of the letters in the word . The unit for the first letter to be typed was made to inhibit the units for the second and following letters , the unit

1. THEAPPEOALFPOP 15

for the second to inhibit the third and following letters, and so on. As a result of the interplay of activation and inhibition among these units , the unit for the first letter was at first the most strongly active, and the units for the other letters were partially activated.
Each letter unit exerts influences on the hand and finger involved in typing the letter . The v unit , for example, tends to cause the index finger to move down and to cause the whole hand to move down with
it . The e unit , on the other hand, tends to cause the middle finger on the left hand to move up and to cause the whole hand to move up also. The r unit also causes the left index finger to move up and the left hand to move up with it .
The extent of the influences of each letter on the hand and finger it directs depends on the extent of the activation of the letter ." Therefore , at first , in typing the word very, the v exerts the greatest control .

Response System
Keypress Schemata

upward

W"~-..'. az-":o~o~"wo'wzX-

...tw8+rd inward
PALM

w

W

~ 5 ~ -l oQz ~

z-

~~

(- I : -- l

THUMB
PALM

upward
;ftW+ idO.U.. Iw downward

RESPONSE SYSTEM
LI (- 1 , + 0 .5) LM (+ 1 , - 0 .3 ) LI (+ 1, - 0 .3 ) RI (+ 1, + 1.3 )
.target finger position .. current finger position

Word Schema

FIGURE 4. The interactionof activationsin typing the word very. The veryunit is activatedfrom outside the mode.l It in turn activatesthe units for eachof the com-
ponentletters. Eachletter unit specifiesthe target finger positions, specifiedin a keyboardcoordinatesystem. Land R standfor the left and right hands, andI and M for the
index and middle fingers. The letter units receiveinformation about the current finger positionfrom the responsesystem. Eachletter unit inhibits the activationof all letter units that follow it in the word: inhibitory connectionsare indicatedby the lines with solid dots at their terminations. (From "Simulatinga SkilledTypist: A Studyof Skilled Motor Pe~formance" by D. E. Rumelhartand D. A. Norman, 1982, CognitiveScienc,e6, p. 12. Copyright1982byAblex Publishing. Reprintedby permission.)

16 THEPOPERSPECTIVE
Becausethe e and r are simultaneously pulling the hand up, though , the
v is typed primarily by moving the index finger , and there is little movement on the whole hand.
Once a finger is within a certain striking distance of the key to be typed, the actual pressing movement is triggered, and the keypress occurs. The keypress itself causes a strong inhibitory signal to be sent to the unit for the letter just typed, thereby removing this unit from the picture and allowing the unit for the next letter in the word to become the most strongly activated.
This mechanism provides a simple way for all of the letters to jointly determine the successiveconfigurations the hand will enter into in the process of typing a word. This model has shown considerable success predicting the time between successive keystrokes as a function of the different keys involved . Given a little noise in the activation process, it can also account for some of the different kinds of errors that have been observed in transcription typing .
The typing model represents an illustration of the fact that serial behavior - a succession of key strokes- is not necessarily the result of an inherently serial processing mechanism. In this model, the sequential structure of typing emerges from the interaction of the excitatory and inhibitory influences among the processing units .
Reaching for an object without falling over. Similar mechanisms can be used to model the process of reaching for an object without losing one' s balance while standing, as Hinton ( 1984) has shown. He considered a simple version of this task using a two-dimensional " person" with a foot , a lower leg, an upper leg, a trunk , an upper arm, and a lower arm. Each of these limbs is joined to the next at a joint which has a single degree of rotational freedom . The task posed to this person is to reach a target placed somewhere in front of it , without taking any steps and without falling down. This is a simplified version of the situation in which a real person has to reach out in front for an object placed somewhere in the plane that vertically bisects the body. The task is not as simple as it looks, since if we just swing an arm out in front of ourselves, it may shift our center of gravity so far forward that we will lose our balance. The problem, then, is to find a set of joint angles that simultaneously solves the two constraints on the task. First , the tip of the forearm must touch the object. Second, to keep from falling down, the person must keep its center of gravity over the foot .
To do this , Hinton assigneda single processorto eachjoint . On each computational cycle, each processor received information about how far the tip of the hand was from the target and where the center of gravity was with respect to the foot . Using these two pieces of information , each joint adjusted its angle so as to approach the goals of maintaining

I. THEAPPEOALFPDP 17
balance and bringing the tip closer to the target. After a number of iterations , the stick-person settled on postures that satisfied the goal of reaching the target and the goal of maintaining the center of gravity over the "feet."
Though the simulation was able to perform the task, eventually satisfying both goals at once, it had a number of inadequacies stemming from the fact that each joint processor attempted to achieve a solution in ignorance of what the other joints were attempting to do. This problem was overcome by using additional processorsresponsible for setting combinations of joint angles. Thus, a processor for flexion and extension of the leg would adjust the knee, hip , and ankle joints synergistically, while a processor for flexion and extension of the arm would adjust the shoulder and elbow together. With the addition of processors of this form , the number of iterations required to reach a solution was greatly reduced, and the form of the approach to the solution looked very natural. The sequence of configurations attained in one processing run is shown in Figure 5.
Explicit attempts to program a robot to cope with the problem of maintaining balance as it reaches for a desired target have revealed the difficulty of deriving explicitly the right combinations of actions for each possible starting state and goal state. This simple model illustrates that we may be wrong to seek such an explicit solution . We see here that a solution to the problem can emerge from the action of a number of simple processors each attempting to honor the constraints independently .

+

+

+

+
FIGURE 5. A sequenceof configurationsassumedby the stick"person" performingthe reachingtaskdescribedin the text, from Hinton (1984). The smallcirclerepresentsthe center of gravity of the whole stick-figure, and the cross representsthe goal to be reached. The configurationis shownon everyseconditeration.

18 THEPOPPERSPECTIVE Perception

Stereoscopic

vision

.

One

early

model

using

parallel

distributed

pro

-

cessing

was

the

model

of

stereoscopic

depth

perception

proposed

by

Marr

and

Poggio

( 1976

).

Their

theory

proposed

to

explain

the

percep

-

tion terms

of

depth

in

random

of

a

simple

distributed

- dot

stereograms processing

( Julesz mechanism

,

1971

.

;

see

Figure

6)

in

Julesz

's

random

- dot

stereograms

present

interesting

challenges

to

mechanisms

of

depth

percepti

on

.

A

stereogram

consists

of

two

random

- dot

patterns

.

In

a

simple

stereogram

such

as

the

one

shown

here

,

one

pattern

is

an

exact

copy

of

the

other

except

that

the

pattern

of

dots

respect

corresponding

random

sidered

in

a

region

of

one

of

the

patterns

is

shifted

horizontally

to

the

rest

of

the

pattern

.

Each

of

the

two

patterns

to

two

retinal

images

-

consists

entirely

of

a

pattern

dots

,

so

there

is

no

information

in

either

of

the

two

views

alone

that

can

indicate

the

presence

of

different

surfaces

with

-

of

con

-

,

let

alone

depth

relations

among

those

surfaces

.

Yet

,

when

one

of

these

dot

patterns

an

observer

is

projected

sees

each

to

the

region

left

eye

and

as

a

surface

the

other

,

with

to

the

the

shifted

right

eye

,

region

hovering

the

shift

in .

front

of

or

behind

the

other

,

depending

on

the

direction

of

FIGURE

6.

Random

- dot

stereograms

.

The

two

patterns

are

identical

except

that

the

pattern

of

dots

in

the

central

region

of

the

left

pattern

are

shifted

over

with

respect

to

those

in

the

right

.

When

viewed

stereoscopically

such

that

the

left

pattern

projects

to

the

left

eye

and

the

right

pattern

to

the

right

eye

, the

shifted

area

appears

to

hover

above

the

page far

.

Some

readers

wall

)

and

then

may interposing

be

able

to

achieve

the

figure

this

by

into

the

converging

line

of

sight

to

a

distant

.

( From

point Foundations

( e .g . , a of

Cyclopean Copyright

Perception

,

p.

21

,

by

1971

by

Bell

Telephone

B.

Julesz

Laboratories

,

1971

,

Chicago

:

University

, Inc

.

Reprinted

by

of permission

Chicago .)

Press

.

1. THEAPPEOALFPDP 19
What kind of a mechanismmight we proposeto accountfor these facts? Marr and Poggio(1976) beganby explicitly representingthe two viewsin two arrays, as human observersmight in two different retinal images. They noted that correspondingblack dots at different perceived distancesfrom the observerwill be offset from eachother by gifferent amountsin the two views. The job of the model is to determine which points correspond. This task is, of course, madedifficult by the fact that there will be a very large number of spurious correspondenceosf individual dots. The goal of the mechanism, then, is to find thosecorrespondencetshat representreal correspondenceisn depthandsuppressthosethat representspuriouscorrespondence. s
To carry out this task, Marr and Poggioassigneda processingunit to each possible,conjunction of a point in one imageand a point in the other. Sincethe eyesare offset horizontally, the possbi le conjunctions occur at various offsets or disparitiesalong the horizontal dimension. Thus, for each point in one eye, there was a set of processingunits with one unit assignedto the conjunctionof that point and the point at eachhorizontaloffset from it in the other eye.
Eachprocessingunit receivedactivationwheneverboth of the points the unit stoodfor containeddots. So far, then, units for both real and spurious correspondenceswould be equally activated. To allow the mechanismto find the right correspondence, sthey pointed out two generalprinciplesabout the visual world: (a) Eachpoint in eachview generallycorrespondsto one and only one point in the other view, and (b) neighboringpointsin spacetend to be at nearlythe samedepthand therefore at about the samedisparity in the two images. While there are discontinuities at the edges of things, over most of a twodimensionalview of the world there will be continuity. Theseprinciplesarecalledthe uniquenesasndcontinuityconstraints, respectivel.y
Marr and Poggioincorporatedtheseprinciplesinto the interconnections betweenthe processingunits. The uniquenessconstraintwascaptured by inhibitory connectionsamongthe units that standfor alternative correspondencesof the samedot. The continuity principle was capturedby excitatoryconnectionsamongthe units that standfor similar offsetsof adjacentdots.
These additional connectionsallow the Marr and Poggiomodel to "solve" stereogramslike the one shownin the figure. At first, when a pair of patternsis presented, the units for all possiblecorrespondences of a dot in one eye with a dot in the other will be equally excited. However, the excitatory connectionscausethe units for the correct conjunctionsto receivemore excitationthan units for spuriousconjunctions, and the inhibitory connectionsallow the units for the correct conjunctionsto turn off the units for the spuriousconnections. Thus,

20 THEPOPERSPECTIVE
the model tends to settle down into a stable state in which only the correct correspondenceof each dot remains active.
There are a number of reasons why Marr and Poggio ( 1979) modified this model (see Marr , 1982, for a discussion) , but the basic mechanisms of mutual excitation between units that are mutually consistent and mutual inhibition between units that are mutually incompatible provide a natural mechanism for settling on the right conjunctions of points and rejecting spurious ones. The model also illustrates how general principles or rules such as the uniqueness and continuity princi ples may be embodied in the connections between processingunits , and how behavior in accordance with these principles can emerge from the interactions determined by the pattern of these interconnections.
Perceptual completion of familiar patterns . Perception, of course, is influenced by familiarity . It is a well-known fact that we often misperceive unfamiliar objects as more familiar ones and that we can get by with less time or with lower-quality information in perceiving familiar items than we need for perceiving unfamiliar items. Not only does familiarity help us determine what the higher-level structures are when the lower-level information is ambiguous~ it also allows us to fill in missing lower-level information within familiar higher-order patterns. The well-known phonemic restoration effect is a case in point . In this phenomenon, perceivers hear sounds that have been cut out of words as if they had actually been present. For example, Warren (1970) presented /egi# /ature to subjects, with a click in the location marked by the # . Not only did subjects correctly identify the word legislature~ they also heard the missing / s/ just as though it had been presented. They had great difficulty localizing the click , which they tended to hear as a disembodied sound. Similar phenomena have been observed in visual perception of words since the work of Pillsbury ( 1897) .
Two of us have proposed a model describing the role of familiarity in perception based on excitatory and inhibitory interactions among units standing for various hypotheses about the input at different levels of abstraction (McClelland & Rumelhart , 1981~ Rumelhart & McClelland , 1982) . The model has been applied in detail to the role of familiarity in the perception of letters in visually presented words, and has proved to provide a very close account of the results of a large number of experiments.
The model assumes that there are units that act as detectors for the visual features which distinguish letters, with one set of units assigned to detect the features in each of the different letter -positions in the word. For four -letter words, then , there are four such sets of detectors. There are also four sets of detectors for the letters themselves and a set of detectors for the words.

I. THEAPPEOAFLPOP21
In the model, each unit has an activation value, corresponding roughly to the strength of the hypothesis that what that uni t stands for
is present in the perceptual input . The model honors the following important relations which hold between these "hypotheses" or activations: First , to the extent that two hypotheses are mutually consistent, they should support each other . Thus, units that are mutually consistent, in the way that the letter T in the first position is consistent with the word TAKE, tend to excite each other . Second, to the extent that two hypotheses are mutually inconsistent, they should weaken each other . Actually , we can distinguish two kinds of inconsistency: The first kind might be called between-level inconsistency. For example, the hypothesis that a word begins with a T is inconsistent with the hypothesis that the word is MO VE. The second might be called mutual exclusion. For example, the hypothesis that a word begins with T excludes the hypothesis that it begins with R since a word can only begin with one letter . Both kinds of inconsistencies operate in the word perception model to reduce the activations of units. Thus, the letter units in each position compete with all other letter units in the same position , and the word units compete with each other . This type of inhibitory interaction is often called competitiveinhibition. In addition , there are inhibitory interactions between incompatible units on different levels. This type of inhibitory interaction is simply called between-level inhibition.
The set of excitatory and inhibitory interactions between units can be diagrammed by drawing excitatory and inhibitory links between them . The whole picture is too complex to draw, so we illustrate only with a fragment: Some of the interactions between some of the units in this model are illustrated in Figure 7.
Let us consider what happens in a system like this when a familiar stimulus is presented under degraded conditions . For example, consider the display shown in Figure 8. This display consists of the letters W, 0 , and R , completely visible , and enough of a fourth letter to rule out all letters other than Rand K . Before onset of the display, the activations of the units are set at or below o. When the display is presented, detectors for the features present in each position become active (i.e., their activations grow above 0) . At this point , they begin to excite and inhibit the corresponding detectors for letters. In the first three positions, W, 0 , and R are unambiguously activated, so we will focus our attention on the fourth position where Rand K are both equally consistent with the active features. Here, the activations of the detectors for Rand K start out growing together, as the feature detectors below them become activated. As these detectors become active, they and the active letter detectors for W, 0 , and R in the other positions start to activate detectors for words which have these letters in

I. THEAPPEOALFPOP 23 Word Level
Letter Level
FIGURE 8. A possible display which might be presented to the interactive activation model of word recognition , and the resulting activations of selected letter and word units. The letter units are for the letters indicated in the fourth position of a four -letter display.
K detector allows it to dominate the pattern of activation , suppressing the R detector completely.
This example illustrates how POP models can allow knowledge about what letters go together to form words to work together with natural constraints on the task (i.e., that there should only be one letter in one place at one time ) , to produce perceptual completion in a simple and di rect way.
Completion of novel patterns . However, the perceptual intelligence of human perceivers far exceeds the ability to recognize familiar patterns and fill in missing portions . We also show facilitation in the

24 THEPDPERSPECTIVE
perception of letters in unfamiliar letter strings which are word -like but not themselves actually familiar .
One way of accounting for such performances is to imagine that the perceiver possesses, in addition to detectors for familiar words , sets of detectors for regular subword units such as familiar letter clusters , or that they use abstract rules , specifying which classes of letters can go with which others in different contexts . It turns out , however , that the model we have already described needs no such additional structure to produce perceptual facilitation for word -like letter strings ~ to this extent it acts as if it " knows " the orthographic structure of English . We illus trate this feature of the model with the example shown in Figure 9, where the nonword rEAD is shown in degraded form so that the second letter is incompletely visible . Given the information about this letter , considered alone , either E or F would be possible in the second position . Yet our model will tend to complete this letter as an E .
The reason for this behavior is that , when YEAD is shown , a number of words are partially activated . There is no word consistent with Y, E or F, A , and D , but there are words which match YEA- ( YEAR , for example ) and others which match _ EAD (BEAD , DEAD , HEAD , and READ , for example ) . These and other near misses are partially activated as a result of the pattern of activation at the letter level . While they compete with each other , none of these words gets strongly enough activated to completely suppress all the others . Instead , these units act as a group to reinforce particularly the letters E and A . There are no close partial matches which include the letter F in the second position , so this letter receives no feedback support . As a result , E comes to dominate , and eventually suppress , the F in the second position .
The fact that the word perception model exhibits perceptual facilita tion to pronounceable nonwords as well as words illustrates once again how behavior in accordance with general principles or rules can emerge from the interactions of simple processing elements . Of course , the behavior of the word perception model does not implement exactly any of the systems of orthographic rules that have been proposed by linguists (Chomsky & Halle , 1968; Venesky , 1970) or psychologists (Spoehr & Smith , 1975) . In this regard , it only approximates such rule -based descriptions of perceptual processing . However , rule systems such as Chomsky and Halle ' s or Venesky ' s appear to be only approximately honored in human performance as well (Smith & Baker , 1976) . Indeed , some of the discrepancies between human performance data and rule systems occur in exactly the ways that we would predict from the word perception model ( Rumelhart & McClelland , 1982) . This illustrates the possibility that POP models may provide more accurate accounts of the details of human performance than models

1. THEAPPEALOFPOP 25
Word Level

Letter Level
E

Time

C&F L

~ :1 W~ ~J

~ :1 wI~ ~

Jl
FIGURE 9. An example of a nonword display that might be presented to the interactive activation model of word recognition and the response of selected units at the letter and word levels. The letter units illustrated are detectors for letters in the second input position .
based on a set of rules representing human competence - at least in some domains.
Retrieving Information From Memory
Content addressabi/ity. One very prominent feature of human memory is that it is content addressable. It seems fairly clear that we

26 THEPOPPERSPECTIVE
can access.information in. memory .based on nearly any attribute of the representation we are trYing to retrieve .
Of course, some cues are much better than others. An attribute which is shared by a very large number of things we know about is not a very effective retrieval cue, since it does not accurately pick out a particular memory representation. But, several such cues, in conjunction , can do the job . Thus, if we ask a friend who goes out with several women, "Who was that woman I saw you with ?" , he may not know which one we mean- but if we specify something else about her- say the color of her hair , what she was wearing (in so far as he remembers this at all) , where we saw him with her - he will likely be able to hit upon the right one.
It is, of course, possible to implement some kind of content addressability of memory on a standard computer in a variety of dif ferent ways. One way is to search sequentially, examining each memory in the system to find the memory or the set of memories which has the particular content specified in the cue. An alternative , somewhat more efficient , scheme involves some form of indexing keeping a list , for every content a memory might have, of which memories have that content .
Such an indexing scheme can be made to work with error-free probes, but it will break down if there is an error in the specification of the retrieval cue. There are possible ways of recovering from such errors, but they lead to the kind of combinatorial explosions which plague this kind of computer implementation .
But suppose that we imagine that each memory is represented by a unit which has mutually excitatory interactions with units standing for each of its properties. Then , whenever any property of the memory became active, the memory would tend to be activated, and whenever the memory was activated, all of its contents would tend to become activated. Such a scheme would automatically produce content addressability for us. Though it would not be immune to errors, it would not be devastated by an error in the probe if the remaining properties specified the correct memory .
As described thus far , whenever a property that is a part of a number of different memories is activated, it will tend to activate all of the memories it is in . To keep these other activities from swamping the "correct" memory unit , we simply need to add initial inhibitory connections among the memory units . An additional desirable feature would be mutually inhibitory interactions among mutually incompatible property units. For example, a person cannot both be single and married at the same time , so the units for different marital states would be mutually inhibitory .

1. THEAPPEOALFPOP 27

McClelland ( 1981) developed a simulation model that illustrates how a system with these properties would act as a content addressable memory. The model is obviously oversimplified , but it illustrates many of the characteristics of the more complex models that will be considered in later chapters.
Consider the information represented in Figure 10, which lists a number of people we might meet if we went to live in an unsavory neighborhood, and some of their hypothetical characteristics. A subset

.)~=.C)=~I.C)=~I.C}~=I.C}~=I.C}=~I.C}=IN.C}=~I.C}=~I.C}~=I.C}=~I.C}~=ICI

The Jets and The Sharks

Name

Gang Age
40 ' s 30 ' s 20 ' s 40 ' s 30 ' s 20 ' s 20 ' s 20 ' s 30 ' s 20 ' s 20 ' s 20 ' s 20 ' s 20 ' s 30 ' s

Edu Mar Occupation

Sing . Mar . Sing . Sing . Sing . Div . Mar . Mar . Sing . Mar . Div . Sing . Sing . Sing . Sing .
Mar . Sing . Sing . Mar . Mar . Mar . Sing . Mar . Div . Mar . Sing . Div .

Pusher
Burglar Bookie Bookie
Bookie
Burglar Pusher
Burglar Bookie
Burglar
Burglar Bookie Pusher
Pusher
Pusher
Pusher Bookie Pusher Burglar Bookie Bookie Burglar Burglar Burglar Pusher Bookie Pusher

FIGURE 10. Characteristicosf a numberof individualsbelongingto two gangs, the Jets and the Sharks. (From "Retrieving General and Specific KnowledgeFrom Stored Knowledgeof Specific'Sby J. L. McClelland, 1981, Proceedingosf theThirdAnnualConfe-r enceof theCognitiveScienceSociet,yBerkeley, CA. Copyright 1981by J. L. McClelland. Reprintedby permission.)

28 THEPOPERSPECTIVE
of the units needed to represent this information is shown in Figure 11. In this network , there is an " instance unit " for each of the characters described in Figure 10, and that unit is linked by mutually excitatory connections to all of the units for the fellow 's properties. Note that we have included property units for the names of the characters, as well as units for their other properties.
Now, suppose we wish to retrieve the properties of a particular indi vidual , say Lance. And supposethat we know Lance's name. Then we can probe the network by activating Lance's name unit , and we can see what pattern of activation arises as a result . Assuming that we know of no one else named Lance, we can expect the Lance name unit to be hooked up only to the instance unit for Lance. This will in turn activate the property units for Lance, thereby creating the pattern of
FIGURE 11. Someof the unitsand interconnectionsneededto representhe individuals shownin Figure10. The unitsconnectedwith double-headedarrowsaremutuallyexcitatory. All the units within the samecloud are mutually inhibitory. (From "Retrieving General and Specific ..KnowledgeFrom Stored Knowledge of Specific"s by J. L. McClelland, 1981, Proceedingosf the Third Annual Conferenceof the CognitiveScience Societ,yBerkeley, CA. Copyright1981by J. L. McClelland. Reprintedby permission.)

1. THEAPPEAOLFPOP 29

activation

corresponding

to Lance . In effect , we have retrieved

a

representation

of Lance . More will happen than just what we have

described so far , but for the moment let us stop here .

Of course , sometimes

we may wish to retrieve a name , given other

information

. In this case , we might start with some of Lance ' s

properties , effectively

asking the system , say " Who do you know who is

a Shark and in his 20s ?" by activating the Shark and 20s units . In this

case it turns out that there is a single individual , Ken , who fits the

description . So , when we activ.ate these two properties , we will activate the instance unit for Ken , and this in turn will activate his name unit ,

and fill in his other properties as well .

Graceful degradation . A few of the desirable properties of this kind

of model are visible from considering

what happens as we vary the set

of features we use to probe the memory in an attempt to retrieve a par -

ticular individual ' s name . Any set of features which is sufficient

to

uniquely characterize

a particular item will activate the instance node

for that item more strongly than any other instance node . A probe

which contains misleading

features will most strongly activate the node

that it matches best . This will clearly be a poorer cue than one which

contains no misleading

information

- but it will still be sufficient

to

activate the " right answer " more strongly than any other , as long as the

introduction

of misleading information

does not make the probe closer

to some other item . In general , though the degree of activation of a

particular instance node and of the corresponding

name nodes varies in

this model as a function of the exact content of the probe , errors in the

probe will not be fatal unless they make the probe point to the wrong

memory . This kind of model ' s handling of incomplete

or partial probes

also requires no special error - recovery scheme to work - it is a natural

by - product of the nature of the retrieval mechanism

that it is capable of

graceful degradation . These aspects of the behavior

of the Jets and Sharks model deserve

more detailed consideration

than the present space allows . One reason

we do not go into them is that we view this model as a stepping stone

in the development

of other models , such as the models using more

distributed

representations

, that occur in other parts of this book . We

do , however , have more to say about this simple model , for like some

of the other models we have already examined , this model exhibits

some . useful. properties cess1ng un1 ts .

which emerge from the interactions

of the pro -

Default assignment . It probably will have occurred to the reader that in many of the situations we have been examining , there will be other

30 THEPOPPERSPECTIVE
activations occurring which may influence the pattern of activation which is retrieved . So, in the casewhere we retrieved the properties of Lance, those properties, once they become active, can begin to activate the units for other individuals with those same properties. The memory unit for Lance will be in competition with these units and will tend to keep their activation down, but to the extent that they do become active, they will tend to activate their own properties and therefore fill them in . In this way, the model can fill in properties of individuals basedon what it knows about other , similar instances.
To illustrate how this might work we have simulated the case in which we do not know that Lance is a Burglar as opposed to a Bookie or a Pusher. It turns out that there are a group of individuals in the set who are very similar to Lance in many respects. When Lance's properties become activated, these other units become partially activated, and they start activating their properties. Since they all share the same "occupation," they work together to fill in that property for Lance. Of course, there is no reason why this should necessarily be the right answer, but generally speaking, the more similar two things are in respects that we know about, the more likely they are to be similar in respectsthat we do not , and the model implements this heuristic .
Spontaneous generalization . The model we have been describing has another valuable property as well - it tends to retrieve what is common to those memories which match a retrieval cue which is too general to capture anyone memory . Thus, for example, we could probe the system by activating the unit corresponding to membership in the Jets. This unit will partially activate all the instances of the Jets, thereby causing each to send activations to its properties. In this way the model can retrieve the typical values that the members of the Jets have on each dimension - even though there is no one Jet that has these typical values. In the example, 9 of 15 Jets are single, 9 of 15 are in their 20s, and 9 of 15 have only a Junior High School education~ when we probe by activating the Jet unit , all three of these properties dominate. The Jets are evenly divided between the three occupations, so each of these units becomes partially activated. Each has a different name, so that each name unit is very weakly activated, nearly cancelling each other out .
In the example just given of spontaneous generalization, it would not be unreasonable to suppose that someone might have explicitly stored a generalization about the members of a gang. The account just given would be an alternative to " explicit storage" of the generalization. It has two advantages, though , over such an account. First , it does not require any special generalization formation mechanism. Second, it can provide us with generalizations on unanticipated lines, on demand.

1. THEAPPEOAFLPDP 31
Thus, if we want to know , for example, what people in their 20s with a junior high school education are like , we can probe the model by activating these two units . Since all such people are Jets and Burglars, these two units are strongly activated by the model in this case; two of them are divorced and two are married , so both of these units are partially activated. 1
The sort of model we are considering, then , is considerably more than a content addressable memory . In addition , it performs default assignment, and it can spontaneously retrieve a general concept of the individuals that match any specifiable probe. These properties must be explicitly implemented as complicated computational extensions of other models of knowledge retrieval , but in POP models they are natural by-products of the retrieval processitself .
REPRESENATTION AND LEARNING IN PDPMODELS
In the Jets and Sharks model, we can speak of the model's active representationat a particular time , and associatethis with the pattern of activation over the units in the system. We can also ask: What is the stored knowledge that gives rise to that pattern of activation ? In considering this question, we see immediately an important difference between PDP models and other models of cognitive processes. In most models, knowledge is stored as a static copy of a pattern. Retrieval amounts to finding the pattern in long-term memory and copying it into a buffer or working memory . There is no real difference between the stored representation in long-term memory and the active representation in working memory . In POP models, though , this is not the case. In these models, the patterns themselves are not stored. Rather, what is stored is the connectionstrengthsbetween units that allow these patterns to be re-created. In the Jets and Sharks model, there is an instance unit assignedto each individual , but that unit does not contain a copy of the representation of that individual . Instead, it is simply the case that the connections between it and the other units in the system are such that activation of the unit will cause the pattern for the individual to be reinstated on the property units .

I In this and all other cases , there is a tendency

for the pattern of activation

to be innu -

enced by partially

activated , near neighbors

, which do not quite match the probe . Thus ,

in this case , there is a Jet AI , who is a Married

Burglar . The unit for AI gets slightly

activated , giving Married

a slight edge over Divorced

in the simulation

.

32 THEPOPPERSPECTIVE
This difference between PDP models and conventional models has
enormous implications , both for processing and for learning. We have already seen some of the implications for processing . The representa tion of the knowledge is set up in such a way that the knowledge necessarily influences the course of processing . Using knowledge in process ing is no longer a matter of finding the relevant information in memory and bringing it to bear ~ it is part and parcel of the processing itself .
For learning , the implications are equally profound . For if the knowledge is the strengths of the connections , learning must be a matter of finding the right connection strengths so that the right pat terns of activation will be produced under the right circumstances . This is an extremely important property of this class of models , for it opens up the possibility that an information processing mechanism could learn , as a result of tuning its connections , to capture the interdependencies between activations that it is exposed to in the course of processing .
In recent years , there has been Quite a lot of interest in learning in cognitive science . Computational approaches to learning fall predom inantly into what might be called the " explicit rule formulation " tradi tion , as represented by the work of Winston ( 1975) , the suggestions of Chomsky , and the ACT . model of J. R . Anderson ( 1983) . All of this work shares the assumption that the goal of learning is to formulate explicit rules (propositions , productions , etc .) which capture powerful generalizations in a succinct way . Fairly powerful mechanisms , usually with considerable innate knowledge about a domain, and/ or some starting set of primitive propositional representations , then formulate hypothetical general rules , e.g., by comparing particular cases and for mulating explicit generalizations .
The approach that we take in developing POP models is completely different . First , we do not assume that the goal of learning is the for mulation of explicit rules . Rather , we assume it is the acquisition of connection strengths which allow a network of simple units to act as though it knew the rules . Second , we do not attribute powerful compu tational capabilities to the learning mechanism . Rather , we assume very simple connection strength modulation mechanisms which adjust the strength of connections between units based on information locally available at the connection .
These issues will be addressed at length in later sections of this book . For now , our purpose is to give a simple , illustrative example of the connection strength modulation process , and how it can produce net works which exhibit some interesting behavior .
Local vs. distributed representation . Before we turn to an explicit consideration of this issue , we raise a basic question about

I. THEAPPEALOFPOP 33
representation. Once we have achieved the insight that the knowledge is stored in the strengths of the interconnections between units , a question arises. Is there any reason to assign one unit to each pattern that we wish to learn? Another possibility - one that we explore extensively in this book - is the possibility that the knowledge about any individual pattern is not stored in the connections of a special unit reserved for that pattern, but is distributed over the connections among a large number of processing units . On this view, the Jets and Sharks model represents a special case in which separate units are reserved for each instance.
Models in which connection information is explicitly thought of as distributed have been proposed by a number of investigators. The units in these collections may themselves correspond to conceptual primitives , or they may have no particular meaning as individuals . In either case, the focus shifts to patterns of activation over these units and to mechanisms whose explicit purpose is to learn the right connection strengths to allow the right patterns of activation to become activated under the right circumstances.
In the rest of this section, we will give a simple example of a POP model in which the knowledge is distributed . We will first explain how the model would work , given pre-existing connections, and we will then describe how it could come to acquire the right connection strengths through a very simple learning mechanism. A number of models which have taken this distributed approach have been discussedin this book's predecessor, Hinton and J. A . Anderson 's ( 1981) Parallel Models of Associative Memory. We will consider a simple version of a common type of distributed model, a pattern associato.r
Pattern associators are models in which a pattern of activation over one set of units can cause a pattern of activation over another set of units without any intervening units to stand for either pattern as a whole. Pattern associators would , for example, be capable of associating a pattern of activation on one set of units corresponding to the appearanceof an object with a pattern on another set corresponding to the aroma of the object, so that , when an object is presented visually, causing its visual pattern to become active, the model produces the pattern corresponding to its aroma.
How a pattern associator works. For purposes of illustration , we present a very simple pattern associator in Figure 12. In this model, there are four units in each of two pools. The first pool, the A units , will be the pool in which patterns corresponding to the sight of various objects might be represented. The second pool, the B units , will be the pool in which the pattern corresponding to the aroma will be represented. We can pretend that alternative patterns of activation on

34 THEPOPERSPECTIVE
From Vision
A Units
B Units
FIGURE 12. A simple pattern associator. The example assumes that patterns of activation in the A units can be produced by the visual system and patterns in the B units can be produced by the olfactory system. The synaptic connections allow the outputs of the A units to influence the activations of the B units. The synaptic weights linking the A units to the B units were selected so as to allow the pattern of activation shown on the A units to reproduce the pattern of activation shown on the B units without the need for any olfactory input .
the A units are produced upon viewing a rose or a grilled steak, and alternative patterns on the B units are produced upon sniffing the same objects. Figure 13 shows two pairs of patterns, as well as sets of inter connections necessaryto allow the A member of each pair to reproduce the B member.
The details of the behavior of the individual units vary among dif ferent versions of pattern associators. For present purposes, we' ll assume that the units can take on positive or negative activation values, with 0 representing a kind of neutral intermediate value. The strengths of the interconnections between the units can be positive or negative real numbers.
The effect of an A unit on a B unit is determined by multiplying the activation of the A unit times the strength of its synaptic connection with the B unit . For example, if the connection from a particular A unit to a particular B unit has a positive sign, when the A unit is

1. THEAPPEALOFPOP 35

+1 - 1 - 1 +1
- .25 +.25 +.25 - .25 - 1 - .25 +.25 +.25 - .25 - 1 +.25 - .25 - .25 +.25 + 1 +.25 - .25 - .25 +.25 + 1

- 1 +1 - 1 +1
-1 +1 +1 -1

FIGURE 13. Two simpleassociatorrsepresentedasmatrices. The weightsin the first two matricesallow the A patternshownabovethe matrix to producethe B patternshownto the right of it. Note that the weightsin the first matrix are the sameas thoseshownin the diagramin Figure12.

excited (activation greater than 0) , it will excite the B unit . For this example, we' ll simply assume that the activation of each unit is set to the sum of the excitatory and inhibitory effects operating on it . This is one of the simplest possible cases.
Suppose, now, that we have created on the A units the pattern corresponding to the first visual pattern shown in Figure 13, the rose. How should we arrange the strengths of the interconnections between the A units and the B units to reproduce the pattern corresponding to the aroma of a rose? We simply need to arrange for each A unit to tend to excite each B unit which has a positive activation in the aroma
pattern and to inhibit each B unit which has a negative activation in the aroma pattern. It turns out that this goal is achieved by setting the strength of the connection between a given A unit and a given B unit to a value proportional to the product of the activation of the two units . In Figure 12, the weights on the connections were chosen to allow the A pattern illustrated there to produce the illustrated B pattern according to this principle . The actual strengths of the connections were set to :::t: .25, rather than :t: 1, so that the A pattern will produce the right magnitude , as well as the right sign, for the activations of the units in the B pattern. The same connections are reproduced in matrix form in Figure 13A.
Pattern associators like the one in Figure 12 have a number of nice
properties. One is that they do not require a perfect copy of the input to produce the correct output , though its strength will be weaker in this case. For example, suppose that the associator shown in Figure 12 were presented with an A pattern of ( 1,- 1,0, 1) . This is the A pattern shown in the figure , with the activation of one of its elements set to O. The B pattern produced in response will have the activations of all of the B units in the right direction ; however, they will be somewhat weaker than they would be, had the complete A pattern been shown. Similar

36 THEPOPERSPECTIVE
effectsare producedif an elementof the patternis distorted- or if the model is damage,deither by removingwhole units, or randomsetsof connections, etc. Thus, their pattern retrieval performanceof the model degradesgracefully both under degraded input and under damage.
How a pattern associatorlearns. So far, we have seenhow we as model builderscan constructthe right set of weightsto allow one pattern to causeanother. The interestingthing, though, is that we do not need to build theseinterconnectionstrengthsin by hand. Instead, the pattern associatorcan teach itself the right set of interconnections through experienceprocessingthe patterns in conjunction with each other.
A number of different rules for adjustingconnectionstrengthshave beenproposed. Oneof the first- anddefinitely the bestknown- is due to D. O. Hebb (1949) . Hebb's actual proposalwas not sufficiently quantitativeto build into an explicit model. However, a numberof different variantscan tracetheir ancestrybackto Hebb. Perhapsthe simplest version is:
When unit A and unit B are simultaneouslyexcited, increase the strengthof the connectionbetweenthem.
A natural extension of this rule to cover the positive and negative activationvaluesallowedin our exampleis:
Adjust the strengthof the connectionbetweenunits A and B in proportionto the productof their simultaneousactivation.
In this formulation, if the product is positive, the changemakesthe connectionmore excitatory, and if the product is negative, the change makesthe connectionmore inhibitory. For simplicity of reference, we will call this the Hebb rule, although it is not exactly Hebb's original formulation.
With this simple learningrule, we could train a "blank copy" of the patternassociatorshownin Figure 12 to producethe 8 patternfor rose when the A pattern is shown, simply by presentingthe A and B patterns togetherandmodulatingthe connectionstrengthsaccordingto the Hebb rule. The size of the change made on every trial would, of course, be a paramete.r We generallyassumethat the changesmadeon eachinstanceare rather small, and that connectionstrengthsbuild up gradually. The valuesshownin Figure 13A, then, would be acquiredas a result of a numberof experienceswith the A and B patternpair.

1. THEAPPEOALFPDP 37
It is very important to note that the information needed to use the Hebb rule to determine the value each connection should have is locally available at the connection . All a given connection needs to consider is the activation of the units on both sides of it . Thus, it would be possible to actually implement such a connection modulation scheme locally, in each connection, without requiring any programmer to reach into each connection and set it to just the right value.
It turns out that the Hebb rule as stated here has some serious limi tations, and, to our knowledge, no theorists continue to use it in this simple form . More sophisticated connection modulation .schemeshave been proposed by other workers~ most important among these are the delta rule , discussed extensively in Chapters 8 and 11; the competitive learning rule, discussed in Chapter 5~ and the rules for learning in stochastic parallel models, described in Chapters 6 and 7. All of these learning rules have the property that they adjust the strengths of connections between units on the basis of information that can be assumed to be locally available to the unit . Learning , then , in all of these cases, amounts to a very simple process that can be implemented locally at each connection without the need for any overall supervision. Thus, models which incorporate these learning rules train themselves to have the right interconnections in the course of processing the members of an ensemble of patterns.
Learning multiple patterns in the same set of interconnections. Up to now, we have considered how we might teach our pattern associator to associate the visual pattern for one object with a pattern for the aroma of the same object. Obviously , different patterns of interconnections between the A and B units are appropriate for causing the visual pattern for a different object to give rise to the pattern for its aroma. The same principles apply, however, and if we presented our patterri associator with the A and B patterns for steak, it would learn the right set of interconnections for that case instead (these are shown in Figure 13B) . In fact, it turns out that we can actually teach the same pattern associator a number of different associations. The matrix representing the set of interconnections that would be learned if we taught the same pattern associator both the rose association and the steak association is shown in Figure 14. The reader can verify this by adding the two matrices for the individual patterns together. The reader can also verify that this set of connections will allow the rose A pattern to produce the rose B pattern, and the steak A pattern to produce the steak B pattern: when either input pattern is presented, the correct corresponding output is produced.
The examples used here have the property that the two different visual patterns are completely uncorrelated with each other . This being

+-38 THEPOPERSPECTIVE

-

+ +

-

+ +

+-

-

-+ +-

+-

-

+

+--

--
++
++ - -

FIGURE 14. The weightsin the third matrix allow either A patternshownin Figure 13 to recreatethe corresponding8 pattern. Eachweightin this caseis equalto the sum of the weightfor the A patternandthe weightfor the B pattern, asillustrated.

the case, the rose pattern produces no effect when the interconnections for the steak have been established, and the steak pattern produces no effect when the interconnections for the rose association are in effect .
For this reason, it is possible to add together the pattern of intercon nections for the rose association and the pattern for the steak association , and still be able to associatethe sight of the steak with the smell of a steak and the sight of a rose with the smell of a rose. The two sets of interconnections do not interact at all.
One of the limitations of the Hebbian learning rule is that it can learn the connection strengths appropriate to an entire ensemble of patterns only when all the patterns are completely uncorrelated. This restriction does not , however, apply to pattern associators which use more sophisticated learning schemes.
Attractive properties of pattern ass0ciator models. Pattern associator models have the property that uncorrelated patterns do not interact with each other , but more similar ones do. Thus, to the extent that a new pattern of activation on the A units is similar to one of the old ones, it will tend to have similar effects. Furthermore , if we assume that learning the interconnections occurs in small increments, similar patterns will essentially reinforce the strengths of the links they share in common with other patterns. Thus, if we present the same pair of patterns over and over, but each time we add a little random noise to each element of each member of the pair, the system will automatically learn to associate the central tendency of the two patterns and will learn to ignore the noise. What will be stored will be an average of the similar patterns with the slight variations removed. On the other hand, when we present the system with completely uncorrelated patterns, they will not interact with each other in this way. Thus, the same pool of units can extract the central tendency of each of a number of pairs of unrelated patterns. This aspect of distributed models is exploited extensively in Chapters 17 and 25 on distributed memory and amnesia.

_

'1. 11_1 11 I

.

~

-

III !

~

.~

-

1. THEAPPEOALFPOP 39
Extracting the structure of an ensemble of patterns . The fact that similar patterns tend to produce similar effects allows distributed models to exhibit a kind of spontaneous generalization, extending behavior appropriate for one pattern to other similar patterns. This property is shared by other PDP models, such as the word perception model and the Jets and Sharks model described above~the main differ ence here is in the existence of simple, local, learning mechanisms that can allow the acquisition of the connection strengths needed to produce these generalizations through experience with members of the ensemble of patterns. Distributed models have another interesting property as well: If there are regularities in the correspondences between pairs of patterns, the model will naturally extract these regularities. This property allows distributed models to acquire patterns of interconnections that lead them to behave in ways we ordinarily take as evidence for the use of linguistic rules.
A detailed example of such a model is described in Chapter 18. Here, we describe the model very briefly . The model is a mechanism that learns how to construct the past tenses of words from their root forms through repeated presentations of examples of root forms paired with the corresponding past-tense form . The model consists of two pools of units . In one pool, patterns of activation representing the phonological structure of the root form of the verb can be represented, and, in the other , patterns representing the phonological structure of the past tense can be represented. The goal of the model is simply to learn the right connection strengths between the root units and the past-tense units , so that whenever the root form of a verb is presented the model will construct the corresponding past-tense form . The model is trained by presenting the root form of the verb as a pattern of activation over the root units , and then using a simple, local, learning rule to adjust the connection strengths so that this root form will tend to produce the correct pattern of activation over the past-tense units . The model is tested by simply presenting the root form as a pattern of activation over the root units and examining the pattern of activation produced over the past-tense units .
The model is trained initially with a small number of verbs children learn early in the acquisition process. At this point in learning, it can only produce appropriate outputs for inputs that it has explicitly been shown. But as it learns more and more verbs, it exhibits two interesting behaviors. First , it produces the standard ed past tense when tested with pseudo-verbs or verbs it has never seen. Second, it " overregularizes" the past tense of irregular words it previously completed correctly . Often , the model will blend the irregular past tense of the word with the regular ed ending, and produce errors like CAMED as the past of

40 THEPOPPERSPECTIVE
COME . These phenomena mirror those observed in the early phases of acquisition of control over past tenses in young children .
The generativity of the child ' s responses - the creation of regular past tenses of new verbs and the overregularization of the irregular verbs - has been taken as strong evidence that the child has induced the rule which states that the regular correspondence for the past tense in English is to add a final ed (Berko , 1958) . On the evidence of its per formance , then , the model can be said to have acquired the rule . How ever , no special rule -induction mechanism is used , and no special language -acquisition device is required . The model learns to behave in accordance with the rule , not by explicitly noting that most words take ed in the past tense in English and storing this rule away explicitly , but simply by building up a set of connections in a pattern associator through a long series of simple learning experiences . The same mechanisms of parallel distributed processing and connection modi fica -. tion which are used in a number of domains serve , in this case , to pro duce implicit knowledge tantamount to a linguistic rule . The model also provides a fairly detailed account of a number of the specific aspects of the error patterns children make in learning the rule . In this sense, it provides a richer and more detailed description of the acquisi tion process than any that falls out naturally from the assumption that the child is building up a repertoire of explicit but inaccessible rules .
There is a lot more to be said about distributed models of learning , about their strengths and their weaknesses , than we have space for in this preliminary consideration . For now we hope mainly to have suggested that they provide dramatically different accounts of learning and acquisition than are offered by traditional models of these processes . We saw in earlier sections of this chapter that performance in accor dance with rules can emerge from the interactions of simple , intercon nected units . Now we can see how the aquisition of performance that conforms to linguistic rules can emerge from a simple , local , connec tion strength modulation process .
We have seen what the properties of POP models are in informal terms , and we have seen how these properties operate to make the models do many of the kinds of things that they do . The business of the next chapter is to layout these properties more formally , and to introduce some formal tools for their description and analysis . Before we turn to this , however , we wish to describe some of the major sources of inspiration for the POP approach .

1. THEAPPEAOLFPOP 41
ORIGINSOF PARALLEL DISTRIBUTEDPROCESSING
The ideas behind the PDP approach have a history that stretches back indefinitely . In this section, we mention briefly some of the people who have thought in these terms, particularly those whose work has had an impact on our own thinking . This section should not been seen as an authoritative review of the history , but only as a description of our own sources of inspiration .
Some of the earliest roots of the POP approach can be found in the work of the unique neurologists, Jackson ( 1869/ 1958) and Luria ( 1966) . Jackson was a forceful and persuasive critic of the simplistic localizationist doctrines of late nineteenth century neurology, and he argued convincingly for distributed , multilevel conceptions of processing systems. Luria , the Russian psychologist and neurologist, put for ward the notion of the dynamicfunctional system. On this view, every behavioral or cognitive process resulted from the coordination of a large number of different components, each roughly localized in different regions of the brain, but all working together in dynamic interaction . Neither Hughlings-Jackson nor Luria is noted for the clarity of his views, but we have seen in their ideas a rough characterization of the kind of parallel distributed processingsystem we envision .
Two other contributors to the deep background of POP were Hebb ( 1949) and Lashley ( 1950) . We already have noted Hebb's contribu tion of the H,ebb rule of synaptic modification ~ he also introduced the concept of cell assemblies- a concrete example of a limited form of distributed processing- and discussed the idea of reverberation of activation within neural networks. Hebb's ideas were cast more in the form of speculations about neural functioning than in the form of concrete processing models, but his thinking captures some of the flavor of parallel distributed processing mechanisms. Lashley's contribution was to insist upon the idea of distributed representation. Lashley may have been too ' radical and too vague, and his doctrine of equipotentiality of broad regions of cortex clearly overstated the case. Yet many of his insights into the difficulties of storing the "engram" locally in the brain are telling , and he seemed to capture quite precisely the essenceof distributed representation in insisting that "there are no special cells reserved for special memories" (Lashley, 1950, p. 500) .
In the 1950s, there were two major figures whose ideas have contri buted to the development of our approach. One was Rosenblatt ( 1959, 1962) and the other was Selfridge ( 1955) . In his Principles of Neurodynamics ( 1962) , Rosenblatt articulated clearly the promise of a neurally inspired approach to computation , and he developed the perceptron convergenceprocedure, an important advance over the Hebb rule for

42 THEPOPERSPECTIVE
changing synaptic connections . Rosenblatt ' s work was very controver sial at the time , and the specific models he proposed were not up to all the hopes he had for them . But his vision of the human information processing system as a dynamic, interactive , self-organizing system lies at the core of the POP approach. Selfridge's contribution was his insistence on the importance of interactive processing , and the develop ment of Pandemonium , an explicitly computational example of a dynamic , interactive mechanism applied to computational problems in perception .
In the late 60s and early 70s, serial processing and the von Neumann computer dominated both psychology and artificial intelligence , but there were a number of researchers who proposed neural mechanisms which capture much of the flavor of PDP models . Among these fig ures , the most influential in our work have been J . A . Anderson , Grossberg , and Longuet -Higgins . Grossberg ' s mathematical analysis of the properties of neural networks led him to many insights we have only come to appreciate through extensive experience with computer simulation , and he deserves credit for seeing the relevance of neurally inspired mechanisms in many areas of perception and memory well before the field was ready for these kinds of ideas (Grossberg , 1978) . Grossberg ( 1976) was also one of the first to analyze some of the properties of the competitive learning mechanism explored in Chapter 5. Anderson ' s work differs from Grossberg ' s in insisting upon distributed representation , and in showing the relevance of neurally inspired models for theories of concept learning (Anderson , 1973, 1977) ; the work in Chapters 17 and 25 on distributed memory and amnesia owes a great deal to Anderson ' s inspiration . Anderson ' s work also played a crucial role in the formulation of the cascade model (McClelland , 1979) , a step away from serial processing down the road to PDP . Longuet -Higgins and his group at Edinburgh were also pursu ing distributed memory models during the same period , and David Willshaw , a member of the Edinburgh group, provided some very elegant mathematical analyses of the properties of various distributed representation schemes (Willshaw , 1981) . His insights provide one of the sources of the idea of coarse coding described at length in Chapter 3. Many of the contributions of Anderson , Willshaw , and others distributed modelers may be found in Hinton and Anderson ( 1981) . Others who have made important contributions to learning in POP models include Amari ( 1977a) , Bienenstock , Cooper , and Munro ( 1982) , Fukushima ( 1975) , Kohonen ( 1977 , 1984) , and von der Malsburg ( 1973) .
Toward the middle of the 1970s, the idea of parallel processing began to have something of a renaissance in computational circles . We have already mentioned the Marr and Poggio ( 1976) model of stereoscopic

1. THEAPPEALOFPOP 43
depth perception . Another model from this period , the HEARSA Y model of speech understanding , played a prominent role in the development of our thinking . Unfortunately , HEARSAY ' s computa tional architecture was too demanding for the available computational resources , and so the model was not a computational success. But its basically parallel , interactive character inspired the interactive model of reading (Rumelhart , 1977) , and the interactive activation model of word recognition (McClelland & Rumelhart , 1981~ Rumelhart & McClelland , 1982) .
The ideas represented in the interactive activation model had other precursors as well . Morton ' s logogen model (Morton , 1969) was one of the first models to capture concretely the principle of interaction of dif ferent sources of information , and Marslen -Wilson (e.g., Marslen Wilson & Welsh , 1978) provided important empirical demonstrations of interaction between different levels of language processing . Levin ' s ( 1976) Proteus model demonstrated the virtues of activation competition mechanisms , and Glushko ( 1979) helped us see how con spiracies of partial activations could account for certain aspects of apparently rule -guided behavior .
Our work also owes a great deal to a number of colleagues who have been working on related ideas in recent years . Many of these col leagues appear as authors or coauthors of chapters in this book . But there are others as well . Several of these people have been very influential in the development of the ideas in this book . Feldman and Ballard ( 1982) laid out many of the computational principles of the POP approach (under the name of connectionism ) , and stressed the bio logical implausibility of most of the prevailing computational models in artificial intelligence . Hofstadter ( 1979, 1985) deserves credit for stressing the existence of a subcognitive - what we call microstructural - level , and pointing out how important it can be to delve into the microstructure to gain insight . A sand dune , he has said , is not a grain of sand . Others have contributed crucial technical insights . Sutton and Barto ( 1981) provided an insightful analysis of the connection modification scheme we call the delta rule and illustrated the
power of the rule to account for some of the subtler properties of classical conditioning . And Hopfield ' s ( 1982) contribution of the idea that network models can be seen as seeking minima in energy landscapes played a prominent role in the development of the Boltzmann machine (Chapter 7) , and in the crystallization of the ideas presented in Chapters 7 and 14 on harmony theory and schemata .
The power of parallel distributed processing is becoming more and more apparent , and many others have recently joined in the exploration of the capabilities of these mechanisms . We hope this book represents

44 THEPOPPERSPECTIVE
the nature of the enterprisewe areall involved in, and that it doesjustice to the potentialof the POPapproach.
ACKNOWLEDGMENTS
This researchwas supportedby Contract NOOO1-749-C-O323, NR 667-437 with the Personneland Training ResearchProgramsof the Office of Naval Researc,h by grants from the SystemDevelopment Foundation, and By a NIMH CareerDevelopmentAward (MHOO38)5 to the first author.

CHAP2TER
A General Framework for Parallel Distributed Processing D. E. RUMELHAR,TG. E. HINTON, andJ. L. McCLELLAND

In Chapter 1 and throughout this book, we describe a large number of models, each different in detail- each a variation on the parallel distributed processing (POP) idea. These various models, and indeed many in the literature , clearly have many features in common , but they are just as clearly distinct models. How can we characterize the general model of which these specific models are instances? In this chapter we propose a framework sufficiently general so that all of the various models discussed in the book and many models in the literature are special cases. We will proceed by first sketching the general framework and then by showing properties of certain specific realizations of the general model. 1
The GeneralFramework

It is useful

our

models

to

begin

and

then

with describe

an

analysis

the

various

of

the

various

components

specific

assumptions

of

we

can

1 We are , of course

, not the first

to attempt

class of models

. Kohonen

( 1977 , 1984 ) , Amari

are papers

with

similarly

general

aims .

a general

characterization

( 1977a ) , and Feldman

of this and Ballard

general ( 1982 )

46 THEPOPERSPECTIVE
make about these component.s There are eight major aspectsof a paralleldistributedprocessingmodel:
. A set of processingunits . A state of activation . An outputfunction for each uni t . A pattern of connectivityamong units . A propagation rule for propagating patterns of activities through
the network of connectivities . An activation rule for combining the inputs impinging on a unit
with the current state of that unit to produce a new level of activation for the unit . . A lear.ning rule whereby patterns of connectivity are modified by experIence . An environmentwithin which the system must operate
Figure 1 illustrates the basic aspectsof these systems. There is a set of processing units generally indicated by circles in our diagrams; at each point in time , each unit Ui has an activation value, denoted in the diagram as 0; (t ) ; this activation value is passedthrough a function I ; to produce an output value i (t ) . This output value can be seen as passing through a set of unidirectional connections (indicated by lines or arrows in our diagrams) to other units in the system. There is assoc-i ated with each connection a real number , usually called the weight or strength of the connection designated W}i which determines the amount of effect that the first unit has on the second. All of the inputs must then be combined by some operator (usually addition) - and the combined inputs to a unit , along with its current activation value, determine , via a function F, its new activation value. The figure shows illus trative examples of the function I and F. Finally , these systems are viewed as being plastic in the sense that the pattern of interconnections is not fixed for all time ; rather, the weights can undergo modification as a function of experience. In this way the system can evolve . What a unit represents can change with experience, and the system can come to perform in substantially different ways. In the following sections we develop an explicit notation for each of these components and describe some of the alternate assumptions that have been made concerning each such component .
A set of processingunits. Any parallelactivationmodel beginswith a set of processingunits. Specifyingthe set of processingunits and what they representis typically the first stage of specifyinga POP model. In somemodelstheseunits may representparticularconceptual objectssuch as features, letters, words, or concepts; in othersthey are

2. A FRAMEWORFKORPOP 47
G(I )t

1

/ } (o} )

0

.m

0

+m

Thr ~ hoId Output Function

a,MM0-m,=10(I)lj(lO) j
SigmoidActivation
Function

FIGUR1E. The basiccomponentsof a paralleldistributedprocessingsystem.

simply abstract elements over which meaningful patterns can be defined. When we speak of a distributed representation, we mean one in which the units represent small, feature-like entities. In this caseit is the pattern as a whole that is the meaningful level of analysis. This should be contrasted to a one-unit- one-conceptrepresentational system in which single units represent entire concepts or other large meaningful entities .
We let N be the number of units. We can order the units arbitrarily and designate the ith unit U; . All of the processing of a POP model is carried out by these units . There is no executive or other overseer. There are only relatively simple units , each doing it own relatively simple job . A unit 's job is simply to receive input from its neighbors and, as a function of the inputs it receives, to compute an output value which it sends to its neighbors. The system is inherently parallel in that many units can carry out their computations at the same time .

48 THEPOPPERSPECTIVE

Within

any

system

we

are

modeling

,

it

is

useful

to

characterize

three

types sources

of

units

external

:

input

,

output

,

and

to

the

system

hidden under

.

Input

units

study

.

These

receive inputs

inputs

may

be

from either

sensory which

input

the

model

or

inputs

is

embedded

from

other

.

The

parts output

of

the

processing

units

send

signals

system

in

out

of

the

system influence den tem

. units

They other are

may systems those

we

are

modeling

either

directly

external

whose

only

.

They

are

affect

to

the

ones

inputs

and

not

" visible

motoric

we

are

outputs

"

to

outside

systems modeling are

within

systems

or

simply

. The

hid

-

the

sys

-

.

The

state

of

activation

.

In

addition

,

to

the

set

of

units

,

we

need

a

representation

of

the

state

of

the

system

at

time

t.

This

is

primarily

specified

of

activation

tor

stands

by

a

vector

over

for

the

of

N

real

numbers

the

set

of

processing

activation

of

one

, a

(t ) ,

representing

units

.

Each

element

of

the

units

at

time

the

pattern

of

the

vec

-

t.

The

activa

-

tion

of

unit

Uj

at

time

t

is

designated

tion

over

the

set

of

units

that

captures

Qj

(t ) .

It

is

the

pattern

of

activa

-

what

the

system

is

representing

at

any

time

.

It

is

useful

to

see

processing

in

the

system

as

the

evolu

-

tion

,

through

Different

time models

,

of

a

pattern

make

different

of

activity

over

assumptions

the

set

about

of

units

the

. activation

values

a

unit

is

allowed

to

take

on

.

Activation

values

may

be

continu

-

ous bounded small

or

discrete

.

If

they

are

continuous

.

If

they

set

of

values

are .

discrete Thus

,

they

in

some

may models

,

they

may

take

binary

,

units

be

unbounded

values

or

any

are

continuous

or

of

a

and

may

take

on

any

real

number

as

an

activation

value

.

In

other

cases

,

they imum are

may such
restricted

take

on

any

as

,

for

example

to

discrete

real

value

between

,

the

interval

values

they

most

some

minimum

and

max

-

[0 , 1 ] .

When

activation

values

often

are

binary

.

Sometimes

they mean

are

restricted

that

the

unit

to

the

is

active

values and

0

and

1

where

0

is

taken

to

1

is

usually

taken

mean

that

it

is

inactive

to .

In

other

models

,

activation

values

are

restricted

( often

denoted

simply

{-

,+

}) .

Other

times

are

involved

.

Thus

,

for

example

,

they

may

to

the

nortbinary

be

restricted

values discrete

{-

l ,+

l}

values

to

the

set

{-

I , 0 ,+

I} ,

or

to

As

we

shall

see

a

small

.

each

finite of

set these

of

values

assumptions

such

as leads

{ I , 2 ,3 ,4 , 5 ,6 ,7 ,8 ,9 } .

to

a

model

with

slightly represented assumptions

different

characteristics

in

this

book

.

.

It

is

part

to

determine

the

of

the

implications

program

of

of

these

research various

Output of the units. Units interact. They do so by transmittingsignalsto their neighbors. The strengthof their signals, and thereforethe
degree to which they affect their neighbors, is determined by their degreeof activation. Associatedwith eachunit, u;, there is an output function, Ii (ai (1)) , which mapsthe current stateof activationOi(1) to

2. A FRAMEWORFKORPOP 49
an output signal 0; (t ) (i.e., 0; (t ) ~ I ; (a; (t ) . In vector notation , we represent the current set of output values by a vector, 0 (I ) . In some of our models the output level is exactly equal to the activation level of the unit . In this casef is the identity function f (x )~ x . More often , however, I is some sort of threshold function so that a unit has no affect on another unit unless its activation exceeds a certain value. Sometimes the function f is assumed to be a stochastic function in which the output of the unit depends in a probabilistic fashion on its activation values.
The pattern o/ connectivity. Units are connected to one another. It is this pattern of connectivity that constitutes what the system knows and determines how it will respond to any arbitrary input . Specifying the processing system and the knowledge encoded therein is, in a parallel distributed processing model , a matter of specifying this pattern of connectivity among the processingunits .
In many cases, we assume that each unit provides an additive contri bution to the input of the units to which it is connected. In such cases, the total input to the unit is simply the weighted sum of the separate inputs from each of the individual units . That is, the inputs from all of the incoming units are simply multiplied by a weight and summed to get the overall input to that unit . In this case, the total pattern of connectivity can be represented by merely specifying the weights for each of the connections in the system. A positive weight represents an excitatory input and a negative weight represents an inhibitory input . As mentioned in the previous chapter, it is often convenient to represent such a pattern of connectivity by a weight matrix W in which the entry
W;j represents the strength and sense of the connection from unit Uj to unit u; . The weight Wij is a positive number if unit Uj excites unit Ui; it is a negative number if unit Uj inhibits unit Ui~and it is 0 if unit Uj has no direct connection to unit Ui. The absolute value of Wij specifies the strength of the connection. Figure 2 illustrates the relationship between the connectivity and the weight matrix .
In the general case, however, we require rather more complex patterns of connectivity . A given unit may receive inputs of different kinds whose effects are separately summated. For example, in the previous paragraph we assumed that the excitatory and inhibitory connections simply summed algebraically with positive weights for excitation and negative weights for inhibition . Sometimes, more complex inhibition / excitation combination rules are required. In such casesit is convenient to have separateconnectivity matrices for each kind of connection. Thus, we can represent the pattern of connectivity by a set of connectivity matrices, Wi , one for each type of connection. It is common, for example, to have two types of connections in a model: an

uO'lelUaSaJda ~ X!J\BV-.j

50

THE POP PERSPECTIVE

-------_ .

- -- - - -- -

-------_ .

--------

-------_ .

--------

--------

--- -- ---

.

.

,

2 . A FRAMEWORFKORPOP 51
inhibitory connection and an excitatory connection. When the models assume simple addition of inhibition and excitation they do not constitute different typesof connections in our present sense. They only constitute distinct types when they combine through some more complex rules.
The pattern of connectivity is very important . It is this pattern which determines what each unit represents. As we shall see below, many of the issues concerning whether top-down or bottom-up processing systems are correct descriptions or whether a system is hierarchical and if so how many levels it haS, etc., are all issues of the nature of the connectivity matrix . One important issue that may determine both how much information can be stored and how much serial processing the network must perform is the fan -in and fan -out of a unit . The fan-in is the number of elements that either excite or inhibit a given unit . The fanout of a unit is the number of units affected directly by a unit . Note , in some caseswe need more general patterns of connectivity . Specifying such a pattern in the general case is complex and will be addressed in a later section of this chapter.
The rule of propagation . We also need a rule which takes the output vector, 0 (t ) , representing the output values of the units and combines it with the connectivity matrices to produce a net input for each type of
input into the unit . We let net}j be the net input of type ; to unit u} . Whenever only one type of connectivity is involved we suppress the first subscript and use net} to mean the net input into unit u} . In vector notation we can write netj (t ) to represent the net input vector for inputs of type i. The propagation rule is generally straightforward . For example, if we have two types of connections, inhibitory and excitatory , the net excitatory input is usually the weighted sum of the excitatory inputs to the unit . This is given by the vector product nete = WeO(t ) . Similarly , the net inhibitory effect can be written as netj = Wjo (t ) . When more complex patterns of connectivity are involved , more complex rules of propagation are required. We treat this in the final section 01:-the chapter.
Activation rule . We also need a rule whereby the net inputs of each type impinging on a particular unit are combined with one another and with the current state of the unit to produce a new state of activation .
We need a function , F , which takes a (1) and the vectors netj for each different type of connection and produces a new state of activation . In the simplest cases, when F is the identity function and when all connections are of the same type, we can write a (1+ 1) = Wo (1) = net (1) . Sometimes F is a threshold function so that the net input must exceed some value before contributing to the new state of activation . Often ,

52 THEPDPPERSPECTIVE
the new state of activation dependson the old one as well as the current input. In genera,l however, we have
a(t+ 1) ~ F (8 (t ),net (t ) 1,net (t )2,...) ~
the function F itself is what we call the activation rule . Usually , the function is assumed to be deterministic . Thus , for example , if a threshold is involved it may be that aj (t ) = 1 if the total input exceeds some threshold value and equals 0 otherwise . Other times it is assumed that F is stochastic . Sometimes activations are assumed to decay slowly with time so that even with no external input the activa tion of a unit will simply decay and not go directly to zero . Whenever a; (t ) is assumed to take on continuous values it is common to assume that F is a kind of sigmoid function . In this case, an individual unit can saturate and reach a minimum or maximum value of activation .
Perhaps the most common class of activations functions is the quasilinear activation function . In this case the activation function , F , is a nondecreasing function of a single type of input . In short ,
Qj(/+ 1) = F (netj(I )) = F (I . wjjoj). j
It is sometimesuseful to add the constraint that F be a differentiable function. We refer to differentiablequas-ilinear activationfunctions as semilineafrunctions (seeChapter8) .
ModifYing patterns of connectivity as a jilnction of experience. Changing the processing or knowledge structure in a parallel distributed processing model involves modifying the patterns of interconnectivity . In principle this can involve three kinds of modifications :
1. The developmentof newconnection.s 2. The lossof existingconnection.s 3. The modification of the strengthsof connectionsthat already
exist.
Very little work has been done on (1) and (2) above. To a first order of approximation , however, (1) and (2) can be considered a special case of (3) . Whenever we change the strength of connection away from zero to some positive or negative value, it has the same effect as growing a new connection. Whenever we change the strength of a connection to zero, that has the same effect as losing an existing connection . Thus, in this section we will concentrate on rules whereby strengthsof connections are modified through experience.

2. AFRAMEWFOORRPKDP 53

Virtually all learning rules for models of this type can be considered a variant of the Hebbian learning rule suggested by Hebb in his classic book Organization of Behavior ( 1949) . Hebb 's basic idea is this : If a
unit , Ui, receives a input from another unit , u} ; then , if both are highly active, the weight, W}i , from Uj to Ui should be strengthene.d This idea has been extended and modified so that it can be more generally stated
as

4 W;j ~ g (a; (1) ,1; (1 h (OJ(1) ,W;j ) ,

where ti (t ) is a kind of teaching input to Ui. Simply stated , this equa -
tion says that the change in the connection from Uj to Ui is given by the product of a function , gO , of the activation of Ui and its teaching input
ti and another function , hO , of the output value of Uj and the con nection strength Wij. In the simplest versions of Hebbian learning there is no teacher and the functions g and h are simply proportional to their first arguments . Thus we have

AW " = ' nQ . O '

~

I)

."

) ,

where 11 is the constant of proportionality representing the learning
rate . Another common variation is a rule in which h (OJ(t ) ,W;j ) = OJ(t ) and g (a; (t ) ,t; (t = '7) (t; (t )- a; (1 . This is often called the Widrow Hoff rule (Sutton & Barto , 1981) . However , we call it the delta rule because the amount of learning is proportional to the difference (or delta ) between the actual activation achieved and the target activation provided by a teacher . (The delta rule is discussed at length in Chapters 8 and 11.) In this case we have

~ W;j ~ 'r) (t; (t )- a; (t Oj (t ) .
This is a generalization of the perceptron learning rule for which the famous perception convergence theorem has been proved . Still another variation has

6 Wij ~ 7) Q; (I ) (OJ(/ )- Wij) .
This is a rule employed by Grossberg ( 1976) and a simple variant of which has been employed in Chapter 5. There are many variations on this generalized rule , and we will describe some of them in more detail when we discuss various specific models below .

Representation of the environment. It is crucial in the development
of any model to have a clear model of the environment in which this
model is to exist . In POP models , we represent the environment as a
time -varying stochastic function over the spaceof input patterns. That

54 THEPDPPERSPECTIVE
is, we imagine that at any point in time , there is some probability that any of the possible set of input patterns is impinging on the input units . This probability function may in general depend on the history of inputs to the system as well as outputs of the system. In practice, most PDP models involve a much simpler characterization of the environ ment . Typically , the environment is characterized by a stable probability distribution over the set of possible input patterns independent of past inputs and past responses of the system. In this case, we can imagine listing the set of possible inputs to the system and numbering them from 1 to M . The environment is then characterized by a set of probabilities , Pi for i = 1, . . . , M . Since each input pattern can be considered a vector, it is sometimes useful to characterize those patterns with nonzero probabilities as constituting orthogonal or linearly independent sets of vectors. 2 Certain PDP models are restricted in the kinds of patterns they are able to learn: some being able to learn to respond correctly only if the input vectors form an orthogonal set; others if they form a linearly independent set of vectors; and still others are able to learn to respond to essentially arbitrary patterns of inputs .
CLASSEOSFPDPMODELS
There are many paradigms and classesof POP models that have been developed. In this section we describe some general classesof assumptions and paradigms. In the following section we describe some specific PDP models and show their relationships to the general framework outlined here.
Paradigmsof Learning
Although most learning rules have roughly the form indicated above, we can categorize the learning situation into two distinct sorts. These are:
. Associative learning, in which we learn to produce a particular pattern of activation on one set of units whenever another particular pattern occurs on another set of units . In general, such a learning scheme must allow an arbitrary pattern on one set of
2 See Chapter 9 for explication of these terms .

2. AFRAMEWFOORRPKOP 55
units to produce another arbitrary pattern on another set of units.
. Regularity discovery, in which units learn to respond to " interesting " patterns in their input . In general, such a scheme should be able to form the basis for the development of feature detectors and therefore the basis for knowledge representation in a PD P system.
In certain cases these two modes of learning blend into one another, but it is valuable to see the different goals of the two kinds of learning. Associative learning is employed whenever we are concerned with storing patterns so that they can be re-evoked in the future . These rules are primarily concerned with storing the relationships among subpatterns. Regularity detectors are concerned with the meaning of a single units response. These kinds of rules are used when feature discoveryis the essential task at hand.
The associative learning case generally can be broken down into two subcases- pattern association and auto-association. A pattern association paradigm is one in which the goal is to build up an association between patterns defined over one subset of the units and other patterns defined over a second subset of units . The goal is to find a set of connections so that whenever a particular pattern reappearson the first set of units , the associatedpattern will appear on the second set. In this case, there is usually a teachinginput to the second set of units during training indi cating the desired pattern association. An auto-associationparadigm is one in which an input pattern is associatedwith itself . The goal here is pattern completion . Whenever a portion of the input pattern is presented, the remainder of the pattern is to be filled in or completed. This is similar to simple pattern association, except that the input pattern plays both the role of the teaching input and of the pattern to be associated. It can be seen that simple pattern association is a special case of auto-association. Figure 3 illustrates the two kinds of 'learning paradigms. Figure 3A shows the basic structure of the pattern association situation . There are two distinct groups of units - a set of input units and a set of output units . Each input unit connects with each output unit and each output unit receives an input from each input unit . During training , patterns are presented to both the input and output units . The weights connecting the input to the output units are modi fied during this period. During a test, patterns are presented to the input units and the response on the output units is measured. Figure 3B shows the connectivity matrix for the pattern associator. The only modifiable connections are from the input units to the output units . All other connections are fixed at zero. Figure 3C shows the ha.'\ic

2. AFRAMEWFOORPRKDP 57
potentially a modifiable connection from every unit to every other unit . In the case of pattern association, however, the units are broken into two subpatterns, one representing the input pattern and another representing the teaching input . The only modifiable connections are those from the input units to the output units receiving the teaching input . In other casesof associative learning the teaching input may be more or less indirect . The problem of dealing with indirect feedback is difficult , but central to the development of more sophisticated models of learning. Barto and Sutton ( 1981) have begun a nice analysis of such learning situations.
In the case of regularity detectors, a teaching input is not explicitly provided~instead, the teaching function is determined by the unit itself . The form of the internal teaching function and the nature of its input patterns determine what features the unit will learn to respond to. This is sometimes called unsupervised learning. Each different kind of unsupervised learning procedure has its own evaluation function . The particular evaluation procedures are mentioned when we treat these models. The three unsupervised learning models discussed in this book are addressedin Chapters 5, 6, and 7.
HierarchicalOrganizationsof PDP Networks
It has become commonplace in cognitive science to describe such processes as top-down, bottom-up, and interactive to consist of many stagesof processing, etc. It is useful to see how these concepts can be represented in terms of the patterns of connectivity in the PDP framework . It is also useful to get some feeling for the processing consequences of these various assumptions.
Bottom-Up Processing
The fundamental characteristic of a bottom -up system is that units at level i may not affect the activity of units at levels lower than i . To see how this maps onto the current formulation , it is useful to partition the coalitions of units into a set of discrete categories corresponding to the levels their inputs come from . There are assumed to be no coalitions with inputs from more than one level . Assume that there are Lj units at level i in the system. We then order the units such that those in level L 1 are numbered UI, . . . , ULI' those in level L 2 are numbered UL1+1, . . . , ULI+L2' etc. Then , the constraint that the system be a pure

58 THEPOPPERSPEcrIVE
bottom -up system is equivalent to the constraint that the connectivity matrix , W , has zero entries for Wij in which Uj is the member of a level no higher than U; . This amounts to the requirement that the upper right -hand region of W contains zero entries. Table 1 shows this constraint graphically. The table shows an example of a three-level system with four units at each level.3 This leads to a 12x 12connectivity matrix and an a vector of length 12. The matrix can be divided up into 9 regions. The upper-left region represents interactions among Levell units . The entries in the left -middle region of the matrix represents the effects of Level 1 units on Level 2 units . The lower-left region represents the effects of Levell uni ts on Level 3 units. Often bottom -up models do not allow units at level i effect units at level i + 2. Thus, in the diagram we have left that region empty representing no effect of Level 1 on Level 3. It is typical in a bottom -up system to assume as well that the lowest level units (Levell ) are input units and that the highest level units (Level 3) are output units . That is, the lowest level of the system is the only one to receive direct inputs from outside of this module and only the highest level units affect other units outside of this module .

TABLEt

Levell Input Units ul u2 u3 u4

Level 2 Hidden Units uS u6 u7 u8

Level 3
Output Units u9 ulO ull u12

ul

Levell

u2

Units u3

u4

uS level 2 u6 Units u7
u8

u9
Level 3 ul0 Units u 11
u12

within Levell effects
Levell affecting Level 2

within level 2 errects
Leve .l 2 affecting Level 3

within
Level 3 effects

3 In general , of course , we would expect many levels and many units at each level .

Top-Down Processing

2. A FRAMEWORFKORPOP 59

The generalization to a hierarchical top-down system should be clear enough. Let us order the units into levels just as before. A top-down model then requires that the lower-left regions of the weight matrix be empty - that is, no lower level unit affects a higher level unit . Table 2 illustrates a simple example of a top-down processing system. Note, in this case, we have to assume a top-down input or " message" that is propagated down the system from higher to lower levels as well as any data input that might be coming directly into Levell units .

Interactive Models

Interactive models are simply models in which there can be both
top-down and bottom -up connections. Again the generalization is straightforward . In the general interactive model, any of the cells of the weight matrix could be nonzero. The more restricted models in which information flows both ways, but in which information only flows between adjacent levels, assume only that the regions of the matrix more than one region away from the main diagonal are zero. Table 3 illustrates a simple three-level interactive model with both topdown and bottom -up input . Most of the models that actually have been
suggestedcount as interactive models in this sense.

TABLE2

Levell

Level 2

Level 3

Input Units HiddenUnits OutputUnits

ul u2 u3 u4 uS u6 u7 u8 u9 ulO ull u12

ul

Levell

u2

Units

u3

u4

uS

Level 2 u6

Units

u7

u8

u9
Level 3 ulO Units uII
u12

within Levell effects

Level 2 affecting Levell
within Level 2 effects

Level 3 affecting Level 2
within Level 3 effects

60 THEPOPERSPECTIVE

TABLE3

Levell

Level 2

Level 3

Input Units HiddenUnits OutputUnits

ul u2 u3 u4 u5 u6 u7 u8 u9 uIO uII u12

ul
Levell u2
Uni1s u3
u4
u5
Level 2 u6 Units u7
u8
u9 Level 3 ulO Units ull
u12

within level 1 effects
Levell affecting Level 2

Level 2 affecting Levell
within Level 2 effects
Level 2 affecting Level 3

Level 3 affecting Level 2
within level 3 errects

It is sometimes supposed that a " single level " system with no hierarchical structure in which any unit can communicate with any other unit is somehow less powerful than these multilevel hierarchical systems. The present analysis shows that , on the contrary, the existenceof levelsamounts to a restriction, in general, of free communication among all units . Such nonhierarchical systems actually form a superset of the kinds of layered systems discussed above. There is, however, something ~to the view that having multiple levels can increase the power of certain systems. In particular, a "one-step" system consisting of only input and output units and no communication between them in which there is no opportunity for feedback or for hidden units is less powerful than systems with hidden units and with feedback. Since, in general, hierarchical systems involve many hidden units , some intralevel communication , and some feedback among levels, they are more powerful than systems not involving such hidden units . However, a system with an equal number of hidden units , but one not characterizable as hierarchical by the communication patterns is, in general, of more potential computational power. We address the issue of hidden units and "single-step" versus " multiple -step" systems in our discussion of specific models below.

2. AFRAMEWFOORRPKOP 61
Synchronous Versus Asynchronous Update
Even given all of the components of the POP models we have described so far , there is still another important issue to be resolved in the development of specific models; that is the timing of the application of the activation rule . In some models, there is a kind of central timing pulse and after each such clock tick a new value is determined simul taneously for all units . This is a synchronousupdate procedure. It is usually viewed as a discrete, difference approximation to an underlying continuous , differential equation in which all units are continuously updated. In some models, however, units are updated asynchronously and at random. The usual assumption is that at each point in time each unit has a fixed probability of evaluating and applying its activation rule and updating its activation value. This later method has certain theoretical advantages and was developed by Hopfield (1982) and has been employed in Chapters 6, 7, and 14. The major advantage is that since the units are independently being updated, if we look at a short enough time interval , only one unit is updating at a time . Among other things, this system can help the stability of the network by keeping it out of oscillations that are more readily entered into with synchronous update procedures.
SPECIFICVERSIONSOF THE GENERALPARALLEL
ACTIVATION MODEL
In the following sections we will show how specification of the particular functions involved produces various kinds of these models. There have been many authors who have contributed to the field and whose work might as well have been discussed. We discuss only a representative sample of this work .
Simple Linear Models
Perhapsthe simplestmodel of this classis the simple linear model. In the simple linear model, activationvaluesare real numberswithout restriction. They can be either positive or negative and are not bounded. The output function, f (at) , in the linear model is just equal to the activationlevel at. Typically, linear modelsconsistof two setsof units: a set of input units and a set of output units. (As discussed

62 THEPOPERSPECTIVE
below , there is no need for hidden units since all computation possible with a multiple -step linear system can be done with a single -step linear system .) In general , any unit in the input layer may connect to any unit in the output layer . All connections in a linear model are of the same type . Thus , only a single connectivity matrix is required . The matrix consists of a set of positive , negative , and zero values , for excitatory values , inhibitory values , and zero connections , respectively . The new value of activation of each unit is simply given by the weighted sums of the inputs . For the simple linear model with connectivity matrix W we have
a (t + l ) = Wa (t ) .
In general , it can be shown that a linear model such as this has a number of limitations . In particular , it can be shown that nothing can be computed from two or more steps that cannot be computed by a single step . This follows because the above equation implies
a (t ) = W ' a (0) .
We can see this by proceeding step by step . Clearly ,
a (2) = Wa ( 1) = W ( Wa (0 = W 28 (0) .
It should be clear that similar arguments lead to a (t ) = W ' a (0) . From this , it follows that for every linear model with connectivity matrix W that can attain a particular state in t steps , there is another linear model with connectivity matrix W t that can reach the same state in one step . This means , among other things , that there can never be any computational advantage in a linear model of multiple -step systems , nor can there ever be any advantage for allowing feedback .
The pattern association paradigm is the typical learning situation for a linear model . There is a set of input units and a set of output units . In general , each input unit may be connected to any output unit . Since this is a linear network , there is no feedback in the system nor are there hidden units between the inputs and outputs . There are two sources of input in the system . There are the input patterns that estab lish a pattern of activation on the input units , and there are the teach ing units that establish a pattern of activation on the output units . Any of several learning rules could be employed with a linear network such as this , but the most common are the simple Hebbian rule and the d~lta rule . The linear model with the simple Hebbian rule is called the simple linear associator (cf . Anderson , 1970; Kohonen , 1977, 1984) . In this case, the increment in weight Wij is given by 4 wij = T) aj ti ' In matrix notation , this means that .6W ~ TITaT . The system is then tested by presenting an input pattern without a teaching input and

2. A FRAMEWORFKORPOP 63
seeing how close the pattern generated on the output layer matches the original teaching input . It can be shown that if the input patterns are orthogonal ,4 there will be no interference and the system will perfectly produce the relevant associatedpatterns exactly on the output layer. If they are not orthogonal , however, there will be interference among the input patterns. It is possible to make a modification in the learning rule and allow a much larger set of possible associations. In particular , it is possible to build up correct associations among patterns whenever the set of input patterns are linearly independent. To achieve this , an error correcting rule must be employed. The delta rule is most commonly employed. In this case, the rule becomes .6W;j = T) (t;- a; )aj . What is learned is essentially the difference between the desired response and that actually attained at unit u; due to the input . Although it may take many presentations of the input pattern set, if the patterns are linearly independent the system will eventually be able to produce the desired outputs. Kohonen ( 1977, 1984) has provided an important analysis of this and related learning rules.
The examples described above were for the case of the pattern associator. Essentially the same results hold for the auto-associator version of the linear model. In this case, the input patterns and the teaching patterns are the same, and the input layer and the output layer are also the same. The tests of the system involve presenting a portion of the input pattern and having the system attempt to reconstruct the missing parts.
Linear ThresholdUnits
The weaknessesof purely linear systemscan be overcomethrough the addition of nonlinearities. Perhapsthe simplest of the nonlinear system consists of a network of linear threshold units. The linear threshold unit is a binary unit whose activation takes on the values {O,l } . The activation value of unit Uj is 1 if the weightedsum of its inputs is greaterthan somethreshold(Jj and is 0 otherwise. The connectivity matrix for a network of such units, as in the linear system, is a matrix consistingof positiveandnegativenumbers. The output function, /, is the identity function so that the output of a unit is equal to its activationvalue.
4 SeeChapter 9 for a discussion of orthogonality , linear independence , etc.

64 THEPOPERSPECTIVE
It is useful to see some of the kinds of functions that can be computed with linear threshold units that cannot be computed with simple linear models. The classic such function is the exclusiveor (XOR ) illus trated in Figure 4. The idea is to have a system which responds { I } if it receives a {O,l } or a { I ,O} and responds to} otherwise. The figure shows a network capable of this pattern. In this case we require two
x 0 R Netwo rk

Output Unit

+1

+1

Internal Units

Thresholds=.01

+1

-1

+1

InpOututput

Input

Units

0101} 0

0110J 1
FIGURE4. A networkof linearthresholdunitscapabloef respondincgorrectlyon the XORproblem.

2. A FRAMEWORFKORPOP 65
layers of units . Each unit has a zero threshold and respondsjust in case its input is greater than zero. The weights are :t: 1. Since the set of stimulus patterns is not linearly independent, this is a discrimination that can never be made by a simple linear model and cannot be done in a single step by any network of linear threshold units .
Although multilayered systems of linear threshold units are very powerful and, in fact, are capable of computing any boolean function , there is no generally known learning algorithm for this general case (see Chapter 8) . There is, however, a well-understood learning algorithm for the special case of the perceptron. A perceptron is essentially a single-layer network of linear threshold units without feedback. The learning situation here is exactly the same as that for the linear model. An input pattern is presented along with a teaching input . The perceptroD learning rule is precisely of the same form as the delta rule for error correcting in the linear model, namely, 4. Wjj= 7) (tj- aj )aj . Since the teaching input and the activation values are only 0 or 1, the rule reduces to the statements that:
1. Weights are only changed on a given input line when that line is turned on (i.e., Qj = 1) .
2. If the system is correct on unit i (i .e., t; = a;) , make no change on any of the input weights.
3. If the unit j responds0 when it should be 1, increaseweights on all activelines by amount11.
4. If the unit j responds1 when it should be 0, decreaseweights on all activelines by amount1} .
There is a theorem , the perceptron convergence theorem , that guarantees that if the set of patterns are learnable by a perceptron, this learning procedure will find a set of weights which allow it to respond correctly to all input patterns. Unfortunately , even though multilayer linear threshold networks are potentially much more powerful than the linear associator, the perceptron for which a learning result exists can learn no patterns not learnable by the linear associator. It was the limi tations on what perceptrons could possibly learn that led to Minsky and Papert's (1969) pessimistic evaluation of the perceptron. Unfortunately that evaluation has incorrectly tainted more interesting and powerful networks of linear threshold and other nonlinear units . We have now developed a version of the delta rule - the generalized delta rule - which is capable of learning arbitrary mappings. It does not work for linear threshold units , but does work for the class of semilinear activation

66 THEPOPPERSPECTIVE
functions (i .e., differentiable activation functions ) . See Chapter 8 for a full discussion . As we shall see in the course of this book , the limita tions of the one -step perceptron in no way apply to the more complex
networks .
Brain State in a Box
The brain state in a box model was developed by J. A . Anderson ( 1977) . This model too is a close relative of the simple linear associator . There is , however , a maximum and minimum activation value associated with each unit . Typically , units take on activation values in the interval [- 1, 1] . The brain state in a box (BSB) models are organ ized so that any unit can, in general , be connected to any other unit . The auto-associator illustrated in Figure 3 is the typical learning paradigm for BSB. Note that with this pattern of interconnections the system feeds back on itself and thus the activation can recycle through the system in a positive feedback loop . The positive feedback is especially evident in J. A . Anderson and Mozer ' s ( 1981) version . Their activation rule is gi ven by
aj (t+ l ) = aj (t )+ Ew ;jaj (t )
if aj is less than 1 and greater than - 1. Otherwise , if the quantity is greater than 1, aj = 1 and if it is less than - 1, aj = - 1. That is , the activation state at time t + 1 is given by the sum of the state at time t and the activation propagated through the connectivity matrix provided that total is in the interval [- 1, 1] . Otherwise it simply takes on the maximum or minimum value . This formulation will lead the system to a state in which all of the units are at either a maximum or minimum value . It is possible to understand why this is called a brain state in a box model by considering a geometric representation of the system . Figure ' 5 illustrates the " activation space" of a simple BSB system con sisting of three units . Each point in the box corresponds to a particular value of activation on each of the three units . In this case we have a three -dimensional space in which the first coordinate corresponds to the activation value of the first unit , the second coordinate corresponds to the activation value of the second unit , and the third coordinate corresponds to the activation value of the third unit . Thus , each point in the space corresponds to a possible state of the system . The feature that each unit is limited to the region [- 1, 1] means that all points must lie somewhere within the box whose vertices are given by the points (- 1,- 1,- 1) , (- 1,- 1,+ 1) , (- 1,+ 1,- 1) , (- 1,+ 1,+ 1) , (+ 1,- 1,- 1) , (+ 1,- 1,+ 1) , (+ 1,+ 1,- 1) , and (+ 1,+ 1,+ 1) . Moreover , since the

2. AFRAMEWFOORRPKOP 67

(- ,- ,

( - ,+ ,+ )
11 I I

( + ,+ ,+ )

1(- .+,- )

~

-

Activation of Unit 2

.~t'J / ~
~~ / 0'
.~-(:t / .~~ I
~
~ /

/

(+,+,- )

(- ,- ,- )

,

,

~

Activation of Unit 1

FIGURE 5. The statespacefor a three-unit versionof a BSBmodel. Eachdimensionof the box representsthe activationvalue of one unit. Eachunit is boundedin activation between[- 1,1] . The curvingarrow in the box representsthe sequenceof statesthe system movedthrough. It beganat the blackspot nearthe middle of the box and, asprocessingproceede,dmovedto the (- ,+ ,+ ) cornerof the box. BSBsystemsalwaysendup in oneor anotherof the corners. The particularcornerdependson the start stateof the network, the input to the system, andthe patternof connectionsamongthe units.

systeminvolvespositivefeedback, it is eventuallyforcedto occupyone of these vertices. Thus, the state of the systemis constrainedto lie within the box and eventually, as processingcontinues, is pushedto one of the vertices. Of course, the samegeometricanalogycarriesover to higher dimensionalsystems. If there are N units, the state of the systemcanbe characterizedasa point within this N-dimensionalhypercubeand eventuallythe systemendsup in one of the 2N comersof the hypercube.

68 THEPOPERSPECfIVE
Learning in the BSB system involves auto-association. In different applications two different learning rules have been applied. J. A . Anderson and Mozer (1981) applied the simplest rule . They simply allowed the system to settle down and then employed the simple Hebbian learning rule . That is, 4 W;j = 11a;aj ' The error correction rule has also been applied to the BSB model . In this case we use the input as the teaching input as well as the source of activation to the system. The learning rule thus becomes4 W;j = "1(I;- a; )aj where t; is the input to .unit i and where Q; and Qj are the activation values of the system after it has stabilized in one of the corners of the hypercube.
Thermoldynamic Models
Other more recent developments are the thermodynamic models. Two examples of such models are presented in the book. One, harmony theory, was developed by Paul Smolensky and is described in detail in Chapter 6. The other , the Boltzmann machine, was developed by Hinton and Sejnowski and is described in Chapter 7. Here we describe the basic ,idea behind these models and show how they relate to the general class of models under discussion. To begin, the thermo dynamic models employ binary units which take on the values {O, I } . The units are divided into two categories: the visible units corresponding to our input and output units and the hidden units . In general, any unit may connect to any other unit . However, there is a constraint that the connections must be symmetric . That is, the Wlj= Wji . In these models, there is no distinction between the output of the unit and its activation value. The activation values are, however, a stochastic func -
tion of tphe(0i;n(p/u)=tsI.)T=ha-It +is,e-(Ij,W;j1O+"l;-j8;)/T
where 11; is the input from outside of system into unit i , 9; is the threshold for the unit , and T is a parameter, called temperature, which determines the slope of the probability function . Figure 6 shows how the probabilities vary with various values of T . It should be noted that as T approacheszero, the individual units become more and more like linear threshold units . In general, if the unit exceeds threshold by a great enough margin it will always attain value 1. If it is far enough below threshold , it always takes on value O. Whenever the unit is above threshold, the probability that it will turn on is greater than 1/ 2.

2. A FRAMEWORFKORPOP
Temperature =
I
0.0 I I 1__.J--t ---I- ~ - 25 - 20 - 15 - 10 - 5 0 5 10 15 20 Net Input
FIGURE 6. Probabilityof attainingvalue 1 as a function of the distanceof the input of the unit from threshold. The functionis plottedfor severalvaluesof T.
Whenever it is below threshold , the probability that it will turn off is greater than 1/ 2. The temperature simply determines the range of uncertainty as to whether it will turn on or off . This particular configuration of assumptions allows a formal analogy between these models and thermodynamics and allows the proof of theorems concerning its performance as a function of the temperature of the system. This is not the place to discuss these theorems in detail, suffice it to say that this system, like the BSB system, can be viewed as attaining states on the corners of a hypercube. There is a global measure of the degree to which each state of the system is consistent with its input . The system moves into those states that are maximally consistent with the input and with the internal constraints represented by the weights. It can be shown that as the temperature approaches0, the probability that the system attains the maximally consistent state approaches 1. These results are discussedin some detail in Chapters 6 and 7.
There is a learning scheme associated with the Boltzmann machine which is somewhat more complex than the others. In this case, the learning events are divided into two phases. During one phase, a set of patterns is randomly presented to the visible units and the system is allowed to respond to each in turn . During this phase of learning, the system is environmentally driven ; a simple Hebbian rule is assumed to

II

0N.

0~.

BUWL;1! WJ: 1

0~.

0.m

lilll - . -

..0..

70 THEPOPPERSPECTIVE

apply

so that d W ;j = 1) Q ; a j . Note , since

activations

take on values

of 0

and

1 this

says

that

the weight

is incremented

by an amount

1) when -

ever

unit

i and j are on , otherwise

no change

occurs

. During

the

second

phase

of learning

, the system

is allowed

to respond

for an equal

period

of time

in a so - called

free - running

state

in which

no inputs

are

presented

. Since

the system

is stochastic

, it will

continue

to respond

even

though

no actual

stimuli

are presented

. During

this phase , a sim -

ple anti - Hebbian

rule

is employed

, ~ Wjj = - ..,., ajaj .

roughly

that

the performance

during

the environmentally

is determined

by both

the

pattern

of interconnections

environment

. The

performance

during

the free - running

The

intuition

is

driven

phase

and

by the

phase

is deter -

mined

only

by the internal

set of connections

. To correctly

reflect

the

environment

, we should

look

at its performance

due

to the environ

-

ment

plus

to internal

internal structure

structure alone

and . This

then

subtract

is actually

out Quite

its performance a powerful

due learning

scheme

. It can be shown

that if a portion

of the input

units

are turned

on after of the

the system

visible

units

has learned

with

the

, it will probability

complete that

the those

remaining units

portion

had

been

present turned

in the stimulus

on . These

issues

patterns are again

given addressed

the subpattern in Chapter

that

had

been

7.

Grossberg

Stephen

Grossberg

of this

class

over

has been the years .

one of the major

contributors

His work

is complex

and

to models

contains

many

important descri be

details

some

of

which the central

we

cannot

aspects

review of his work

here . We and show

will how

instead it relates

to

the

general

framework

.

Perhaps

the

clearest

summary

of

Grossberg allowed

' s work

appears

in Grossberg

to take

on any real activation

( 1980 ) . Grossberg

' s units

are

value

between

a minimum

and a

maximum

value . The output

function

is , in many

of Grossberg

' s appli -

cations

, a threshold

function

so that a given

unit

will affect

another

unit

only

if its activation

level

is above

its threshold

. Moreover

, Grossberg

argues of the

that the activation

output value

function of the

must

be a sigmoid

or S - shaped

unit . Grossberg

' s activation

rule

function is rather

more

complex

than

the others

we have

discussed

thus

far in that

excita

-

tory

and inhibitory

inputs

don ' t simply

sum , but appear

the

activation

rule . Grossberg

has

presented

a number

separately

in

of possible

activation

rules , but they

typically

have

the form

2. AFRAMEWFOORPRKOP71

OJ ( / + I ) = OJ ( I ) ( I - A ) + ( B - oj ( /

nelej

( I ) - ( OJ ( / ) + C ) nel ;j ( I )

where

A

is the

decay

tion

of

represents

the

unit

, and

the

maximal

rate

, B

represents

the

maximal

degree

of excita

-

C

is much

amount

smaller

the

unit

in can

magnitude

be

inhibited

than

Band

below

the

resting

value

inputs

come

is embedded

from

another

Grossberg

of from
and level

O . Grossberg

generally

a kind

of recurrent

the

excitatory

inputs

of the

system

.

assumes

that

inhibitory

field

in

come

from

the

the which unit

inhibitory the
itself

unit and

has

studied

learning

in these

networks

over

a number

of

years

and

has

studied

several

different

rule

he

Chapter

has

studied

most

5 and

is gi ven

by

, however

learning , is similar

schemes

to

the

. The

learning

one

analyzed

in

. t1W '.1. = ' . n"Q . ( O 1' - W '.1. ) .

Grossberg

has

applied

cases present

, but

a review

discussion

.

this

and

similar

of

these

applications

learning

rules

is beyond

in the

a number

scope

of

of the

Interactive

Activation

Model

The

interactive

activation

model

of

McClelland

and

Rumelhart

( 1981

)

and

Rumelhart

and

McClelland

( 1982

)

had

units

which

represented

value

in

visual

the

range

features [ min

, letters

, max

] .

and

words

The

output

. Units function

could was

function

such

that

the

output

was

0

if

the

activation

threshold

and

was

equal

to

the

difference

of

the

activation

the

threshold

if the

activation

was

above

threshold

. The

take

on any

a threshold

was

below

value

and

interactive

activation

model

involves

a connectivity

pattern

in

which

units

are

organized

in layers

, such

that

an element

in a layer

connects

with

exci

-

tatory

connections

with

all elements

in the

layers

above

and

below

that

are

consistent

with

that

unit

, and

connects

negatively

to all units

in the

layers each unit

above

and

unit

inhibits

in

question

below

that

are

inconsistent

all units

in its own

layer

. Thus

, the

interactive

with

that

unit

that

are

inconsistent

activation

model

. In addition with
is a kind

, the
of

positive

feedback

system

with

maximum

and

minimum

values

for

each

unit

, like

weighted

the ( by

BSB

model

. The

the

interconnection

information strengths

coming

into

each

unit

is

) and

summed

algebraically

to yield

a " net

input

" to the

unit

. Let

netj

= I , wija

; be the

net

input

to

unit

j . This

net

input

is then

combined

with

the

previous

activation

72 THEPOPERSPECfIVE

value

to

activation

produce rule :

the new

activation

value

according

to the following

aj ( / + 1 ) = aj ( / ) ( 1 - 8 ) + I nentet : <. a( jmax( / ) -- majin ( I

noethljerwis>e 0

where

@ is the decay

rate of the activation

given

no input . In other

words

, the new

activation

value

is given

by the old activation

value

properly minimum

decayed

, plus

or maximum

( or value

minus

) a

depending

factor on

that

pushes

the magnitude

toward

the

of the net

input

into

the unit . This

activation

rule

is similar

to that

employed

by

Grossberg

, except

in this formulation

the excitation

and inhibition

are

algebraically

combined

.

The

interactive

activation

model

was designed

as a model

for a pro -

cessing specific

system aspects

and our of word

goals

were

perception

to show

how

. Thus , there

we could

account

for

was no specific

model

of learning assumed

proposed

came

from

to explain . As we shall

where

the

see , much

particular of the

work

network

we

on learning

reported

in this

book

has

how

such

a network

might

5 and 6 . )

been have

aimed

at giving

plausible

accounts

of

been

learned

. ( See especially

Chapters

Feldman

and

Ballard

Feldman

and

Ballard

( 1982 ) have

proposed

a framework

they

call

connectionist

modeling

. The

units

have

continuous

activation

values

,

which

they

call potential

which

[- 10 , 10 ] . Their

is allowed

to

output

take

on

function a small

can take is a kind
number

on any

value

of threshold of discrete

in the function integer

range which values

( O ~ Oi ~ 9 ) . They

with

a somewhat

have different

proposed activation

a number rule .

of Their

other

unit

simplest

types

each

unit

type

is

what

they

call the P - unit . In this case the activation

rule is given

by

aj ( t + 1 ) = aj ( t ) + f : Jnetj ( t ) .

Once

the activation

reaches

its maximum

or minimum

value

it is sim -

ply pinned

to that

value . Decay

is implemented

by self

inhibition

.

Feldman

and Ballard

also have

a cofljunctive

unit

similar

to our sigma - pi

units

described

below

. Feldman

( 1981 ) has also

considered

learning

.

In general available

, the within

approach

to

our

current

learning framework

offers .

more

machinery

In practice

, however

than ,

is the

learning discussed

rules .

actually

examined

are of the same

class we have

already

SIGMA-PI UNITS

2. AFRAMEWFOORRPKOP 73

Before completing our section on a general framework , it should be mentioned that we have sometimes found it useful to postulate units that are more complex than those described up to this point in this chapter. In our descriptions thus far, we have assumed a simple addi-
tive unit in which the net input to the unit is given by I . W;j a; . This is certainly the most common form in most of our models. Sometimes, however, we want multiplicative connections in which the output values of two (or possibly more) units are multiplied before entering into the sum. Such a multiplicative connection allows one unit to gate another. Thus, if one unit of a multiplicative pair is zero, the other member of the pair can have no effect , no matter how strong its output . On the other hand, if one unit of a pair has value 1, the output of the other is passed unchanged to the receiving unit . Figure 7 illustrates several such connections. In this case, the input to unit A is the weighted sum of the products of units Band C and units D and E. The pairs, BC and DE are called conjuncts. In this case we have conjuncts of size 2. In general, of course, the conjuncts could be of any size. We have no applications, however, which have required conjuncts larger than size 2. In general, then , we assume that the net input to a unit is given by the weighted sum of the products of a set of individual inputs. That is, the net input to a unit is given by I . w;~;II a;1a;2 . . . a;k where i indexes the conjuncts impinging on unit j and Uj1, Uj2, . . . , Ukj are the k units in the conjunct. We call units such as these sigma-pi units.
In addition to their use as gates, sigma-pi units can be used to convert the output level of a unit into a signal that acts like a weight connecting two units . Thus, assume we have the pattern of connections illustrated in the figure . Assume further that the weights on those connections are alII . In this case, we can use the output levels of units B and D to , in effect , set the weights from C to A and E to A respectively . Since, in general, it is the weights among the units that determine the behavior of the network , sigma-pi units allow for a dynamically programmable network in which the activation value of some units determine what another network can do.
In addition to its general usefulness in these cases, one might ask whether we might not sometime need still more complex patterns of interconnections. Interestingly , as described in Chapter 10, we will never be forced to develop any more complex interconnection type, since sigma-pi units are sufficient to mimic any function monotonic of its inputs.

74 THEPOPPERSPECTIVE
SigmaPi Units
A
neAt = IWiA1'1Coni
i
Con 1 - as . aC
Con2= aD ' aE
FIGURE 7. Two conjunctiveinputsto unit A from the conjunct8 and C and D and E. The input to unit A is the sumof the productof the outputsof units DCandDE.
CONCLUSION
We have provided a very general mathematical and conceptual framework within which we develop our models. This framework provides a language for expressing PDP models, and, though there is a lot of freedom within it , it is at least as constrained as most computational formalisms , such as production systems or high-level languagessuch as Lisp .
We must take note of the fact, however, that the framework does not specify all of the constraints we have imposed on ourselves in our model building efforts . For example, virtually any computing device, serial or parallel, can be described in the framework we have described here.

2. A FRAMEWORFKORPOP 75
There is a further set of considerations which has guided our particular formulations . These further considerations arise from two sources:
our beliefs about the nature of the hardware available for carrying out mental processesin the brain and our beliefs about the essential character of these mental processesthemselves. We discuss below the additional constraints on our model building which arise from these two beliefs.
. First , the operations in our models can be characterized as "neurally inspired." We wish to replace the "computer metaphor" as a model of mind with the " brain metaphor" as model of mind . This leads us to a number of considerations which further inform and constrain our model building efforts . Perhapsthe most crucial of these is time . Neurons are remarkably slow relative to components in modern computers. Neurons operate in the time scale of milliseconds whereas computer components operate in the time scale of nanoseconds- a factor of 106 faster. This means that human processesthat take on the order of a second or less can involve only a hundred or so time steps. Since most of the processeswe have studied- perception, memory retrieval , speech processing, sentence comprehension, and the like - take about a second or so, it makes sense to impose what Feldman ( 1985) calls the " 100step program" constraint. That is, we seek explanations for these mental phenomena which do not require more than about a hundred elementary sequential operations. Given that the processes we seek to characterize are often quite complex and may involve consideration of large numbers of simultaneous constraints, our algorithms must involve considerable parallelism. Thus, although a serial computer could be created out of the kinds of components represented by our units , such an implementation would surely violate the tOO-step program constraint for any but the simplest processes.
A second co~sideration differentiates our models from those inspired by the computer metaphor: that is, the constraint that all the knowledge is in the connection.s From conventional programmable computers we are used to thinking of knowledge as being stored in the state of certain units in the system. In our systems we assume that only very short term storage can occur in the states of units ; long term storage takes place in the connections among units . Indeed, it is the connections- or perhaps the rules for forming them through experience- which primarily differentiate one model from another. This is a profound difference between our approach and other more conventional approaches, for it means that almost all knowledge is implicit in the structure of the device that carries out the task rather than explicit in the states of units themselves. Knowledge is not directly accessible to interpretation by some separate processor, but it is built into the processor itself and directly determines the course of

76 THEpOPERSPECTIVE
processin.g It is acquiredthrough tuning of connectionsas theseare used in processin,g rather than formulated and stored as declarative facts.
In addition to thesetwo neurallyinspiredworkingassumption,sthere are a number of other constraintsthat derive rather directly from our understandingof the nature of neural information processin.g These assumptionsarediscussedmore fully in Chapter4.
The secondclass of constraintsarises from our beliefs about the nature of human information processingconsideredat a more abstrac,t computationallevel of analysis. We see the kinds of phenomenawe have beenstudyingas productsof a kind of constraintsatisfactionprocedurein which a very largenumber of constraintsact simultaneously to producethe behavior. Thus, we seemost behaviornot as the product of a single, separatecomponentof the cognitivesystem, but asthe productof largeset of interactingcomponents, eachmutuallyconstraining the others and contributing in its own way to the globally observable behaviorof the system. It is very difficult to useserialalgorithms to implementsucha conception, but very naturalto usehighly parallel ones. These problems can often be characterizedas best match or optimizationproblems. As Minsky and Papert(1969) havepointedout, it is very difficult to solvebestmatchproblemsserially. However, this is precisely the kind of problem that is readily implemented using highly parallel algorithms of the kind we consider in this book. See Kanerva (1984) for a discussionof the best match problem and its solution with parallelprocessingsystems.
To summarize, the POP framework consistsnot only of a formal language, but a perspectiveon our models. Other QualitativeandQuantitative considerationsarisingfrom our understandingof brain proces-s ing and of human behavior combinewith the formal systemto form what might be viewed as an aestheticfor our model building enterprises. The remainderof our book is largelya studyof this aestheticin practice.
ACKNOWLEDGMENTS
This research was supported by Contract NOOO14-79-C-O323, NR 667 -437 with the Personnel and Training Research Programs of the Office of Naval Research , by grants from the System Development Foundation , and by a NIMH Career Development Award (MHOO385 ) to the second author .

CHAP3TER
Distributed Representations
G. E. HINTON, J. L. McCLELLAN,DandD. E. RUMELHART
Given a network of simple computing elements and some entities to be represented, the most straightforward scheme is to use one comput ing element for each entity . This is called a local representation. It is easy to understand and easy to implement becausethe structure of the physical network mirrors the structure of the knowledge it contains. The naturalness and simplicity of this relationship between the knowledge and the hardware that implements it have led many people to simply assume that local representations are the best way to use parallel hardware. There are, of course, a wide variety of more compli cated implementations in which there is no one-to-one correspondence between concepts and hardware units , but these implementations are only worth considering if they lead to increased efficiency or to interesting emergent properties that cannot be conveniently achieved using local representations.
This chapter describes one type of representation that is less familiar and harder to think about than local representations. Each entity is represented by a pattern of activity distributed over many computing elements, and each computing element is involved in representing many different entities. The strength of this more complicated kind of representation does not lie in its notational convenience or its ease of implementation in a conventional computer , but rather in the efficiency with which it makes use of the processing abilities of networks of simple, neuron-like computing elements.

78 THEPOPPERSPECTIVE

Every

representational

uted

representations

scheme

are

no

exception

has

its

good

.

Some

and

bad

desirable

points

.

Distrib

-

properties

arise

very

naturally

Other

properties

trarv

~

associations

best

psychological

to

which

their

mind

.

from

the

use

of

patterns

of

activity

as

representations

.

, like ,. are

the

ability

much

to harder

temporarily

to

achieve

store

.

As

a large

set

we

shall

of see

arbi

-

, the

evidence

for

distributed

representations

is

the

degree

strengths

and

weaknesses

match

those

of

the

human

The

first

section

of

this

chapter

stresses

some

of

the

virtues

of

distributed

of

distributed

representations representations

.

The

second

,

and

section shows

considers clearly

the

efficiency

why

distributed

representations

lems

.

A

final

can

be

better

section

discusses

than

local

some

ones difficult

for

certain

issues

classes which

of

prob

-

are

often

avoided representation processing

by

advocates

of

of

constituent

effort

on

different

distributed structure
aspects

representations

and

the

of

a structured

,

such

as

sequential

focusing

object

.

the of

Disc

/ aimers

.

Before

examining

the

detailed

arguments

in

favor

of

distributed within

representations

an

overall

theory

, it

is

important

of

human

information

to

be

clear

processing

about

their

status

.

It

would

be

wrong tional

to

view

schemes

distributed like

semantic

representations networks

as

an

or

production

alternative

to systems

representa that

have

been

found

useful

is

more

fruitful

in

cognitive

to

view

them

psychology

as

one

way

and

artificial

of

implementing

intelligence these

.

It

more

abstract

schemes

in

parallel

networks

, but

with

one

proviso

:

Distri

b-

uted

representations

give

rise

to

some

powerful

and

unexpected

emer

-

gent

properties

.

These

properties

can

therefore

be

taken

as

primitives

when

working

in

a more

abstract

formalism

.

For

example

, distributed

representations

are

good

for

content

- addressable

memory

,

automatic

generalization situation

, and

the

selection

.

So

if

one

assumes

of

the

rule

that

best

fits

the

current

that

more

abstract

models

are

imple

-

mented sonable

in

the

to

treat

brain

using

abilities

distributed

like

content

representations - addressable

, it

is

not

unrea

-

memory

, automatic

generalization

operations

tions

in

,

or

the

selection

, even conventional

though

there computers

of

an

appropriate

rule

is

no

easy

.

Some

way

to

implement

of

the

emergent

as

primitive

these properties

opera

of

distributed

representations

are

not

easily

captured

in

higher

- level

malisms

.

For

example

, distributed

representations

are

consistent

the

simultaneous

application

of

a large

number

of

partially

fitting

to

the

relevant

current

.

We

situation shall

, each examine

rule these

being properties

applied

to

the

of

distributed

degree

that representa

for

-

with

rules

it

is

-

tions

in

the

chapter

on

schemata

( Chapter

14 ) . There

we

will

see

clearly

that

schemata

and

other

higher

- level

constructs

provide

only

approxi

-

mate

characterizations

of

mechanisms

which

rely

on

distributed

3. DISTRIBUTREEDP~RENATTIONS 79
representations. Thus, the contribution that an analysis of distributed representations can make to these higher-level formalisms is to legiti mize certain powerful , primitive operations which would otherwise appear to be an appeal to magic~ to enrich our repertoire of primitive operations beyond those which can conveniently be captured in many higher-level formalisms ; and to suggest that these higher-level formal isms may only capture the coarse features of the computational capabilities of the underlying processing mechanisms.
Another common source of confusion is the idea that distributed representations are somehow in conflict with the extensive evidence for localization of function in the brain (Luria , 1973) . A system that uses distributed representations still requires many different modul(;s for representing conipletely different kinds of thing at the same time . The distributed representations occur within these localized modules. For example, different modules would be devoted to things as different as mental images and sentence structures, but two different mental images would correspond to alternative patterns of activity in the same module . The representations advocated here are local at a global scale but global at a local scale.
VIRTUESOF DISTRIBUTEDREPRESENTATIONS
This section considers three important features of distributed representations: (a) their essentially constructive character; (b) their ability to generalize automatically to novel situations; and (c) their tunability to changing environments . Several of these virtues are shared by certain local models, such as the interactive activation model of word perception, or McClelland 's ( 1981) model of generalization and retrieval described in Chapter 1.
Memory as Inference
People have a very flexible way of accessingtheir memories: They can recall items from partial descriptions of their contents (Norman & Bobrow, 1979) . Moreover , they can do this even if some parts of the partial description are wrong. Many people, for example, can rapidly retrieve the item that satisfies the following partial description: It is an actor, it is intelligent , it is a politician . This kind of content-addressable memory is very useful and it is very hard to implement on a conventional computer because computers store each item at a particular

80 THEPOPERSPECTIVE
address , and to retrieve an item they must know its address . If all the combinations of descriptors that will be used for access are free of errors and are known in advance , it is possible to use a method called hash coding that Quickly yields the address of an item when given part of its content .- In general , however , content -addressable memory requires a massive search for the item that best fits the partial descrip tion . The central computational problem in memory is how to make this search efficient . When the cues can contain errors , this is very dif ficult because the failure to fit one of the cues cannot be used as a filter for Quickly eliminating inappropriate ans .'ers .
Distributed representations provide an efficient way of using parallel hardware to implement best -fit searches . The basic idea is fairly sim ple , though it is Quite unlike a conventional computer memory . Dif ferent items correspond to different patterns of activity over the very same group of hardware units . 1\ partial description is presented in the form of a partial activity pattern , activating some of the hardware units . 1 Interactions between the units then allow the set of active units to influence others of the units , thereby completing the pattern , and generating the item that best fits the description . A new item is "stored " by modifying the interactions between the hardware units so as to create a new stable pattern of activity . The main difference from a conventional computer memory is that patterns which are not active do not exist anywhere . They can be re-created because the connection strengths between units have been changed appropriately , but each con nection strength is involved in storing many patterns , so it is impossible to point to a particular place where the memory for a particular item is stored .
Many people are surprised when they understand that the connec tions between a set of simple processing units are capable of supporting a large number of different patterns . Illustrations of this aspect of dis tributed models are provided in a number of papers in the literature (e.g., Anderson , 1977~ Hinton , 1981a) ~ this property is illustrated in the model of memory and amnesia described in Chapters 17 and 25.
One way of thinking about distributed memories is in terms of a very large set of plausible inference rules . Each active unit represents a "microfeature " of an item , and the connection strengths stand for plau sible " microinferences " between microfeatures . Any particular pattern
1 This is eas.yif the p- artialdescriptionis simplya set of features, but it is much more difficult if the partialdescriptionmentionsrelationshipsto other objects. If, for example, the systemis askedto retrieveJohn's father, it must representJohn, but if Johnand his father are representedby mutually exclusivepatternsof activity in the very samegroup of units., it is hard to seehow this canbe done without preventingthe representationof John"s father. A distributedsolutionto this problemis describedin the text.

3. DISTRIBURTEEPDRESAnEONNTS 81
of activity of the units will satisfy some of the microinferences and violate others. A stable pattern of activity is one that violates the plausible microinferences less than any of the neighboring patterns. A new stable pattern can be created by changing the inference rules so that the new pattern violates them less than its neighbors. This view of memory makes it clear that there is no sharp distinction between genuine memory and plausible reconstruction . A genuine memory is a pattern that is stable becausethe inference rules were modified when it occurred before. A "confabulation " is a pattern that is stable becauseof the way the inference rules have been modified to store several dif ferent previous patterns. So far as the subject is concerned, this may be indistinguishable from the real thing .
The blurring of the distinction between veridical recall and confabulation or plausible reconstruction seems to be characteristic of human memory (Bartlett , 1932; Neisser, 1981) . The reconstructive nature of human memory is surprising only becauseit conflicts with the standard metaphors we use. We tend to think that a memory system should work by storing literal copies of items and then retrieving the stored copy, as in a filing cabinet or a typical computer database. Such systems are not naturally reconstructive.
If we view memory as a process that constructs a pattern of activity which represents the most plausible item that is consistent with the given cues, we need some guarantee that it will converge on the representation of the item that best fits the description, though it might be tolerable to sometimes get a good but not optimal fit . It is easy to imagine this happening, but it is harder to make it actually work . One recent approach to this problem is to use statistical mechanics to analyze the behavior of groups of interacting stochastic units . The analysis guaranteesthat the better an item fits the description, the more likely it is to be produced as the solution . This approach is described in Chapter 7, and a related approach is described in Chapter 6. An alternative approach, using units with continuous activations (Hopfield , 1984) is described in Chapter 14.
Similarity and Generalization
When a new item is stored, the modifications in the connection strengths must not wipe out existing items. This can be achieved by modifying a very large number of weights very slightly . If the modifi cations are all in the direction that helps the pattern that is being stored, there will be a conspiracy effect : The total help for the intended pattern will be the sum of all the small separatemodifications .

82 THEPOPERSPECTIVE

For unrelated patterns , however , there will be very little transfer of effect because some of the modifications will help and some will

hinder . Instead of all the small modifications conspiring together , they

will mainly cancel out . This kind of statistical reasoning underpins

most distributed memory models , but there are many variations of the

basic idea (See Hinton & Anderson , 1981 , for several examples ) .

It is possible to prevent interference altogether by using orthogonal

patterns of activity for the various items to be stored (a rudimentary

example of such a case is given in Chapter 1) . However , this elim -

inates one of the most interesting properties of distributed representa -

tions : They automatically give rise to generalizations . If the task is

simply to remember accurately a set of unrelated items , the generaliza tion effects are harmful and are called interference . But generalization

is normally a helpful phenomenon . It allows us to deal effectively with

situations that are similar but not identical to previously experienced

.

.

situations .

People are good at generalizing newly acquired knowledge . If you

learn a new fact about an object , your expectations about other similar

objects tend to change . If , for example , you learn that chimpanzees like

onions you will probably raise your estimate of the probability that

gorillas like onions . In a network that uses distributed representations , this kind of generalization is automatic . The new knowledge about chimpanzees is incorporated by modifying some of the connection

strengths so as to alter the causal effects of the distributed pattern of

activity that represents chimpanzees . 2 The modifications automatically

change the causal effects of all similar activity patterns . So if the

representation of gorillas is a similar activity pattern over the same set

of units , its causal effects will be changed in a similar way .

The very simplest distributed scheme would represent the concept of onion and the concept of chimpanzee by alternative activity patterns

over the very same set of units . It would then be hard to represent chimps and onions at the same time . This problem can be solved by

using separate modules for each possible role of an item within a larger

structure . Chimps , for example , are the " agent " of the liking and so a

pattern representing chimps occupies the " agent " module and the pat -

tern representing onions occupies the " patient " module (see Figure 1) .

2 The internal structure of this pattern may also change . There is always a choice between changing the weights on the outgoing connections and changing the pattern itself so that different outgoing connections become relevant . Changes in the pattern itself alter its similarity to other patterns and thereby alter how generalization will occur in the future . It is generally much harder to figure out how to change the pattern that represents an item than it is to figure out how to change the outgoing connections so that a particular pattern will have the desired effects on another part of the network .

3. DISTRIBUTERDEPR~ ENTAnONS 83
Each module can have alternative patterns for all the various items, so this scheme does not involve local representations of items. What is localized is the role.
If you subsequently learn that gibbons and orangutans do not like onions your estimate of the probability that gorillas like onions will fall , though it may still remain higher than it was initially . Obviously , the combination of facts suggests that liking onions is a peculiar quirk of chimpanzees. A system that uses distributed representations will automatically arrive at this conclusion, provided that the alternative patterns that represent the various apes are related to one another in a particular way that is somewhat more specific than just being similar to one another: There needs to be a part of each complete pattern that is identical for all the various apes. In other words, the group of units used for the distributed representations must be divided into two
RELATIONSHIP

AGENT

PATIENT
I I I

FIGURE 1. In this simplified schemethere are two different modules, one of which representsthe agentand the other the patien.t To incorporatethe fact that chimpanzees like onions, the patternfor chimpanzeeisn one modulemust be associatedwith the pattern for onions in the other module. Relationshipsother than "liking" can be implementedby havinga third groupof units whosepatternof activity representsthe relationship. This pattern must then "gate" the interactionsbetweenthe agent and patient groups. Hinton (1981)a describesone wayof doingthis gatingby usinga fourth groupof units.

84 THEPDPPERSPECTIVE
subgroups, and all the various apes must be represented by the same pattern in the first su~group, but by different patterns in the second subgroup. The pattern of activity over the first subgroup represents the type of the item , and the pattern over the second subgroup represents additional microfeatures that discriminate each instance of the type from the other instances. Note that any subset of the microfeatures can be considered to define a type. One subset might be common to all apes, and a different (but overlapping) subset might be common to all pets. This allows an item to be an instance of many different types simultaneously.
When the system learns a new fact about chimpanzees, it usually has no way of knowing whether the fact is true of all apes or is just a property of chimpanzees. The obvious strategy is therefore to modify the strengths of the connections emanating from all the active units , so that the new knowledge will be partly a property of apes in general and partly a property of whatever features distinguish chimps from other apes. If it is subsequently learned that other apes do not like onions, correcting modifications will be made so that the information about onions is no longer associatedwith the subpattern that is common to all apes. The knowledge about onions will then be restricted to the subpattern that distinguishes chimps from other apes. If it had turned out that gibbons and orangutans also liked onions, the modifications in the weights emanating from the subpattern representing apes would have reinforced one another, and the knowledge would have become assoc-i ated with the subpattern shared by all apes rather than with the patterns that distinguish one ape from another.
A very simple version of this theory of generalization has been implemented in a computer simulation (Hinton , 1981a) . Several applications that make use of this property can be found in Part IV of this book .
There is an obvious generalization of the idea that the representation of an item is composed of two parts, one that represents the type and another that represents the way in which this particular instance differs from others of the same type. Almost all types are themselves instances of more general types, and this can be implemented by divid ing the pattern that represents the type into two subpatterns, one for the more general type of which this type is an instance, and the other for the features that discriminate this particular type from others instances of the same general type. Thus the relation between a type and an instance can be implemented by the relationship between a set of units and a larger set that includes .it . Notice that the more general the type, the smaller the set of units used to encode it . As the number of terms in an intensional description gets smaller, the corresponding extensionalset gets larger.

3. DISTRIBUTERDEPRFSENATIONS 8S
In traditional semantic networks that use local representations , gen eralization is not a direct consequence of the representation . Given that chimpanzees like onions , the obvious way of incorporating the new knowledge is by changing the strengths of connections belonging to the chimpanzee unit . But this does not automatically change connections that belong to the gorilla unit . So extra processes must be invoked to implement generalization in a localist scheme . One commonly used method is to allow activation to spread from a local unit to other units that represent similar concepts (Collins & Loftus , 1975; Quillian , 1968) . Then when one concept unit is activated , it will partially activate its neighbors and so any knowledge stored in the connections emanating from these neighbors will be partially effective . There are many variations of this basic idea (Fahlman , 1979; Levin , 1976; McClelland , 1981) .
It is hard to make a clean distinction between systems that use local representations plus spreading activation and systems that use distrib uted representations . In both cases the result of activating a concept is that many different hardware units are active . The distinction almost completely disappears in some models such as McClelland ' s ( 1981) generalization model , where the properties of a concept are represented by a pattern of activation over feature units and where this pattern of activation is determined by the interactions of a potentially very large number of units for instances of the concept . The main difference is that in one case there is a particular individual hardware unit that acts as a " handle " which makes it easy to attach purely conventional proper ties like the .name of the concept and easier for the theorist who con structed the network to know what the individual parts of the network stand for .
If we construct our networks by hand -specifying the connections between the units in the network , a local representation scheme has some apparent advantages . First , it is easier to think ' one understands the behavior of a network if one has put in all the " knowledge " - all the connections - oneself . But if it is the entire , distributed pattern of interacting influences among the units in the network that is doing the work , this understanding can often be illusory . Second , it seems intui tively obvious that it is harder to attach an arbitrary name to a distrib uted pattern than it is to attach it to a single unit . What is intuitively harder , however , may not be more efficient . We will see that one can actually implement aribitrary associations with fewer units using distrib uted representations . Before we turn to such considerations , however , we examine a different advantage of distributed representations : They make it possible to create new concepts without allocating new
hardware .

86 THEPOPPERSPECTIVE
CreatingNew Concepts
Any plausible scheme for representing knowledge must be capable of learning novel concepts that could not be anticipated at the time the network was initially wired up. A scheme that uses local representations must first make a discrete decision about when to form a new concept, and then it must find a spare hardware unit that has suitable connections for implementing the concept involved . Finding such a unit may be difficult if we assume that, after a period of early development, new knowledge is incorporated by changing the strengths of the existing connections rather than by growing new ones. If each unit only has connections to a small fraction of the others, there will probably not be any units that are connected to just the right other ones to implement a new concept. For example, in a collection of a million units each connected at random to ten thousand others, the chance of there being any unit that is connected to a particular set of 6 others is only one in a million .
In an attempt to rescue local representations from this problem , several clever schemes have been proposed that use two classes of units . The units that correspond to concepts are not directly connected to one another. Instead, the connections are implemented by indirect pathways through several layers of intermediate units (Fahlman, 1980; Feldman, 1982) . This scheme works because the number of potential pathways through the intermediate layers far exceeds the total number of physical connections. If there are k layers of units , each of which has a fan-out of n connections to randomly selected units in the follow ing layer, there are nk potential pathways. There is almost certain to be a pathway connecting any two concept-units , and so the intermediate units along this pathway can be dedicated to connecting those two concept-units . However, these schemes end up having to dedicate several intermediate units to each effective connection, and once the dedication has occurred, all but one of the actual connections emanating from each intermediate unit are wasted. The use of several inter mediate units to create a single effective connection may be appropriate in switching networks containing elements that have units with relatively small fan-out , but it seems to be an inefficient way of using the hardware of the brain .
The problems of finding a unit to stand for a new concept and wiring it up appropriately do not arise if we use distributed representations. All we need to do is modify the interactions between units so as to create a new stable pattern of activity . If this is done by modifying a large number of connections very slightly , the creation of a new pattern need not disrupt the existing representations. The difficult problem is

3. DISTRIBUTERDEPRESEANTTIONS 87
to choose an appropriate pattern for the new concept. The effects of the new representation on representations in other parts of the system will be determined by the units that are active, and so it is important to use a collection of active units that have roughly the correct effects. Fine-tuning of the effects of the new pattern can be achieved by slightly altering the effects of the active units it contains, but it would be unwise to choose a random pattern for a new concept becausemajor changes would then be needed in the weights, and this would disrupt other knowledge. Ideally, the distributed representation that is chosen for a new concept should be the one that requires the least modification of weights to make the new pattern stable and to make it have the required effects on other representations.
Naturally , it is not necessaryto create a new stable pattern all in one step. It is possible for the pattern to emerge as a result of modifications on many separate occasions. This alleviates an awkward problem that arises with local representations: The system must make a discrete allor-none decision about when to create a new concept. If we view concepts as stable patterns, they are much less discrete in character. It is possible, for example, to differentiate one stable pattern into two closely related but different variants by modifying some of the weights slightly . Unless we are allowed to clone the hardware units (and all their connections) , this kind of gradual, conceptual differentiation is much harder to achieve with local representations.
One of the central problems in the development of the theory of distributed representation is the problem of specifying the exact procedures by which distributed representations are to be learned. All such procedures involve connection strength modulation , following "learning rules" of the type outlined in Chapter 2. Not all the problems have been solved, but significant progress is being made on these problems. (See the chapters in Part II .)
DISTRIBUTEDREPRESENTATIONTSHAT WORKEFFICIENTLY
In this section, we consider some of the technical details about the implementation of distributed representations. First , we point out that certain distributed representation schemes can fail to provide a suffi cient basis for differentiating different concepts, and we point out what is required to avoid this limitation . Then , we describe a way of using distributed representations to get the most information possible out of a simple network of connected units . The central result is a surprising one: If you want to encode features accurately using as few units as

88 THEPOPERSPECTIVE
possible , it pays to use units that are very coarsely tuned , so that each feature activates many different units and each unit is activated by many different features . A specific feature is then encoded by a pattern of activity in many units rather than by a single active unit , so coarse coding is a form of distributed representation .
To keep the analysis simple , we shall assume that the units have only two values , on and off .3 We shall also ignore the dynamics of the system because the question of interest , for the time being , is how many units it takes to encode features with a given accuracy . We start by considering the kind of feature that can be completely specified by giv ing a type (e.g., line -segment , corner , dot ) and the values of some continuous parameters that distinguish it from other features of the same type (e.g., position , orientation , size .) For each type of feature there is a space of possible instances . Each continuous parameter defines a dimension of the feature space, and each particular feature corresponds to a point in the space. For features like dots in a plane , the space of possible features is two -dimensional . For features like stopped , oriented edge-segments in three -dimensional space, the feature space is six -dimensional . We shall start by considering two dimensional feature spaces and then generalize to higher dimensionali ties .
Suppose that we wish to represent the position of a single dot in a plane , and we wish to achieve high accuracy without using too many units . We define the accuracy of an encoding scheme to be the number of different encodings that are generated as the dot is moved a standard distance through the space. One encoding scheme would be to divide the units into an X group and a Y group , and dedicate each unit to encoding a particular X or Y interval as shown in Figure .2. A given dot would then be encoded by activity in two units , one from each group , and the accuracy would be proportional to the number of units used . Unfortunately , there are two problems with this . First , if two dots have to be encoded at the same time , the method breaks down . The two dots will activate two units in each group , and there will be no way of telling , from the active units , whether the dots were at (x 1, y 1) and (x2 , y2 ) or at (x 1, y2 ) and (x2 , y 1) . This is called the binding prob lem. It arises because the representation does not specify what goes with what .
3 Similar argumentsapplywith multivaluedactivity levels, but it' is important not to allowactivitylevelsto havearbitraryprecisionbecausethis makesit possibleto represent an infinite amountof informationin a singleactivity level. Units that transmita discrete impulsewith a probabilitythat variesas a function of their activationseemto approx-i matethe kind of precisionthat is possiblein neuralcircuitry (seeChapters20and21).

3. DISTRIBURTEEPD~RENATTIONS89
.
Ygroup

X group

Y group

0

1

.

0

0

1

.

0

0

0

00100010

X group

FIGURE 2. A: A simplewayof usingtwo groupsof binaryunitsto encodethe position of a point in a two-dimensionalspace. The activeunits in the X and Y groupsrepresent the x- and y-coordinate.s B: When two pointsmust be encodedat the sametime, it is impossibleto tell whichx-coordinategoeswith whichy-coordinate.

The second problem arises even if we allow only one point to be represented at a time . Suppose we want certain representations to be associated with an overt response, but not others: We want (x 1, y 1) and (x2 , y2 ) to be associated with a response, but not (xl , y2 ) or (x 2, y 1) . We cannot implement this association using standard weighted connections to response units from units standing for the values on the two dimensions separately. For the unit for x 1 and the unit for x2 would both have to activate the response, and the unit for

